Repository,Number,Body,class,Title,Combined_Text
incubator-mxnet,9216,"## Description
1. BatchNorm loses a little precision
2. the output_var in BatchNorm may be wrong

## Environment Info
OS: Arch Linux 4.14.8
MXNet: 1.0.0 and 1.0.1 (the latest version, CPU version)

## Build Config
make -j8 USE_OPENCV=1 USE_BLAS=openblas
***

Hi, there.

I converted [ResNet Model on Caffe](https://github.com/KaimingHe/deep-residual-networks) to [ResNet model on MXNet](https://github.com/wkcn/resnet-v1-mx).

And I found that the output results between Caffe and MXNet are different.

The reason is that the computations of Caffe and MXNet are different.

For the BatchNorm in Caffe, the output is .

For the BatchNorm in MXNet, the output is , and .

I think the method in MXNet will **lose a little precision** but bring the **higher performance** (Reduce the times of division).

At the same time, I found that the  in BatchNorm may be wrong. 

The  is **invstd**, namely the multiplicative inverse of the standard deviation. I think it should be the variance.

## Steps to reproduce

Here is [my testing code](https://github.com/wkcn/test_mxnet_bn).

I compare three outputs:

- numpy (compute manally)
- caffe
- mxnet



The first column is the , and the second column is the .

# What I have tried to solve it

I change the BatchNorm implement in MXNet, and the output is below:



The modified BatchNorm(cpu) code is [here](https://github.com/wkcn/incubator-mxnet/commit/5ecd4882bc043cf059e962f7ce488270bafa07c7).
",1,Loss of Precision in BatchNorm and output_var may be wrong,"Loss of Precision in BatchNorm and output_var may be wrong ## Description
1. BatchNorm loses a little precision
2. the output_var in BatchNorm may be wrong

## Environment Info
OS: Arch Linux 4.14.8
MXNet: 1.0.0 and 1.0.1 (the latest version, CPU version)

## Build Config
make -j8 USE_OPENCV=1 USE_BLAS=openblas
***

Hi, there.

I converted [ResNet Model on Caffe](https://github.com/KaimingHe/deep-residual-networks) to [ResNet model on MXNet](https://github.com/wkcn/resnet-v1-mx).

And I found that the output results between Caffe and MXNet are different.

The reason is that the computations of Caffe and MXNet are different.

For the BatchNorm in Caffe, the output is .

For the BatchNorm in MXNet, the output is , and .

I think the method in MXNet will **lose a little precision** but bring the **higher performance** (Reduce the times of division).

At the same time, I found that the  in BatchNorm may be wrong. 

The  is **invstd**, namely the multiplicative inverse of the standard deviation. I think it should be the variance.

## Steps to reproduce

Here is [my testing code](https://github.com/wkcn/test_mxnet_bn).

I compare three outputs:

- numpy (compute manally)
- caffe
- mxnet



The first column is the , and the second column is the .

# What I have tried to solve it

I change the BatchNorm implement in MXNet, and the output is below:



The modified BatchNorm(cpu) code is [here](https://github.com/wkcn/incubator-mxnet/commit/5ecd4882bc043cf059e962f7ce488270bafa07c7).
"
incubator-mxnet,10881,"We are using mx.sym.dot() operator in Keras heavily. We observe CPU performance is suspiciously slower. On profiling a RNN LSTM example, the observation is as shown below.

dot() operator  is contributing to 90% of computation time. Is there any performance implication of mx.sym.dot() operator on CPU? 

We are using mxnet-mkl-dnn build, is the operator using gemm operations under the hood?
 
![image](https://user-images.githubusercontent.com/3403674/39853665-655d9708-53d8-11e8-8f34-58de7cbafd0e.png)

@anirudh2290 @zheng-da - Any suggestions / comments?",1,mx.sym.dot() performance on CPU,"mx.sym.dot() performance on CPU We are using mx.sym.dot() operator in Keras heavily. We observe CPU performance is suspiciously slower. On profiling a RNN LSTM example, the observation is as shown below.

dot() operator  is contributing to 90% of computation time. Is there any performance implication of mx.sym.dot() operator on CPU? 

We are using mxnet-mkl-dnn build, is the operator using gemm operations under the hood?
 
![image](https://user-images.githubusercontent.com/3403674/39853665-655d9708-53d8-11e8-8f34-58de7cbafd0e.png)

@anirudh2290 @zheng-da - Any suggestions / comments?"
incubator-mxnet,10368,"The train part cost 0.01 second, but the asscalar operation cost a few seconds sometimes more than 10. I install the newest version of mxnet by pip, and this was happened with cpu and gpu context both.
Does anyone have any idea for fixing this? Thank you very much.
`",1,asscalar is very slow,"asscalar is very slow The train part cost 0.01 second, but the asscalar operation cost a few seconds sometimes more than 10. I install the newest version of mxnet by pip, and this was happened with cpu and gpu context both.
Does anyone have any idea for fixing this? Thank you very much.
`"
incubator-mxnet,3591,"I have quite a deep net trained on 4 gpus which all works fine.

But when I try and run predict it is very very slow. only 1-cpu is doing anything (out of 16) and the GPUs are doing nothing. Looks like the model is loaded in gpu memory and actually I think it was never unloaded after training. Not sure if that should happen automatically or not.

How do I force the predict to run on GPU?
",1,In R prediction is running only on CPU very sow,"In R prediction is running only on CPU very sow I have quite a deep net trained on 4 gpus which all works fine.

But when I try and run predict it is very very slow. only 1-cpu is doing anything (out of 16) and the GPUs are doing nothing. Looks like the model is loaded in gpu memory and actually I think it was never unloaded after training. Not sure if that should happen automatically or not.

How do I force the predict to run on GPU?
"
incubator-mxnet,13449,"It seems https://github.com/apache/incubator-mxnet/pull/12380 causes significant performance regression in SpMV. It causes about 3 times slow down on p3.16x. The main reason is that the PR causes a small number of omp threads to perform computation.

Here is the minimal code for reproducing the bug. It seems the problem occurs only when a model is initialized with multiple GPUs.

use the code below to run the code.


The csr file can be downloaded from


",1,significant performance regression in SpMV,"significant performance regression in SpMV It seems https://github.com/apache/incubator-mxnet/pull/12380 causes significant performance regression in SpMV. It causes about 3 times slow down on p3.16x. The main reason is that the PR causes a small number of omp threads to perform computation.

Here is the minimal code for reproducing the bug. It seems the problem occurs only when a model is initialized with multiple GPUs.

use the code below to run the code.


The csr file can be downloaded from


"
incubator-mxnet,7820,"I have changed a model which called pvanet from caffe [https://github.com/sanghoon/pva-faster-rcnn](https://github.com/sanghoon/pva-faster-rcnn), it is a implementation of the article by the author [https://arxiv.org/abs/1608.08021](https://arxiv.org/abs/1608.08021), my problem is why my accuracy is low than author's
What I have done:
1 Implement the classification net: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py)
2 feed the classification to Faster R-CNN module: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py)
Most job I have done is to atapt Faster-R-CNN,  replace the vgg pre-trained model with pvanet pre-trained model, for details see #7786 
Firstly the classification net pvanet's accuracy is 64.0%(70.6% as article)
Secondly detection net (pvanet+rpn+rcnn)'s mAP is 59.37%(82.5% as article)
I checked my net structure carefully to make it the same as author's implementation in caffe, is there anything I do wrong?  ",1,Low accuracy of pvanet,"Low accuracy of pvanet I have changed a model which called pvanet from caffe [https://github.com/sanghoon/pva-faster-rcnn](https://github.com/sanghoon/pva-faster-rcnn), it is a implementation of the article by the author [https://arxiv.org/abs/1608.08021](https://arxiv.org/abs/1608.08021), my problem is why my accuracy is low than author's
What I have done:
1 Implement the classification net: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py)
2 feed the classification to Faster R-CNN module: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py)
Most job I have done is to atapt Faster-R-CNN,  replace the vgg pre-trained model with pvanet pre-trained model, for details see #7786 
Firstly the classification net pvanet's accuracy is 64.0%(70.6% as article)
Secondly detection net (pvanet+rpn+rcnn)'s mAP is 59.37%(82.5% as article)
I checked my net structure carefully to make it the same as author's implementation in caffe, is there anything I do wrong?  "
incubator-mxnet,269,"Hi，
I use Alexnet.py in /example/imagenet to training with the configure unchanged,but after 20 rounds ,the accuracy is only 0.438870,much worse than the result shown in the docs(81%).
the dataset is from imagenet.
I wonder where this difference comes from.
Any help?
Thx.
",1,About training accuracy,"About training accuracy Hi，
I use Alexnet.py in /example/imagenet to training with the configure unchanged,but after 20 rounds ,the accuracy is only 0.438870,much worse than the result shown in the docs(81%).
the dataset is from imagenet.
I wonder where this difference comes from.
Any help?
Thx.
"
incubator-mxnet,13454,"## Description

The PR (#11001) introduced a checked in SymbolBlock.imports that makes the loading of large graph takes very long time (it used to be instantaneous):

The issue is the code checking if any symbol is row_sparse, removing this check allows to load large model instantaneously again.

## Environment info (Required)

----------Python Info----------
Version      : 3.6.5
Compiler     : GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)
Build        : ('default', 'Jun 17 2018 12:26:58')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 18.0
Directory    : /usr/local/lib/python3.6/site-packages/pip
----------MXNet Info-----------
/usr/local/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24) or chardet (3.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
Version      : 1.3.0
Directory    : /usr/local/lib/python3.6/site-packages/mxnet
Commit Hash   : b3be92f4a48bce62a5a8424271871c2f81c8f7f1
----------System Info----------
Platform     : Darwin-16.7.0-x86_64-i386-64bit
system       : Darwin
node         : 186590d6796f.ant.amazon.com
release      : 16.7.0
version      : Darwin Kernel Version 16.7.0: Wed Oct 10 20:06:00 PDT 2018; root:xnu-3789.73.24~1/RELEASE_X86_64
----------Hardware Info----------
machine      : x86_64
processor    : i386
b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT FPU_CSDS'
b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
b'machdep.cpu.brand_string: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz'
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0543 sec, LOAD: 1.2793 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0628 sec, LOAD: 0.9555 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0802 sec, LOAD: 0.8386 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0073 sec, LOAD: 1.2169 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0521 sec, LOAD: 1.1819 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0419 sec, LOAD: 0.3027 sec.



## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. download model attached and script to load it
[model-loading-issue.zip](https://github.com/apache/incubator-mxnet/files/2629332/model-loading-issue.zip)
2. python slow_model_loading.py

## What have you tried to solve it?

1. comment check that symbol is row_sparse
",1,Model loading became very slow after #11001,"Model loading became very slow after #11001 ## Description

The PR (#11001) introduced a checked in SymbolBlock.imports that makes the loading of large graph takes very long time (it used to be instantaneous):

The issue is the code checking if any symbol is row_sparse, removing this check allows to load large model instantaneously again.

## Environment info (Required)

----------Python Info----------
Version      : 3.6.5
Compiler     : GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)
Build        : ('default', 'Jun 17 2018 12:26:58')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 18.0
Directory    : /usr/local/lib/python3.6/site-packages/pip
----------MXNet Info-----------
/usr/local/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24) or chardet (3.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
Version      : 1.3.0
Directory    : /usr/local/lib/python3.6/site-packages/mxnet
Commit Hash   : b3be92f4a48bce62a5a8424271871c2f81c8f7f1
----------System Info----------
Platform     : Darwin-16.7.0-x86_64-i386-64bit
system       : Darwin
node         : 186590d6796f.ant.amazon.com
release      : 16.7.0
version      : Darwin Kernel Version 16.7.0: Wed Oct 10 20:06:00 PDT 2018; root:xnu-3789.73.24~1/RELEASE_X86_64
----------Hardware Info----------
machine      : x86_64
processor    : i386
b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT FPU_CSDS'
b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
b'machdep.cpu.brand_string: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz'
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0543 sec, LOAD: 1.2793 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0628 sec, LOAD: 0.9555 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0802 sec, LOAD: 0.8386 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0073 sec, LOAD: 1.2169 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0521 sec, LOAD: 1.1819 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0419 sec, LOAD: 0.3027 sec.



## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. download model attached and script to load it
[model-loading-issue.zip](https://github.com/apache/incubator-mxnet/files/2629332/model-loading-issue.zip)
2. python slow_model_loading.py

## What have you tried to solve it?

1. comment check that symbol is row_sparse
"
incubator-mxnet,8335,"I've been testing MXNet on both Win10 and Ubuntu 16.04 in a long time. I found that the performance of Windows is lower than Linux by 15%-20% on both GPU and CPU contexts. So I wonder what makes the performance gap and I hope someone can solve this problem. My config is like following:
MXNet on Ubuntu:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with Makefile
MXNet on Windows:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with CMake",1,Performance of MXNet on Windows  is lower than that on Linux by 15%-20%,"Performance of MXNet on Windows  is lower than that on Linux by 15%-20% I've been testing MXNet on both Win10 and Ubuntu 16.04 in a long time. I found that the performance of Windows is lower than Linux by 15%-20% on both GPU and CPU contexts. So I wonder what makes the performance gap and I hope someone can solve this problem. My config is like following:
MXNet on Ubuntu:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with Makefile
MXNet on Windows:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with CMake"
incubator-mxnet,11919,"## Description
I trained same SqueezeNet model with same hyper-parameters and dataset on p3.8xlarge and p3.16xlarge with same AMI but got ~3% lower accuracies on p3.16xlarge. I used same batch size per GPU but effective batch size is 2x in p3.16xlarge due to 2x number of GPUs.

## Environment info (Required)

p3.8xlarge


p3.16xlarge


Package used: Python

## Minimum reproducible example
Used model definition and training script from GluonCV - https://gluon-cv.mxnet.io/build/examples_classification/dive_deep_imagenet.html#sphx-glr-build-examples-classification-dive-deep-imagenet-py

## Steps to reproduce

1. p3.8xlarge - 

2. p3.16xlarge - 
",1,Accuracy changes with number of GPUs,"Accuracy changes with number of GPUs ## Description
I trained same SqueezeNet model with same hyper-parameters and dataset on p3.8xlarge and p3.16xlarge with same AMI but got ~3% lower accuracies on p3.16xlarge. I used same batch size per GPU but effective batch size is 2x in p3.16xlarge due to 2x number of GPUs.

## Environment info (Required)

p3.8xlarge


p3.16xlarge


Package used: Python

## Minimum reproducible example
Used model definition and training script from GluonCV - https://gluon-cv.mxnet.io/build/examples_classification/dive_deep_imagenet.html#sphx-glr-build-examples-classification-dive-deep-imagenet-py

## Steps to reproduce

1. p3.8xlarge - 

2. p3.16xlarge - 
"
incubator-mxnet,913,"Hi, I test on my Ubuntu 14.04 GTX 970

2015-12-13 18:43:42,924 Node[0] Start training with [gpu(0)]
2015-12-13 18:44:41,062 Node[0] Iter[0] Batch [50]      Speed: 395.17 samples/sec
2015-12-13 18:44:57,556 Node[0] Iter[0] Batch [100]     Speed: 388.03 samples/sec
2015-12-13 18:45:14,045 Node[0] Iter[0] Batch [150]     Speed: 388.13 samples/sec
2015-12-13 18:45:30,548 Node[0] Iter[0] Batch [200]     Speed: 387.82 samples/sec

It said the GTX 980 is about 842 img/sec. It's nearly about 2x difference. Any ideas?
",1,Speed has 2x difference between GTX 970 & GTX 980,"Speed has 2x difference between GTX 970 & GTX 980 Hi, I test on my Ubuntu 14.04 GTX 970

2015-12-13 18:43:42,924 Node[0] Start training with [gpu(0)]
2015-12-13 18:44:41,062 Node[0] Iter[0] Batch [50]      Speed: 395.17 samples/sec
2015-12-13 18:44:57,556 Node[0] Iter[0] Batch [100]     Speed: 388.03 samples/sec
2015-12-13 18:45:14,045 Node[0] Iter[0] Batch [150]     Speed: 388.13 samples/sec
2015-12-13 18:45:30,548 Node[0] Iter[0] Batch [200]     Speed: 387.82 samples/sec

It said the GTX 980 is about 842 img/sec. It's nearly about 2x difference. Any ideas?
"
incubator-mxnet,6802,"The cross-entropy loss for classification task is somehow periodic during iteration, and the period is exactly an epoch of iterations of data set. The loss is lowest at the end of every epoch and  increases rapidly(relatively) at the beginning of the next epoch....   
This phenomenon appears in different networks training on different data sets in my experiments , so I think there might be something wrong with my training procedure rather than the model or data sets. Some potential mistake I probably made:
the use of metric
the use of dataIter
the use of optimizer

anyone have encountered similar problem?

here are my codes:

 

",1,Periodic loss value,"Periodic loss value The cross-entropy loss for classification task is somehow periodic during iteration, and the period is exactly an epoch of iterations of data set. The loss is lowest at the end of every epoch and  increases rapidly(relatively) at the beginning of the next epoch....   
This phenomenon appears in different networks training on different data sets in my experiments , so I think there might be something wrong with my training procedure rather than the model or data sets. Some potential mistake I probably made:
the use of metric
the use of dataIter
the use of optimizer

anyone have encountered similar problem?

here are my codes:

 

"
incubator-mxnet,8978,"## Description
Pretrained models dont seem to be working well with gluon, specifically datasets build with Dataloader and ImageRecords or ImageFolders.

As an example, here I load the ImageNet validation dataset and feed it into alexnet downloaded from gluon model zoo



The 12% accuracy shows the issue is probably that the transforms used to train the model dont exactly align with the transforms presented in the Gluon tutorial. It would be nice if an example showing how to properly do this using the new gluon functions were added.

## Environment info (Required)
Python 3.6",1,Very Low Accuracy When Using Pretrained Model,"Very Low Accuracy When Using Pretrained Model ## Description
Pretrained models dont seem to be working well with gluon, specifically datasets build with Dataloader and ImageRecords or ImageFolders.

As an example, here I load the ImageNet validation dataset and feed it into alexnet downloaded from gluon model zoo



The 12% accuracy shows the issue is probably that the transforms used to train the model dont exactly align with the transforms presented in the Gluon tutorial. It would be nice if an example showing how to properly do this using the new gluon functions were added.

## Environment info (Required)
Python 3.6"
incubator-mxnet,13593,"MXNet has low CPU usage when running CPU operations in multiple process scenarios. Specifically, for MXNet computation in a subprocess, MxNet can use only 1 or 2 CPUs to do its job. This issue shows different behavior for different variants of MxNet (see below) and on different machines ...

This issue is critical because it slows down the multiprocess object-detection data-loading in gluoncv very significantly, making Faster-RCNN training in gluoncv unusable.

This is tested on the 20181207 version, and other versions (e.g., 1.3.1) show similar problems. 

Code to reproduce the issue

Filename: 


Detailed experiments:

- Run in the main process:

![image](https://user-images.githubusercontent.com/7865903/49704337-a3807000-fbc6-11e8-9118-0c7034e52cf9.png)
Working fine for all mxnet variants (GPU or CPU-only).

- Run in two subproceses
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704395-420cd100-fbc7-11e8-9607-a0c907b2057a.png)
It uses only 2 CPUs per subprocess.
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704444-14745780-fbc8-11e8-8754-81b90af4f876.png)
Same here. It uses only 2 CPUs per subprocess.
--  on **CPU-only machine c5.18x**:

![image](https://user-images.githubusercontent.com/7865903/49704457-3d94e800-fbc8-11e8-8831-9136465fad1f.png)
**Even worse.** It uses only 1.5 CPUs per subprocess.
-- However, for vanilla CPU-version  on c5.18x:

![image](https://user-images.githubusercontent.com/7865903/49704510-e2afc080-fbc8-11e8-8548-2505a7070205.png)
It is working better. At least, it uses 5 CPUs per subprocess.
-- Weirdly, still vanilla CPU-version  but on **GPU machine p3.16x**:

![image](https://user-images.githubusercontent.com/7865903/49704532-1a1e6d00-fbc9-11e8-8009-95519fd9f1ef.png)
It is working worse, i.e., 2 CPUs per subprocesses.
- This problem seems relevant to how MXNet manage the thread per subprocess. If I do not  in the main process and instead  in each subprocess:

![image](https://user-images.githubusercontent.com/7865903/49704599-d11ae880-fbc9-11e8-8460-e7d1e53abb13.png)
Then everything is working fine. 
",1,Low CPU usage of MXNet in subprocesses,"Low CPU usage of MXNet in subprocesses MXNet has low CPU usage when running CPU operations in multiple process scenarios. Specifically, for MXNet computation in a subprocess, MxNet can use only 1 or 2 CPUs to do its job. This issue shows different behavior for different variants of MxNet (see below) and on different machines ...

This issue is critical because it slows down the multiprocess object-detection data-loading in gluoncv very significantly, making Faster-RCNN training in gluoncv unusable.

This is tested on the 20181207 version, and other versions (e.g., 1.3.1) show similar problems. 

Code to reproduce the issue

Filename: 


Detailed experiments:

- Run in the main process:

![image](https://user-images.githubusercontent.com/7865903/49704337-a3807000-fbc6-11e8-9118-0c7034e52cf9.png)
Working fine for all mxnet variants (GPU or CPU-only).

- Run in two subproceses
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704395-420cd100-fbc7-11e8-9607-a0c907b2057a.png)
It uses only 2 CPUs per subprocess.
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704444-14745780-fbc8-11e8-8754-81b90af4f876.png)
Same here. It uses only 2 CPUs per subprocess.
--  on **CPU-only machine c5.18x**:

![image](https://user-images.githubusercontent.com/7865903/49704457-3d94e800-fbc8-11e8-8831-9136465fad1f.png)
**Even worse.** It uses only 1.5 CPUs per subprocess.
-- However, for vanilla CPU-version  on c5.18x:

![image](https://user-images.githubusercontent.com/7865903/49704510-e2afc080-fbc8-11e8-8548-2505a7070205.png)
It is working better. At least, it uses 5 CPUs per subprocess.
-- Weirdly, still vanilla CPU-version  but on **GPU machine p3.16x**:

![image](https://user-images.githubusercontent.com/7865903/49704532-1a1e6d00-fbc9-11e8-8009-95519fd9f1ef.png)
It is working worse, i.e., 2 CPUs per subprocesses.
- This problem seems relevant to how MXNet manage the thread per subprocess. If I do not  in the main process and instead  in each subprocess:

![image](https://user-images.githubusercontent.com/7865903/49704599-d11ae880-fbc9-11e8-8460-e7d1e53abb13.png)
Then everything is working fine. 
"
incubator-mxnet,2041,"HI, I am using mxnet to train a 11-class image classifier. I am observing a weird behavior training accuracy was increasing slowly and went upto 39% and in next epoch it went down to 9% and then it stays close to 9% for rest of the training.
I restarted the training with saved model (with 39% training accuracy) keeping all other parameter same . Now training accuracy is increasing again. What can be the reason here ? I am not able to understand it . And its getting difficult to train the model this way as it requires me to see training accuracy values constantly.
",1,Sudden drop in accuracy while training a deep neural net,"Sudden drop in accuracy while training a deep neural net HI, I am using mxnet to train a 11-class image classifier. I am observing a weird behavior training accuracy was increasing slowly and went upto 39% and in next epoch it went down to 9% and then it stays close to 9% for rest of the training.
I restarted the training with saved model (with 39% training accuracy) keeping all other parameter same . Now training accuracy is increasing again. What can be the reason here ? I am not able to understand it . And its getting difficult to train the model this way as it requires me to see training accuracy values constantly.
"
incubator-mxnet,7582,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.11
Python version and distribution:
2.7

I am running a vgg+fcn model on keras + tensorflow and gluon. I can set batch_size = 32 on keras + tensorflow, but I can only set batch_size = 20 on gluon. 

The last block of my model on gluon is:

# block 7
self.net = nn.Sequential(prefix='net')
self.net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(max, kernel_size = 1, activation='sigmoid'))
 
The corresponding part on keras+tf is:

x = Conv3D(256, (3, 3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc1')(x)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc2')(x)
x_dist = Conv3D(max, (1, 1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)

",1,Gluon GPU memory efficiency,"Gluon GPU memory efficiency For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.11
Python version and distribution:
2.7

I am running a vgg+fcn model on keras + tensorflow and gluon. I can set batch_size = 32 on keras + tensorflow, but I can only set batch_size = 20 on gluon. 

The last block of my model on gluon is:

# block 7
self.net = nn.Sequential(prefix='net')
self.net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(max, kernel_size = 1, activation='sigmoid'))
 
The corresponding part on keras+tf is:

x = Conv3D(256, (3, 3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc1')(x)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc2')(x)
x_dist = Conv3D(max, (1, 1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)

"
incubator-mxnet,5158,"## Environment info
Operating System: Centos 7.0
Package used (Python/R/Scala/Julia): Python
MXNet version: 0.93
Python version and distribution: 2.7

We are testing the distributed train over multi-machine mxnet.  We compile Mxnet with parameter ""USE_DIST_KVSTORE=1"" , and successful run train a MLP on mnist.   But we found that the speed of distributed training was unusually slow compared to the speed of stand-alone training.

Stand-alone commands and speed：

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 21875.54 samples/sec     Train-accuracy=0.771040
INFO:root:Epoch[0] Batch [200]  Speed: 21260.40 samples/sec     Train-accuracy=0.913906
INFO:root:Epoch[0] Batch [300]  Speed: 21302.58 samples/sec     Train-accuracy=0.933750
INFO:root:Epoch[0] Batch [400]  Speed: 21216.02 samples/sec     Train-accuracy=0.936875
INFO:root:Epoch[0] Batch [500]  Speed: 22835.21 samples/sec     Train-accuracy=0.933594
INFO:root:Epoch[0] Batch [600]  Speed: 21612.71 samples/sec     Train-accuracy=0.947500
INFO:root:Epoch[0] Batch [700]  Speed: 23362.35 samples/sec     Train-accuracy=0.954375
INFO:root:Epoch[0] Batch [800]  Speed: 21683.75 samples/sec     Train-accuracy=0.954219
INFO:root:Epoch[0] Batch [900]  Speed: 21656.14 samples/sec     Train-accuracy=0.955781
INFO:root:Epoch[0] Train-accuracy=0.958615
INFO:root:Epoch[0] Time cost=2.804
INFO:root:Epoch[0] Validation-accuracy=0.957803

Command and speed of distributed training on local machine by using two workers:

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 2580.90 samples/sec      Train-accuracy=0.104425
INFO:root:Epoch[0] Batch [100]  Speed: 2574.24 samples/sec      Train-accuracy=0.096689
INFO:root:Epoch[0] Batch [200]  Speed: 4408.62 samples/sec      Train-accuracy=0.093594
INFO:root:Epoch[0] Batch [200]  Speed: 4399.50 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [300]  Speed: 3343.81 samples/sec      Train-accuracy=0.095469
INFO:root:Epoch[0] Batch [300]  Speed: 3342.38 samples/sec      Train-accuracy=0.097344
INFO:root:Epoch[0] Batch [400]  Speed: 3247.69 samples/sec      Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [400]  Speed: 3245.97 samples/sec      Train-accuracy=0.104531
INFO:root:Epoch[0] Batch [500]  Speed: 3364.46 samples/sec      Train-accuracy=0.102188
INFO:root:Epoch[0] Batch [500]  Speed: 3364.97 samples/sec      Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [600]  Speed: 3729.89 samples/sec      Train-accuracy=0.097500
INFO:root:Epoch[0] Batch [600]  Speed: 3732.76 samples/sec      Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [700]  Speed: 5105.08 samples/sec      Train-accuracy=0.087969
INFO:root:Epoch[0] Batch [700]  Speed: 5097.00 samples/sec      Train-accuracy=0.104375
INFO:root:Epoch[0] Batch [800]  Speed: 3931.05 samples/sec      Train-accuracy=0.099062
INFO:root:Epoch[0] Batch [800]  Speed: 3930.63 samples/sec      Train-accuracy=0.101406
INFO:root:Epoch[0] Batch [900]  Speed: 3763.65 samples/sec      Train-accuracy=0.098906
INFO:root:Epoch[0] Batch [900]  Speed: 3758.21 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Train-accuracy=0.104307
INFO:root:Epoch[0] Time cost=16.560
INFO:root:Epoch[0] Train-accuracy=0.099662
INFO:root:Epoch[0] Time cost=16.584
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029

Command and speed of distributed training on two computers(with same hardware configration):

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 614.03 samples/sec       Train-accuracy=0.097463
INFO:root:Epoch[0] Batch [100]  Speed: 613.66 samples/sec       Train-accuracy=0.096225
INFO:root:Epoch[0] Batch [200]  Speed: 577.24 samples/sec       Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [200]  Speed: 576.24 samples/sec       Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [300]  Speed: 609.78 samples/sec       Train-accuracy=0.094531
INFO:root:Epoch[0] Batch [300]  Speed: 610.73 samples/sec       Train-accuracy=0.098125
INFO:root:Epoch[0] Batch [400]  Speed: 624.24 samples/sec       Train-accuracy=0.100000
INFO:root:Epoch[0] Batch [400]  Speed: 623.74 samples/sec       Train-accuracy=0.100625
INFO:root:Epoch[0] Batch [500]  Speed: 642.81 samples/sec       Train-accuracy=0.096719
INFO:root:Epoch[0] Batch [500]  Speed: 643.28 samples/sec       Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [600]  Speed: 613.65 samples/sec       Train-accuracy=0.097187
INFO:root:Epoch[0] Batch [600]  Speed: 613.63 samples/sec       Train-accuracy=0.096406
INFO:root:Epoch[0] Batch [700]  Speed: 626.13 samples/sec       Train-accuracy=0.106875
INFO:root:Epoch[0] Batch [700]  Speed: 626.15 samples/sec       Train-accuracy=0.096562
INFO:root:Epoch[0] Batch [800]  Speed: 621.21 samples/sec       Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [800]  Speed: 620.83 samples/sec       Train-accuracy=0.099687
INFO:root:Epoch[0] Batch [900]  Speed: 589.75 samples/sec       Train-accuracy=0.098281
INFO:root:Epoch[0] Batch [900]  Speed: 589.72 samples/sec       Train-accuracy=0.104844
INFO:root:Epoch[0] Train-accuracy=0.101351
INFO:root:Epoch[0] Time cost=98.129
INFO:root:Epoch[0] Train-accuracy=0.097551
INFO:root:Epoch[0] Time cost=98.144
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[1] Batch [100]  Speed: 639.28 samples/sec       Train-accuracy=0.097308
INFO:root:Epoch[1] Batch [100]  Speed: 640.32 samples/sec       Train-accuracy=0.096844

We do not know why the speed so slow in distributed training , someone can help us? 
Thanks",1,Distributed training: Speed extremely slow,"Distributed training: Speed extremely slow ## Environment info
Operating System: Centos 7.0
Package used (Python/R/Scala/Julia): Python
MXNet version: 0.93
Python version and distribution: 2.7

We are testing the distributed train over multi-machine mxnet.  We compile Mxnet with parameter ""USE_DIST_KVSTORE=1"" , and successful run train a MLP on mnist.   But we found that the speed of distributed training was unusually slow compared to the speed of stand-alone training.

Stand-alone commands and speed：

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 21875.54 samples/sec     Train-accuracy=0.771040
INFO:root:Epoch[0] Batch [200]  Speed: 21260.40 samples/sec     Train-accuracy=0.913906
INFO:root:Epoch[0] Batch [300]  Speed: 21302.58 samples/sec     Train-accuracy=0.933750
INFO:root:Epoch[0] Batch [400]  Speed: 21216.02 samples/sec     Train-accuracy=0.936875
INFO:root:Epoch[0] Batch [500]  Speed: 22835.21 samples/sec     Train-accuracy=0.933594
INFO:root:Epoch[0] Batch [600]  Speed: 21612.71 samples/sec     Train-accuracy=0.947500
INFO:root:Epoch[0] Batch [700]  Speed: 23362.35 samples/sec     Train-accuracy=0.954375
INFO:root:Epoch[0] Batch [800]  Speed: 21683.75 samples/sec     Train-accuracy=0.954219
INFO:root:Epoch[0] Batch [900]  Speed: 21656.14 samples/sec     Train-accuracy=0.955781
INFO:root:Epoch[0] Train-accuracy=0.958615
INFO:root:Epoch[0] Time cost=2.804
INFO:root:Epoch[0] Validation-accuracy=0.957803

Command and speed of distributed training on local machine by using two workers:

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 2580.90 samples/sec      Train-accuracy=0.104425
INFO:root:Epoch[0] Batch [100]  Speed: 2574.24 samples/sec      Train-accuracy=0.096689
INFO:root:Epoch[0] Batch [200]  Speed: 4408.62 samples/sec      Train-accuracy=0.093594
INFO:root:Epoch[0] Batch [200]  Speed: 4399.50 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [300]  Speed: 3343.81 samples/sec      Train-accuracy=0.095469
INFO:root:Epoch[0] Batch [300]  Speed: 3342.38 samples/sec      Train-accuracy=0.097344
INFO:root:Epoch[0] Batch [400]  Speed: 3247.69 samples/sec      Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [400]  Speed: 3245.97 samples/sec      Train-accuracy=0.104531
INFO:root:Epoch[0] Batch [500]  Speed: 3364.46 samples/sec      Train-accuracy=0.102188
INFO:root:Epoch[0] Batch [500]  Speed: 3364.97 samples/sec      Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [600]  Speed: 3729.89 samples/sec      Train-accuracy=0.097500
INFO:root:Epoch[0] Batch [600]  Speed: 3732.76 samples/sec      Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [700]  Speed: 5105.08 samples/sec      Train-accuracy=0.087969
INFO:root:Epoch[0] Batch [700]  Speed: 5097.00 samples/sec      Train-accuracy=0.104375
INFO:root:Epoch[0] Batch [800]  Speed: 3931.05 samples/sec      Train-accuracy=0.099062
INFO:root:Epoch[0] Batch [800]  Speed: 3930.63 samples/sec      Train-accuracy=0.101406
INFO:root:Epoch[0] Batch [900]  Speed: 3763.65 samples/sec      Train-accuracy=0.098906
INFO:root:Epoch[0] Batch [900]  Speed: 3758.21 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Train-accuracy=0.104307
INFO:root:Epoch[0] Time cost=16.560
INFO:root:Epoch[0] Train-accuracy=0.099662
INFO:root:Epoch[0] Time cost=16.584
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029

Command and speed of distributed training on two computers(with same hardware configration):

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 614.03 samples/sec       Train-accuracy=0.097463
INFO:root:Epoch[0] Batch [100]  Speed: 613.66 samples/sec       Train-accuracy=0.096225
INFO:root:Epoch[0] Batch [200]  Speed: 577.24 samples/sec       Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [200]  Speed: 576.24 samples/sec       Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [300]  Speed: 609.78 samples/sec       Train-accuracy=0.094531
INFO:root:Epoch[0] Batch [300]  Speed: 610.73 samples/sec       Train-accuracy=0.098125
INFO:root:Epoch[0] Batch [400]  Speed: 624.24 samples/sec       Train-accuracy=0.100000
INFO:root:Epoch[0] Batch [400]  Speed: 623.74 samples/sec       Train-accuracy=0.100625
INFO:root:Epoch[0] Batch [500]  Speed: 642.81 samples/sec       Train-accuracy=0.096719
INFO:root:Epoch[0] Batch [500]  Speed: 643.28 samples/sec       Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [600]  Speed: 613.65 samples/sec       Train-accuracy=0.097187
INFO:root:Epoch[0] Batch [600]  Speed: 613.63 samples/sec       Train-accuracy=0.096406
INFO:root:Epoch[0] Batch [700]  Speed: 626.13 samples/sec       Train-accuracy=0.106875
INFO:root:Epoch[0] Batch [700]  Speed: 626.15 samples/sec       Train-accuracy=0.096562
INFO:root:Epoch[0] Batch [800]  Speed: 621.21 samples/sec       Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [800]  Speed: 620.83 samples/sec       Train-accuracy=0.099687
INFO:root:Epoch[0] Batch [900]  Speed: 589.75 samples/sec       Train-accuracy=0.098281
INFO:root:Epoch[0] Batch [900]  Speed: 589.72 samples/sec       Train-accuracy=0.104844
INFO:root:Epoch[0] Train-accuracy=0.101351
INFO:root:Epoch[0] Time cost=98.129
INFO:root:Epoch[0] Train-accuracy=0.097551
INFO:root:Epoch[0] Time cost=98.144
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[1] Batch [100]  Speed: 639.28 samples/sec       Train-accuracy=0.097308
INFO:root:Epoch[1] Batch [100]  Speed: 640.32 samples/sec       Train-accuracy=0.096844

We do not know why the speed so slow in distributed training , someone can help us? 
Thanks"
incubator-mxnet,938,"New to MxNet. I've set up and tested the package on three different systems, an CPU-only Linux VM, an CPU-only Windows Server and a GPU-based windows PC.

The sample I'm using is  **example/notebooks/cifar10-recipe.ipynb**

When comparing the performance across all three systems, I noticed that during the initial training ([12] in **cifar10-recipe.ipynb**), the train-accuracy and validation-accuracy I got is around 0.4~0.5, which is pretty far from the 65% accuracy as the documentation stated. 
Here's an example output during my test on an GPU-based machine.



What is causing this difference between my test and the one in the document when it's using the same code to test the same data set? 

And also the documentation says ""our model is able to achieve about 65% accuracy on testset(If not, try more times)"", what does this ""try more times"" mean? 

Thanks
",1,Training accuracy issue,"Training accuracy issue New to MxNet. I've set up and tested the package on three different systems, an CPU-only Linux VM, an CPU-only Windows Server and a GPU-based windows PC.

The sample I'm using is  **example/notebooks/cifar10-recipe.ipynb**

When comparing the performance across all three systems, I noticed that during the initial training ([12] in **cifar10-recipe.ipynb**), the train-accuracy and validation-accuracy I got is around 0.4~0.5, which is pretty far from the 65% accuracy as the documentation stated. 
Here's an example output during my test on an GPU-based machine.



What is causing this difference between my test and the one in the document when it's using the same code to test the same data set? 

And also the documentation says ""our model is able to achieve about 65% accuracy on testset(If not, try more times)"", what does this ""try more times"" mean? 

Thanks
"
incubator-mxnet,5035,"When using the bucketing module I'd expect the memory usage to be about the same as when using the normal module unrolled to the largest bucket size. However we observe unusually high GPU memory usage in MxNet when using multiple buckets. 
This can be reproduced/observed with the lstm_bucketing.py example from the latest MXNet commit as such:
in examples/rnn/lstm_bucketing.py change:



When using multiple buckets (see line 49), overall memory usage is 1419MB.
When changing line 49 to only use a single bucket (e.g. 60), overall memory usage is only 1185MB.

It should be noted that the initial memory usage for bucketing is the same (1185MB), but after a couple of batches the memory usage increases. We suspect this is due to the BucketingModule binding another sub module when a new bucket size is given by the data iterator and memory sharing across modules isn't working properly.

While for this model the difference is only 300 MB, we observed much higher differences in practice, making it difficult to train any reasonably sized model with bucketing.

Note: the default bucket key is of course the largest bucket.
",1,High memory usage with bucketing,"High memory usage with bucketing When using the bucketing module I'd expect the memory usage to be about the same as when using the normal module unrolled to the largest bucket size. However we observe unusually high GPU memory usage in MxNet when using multiple buckets. 
This can be reproduced/observed with the lstm_bucketing.py example from the latest MXNet commit as such:
in examples/rnn/lstm_bucketing.py change:



When using multiple buckets (see line 49), overall memory usage is 1419MB.
When changing line 49 to only use a single bucket (e.g. 60), overall memory usage is only 1185MB.

It should be noted that the initial memory usage for bucketing is the same (1185MB), but after a couple of batches the memory usage increases. We suspect this is due to the BucketingModule binding another sub module when a new bucket size is given by the data iterator and memory sharing across modules isn't working properly.

While for this model the difference is only 300 MB, we observed much higher differences in practice, making it difficult to train any reasonably sized model with bucketing.

Note: the default bucket key is of course the largest bucket.
"
incubator-mxnet,15148,"## Description
Mxnet consumes nearly 2GB CPU RAM even when loading a relatively small model (e.g. Resnet-18) directed on GPU (). From what I understand, there is no real need to use so much CPU memory when the model is running on GPU.

This issue is extremely prohibitive when trying to run multiple processes with mxnet on the same machine, and IMO gives it a significant disadvantage compared to other frameworks for being used in AI production systems.

## Environment info


Package used (Python/R/Scala/Julia):
I'm using Python3

## Build info
mxnet installed using pip3

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the following code

2. check process memory (run top, shift M to sort processes by memory usage)
3. memory usage is about ~1.5-2GB RAM


",1,Very Large CPU RAM Memory Consumption (>1GB),"Very Large CPU RAM Memory Consumption (>1GB) ## Description
Mxnet consumes nearly 2GB CPU RAM even when loading a relatively small model (e.g. Resnet-18) directed on GPU (). From what I understand, there is no real need to use so much CPU memory when the model is running on GPU.

This issue is extremely prohibitive when trying to run multiple processes with mxnet on the same machine, and IMO gives it a significant disadvantage compared to other frameworks for being used in AI production systems.

## Environment info


Package used (Python/R/Scala/Julia):
I'm using Python3

## Build info
mxnet installed using pip3

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the following code

2. check process memory (run top, shift M to sort processes by memory usage)
3. memory usage is about ~1.5-2GB RAM


"
incubator-mxnet,16687,"## Description
After #16602 merge, java/scala SSD GPU inference latency increased by 20x (from 70ms to 1400ms)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

@PatricZhao @ZhennanQin
Thanks in advance & Happy Halloween!",1,[Performance Regression] Scala/Java SSD inference,"[Performance Regression] Scala/Java SSD inference ## Description
After #16602 merge, java/scala SSD GPU inference latency increased by 20x (from 70ms to 1400ms)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

@PatricZhao @ZhennanQin
Thanks in advance & Happy Halloween!"
incubator-mxnet,3378,"I am trying do the inception-bn-full on my own dataset. (near 1400w and 5190 classes).

python train_imagenet.py --network inception-bn-full --batch-size 100 --lr 0.05 --lr-factor 0.9 --gpus 2,3 --num-epoch 60 --data-dir /data5/rd/xiajizhong/parts_17kClasses/ --train-dataset small_rec/ --val-dataset small_rec_val/ --num-examples=14040000

and, when use the latest mxnet I get bad validation accuracy. 

> 2016-09-24 02:49:24,212 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-accuracy=0.546400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_5=0.787400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_10=0.842400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_20=0.884800
> 2016-09-24 02:49:25,074 Node[0] Update[140401]: Change learning rate to 4.50000e-02
> 2016-09-24 02:49:31,389 Node[0] Epoch[0] Resetting Data Iterator
> 2016-09-24 02:49:31,390 Node[0] Epoch[0] Time cost=301141.343
> 2016-09-24 02:49:31,645 Node[0] Saved checkpoint to ""model/inception_bn_full_Vdian-0001.params""
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-accuracy=**0.142758**
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_5=0.280551
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_10=0.350004
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_20=0.418618

But, I was doing the experiment well in the old version mxnet, which the validation accuracy is also very high near top1=50%, after one epoch. So I am wondering why this happened? I am not very clear about different changed in the new version mxnet. Is it caused by the Pooling layer behavior changed? 

and on the old version, the result below,

> 2016-06-10 10:26:15,591 Node[0] Epoch[0] Batch [140350] Speed: 50.40 samples/sec    Train-accuracy=0.406846
> 2016-06-10 10:27:53,871 Node[0] Epoch[0] Batch [140400] Speed: 50.88 samples/sec    Train-accuracy=0.406867
> 2016-06-10 10:27:53,875 Node[0] Update[140401]: Change learning rate to 4.05000e-01
> 2016-06-10 10:27:59,645 Node[0] Epoch[0] Resetting Data Iterator
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Train-accuracy=0.406869
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Time cost=258948.773
> 2016-06-10 10:28:01,107 Node[0] Saved checkpoint to ""model/vdian5190-0-0001.params""
> 2016-06-10 12:50:10,700 Node[0] Epoch[0] Validation-accuracy=**0.457665**
",1,"Train accuracy high, low validation accuracy","Train accuracy high, low validation accuracy I am trying do the inception-bn-full on my own dataset. (near 1400w and 5190 classes).

python train_imagenet.py --network inception-bn-full --batch-size 100 --lr 0.05 --lr-factor 0.9 --gpus 2,3 --num-epoch 60 --data-dir /data5/rd/xiajizhong/parts_17kClasses/ --train-dataset small_rec/ --val-dataset small_rec_val/ --num-examples=14040000

and, when use the latest mxnet I get bad validation accuracy. 

> 2016-09-24 02:49:24,212 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-accuracy=0.546400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_5=0.787400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_10=0.842400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_20=0.884800
> 2016-09-24 02:49:25,074 Node[0] Update[140401]: Change learning rate to 4.50000e-02
> 2016-09-24 02:49:31,389 Node[0] Epoch[0] Resetting Data Iterator
> 2016-09-24 02:49:31,390 Node[0] Epoch[0] Time cost=301141.343
> 2016-09-24 02:49:31,645 Node[0] Saved checkpoint to ""model/inception_bn_full_Vdian-0001.params""
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-accuracy=**0.142758**
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_5=0.280551
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_10=0.350004
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_20=0.418618

But, I was doing the experiment well in the old version mxnet, which the validation accuracy is also very high near top1=50%, after one epoch. So I am wondering why this happened? I am not very clear about different changed in the new version mxnet. Is it caused by the Pooling layer behavior changed? 

and on the old version, the result below,

> 2016-06-10 10:26:15,591 Node[0] Epoch[0] Batch [140350] Speed: 50.40 samples/sec    Train-accuracy=0.406846
> 2016-06-10 10:27:53,871 Node[0] Epoch[0] Batch [140400] Speed: 50.88 samples/sec    Train-accuracy=0.406867
> 2016-06-10 10:27:53,875 Node[0] Update[140401]: Change learning rate to 4.05000e-01
> 2016-06-10 10:27:59,645 Node[0] Epoch[0] Resetting Data Iterator
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Train-accuracy=0.406869
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Time cost=258948.773
> 2016-06-10 10:28:01,107 Node[0] Saved checkpoint to ""model/vdian5190-0-0001.params""
> 2016-06-10 12:50:10,700 Node[0] Epoch[0] Validation-accuracy=**0.457665**
"
incubator-mxnet,9396,"Hi, I just updated mxnet today from 0.10.0 to 1.0.0 in order to use some new features. Both versions are installed with pip like . However, after a detailed benchmark test, I observed a significant speed drop when running resnet inference especially when batch size is small. The result for resnet152 is like below (network json file is downloaded from [here](http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json))





PS. I noticed that when batch size is small (i.e. batch_size=1), the GPU usage is 95~100% in mxnet 0.10.0 and 80-83% in mxnet 1.0.0 which means the GPU is not fully utilized at all.

Software env: Ubuntu 16.04, Python 3.5, CUDA 8.0, CUDNN 5.1.
GPU: GTX 1080 Ti.

I also test on a server with Titan XP and got a similar result. The speed test script is pasted below:
",1,inference speed drop after updating mxnet from 0.10.0 to 1.0.0,"inference speed drop after updating mxnet from 0.10.0 to 1.0.0 Hi, I just updated mxnet today from 0.10.0 to 1.0.0 in order to use some new features. Both versions are installed with pip like . However, after a detailed benchmark test, I observed a significant speed drop when running resnet inference especially when batch size is small. The result for resnet152 is like below (network json file is downloaded from [here](http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json))





PS. I noticed that when batch size is small (i.e. batch_size=1), the GPU usage is 95~100% in mxnet 0.10.0 and 80-83% in mxnet 1.0.0 which means the GPU is not fully utilized at all.

Software env: Ubuntu 16.04, Python 3.5, CUDA 8.0, CUDNN 5.1.
GPU: GTX 1080 Ti.

I also test on a server with Titan XP and got a similar result. The speed test script is pasted below:
"
incubator-mxnet,11575,"Hi,

I'm trying to train my model with the following code. It has only to classes to predict from 0 and 1.



Here are the results : 
.

> 2018-07-06 00:54:38,926 Epoch[0] Batch [100]	Speed: 20.37 samples/sec	accuracy=0.544554	rmse=0.591505	mae=0.500000
> 2018-07-06 00:54:43,694 Epoch[0] Batch [200]	Speed: 20.97 samples/sec	accuracy=0.470000	rmse=0.586368	mae=0.500000
> 2018-07-06 00:54:48,509 Epoch[0] Batch [300]	Speed: 20.77 samples/sec	accuracy=0.520000	rmse=0.587208	mae=0.500000
> 2018-07-06 00:54:53,286 Epoch[0] Batch [400]	Speed: 20.93 samples/sec	accuracy=0.560000	rmse=0.602946	mae=0.500000
> 2018-07-06 00:54:58,057 Epoch[0] Batch [500]	Speed: 20.96 samples/sec	accuracy=0.460000	rmse=0.576723	mae=0.500000
> 2018-07-06 00:55:02,886 Epoch[0] Batch [600]	Speed: 20.71 samples/sec	accuracy=0.490000	rmse=0.577645	mae=0.500000
> 2018-07-06 00:55:07,703 Epoch[0] Batch [700]	Speed: 20.76 samples/sec	accuracy=0.600000	rmse=0.585552	mae=0.500000
> 2018-07-06 00:55:12,453 Epoch[0] Batch [800]	Speed: 21.05 samples/sec	accuracy=0.560000	rmse=0.585788	mae=0.500000
> 2018-07-06 00:55:17,236 Epoch[0] Batch [900]	Speed: 20.91 samples/sec	accuracy=0.500000	rmse=0.567332	mae=0.500000
> 2018-07-06 00:55:21,993 Epoch[0] Batch [1000]	Speed: 21.02 samples/sec	accuracy=0.590000	rmse=0.580251	mae=0.500000
> 2018-07-06 00:55:26,776 Epoch[0] Batch [1100]	Speed: 20.91 samples/sec	accuracy=0.550000	rmse=0.564997	mae=0.500000
> 2018-07-06 00:55:31,532 Epoch[0] Batch [1200]	Speed: 21.02 samples/sec	accuracy=0.620000	rmse=0.564062	mae=0.500000
> 2018-07-06 00:55:36,281 Epoch[0] Batch [1300]	Speed: 21.06 samples/sec	accuracy=0.650000	rmse=0.566788	mae=0.500000
> 2018-07-06 00:55:41,062 Epoch[0] Batch [1400]	Speed: 20.92 samples/sec	accuracy=0.590000	rmse=0.574353	mae=0.500000
> 2018-07-06 00:55:45,845 Epoch[0] Batch [1500]	Speed: 20.91 samples/sec	accuracy=0.690000	rmse=0.569736	mae=0.500000
> 2018-07-06 00:55:50,623 Epoch[0] Batch [1600]	Speed: 20.93 samples/sec	accuracy=0.700000	rmse=0.579918	mae=0.500000
> 2018-07-06 00:55:55,407 Epoch[0] Batch [1700]	Speed: 20.90 samples/sec	accuracy=0.730000	rmse=0.585157	mae=0.500000
> 2018-07-06 00:56:00,170 Epoch[0] Batch [1800]	Speed: 20.99 samples/sec	accuracy=0.810000	rmse=0.590722	mae=0.500000
> 2018-07-06 00:56:04,944 Epoch[0] Batch [1900]	Speed: 20.95 samples/sec	accuracy=0.860000	rmse=0.601612	mae=0.500000
> 2018-07-06 00:56:09,704 Epoch[0] Batch [2000]	Speed: 21.01 samples/sec	accuracy=0.800000	rmse=0.593426	mae=0.500000
> 2018-07-06 00:56:14,460 Epoch[0] Batch [2100]	Speed: 21.02 samples/sec	accuracy=0.860000	rmse=0.618266	mae=0.500000
> 2018-07-06 00:56:19,215 Epoch[0] Batch [2200]	Speed: 21.03 samples/sec	accuracy=0.760000	rmse=0.605838	mae=0.500000
> 2018-07-06 00:56:23,997 Epoch[0] Batch [2300]	Speed: 20.92 samples/sec	accuracy=0.840000	rmse=0.616089	mae=0.500000
> 2018-07-06 00:56:28,773 Epoch[0] Batch [2400]	Speed: 20.94 samples/sec	accuracy=0.850000	rmse=0.620063	mae=0.500000
> 2018-07-06 00:56:33,562 Epoch[0] Batch [2500]	Speed: 20.88 samples/sec	accuracy=0.820000	rmse=0.608637	mae=0.500000
> 2018-07-06 00:56:38,401 Epoch[0] Batch [2600]	Speed: 20.67 samples/sec	accuracy=0.880000	rmse=0.631159	mae=0.500000
> 2018-07-06 00:56:43,179 Epoch[0] Batch [2700]	Speed: 20.93 samples/sec	accuracy=0.850000	rmse=0.624896	mae=0.500000
> 2018-07-06 00:56:47,975 Epoch[0] Batch [2800]	Speed: 20.85 samples/sec	accuracy=0.830000	rmse=0.631906	mae=0.500000
> 2018-07-06 00:56:52,744 Epoch[0] Batch [2900]	Speed: 20.97 samples/sec	accuracy=0.890000	rmse=0.634412	mae=0.500000
> 2018-07-06 00:56:57,510 Epoch[0] Batch [3000]	Speed: 20.98 samples/sec	accuracy=0.810000	rmse=0.628204	mae=0.500000
> 2018-07-06 00:57:02,293 Epoch[0] Batch [3100]	Speed: 20.91 samples/sec	accuracy=0.900000	rmse=0.648476	mae=0.500000
> 2018-07-06 00:57:07,066 Epoch[0] Batch [3200]	Speed: 20.95 samples/sec	accuracy=0.920000	rmse=0.642261	mae=0.500000

This result looks very strange to me. 
1) mae is always the same.
2) accuracy is almost optimal (near to 1)
3) rmse is worse then the random

How can these 3 things happen at the same time?",1,inconsistent results of mae acc rmse,"inconsistent results of mae acc rmse Hi,

I'm trying to train my model with the following code. It has only to classes to predict from 0 and 1.



Here are the results : 
.

> 2018-07-06 00:54:38,926 Epoch[0] Batch [100]	Speed: 20.37 samples/sec	accuracy=0.544554	rmse=0.591505	mae=0.500000
> 2018-07-06 00:54:43,694 Epoch[0] Batch [200]	Speed: 20.97 samples/sec	accuracy=0.470000	rmse=0.586368	mae=0.500000
> 2018-07-06 00:54:48,509 Epoch[0] Batch [300]	Speed: 20.77 samples/sec	accuracy=0.520000	rmse=0.587208	mae=0.500000
> 2018-07-06 00:54:53,286 Epoch[0] Batch [400]	Speed: 20.93 samples/sec	accuracy=0.560000	rmse=0.602946	mae=0.500000
> 2018-07-06 00:54:58,057 Epoch[0] Batch [500]	Speed: 20.96 samples/sec	accuracy=0.460000	rmse=0.576723	mae=0.500000
> 2018-07-06 00:55:02,886 Epoch[0] Batch [600]	Speed: 20.71 samples/sec	accuracy=0.490000	rmse=0.577645	mae=0.500000
> 2018-07-06 00:55:07,703 Epoch[0] Batch [700]	Speed: 20.76 samples/sec	accuracy=0.600000	rmse=0.585552	mae=0.500000
> 2018-07-06 00:55:12,453 Epoch[0] Batch [800]	Speed: 21.05 samples/sec	accuracy=0.560000	rmse=0.585788	mae=0.500000
> 2018-07-06 00:55:17,236 Epoch[0] Batch [900]	Speed: 20.91 samples/sec	accuracy=0.500000	rmse=0.567332	mae=0.500000
> 2018-07-06 00:55:21,993 Epoch[0] Batch [1000]	Speed: 21.02 samples/sec	accuracy=0.590000	rmse=0.580251	mae=0.500000
> 2018-07-06 00:55:26,776 Epoch[0] Batch [1100]	Speed: 20.91 samples/sec	accuracy=0.550000	rmse=0.564997	mae=0.500000
> 2018-07-06 00:55:31,532 Epoch[0] Batch [1200]	Speed: 21.02 samples/sec	accuracy=0.620000	rmse=0.564062	mae=0.500000
> 2018-07-06 00:55:36,281 Epoch[0] Batch [1300]	Speed: 21.06 samples/sec	accuracy=0.650000	rmse=0.566788	mae=0.500000
> 2018-07-06 00:55:41,062 Epoch[0] Batch [1400]	Speed: 20.92 samples/sec	accuracy=0.590000	rmse=0.574353	mae=0.500000
> 2018-07-06 00:55:45,845 Epoch[0] Batch [1500]	Speed: 20.91 samples/sec	accuracy=0.690000	rmse=0.569736	mae=0.500000
> 2018-07-06 00:55:50,623 Epoch[0] Batch [1600]	Speed: 20.93 samples/sec	accuracy=0.700000	rmse=0.579918	mae=0.500000
> 2018-07-06 00:55:55,407 Epoch[0] Batch [1700]	Speed: 20.90 samples/sec	accuracy=0.730000	rmse=0.585157	mae=0.500000
> 2018-07-06 00:56:00,170 Epoch[0] Batch [1800]	Speed: 20.99 samples/sec	accuracy=0.810000	rmse=0.590722	mae=0.500000
> 2018-07-06 00:56:04,944 Epoch[0] Batch [1900]	Speed: 20.95 samples/sec	accuracy=0.860000	rmse=0.601612	mae=0.500000
> 2018-07-06 00:56:09,704 Epoch[0] Batch [2000]	Speed: 21.01 samples/sec	accuracy=0.800000	rmse=0.593426	mae=0.500000
> 2018-07-06 00:56:14,460 Epoch[0] Batch [2100]	Speed: 21.02 samples/sec	accuracy=0.860000	rmse=0.618266	mae=0.500000
> 2018-07-06 00:56:19,215 Epoch[0] Batch [2200]	Speed: 21.03 samples/sec	accuracy=0.760000	rmse=0.605838	mae=0.500000
> 2018-07-06 00:56:23,997 Epoch[0] Batch [2300]	Speed: 20.92 samples/sec	accuracy=0.840000	rmse=0.616089	mae=0.500000
> 2018-07-06 00:56:28,773 Epoch[0] Batch [2400]	Speed: 20.94 samples/sec	accuracy=0.850000	rmse=0.620063	mae=0.500000
> 2018-07-06 00:56:33,562 Epoch[0] Batch [2500]	Speed: 20.88 samples/sec	accuracy=0.820000	rmse=0.608637	mae=0.500000
> 2018-07-06 00:56:38,401 Epoch[0] Batch [2600]	Speed: 20.67 samples/sec	accuracy=0.880000	rmse=0.631159	mae=0.500000
> 2018-07-06 00:56:43,179 Epoch[0] Batch [2700]	Speed: 20.93 samples/sec	accuracy=0.850000	rmse=0.624896	mae=0.500000
> 2018-07-06 00:56:47,975 Epoch[0] Batch [2800]	Speed: 20.85 samples/sec	accuracy=0.830000	rmse=0.631906	mae=0.500000
> 2018-07-06 00:56:52,744 Epoch[0] Batch [2900]	Speed: 20.97 samples/sec	accuracy=0.890000	rmse=0.634412	mae=0.500000
> 2018-07-06 00:56:57,510 Epoch[0] Batch [3000]	Speed: 20.98 samples/sec	accuracy=0.810000	rmse=0.628204	mae=0.500000
> 2018-07-06 00:57:02,293 Epoch[0] Batch [3100]	Speed: 20.91 samples/sec	accuracy=0.900000	rmse=0.648476	mae=0.500000
> 2018-07-06 00:57:07,066 Epoch[0] Batch [3200]	Speed: 20.95 samples/sec	accuracy=0.920000	rmse=0.642261	mae=0.500000

This result looks very strange to me. 
1) mae is always the same.
2) accuracy is almost optimal (near to 1)
3) rmse is worse then the random

How can these 3 things happen at the same time?"
incubator-mxnet,951,"I used two machine(every machine has one gpu) to use Alexnet run multile machine.the result saids that it is slower than one machine use one gpu. the net is km. 
is multi machine is limited by the net?
",1,run two machine with two gpu is slower than one machine with one gpu,"run two machine with two gpu is slower than one machine with one gpu I used two machine(every machine has one gpu) to use Alexnet run multile machine.the result saids that it is slower than one machine use one gpu. the net is km. 
is multi machine is limited by the net?
"
incubator-mxnet,16568,"Looking at metrics it seems like they behave in a slightly different way depending on how they sum up all the batch inputs. For example, Accuracy does not calculate the mean of single batches, but sums all them up and evaluates a single mean in the get method:

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L507

On the contrary, RMSE evaluates the single RMSE for each batch, and then the average in the get method.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L1273

This leads to some discrepancy in the metrics for example when using metrics which are non-linear (f.i. MAE, MSE, RMSE, PCC) where metric(samples)!=mean(metric(batch_samples)).",1,"Different (not uniform) behavior in RMSE,MSE,MAE","Different (not uniform) behavior in RMSE,MSE,MAE Looking at metrics it seems like they behave in a slightly different way depending on how they sum up all the batch inputs. For example, Accuracy does not calculate the mean of single batches, but sums all them up and evaluates a single mean in the get method:

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L507

On the contrary, RMSE evaluates the single RMSE for each batch, and then the average in the get method.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L1273

This leads to some discrepancy in the metrics for example when using metrics which are non-linear (f.i. MAE, MSE, RMSE, PCC) where metric(samples)!=mean(metric(batch_samples))."
incubator-mxnet,10167,"Here's an interesting example that HybridBlock can sometimes be much slower than Block. We define an Identity block using two strategies and compare the running time.



The result is:

We can find that in this case, using Block is a better choice than using HybridBlock.",1,HybridBlock can be slower than Block,"HybridBlock can be slower than Block Here's an interesting example that HybridBlock can sometimes be much slower than Block. We define an Identity block using two strategies and compare the running time.



The result is:

We can find that in this case, using Block is a better choice than using HybridBlock."
incubator-mxnet,11192,"[mx.sym.BatchNorm operator](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.BatchNorm) is considerably slower on GPUs with channels_last (axis=-1).

My understanding is that, with channels_first (axis=1) operator calls cuDNN implementation and with channels_last(axis=-1) MXNet has its own implementation.

",1,BatchNorm operator on GPUs are slow with channels_last,"BatchNorm operator on GPUs are slow with channels_last [mx.sym.BatchNorm operator](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.BatchNorm) is considerably slower on GPUs with channels_last (axis=-1).

My understanding is that, with channels_first (axis=1) operator calls cuDNN implementation and with channels_last(axis=-1) MXNet has its own implementation.

"
incubator-mxnet,5052,"In the example code below I run simple classification and regression examples for MXNET running from R. In both examples I first solve with CPU, and then GPU.

In the classification example I get a ~ 32x speed-up when using a GPU, however the speed-up when running the regression example is much less (about 3x).

Details are given below, my main questions would be:
1. Is there are reason the speed-up is much less significant for the regression example?
2. Do people who have mxnet get similar/comparable results to me? (Alternatively is there a benchmark I can run and compare to benchmark performances?)

The output I get:


Example code:



Details of my set-up

## Environment info
Operating System: Ubuntu 16.04
R details:

",1,"MXNET R, GPU speed-up much less for regression example than classification","MXNET R, GPU speed-up much less for regression example than classification In the example code below I run simple classification and regression examples for MXNET running from R. In both examples I first solve with CPU, and then GPU.

In the classification example I get a ~ 32x speed-up when using a GPU, however the speed-up when running the regression example is much less (about 3x).

Details are given below, my main questions would be:
1. Is there are reason the speed-up is much less significant for the regression example?
2. Do people who have mxnet get similar/comparable results to me? (Alternatively is there a benchmark I can run and compare to benchmark performances?)

The output I get:


Example code:



Details of my set-up

## Environment info
Operating System: Ubuntu 16.04
R details:

"
incubator-mxnet,8126,"## Environment info
Operating System: Ubuntu 16.04 
Compiler: g++
Package used (Python/R/Scala/Julia): C++

MXNet version: 0.11

Or if installed from source:
MXNet commit hash ():  branch 0.11.0

## Error Message:
**There is no error but the training accuracy always remains ZERO.** Is there a problem with the code for constructing the neural network (the  symbol) or/and is the training procedure correct, i.e. the gradient updates are correctly specified?

## Minimum reproducible example

1. I defined a siamese net like architecture with  as final layer using the code provided below:



The output of the code is always something like:


## What have you tried to solve it?

1. Tried different variations on training data but the network is always predicting ZERO as its output.
",1,Not able to train a neural network [XOR added],"Not able to train a neural network [XOR added] ## Environment info
Operating System: Ubuntu 16.04 
Compiler: g++
Package used (Python/R/Scala/Julia): C++

MXNet version: 0.11

Or if installed from source:
MXNet commit hash ():  branch 0.11.0

## Error Message:
**There is no error but the training accuracy always remains ZERO.** Is there a problem with the code for constructing the neural network (the  symbol) or/and is the training procedure correct, i.e. the gradient updates are correctly specified?

## Minimum reproducible example

1. I defined a siamese net like architecture with  as final layer using the code provided below:



The output of the code is always something like:


## What have you tried to solve it?

1. Tried different variations on training data but the network is always predicting ZERO as its output.
"
incubator-mxnet,7615,"## Environment info
Operating System:
Ubuntu 16.04

MXNet version: 
0.11.0

Or if installed from source:
no, using pip install mxnet-cu80

Python version and distribution:
Python27

I run the demo in [](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/P06-C03-object-detection.ipynb)

and try to modify to use multi-gpu version as follows

and I try to train single-gpu and multi-gpu respectively
here are the results after 165 epochs from scratch

1. single-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9iwppcsj20rs0rsapr.jpg)

2. multi-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9kgp9loj20rs0rs7k0.jpg)

Is that resonable? I am not familiar with new grammar and not sure wether I made a mistale. ",1,accuracy sacrificed with multi-gpu using gluon,"accuracy sacrificed with multi-gpu using gluon ## Environment info
Operating System:
Ubuntu 16.04

MXNet version: 
0.11.0

Or if installed from source:
no, using pip install mxnet-cu80

Python version and distribution:
Python27

I run the demo in [](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/P06-C03-object-detection.ipynb)

and try to modify to use multi-gpu version as follows

and I try to train single-gpu and multi-gpu respectively
here are the results after 165 epochs from scratch

1. single-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9iwppcsj20rs0rsapr.jpg)

2. multi-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9kgp9loj20rs0rs7k0.jpg)

Is that resonable? I am not familiar with new grammar and not sure wether I made a mistale. "
incubator-mxnet,17086,"## Description
RNN op gradient computation on CPU is broken for the source built mxnet. 

I was running a language model training script on my ec2 instance. I tested the script with the latest source built mxnet. During training, I ran into the following log:

### Log Message

The loss value does not change any more. If I use the mxnet build by pip installation  .  The log is normal. There is no gradient  warning and the loss keeps changing:

## To Reproduce
The training script can be found at .  To reproduce the log message, I ran the script with the following command:


## What have you tried to solve it?

The problem occurred when computing gradients (https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py#L381)

Some gradient values are of order . Normally the gradient value should be within .

Thanks to @leezu , he found the error was introduced because of the MKLDNN option. If we use mxnet built from source with MKLDNN turned on, i.e., , the gradient error appears whereas the problem is gone when . Therefore the issue can be traced back to the MKLDNN. @zixuanweeei @ciyongch @pengzhao-intel  

## Environment

My environment specs can be found here

",1,[MKLDNN] RNN Op gradient computation is broken,"[MKLDNN] RNN Op gradient computation is broken ## Description
RNN op gradient computation on CPU is broken for the source built mxnet. 

I was running a language model training script on my ec2 instance. I tested the script with the latest source built mxnet. During training, I ran into the following log:

### Log Message

The loss value does not change any more. If I use the mxnet build by pip installation  .  The log is normal. There is no gradient  warning and the loss keeps changing:

## To Reproduce
The training script can be found at .  To reproduce the log message, I ran the script with the following command:


## What have you tried to solve it?

The problem occurred when computing gradients (https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py#L381)

Some gradient values are of order . Normally the gradient value should be within .

Thanks to @leezu , he found the error was introduced because of the MKLDNN option. If we use mxnet built from source with MKLDNN turned on, i.e., , the gradient error appears whereas the problem is gone when . Therefore the issue can be traced back to the MKLDNN. @zixuanweeei @ciyongch @pengzhao-intel  

## Environment

My environment specs can be found here

"
incubator-mxnet,6974,"I want to get network output in numpy array, which can be achieved with the  method. But I found this very slow since it copies all the elements. The computation takes only a few ms, while the  call takes 100+ ms. How can I obtain the numpy array more efficiently?

I also tried to directly manipulate the mxnet NDArray. I used  or , since ""multi-dimension indexing is not supported"". But both methods only support slicing a contiguous region. This makes a big trouble for me.

BTW, I run my program on CPU and the arrays are of size ~2000x6.",1,NDArray.asnumpy() very slow,"NDArray.asnumpy() very slow I want to get network output in numpy array, which can be achieved with the  method. But I found this very slow since it copies all the elements. The computation takes only a few ms, while the  call takes 100+ ms. How can I obtain the numpy array more efficiently?

I also tried to directly manipulate the mxnet NDArray. I used  or , since ""multi-dimension indexing is not supported"". But both methods only support slicing a contiguous region. This makes a big trouble for me.

BTW, I run my program on CPU and the arrays are of size ~2000x6."
incubator-mxnet,9026,"I test my py on AWS EC2 P3.2xlarge(GPU:V100), AMI: ami-77eb3a0f, python version : 2.7. The .py is as follow:

On my own host, win10, mx0.12, gpu:940M,  I got near 110 samples/seconds with default params,  but surprisingly, on p3.2xlarge, I got only 170 samples/seconds. In detail, with ,  I found the volatile GPU utile is always near 0%, up t0 4%.  WHY???   Is that just because I got a custom DataIter?




",1,why is it so slow (MXNET0.12)even with NVIDIA V100 GPU?,"why is it so slow (MXNET0.12)even with NVIDIA V100 GPU? I test my py on AWS EC2 P3.2xlarge(GPU:V100), AMI: ami-77eb3a0f, python version : 2.7. The .py is as follow:

On my own host, win10, mx0.12, gpu:940M,  I got near 110 samples/seconds with default params,  but surprisingly, on p3.2xlarge, I got only 170 samples/seconds. In detail, with ,  I found the volatile GPU utile is always near 0%, up t0 4%.  WHY???   Is that just because I got a custom DataIter?




"
incubator-mxnet,4163,"I was using the python version of MXNet on a 64-bit Ubuntu 16.04 OS.

I changed the fully connected layers in the VGG-16 network and I wanted to fine-tune it.
At first I used the 'fixed_param_names' in mx.mod.Module class and it seemed to be working very well. The accuracy was getting better and better, with a 75% accuracy at 10th epoch.
Then I saved a checkpoint at the 10th epoch, changed the module by removing the 'fixed_param_names' parameters, set the 'lr_mult' to 0 by calling 'opt.set_lr_mult()', and finally loaded the checkpoint file to continue the training process. However, the accuracy rapidly dropped to about 50% (2 classes were included in the training set.)

Here's the code segment for using 'fixed_param_names':
net, arg_params, aux_params = mx.model.load_checkpoint('../model/vgg16', 0)
name_list = [k for k in arg_params if not 'fc' in k]
mod = mx.module.Module(net, context=ctx, work_load_list=wl, fixed_param_names=name_list)

Here's the codes for 'set_lr_mult' method:
opt = mx.optimizer.Adam(learning_rate=0.001)
mult_dict = {k:0.0 for k in arg_params if not 'fc' in k}
opt.set_lr_mult(mult_dict)
mod.init_optimizer(optimizer=opt)

I understand that the 'fixed_param_names' parameter is related to 'grad_req' when calling the executor, and no memory is allocated for gradients in this way. For 'lr_mult' case, the gradients are calculated, but  are not added to the weights as the learning rate was 0.
But I guess this should only make difference in memory occupation and computation speed. The result should have been the same, as the weights are the same in both cases. Why were they different??

Maybe I was wrong in understanding the matters. Could someone help me with that?

By the way, I cannot understand the difference between 'fixed_param_names' and the 'BlockGrad' operator. I guess both of them save the memory cosuming, only that 'BlockGrad' cut off the backpropagation completely. I guess this could be implemented with 'fixed_param_names' by specifying all layers before the blocking node, right? Furthermore, if I wanted to freeze the middle part of a network while keep the rest parts trainable: {trainable parts} <-- {frozen parts} <-- {trainable parts} <--{deviation}, I guess that 'BlockGrad' would not help, but 'fixed_param_names' would function.

As the results of my training was not correct, I guess there must have been something wrong in my understanding. Would someone please help me? THX.
",1,'fixed_param_names' and 'lr_mult' behave differently,"'fixed_param_names' and 'lr_mult' behave differently I was using the python version of MXNet on a 64-bit Ubuntu 16.04 OS.

I changed the fully connected layers in the VGG-16 network and I wanted to fine-tune it.
At first I used the 'fixed_param_names' in mx.mod.Module class and it seemed to be working very well. The accuracy was getting better and better, with a 75% accuracy at 10th epoch.
Then I saved a checkpoint at the 10th epoch, changed the module by removing the 'fixed_param_names' parameters, set the 'lr_mult' to 0 by calling 'opt.set_lr_mult()', and finally loaded the checkpoint file to continue the training process. However, the accuracy rapidly dropped to about 50% (2 classes were included in the training set.)

Here's the code segment for using 'fixed_param_names':
net, arg_params, aux_params = mx.model.load_checkpoint('../model/vgg16', 0)
name_list = [k for k in arg_params if not 'fc' in k]
mod = mx.module.Module(net, context=ctx, work_load_list=wl, fixed_param_names=name_list)

Here's the codes for 'set_lr_mult' method:
opt = mx.optimizer.Adam(learning_rate=0.001)
mult_dict = {k:0.0 for k in arg_params if not 'fc' in k}
opt.set_lr_mult(mult_dict)
mod.init_optimizer(optimizer=opt)

I understand that the 'fixed_param_names' parameter is related to 'grad_req' when calling the executor, and no memory is allocated for gradients in this way. For 'lr_mult' case, the gradients are calculated, but  are not added to the weights as the learning rate was 0.
But I guess this should only make difference in memory occupation and computation speed. The result should have been the same, as the weights are the same in both cases. Why were they different??

Maybe I was wrong in understanding the matters. Could someone help me with that?

By the way, I cannot understand the difference between 'fixed_param_names' and the 'BlockGrad' operator. I guess both of them save the memory cosuming, only that 'BlockGrad' cut off the backpropagation completely. I guess this could be implemented with 'fixed_param_names' by specifying all layers before the blocking node, right? Furthermore, if I wanted to freeze the middle part of a network while keep the rest parts trainable: {trainable parts} <-- {frozen parts} <-- {trainable parts} <--{deviation}, I guess that 'BlockGrad' would not help, but 'fixed_param_names' would function.

As the results of my training was not correct, I guess there must have been something wrong in my understanding. Would someone please help me? THX.
"
incubator-mxnet,1092,"I run the examples/image_classification/train_mnist.py on single gpu and double gpus. what out of my expectation is that accuracies are slightly different.(around 0.1% different). though it is not a big issue but still i am very confused because they should be completely equal in theory. can you explain what cause this slight difference? thank u!
",1,accuracy  of train_mnist.py are different on single gpu and multi-gpus ,"accuracy  of train_mnist.py are different on single gpu and multi-gpus  I run the examples/image_classification/train_mnist.py on single gpu and double gpus. what out of my expectation is that accuracies are slightly different.(around 0.1% different). though it is not a big issue but still i am very confused because they should be completely equal in theory. can you explain what cause this slight difference? thank u!
"
incubator-mxnet,12612,"i use the dcgan.py to train dataset with mnist, after 25 epochs the netDs loss is a little high, and it looks like don`t converge 

below is netD loss and netG loss:
![d_and_g_loss](https://user-images.githubusercontent.com/28485566/45806511-d582e400-bcf3-11e8-9972-462bece22ccb.png)




",1,cannot converge use the dcgan with mnist and cifar10 dataset?,"cannot converge use the dcgan with mnist and cifar10 dataset? i use the dcgan.py to train dataset with mnist, after 25 epochs the netDs loss is a little high, and it looks like don`t converge 

below is netD loss and netG loss:
![d_and_g_loss](https://user-images.githubusercontent.com/28485566/45806511-d582e400-bcf3-11e8-9972-462bece22ccb.png)




"
incubator-mxnet,6975,"
## Environment info
Operating System:ubuntu14.04

Package used (Python/R/Scala/Julia):Python

MXNet version:0.10.1

Or if installed from source:install from source

If you are using python package, please provide

Python version and distribution:python 2.7


## Problem Message:
1. When I train a model in distribute computers in MXNet-0.10.1, I find it slower than train it in MXNet-0.9.4.
2. I use profile to analyze the program. In MXnet-0.10.1, I find the grad_arrays were pushed to kv-store after all the backward layers compute finished. So the compute can't cover the time of data communicate.
3. In MXNet-0.9.4 the grad_array in each convolution layer will push to kv-store directly after this layers' backward compute.
Why do I meet this problem and how to resolve it?",1,a problem in distribute training,"a problem in distribute training 
## Environment info
Operating System:ubuntu14.04

Package used (Python/R/Scala/Julia):Python

MXNet version:0.10.1

Or if installed from source:install from source

If you are using python package, please provide

Python version and distribution:python 2.7


## Problem Message:
1. When I train a model in distribute computers in MXNet-0.10.1, I find it slower than train it in MXNet-0.9.4.
2. I use profile to analyze the program. In MXnet-0.10.1, I find the grad_arrays were pushed to kv-store after all the backward layers compute finished. So the compute can't cover the time of data communicate.
3. In MXNet-0.9.4 the grad_array in each convolution layer will push to kv-store directly after this layers' backward compute.
Why do I meet this problem and how to resolve it?"
incubator-mxnet,3656,"I tried to learn mxnet on my data, but achieved only 50%.
This is my arch:

 
    


`

But i rly need mxnet, so my question is: ""What am i doing wrong?""
",1,accuracy level on 50%,"accuracy level on 50% I tried to learn mxnet on my data, but achieved only 50%.
This is my arch:

 
    


`

But i rly need mxnet, so my question is: ""What am i doing wrong?""
"
incubator-mxnet,1228,"Hey i'm quite new to mxnet, I followed the installation instructions and succeeded in installing it on windows 8.1 64 bit, I then ran the train_mnist.py --network lenet without a problem, quite slow but the accuracy at the end is good at around 99.2, but when I run it as --network lenet --gpus 0 to use my gpu its definitely a lot faster but the accuracy never gets above 10% which is terrible, there must be something wrong theoretically it should be the same accuracy right? I installed cuda 7.5 and also extracted cuddn v3 just as indicated, everything runs without a problem except the accuracy is terrible, i'm running on a laptop with a nvidia 660m graphics card, it has compute capability 3.0.

After running the file I get Train-accuracy=0.098825
",1,Windows GPU accuracy extremely bad,"Windows GPU accuracy extremely bad Hey i'm quite new to mxnet, I followed the installation instructions and succeeded in installing it on windows 8.1 64 bit, I then ran the train_mnist.py --network lenet without a problem, quite slow but the accuracy at the end is good at around 99.2, but when I run it as --network lenet --gpus 0 to use my gpu its definitely a lot faster but the accuracy never gets above 10% which is terrible, there must be something wrong theoretically it should be the same accuracy right? I installed cuda 7.5 and also extracted cuddn v3 just as indicated, everything runs without a problem except the accuracy is terrible, i'm running on a laptop with a nvidia 660m graphics card, it has compute capability 3.0.

After running the file I get Train-accuracy=0.098825
"
incubator-mxnet,11469,"## Description
There'a big performance regression in the Augmentation for RecordIO pipeline (slowing down from ~5000 samples/sec to ~3000 samples/sec for Resnet50 on Imagenet). This is linked to this PR https://github.com/apache/incubator-mxnet/pull/11027 

What the PR tries to do itself is not problematic, I can get 5k samples/sec with an older commit d37f3a3e63cef5a79c3e673cec30e70f8bf83b3e  on that PR from May24. But in the form it got merged in there's a big slowdown.

## Environment info 
Package used (Python/R/Scala/Julia): Python 3

## Build info
pip nightly (mxnet-cu90-1.3.0b20180627) , as well as built from source from master any commit after the above PR got merged

MXNet commit hash: N/A

Build config: Tried with and without USE_LIBJPEG_TURBO, using that increases the speed a bit (~3500), but still much slower than before. Also enabled USE_CUDA, USE_CUDNN

## Steps to reproduce


## What have you tried to solve it?
I've tried to profile it and see what might be wrong with the tool perf. It looks like opencv is causing a wait for some reason. Please see figure 3 

1.  Here's a perf summary now 
![image](https://user-images.githubusercontent.com/3457240/42059154-67db4e46-7ad7-11e8-875d-2ce64984cdfc.png)

2. Perf summary from the May 24 commit 
![image](https://user-images.githubusercontent.com/3457240/42059170-71a59904-7ad7-11e8-83da-e7701e8dc69a.png)

3. Call graph using perf
![image](https://user-images.githubusercontent.com/3457240/42059189-7e1170aa-7ad7-11e8-8f8a-aab7dbfddd2b.png)



@hetong007 @piiswrong Any ideas?",1,Performance regression in augmentation,"Performance regression in augmentation ## Description
There'a big performance regression in the Augmentation for RecordIO pipeline (slowing down from ~5000 samples/sec to ~3000 samples/sec for Resnet50 on Imagenet). This is linked to this PR https://github.com/apache/incubator-mxnet/pull/11027 

What the PR tries to do itself is not problematic, I can get 5k samples/sec with an older commit d37f3a3e63cef5a79c3e673cec30e70f8bf83b3e  on that PR from May24. But in the form it got merged in there's a big slowdown.

## Environment info 
Package used (Python/R/Scala/Julia): Python 3

## Build info
pip nightly (mxnet-cu90-1.3.0b20180627) , as well as built from source from master any commit after the above PR got merged

MXNet commit hash: N/A

Build config: Tried with and without USE_LIBJPEG_TURBO, using that increases the speed a bit (~3500), but still much slower than before. Also enabled USE_CUDA, USE_CUDNN

## Steps to reproduce


## What have you tried to solve it?
I've tried to profile it and see what might be wrong with the tool perf. It looks like opencv is causing a wait for some reason. Please see figure 3 

1.  Here's a perf summary now 
![image](https://user-images.githubusercontent.com/3457240/42059154-67db4e46-7ad7-11e8-875d-2ce64984cdfc.png)

2. Perf summary from the May 24 commit 
![image](https://user-images.githubusercontent.com/3457240/42059170-71a59904-7ad7-11e8-83da-e7701e8dc69a.png)

3. Call graph using perf
![image](https://user-images.githubusercontent.com/3457240/42059189-7e1170aa-7ad7-11e8-8f8a-aab7dbfddd2b.png)



@hetong007 @piiswrong Any ideas?"
incubator-mxnet,5074,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Ubuntu 14.04.5

Compiler:  gcc 4.8.4

Package used (Python/R/Scala/Julia): python

MXNet version: 

Or if installed from source:  installed by git clone https://github.com/dmlc/mxnet.git ~/mxnet --recursive

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution: python 2.7.13 anaconda 4.3.0

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
Build environment
nvidia 375.26, cuda 8.0, gcc 4.8.4, ubundu 14.04.5, cudnn 5.1

When I use 4 pascal GPUs ( Titan X) to retrain ResNet 50 from model_load_epoch=90 on imagenet'12 dataset. The speed is very slow. Furthermore, the accuracy is also wrong. The following picture shows two procedures. And there are two weird accuracy. ( MXNET is the latest version )

I don't know why. Before change to pascal GPU, I use 4 M40 GPU have no issue ( Old MXNET version, please see the second picture ) .

![image](https://cloud.githubusercontent.com/assets/3366247/23129516/f19b3afe-f7bd-11e6-9f29-e089c7888c68.png)

Obviously, this is an abnormal phenomenon.

Normally, the results should be shown following as 

![image](https://cloud.githubusercontent.com/assets/3366247/23129668/89631b9a-f7be-11e6-8c94-3951d057b8f8.png)


",1,Why is the training speed too slow and is the performance so weird on 4 Titan X GPU ?,"Why is the training speed too slow and is the performance so weird on 4 Titan X GPU ? For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Ubuntu 14.04.5

Compiler:  gcc 4.8.4

Package used (Python/R/Scala/Julia): python

MXNet version: 

Or if installed from source:  installed by git clone https://github.com/dmlc/mxnet.git ~/mxnet --recursive

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution: python 2.7.13 anaconda 4.3.0

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
Build environment
nvidia 375.26, cuda 8.0, gcc 4.8.4, ubundu 14.04.5, cudnn 5.1

When I use 4 pascal GPUs ( Titan X) to retrain ResNet 50 from model_load_epoch=90 on imagenet'12 dataset. The speed is very slow. Furthermore, the accuracy is also wrong. The following picture shows two procedures. And there are two weird accuracy. ( MXNET is the latest version )

I don't know why. Before change to pascal GPU, I use 4 M40 GPU have no issue ( Old MXNET version, please see the second picture ) .

![image](https://cloud.githubusercontent.com/assets/3366247/23129516/f19b3afe-f7bd-11e6-9f29-e089c7888c68.png)

Obviously, this is an abnormal phenomenon.

Normally, the results should be shown following as 

![image](https://cloud.githubusercontent.com/assets/3366247/23129668/89631b9a-f7be-11e6-8c94-3951d057b8f8.png)


"
incubator-mxnet,9171,"## Description
MXNet
Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging (i.e. infinite pause without progress/error/crash) of training run.

## Details
I am running a single training run of a Sequence-to-Sequence model using the BucketingModule. Iam using an Encoder-Decoder network. I am using a FusedRNNCell with its ""bidirectional"" flag turned on for the Encoder and an unfused RNNCell for the Decoder.
GPU utilization is 15000MB / 16000MB. CPU utilization is 95%.
For each batch during training, I do a forward() pass and a backward() pass. After a 5-15 epochs, the training run gets stuck in the forward() pass of one of the mini-batches. The forward pass does not complete. No errors are thrown nor does anything crash. GPU/CPU utilization remains identically the same.

I have tried an ablation of many-many things in my training run (architecture, data, code etc). The conclusion is that specifically using the FusedRNNCell with the ""bidirectional"" flag turned True causes this problem.


## Package used
Python

## Environment info
----------Python Info----------
Version      : 3.5.2
Compiler     : GCC 5.4.0 20160609
Build        : ('default', 'Nov 23 2017 16:37:01')
Arch         : ('64bit', 'ELF')
------------Pip Info-----------
Version      : 9.0.1
Directory    : /usr/local/lib/python3.5/dist-packages/pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : /usr/local/lib/python3.5/dist-packages/mxnet
Commit Hash   : 25720d0e3c29232a37e2650f3ba3a2454f9367bb
----------System Info----------
Platform     : Linux-4.4.0-1039-aws-x86_64-with-Ubuntu-16.04-xenial
system       : Linux
node         : ip-172-31-85-194
release      : 4.4.0-1039-aws
version      : #48-Ubuntu SMP Wed Oct 11 15:15:01 UTC 2017
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                64
On-line CPU(s) list:   0-63
Thread(s) per core:    2
Core(s) per socket:    16
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               1200.582
CPU max MHz:           3000.0000
CPU min MHz:           1200.0000
BogoMIPS:              4600.09
Hypervisor vendor:     Xen
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              46080K
NUMA node0 CPU(s):     0-15,32-47
NUMA node1 CPU(s):     16-31,48-63
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida
----------Network Test----------
Setting timeout: 10
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0300 sec, LOAD: 0.0514 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1141 sec, LOAD: 0.1956 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0016 sec, LOAD: 0.4062 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1799 sec, LOAD: 0.3847 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0046 sec, LOAD: 0.0126 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0154 sec, LOAD: 0.1567 sec.
`
",1,"MXNet: Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging of training run.","MXNet: Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging of training run. ## Description
MXNet
Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging (i.e. infinite pause without progress/error/crash) of training run.

## Details
I am running a single training run of a Sequence-to-Sequence model using the BucketingModule. Iam using an Encoder-Decoder network. I am using a FusedRNNCell with its ""bidirectional"" flag turned on for the Encoder and an unfused RNNCell for the Decoder.
GPU utilization is 15000MB / 16000MB. CPU utilization is 95%.
For each batch during training, I do a forward() pass and a backward() pass. After a 5-15 epochs, the training run gets stuck in the forward() pass of one of the mini-batches. The forward pass does not complete. No errors are thrown nor does anything crash. GPU/CPU utilization remains identically the same.

I have tried an ablation of many-many things in my training run (architecture, data, code etc). The conclusion is that specifically using the FusedRNNCell with the ""bidirectional"" flag turned True causes this problem.


## Package used
Python

## Environment info
----------Python Info----------
Version      : 3.5.2
Compiler     : GCC 5.4.0 20160609
Build        : ('default', 'Nov 23 2017 16:37:01')
Arch         : ('64bit', 'ELF')
------------Pip Info-----------
Version      : 9.0.1
Directory    : /usr/local/lib/python3.5/dist-packages/pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : /usr/local/lib/python3.5/dist-packages/mxnet
Commit Hash   : 25720d0e3c29232a37e2650f3ba3a2454f9367bb
----------System Info----------
Platform     : Linux-4.4.0-1039-aws-x86_64-with-Ubuntu-16.04-xenial
system       : Linux
node         : ip-172-31-85-194
release      : 4.4.0-1039-aws
version      : #48-Ubuntu SMP Wed Oct 11 15:15:01 UTC 2017
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                64
On-line CPU(s) list:   0-63
Thread(s) per core:    2
Core(s) per socket:    16
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               1200.582
CPU max MHz:           3000.0000
CPU min MHz:           1200.0000
BogoMIPS:              4600.09
Hypervisor vendor:     Xen
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              46080K
NUMA node0 CPU(s):     0-15,32-47
NUMA node1 CPU(s):     16-31,48-63
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida
----------Network Test----------
Setting timeout: 10
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0300 sec, LOAD: 0.0514 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1141 sec, LOAD: 0.1956 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0016 sec, LOAD: 0.4062 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1799 sec, LOAD: 0.3847 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0046 sec, LOAD: 0.0126 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0154 sec, LOAD: 0.1567 sec.
`
"
incubator-mxnet,12891,"Hi, I tried MXNet + MKLDNN on AVX 512 capable Windows machine, but performance was terrible. I noticed that MKLDNN pulled by mxnet is quite old, and older version of MKLDNN does not enable OpenMP on Windows (omp support was added in [this commit](https://github.com/intel/mkl-dnn/pull/260)). 

Do you have a plan to upgrade MKLDNN version?",1,[MKLDNN] Performance on Windows - Upgrading MKLDNN submodule?,"[MKLDNN] Performance on Windows - Upgrading MKLDNN submodule? Hi, I tried MXNet + MKLDNN on AVX 512 capable Windows machine, but performance was terrible. I noticed that MKLDNN pulled by mxnet is quite old, and older version of MKLDNN does not enable OpenMP on Windows (omp support was added in [this commit](https://github.com/intel/mkl-dnn/pull/260)). 

Do you have a plan to upgrade MKLDNN version?"
incubator-mxnet,16220,"## Description
 works very slow in imperative execution on GPU (~x3 slower than ReLU).
More details below

## Environment info (Required)



I'm using Python

## Build info (Required if built from source)
N/A

## Error Message:
Running GluonCV resnet18_v2 on ImageNet:
Imperative, with  as activation: throughput ~900 samples/sec.
~x3 slower compared to:
Imperative, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with  as activation: throughput ~3000 samples/sec.


## Minimum reproducible example / Steps to reproduce
1. Start an AWS p3.8xlarge with Deep Learning AMI (Ubuntu) Version 24.1 machine
2. Activate mxnet env: 
3. Install gluoncv: pip install gluoncv
4. Download train_imagenet.py from gluoncv: https://gluon-cv.mxnet.io/_downloads/3bb06a6d6d085b1bb501b30aaf6c21c5/train_imagenet.py (source: https://gluon-cv.mxnet.io/model_zoo/classification.html#imagenet )
5. Modify line 257 ( https://github.com/dmlc/gluon-cv/blob/745ed855d769534eb2e23f0c136cd5f1bc9b60b7/gluoncv/model_zoo/resnet.py#L257 ) in /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluoncv/model_zoo/resnet.py , replace  with 
6. run:



## What have you tried to solve it?
N/A

Might be related to #11683",1,`NDArray.clip()` works very slow in imperative execution on GPU.,"`NDArray.clip()` works very slow in imperative execution on GPU. ## Description
 works very slow in imperative execution on GPU (~x3 slower than ReLU).
More details below

## Environment info (Required)



I'm using Python

## Build info (Required if built from source)
N/A

## Error Message:
Running GluonCV resnet18_v2 on ImageNet:
Imperative, with  as activation: throughput ~900 samples/sec.
~x3 slower compared to:
Imperative, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with  as activation: throughput ~3000 samples/sec.


## Minimum reproducible example / Steps to reproduce
1. Start an AWS p3.8xlarge with Deep Learning AMI (Ubuntu) Version 24.1 machine
2. Activate mxnet env: 
3. Install gluoncv: pip install gluoncv
4. Download train_imagenet.py from gluoncv: https://gluon-cv.mxnet.io/_downloads/3bb06a6d6d085b1bb501b30aaf6c21c5/train_imagenet.py (source: https://gluon-cv.mxnet.io/model_zoo/classification.html#imagenet )
5. Modify line 257 ( https://github.com/dmlc/gluon-cv/blob/745ed855d769534eb2e23f0c136cd5f1bc9b60b7/gluoncv/model_zoo/resnet.py#L257 ) in /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluoncv/model_zoo/resnet.py , replace  with 
6. run:



## What have you tried to solve it?
N/A

Might be related to #11683"
incubator-mxnet,12255,"When i import mxnet in 8 processes simultaneously, all cpu resources will be used and the program stagnates for almost 5 minutes.

It works fine for mxnet1.1 but failed for mxnet1.2 and mxnet1.3
Following is the sample code



Any solution to this for mxnet1.2 and mxnet1.3? Thanks.",1,Pretty high cpu load when import mxnet,"Pretty high cpu load when import mxnet When i import mxnet in 8 processes simultaneously, all cpu resources will be used and the program stagnates for almost 5 minutes.

It works fine for mxnet1.1 but failed for mxnet1.2 and mxnet1.3
Following is the sample code



Any solution to this for mxnet1.2 and mxnet1.3? Thanks."
incubator-mxnet,3039,"It seems that mx.nd.zeros() runs pretty slow on GPU, rather than CPU.
Tested on my 980Ti and AWS g2.8xlarge instance (K520 GPU). CUDA 7.0/cudnn R5.
Python codes and results commented:


",1,mx.nd.zeros() slow on GPU,"mx.nd.zeros() slow on GPU It seems that mx.nd.zeros() runs pretty slow on GPU, rather than CPU.
Tested on my 980Ti and AWS g2.8xlarge instance (K520 GPU). CUDA 7.0/cudnn R5.
Python codes and results commented:


"
incubator-mxnet,1889,"Alright, I'm running the out-of-box CIFAR10 image training script on an 8 GPU system.

It seems like I'm getting the best performance using just 4 GPUs (graph attached.)  Is this expected to be expected or possibly i need to do some additional configuration ?  

Thanks !

![mxnet_cifar10_gpus](https://cloud.githubusercontent.com/assets/442121/14619220/4a43764e-056b-11e6-9fc1-f8259789ca7f.png)
",1,Benchmarking on 8 GPU System,"Benchmarking on 8 GPU System Alright, I'm running the out-of-box CIFAR10 image training script on an 8 GPU system.

It seems like I'm getting the best performance using just 4 GPUs (graph attached.)  Is this expected to be expected or possibly i need to do some additional configuration ?  

Thanks !

![mxnet_cifar10_gpus](https://cloud.githubusercontent.com/assets/442121/14619220/4a43764e-056b-11e6-9fc1-f8259789ca7f.png)
"
incubator-mxnet,4195,"Hi everyone, I want to use lstm and cnn to implement text recognition from image. for example recognize 'good' from a text image bounding box.
and I use warp-ctc as loss function but I find my softmax out are always the same.
## Environment info
Operating System: ubuntu 16.04

Compiler: gcc 5.4


Package used (Python/R/Scala/Julia): Python

MXNet commit hash (): 32cb6bc 

Python version and distribution: Python 2.7.11 |Anaconda 4.0.0 (x86_64)

## Error Message:
The following is my output of final fullyconnected layer as pred:

array([[ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       ..., 
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051]], dtype=float32))

0.01282051=1/78 as I have 78 different chars to classify.
my dataiter is based on bucket_io.py in rnn example dir, and lstm part is based on warp-ctc example.

## Minimum reproducible example

1.my network structure:

2.metric function:

3.DataIter:


## What have you tried to solve it?

1.I try to use bi-lstm but get the same output problem
2.do mxnet provide API to get the middle layers' output when fitting the model?",1,problem with bucketing lstm and cnn for text recognition,"problem with bucketing lstm and cnn for text recognition Hi everyone, I want to use lstm and cnn to implement text recognition from image. for example recognize 'good' from a text image bounding box.
and I use warp-ctc as loss function but I find my softmax out are always the same.
## Environment info
Operating System: ubuntu 16.04

Compiler: gcc 5.4


Package used (Python/R/Scala/Julia): Python

MXNet commit hash (): 32cb6bc 

Python version and distribution: Python 2.7.11 |Anaconda 4.0.0 (x86_64)

## Error Message:
The following is my output of final fullyconnected layer as pred:

array([[ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       ..., 
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051]], dtype=float32))

0.01282051=1/78 as I have 78 different chars to classify.
my dataiter is based on bucket_io.py in rnn example dir, and lstm part is based on warp-ctc example.

## Minimum reproducible example

1.my network structure:

2.metric function:

3.DataIter:


## What have you tried to solve it?

1.I try to use bi-lstm but get the same output problem
2.do mxnet provide API to get the middle layers' output when fitting the model?"
incubator-mxnet,2147,"I'm fine-tuning a model (based on Inception-BN) by using a image dataset with 10 classes (my case is a multi-class problem). I randomly split the whole dataset into training and test subsets. During the training phase, I observe that the training accuracy is very high (i.e., > 90%), while the validation accuracy is rather low (i.e., ~20%).

I also tried to use the model to predict tens of test images. It seems the prediction scores of the 10 classes are roughly the same for each test image, i.e., all the test images were predicted to be of the same class.

I've double checked the  files I generated. They are good. And also, for fine-tuning, I simply copied the Inception-BN symbol file into a new one and modified the last fully connected layer to have its  and its name renamed. Things look pretty good to me.. (what I did is very similar to fine-tuning in , i.e., only need to rename the fully connected layer and reset its  in ).

Did anyone encounter the same problem before? Thanks.
",1,High training accuracy but low validation accuracy?,"High training accuracy but low validation accuracy? I'm fine-tuning a model (based on Inception-BN) by using a image dataset with 10 classes (my case is a multi-class problem). I randomly split the whole dataset into training and test subsets. During the training phase, I observe that the training accuracy is very high (i.e., > 90%), while the validation accuracy is rather low (i.e., ~20%).

I also tried to use the model to predict tens of test images. It seems the prediction scores of the 10 classes are roughly the same for each test image, i.e., all the test images were predicted to be of the same class.

I've double checked the  files I generated. They are good. And also, for fine-tuning, I simply copied the Inception-BN symbol file into a new one and modified the last fully connected layer to have its  and its name renamed. Things look pretty good to me.. (what I did is very similar to fine-tuning in , i.e., only need to rename the fully connected layer and reset its  in ).

Did anyone encounter the same problem before? Thanks.
"
incubator-mxnet,14821,"Hello, I get a problem. 
When I run  under dir , it always gets stuck for many hours. 

Linux distro and version:
LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.2.1511 (Core)
Release:	7.2.1511
Codename:	Core

Other envirs:
GPU type: Tesla V100/P100
nvidia driver version: NVIDIA-SMI 410.48/384.81
CUDA version: 9.2/9.0
CUDNN version: 7.5.0/7.3.1
mxnet(using pip): mxnet-cu92/mxnet-cu90

Anyone can give some advises?",1, Always getting stuck for many hours when run `python lstm_ocr_train.py` under dir `example/ctc`," Always getting stuck for many hours when run `python lstm_ocr_train.py` under dir `example/ctc` Hello, I get a problem. 
When I run  under dir , it always gets stuck for many hours. 

Linux distro and version:
LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.2.1511 (Core)
Release:	7.2.1511
Codename:	Core

Other envirs:
GPU type: Tesla V100/P100
nvidia driver version: NVIDIA-SMI 410.48/384.81
CUDA version: 9.2/9.0
CUDNN version: 7.5.0/7.3.1
mxnet(using pip): mxnet-cu92/mxnet-cu90

Anyone can give some advises?"
incubator-mxnet,2277,"I find for some tasks, using multi-gpu will be slower than single GPU. What may be the main reason for this?

For example. I try to use mxnet to solve image caption problem. I find two strange results:
1. using large batch size (100) will be much slower than small batch size (4)
2. using 4 GPU will be much slower than use 1 GPU.

I other tasks, I does not find similar phenomenon.
",1,Running on multi-gpu is slower than single gpu,"Running on multi-gpu is slower than single gpu I find for some tasks, using multi-gpu will be slower than single GPU. What may be the main reason for this?

For example. I try to use mxnet to solve image caption problem. I find two strange results:
1. using large batch size (100) will be much slower than small batch size (4)
2. using 4 GPU will be much slower than use 1 GPU.

I other tasks, I does not find similar phenomenon.
"
incubator-mxnet,1767,"Hi all,

I tried to predict by using libmxnet_predict.so and libmxnet.so and I find libmxnet_predict.so is much slower than libmxnet.so.
I use inception-bn with  224*224 input image, I am run in CPU 0 and both share same predict.py script.
by using libmxnet.so. predict a image cost
    time elapsed: 0.445577.
by using  libmxnet_predict.so  predict a image cost
    time elapsed: 2.475879.
6 times slower than libmxnet.so I can't figure out what is wrong with libmxnet_predict.so , anybody have ideas ?

thank you in advance!
Haria
",1,Performance issue in libmxnet_predict.so,"Performance issue in libmxnet_predict.so Hi all,

I tried to predict by using libmxnet_predict.so and libmxnet.so and I find libmxnet_predict.so is much slower than libmxnet.so.
I use inception-bn with  224*224 input image, I am run in CPU 0 and both share same predict.py script.
by using libmxnet.so. predict a image cost
    time elapsed: 0.445577.
by using  libmxnet_predict.so  predict a image cost
    time elapsed: 2.475879.
6 times slower than libmxnet.so I can't figure out what is wrong with libmxnet_predict.so , anybody have ideas ?

thank you in advance!
Haria
"
incubator-mxnet,6888,"As input are sparse feature, the total parameters are 1.3G , the speed of distributed trainning are too slow.So mxnet can't support large parameters?
 ",1,distributed mxnet is too slow when parameter size are increased,"distributed mxnet is too slow when parameter size are increased As input are sparse feature, the total parameters are 1.3G , the speed of distributed trainning are too slow.So mxnet can't support large parameters?
 "
incubator-mxnet,8681,"i am training on a machine with P100. At the begining, the training speed is about 400images/secod. It decreases gradually to about 130 images/second at the 100 epoch. Some others user pytorch on the same machine did not meet this this problem. Anyone knows the possibile reasons? ",1,training on P100 gets slower and slower,"training on P100 gets slower and slower i am training on a machine with P100. At the begining, the training speed is about 400images/secod. It decreases gradually to about 130 images/second at the 100 epoch. Some others user pytorch on the same machine did not meet this this problem. Anyone knows the possibile reasons? "
incubator-mxnet,1516,"I tried to use Adam to replace sgd. I did nothing but replaced the optimiser, then I found the speed dropped too much, which was confusing. Using sgd, I got 0.6 sample per sec (I use a large input for fcn). Then using Adam, I got 0.4 sample per sec. I dont know if this makes sense, since the complexity of Adam seems not that high that caused so much difference in speed. Any idea?
",1,Why is Adam much slower than sgd?,"Why is Adam much slower than sgd? I tried to use Adam to replace sgd. I did nothing but replaced the optimiser, then I found the speed dropped too much, which was confusing. Using sgd, I got 0.6 sample per sec (I use a large input for fcn). Then using Adam, I got 0.4 sample per sec. I dont know if this makes sense, since the complexity of Adam seems not that high that caused so much difference in speed. Any idea?
"
incubator-mxnet,6892,"## Environment info
Ubuntu 16.04, GCC-5.4.0, MXNet 0.9.5, Python 2.7

## Error Message
I'd like to train a model without a metric, so I use the code just as follows. But I find that the memory usage keeps increasing until it's full. 

Then I define a class named 'NoMetric' as follows and use it as the metric.

But the memory still keeps increasing, so I try this:

Luckily, the memory usage doesn't increase anymore. But I want to know why I must call asnumpy()?


## Latest

I find that whether I use  or not, the memory keeps increasing. Similarly, if I use multi-process to read data in a queue for acceleration, this problem will also appear.

The latest version of MXNet doesn't fix my bug.
",1,Stop metric made increasing memory usage,"Stop metric made increasing memory usage ## Environment info
Ubuntu 16.04, GCC-5.4.0, MXNet 0.9.5, Python 2.7

## Error Message
I'd like to train a model without a metric, so I use the code just as follows. But I find that the memory usage keeps increasing until it's full. 

Then I define a class named 'NoMetric' as follows and use it as the metric.

But the memory still keeps increasing, so I try this:

Luckily, the memory usage doesn't increase anymore. But I want to know why I must call asnumpy()?


## Latest

I find that whether I use  or not, the memory keeps increasing. Similarly, if I use multi-process to read data in a queue for acceleration, this problem will also appear.

The latest version of MXNet doesn't fix my bug.
"
incubator-mxnet,10095,"As profiler shows, the ""nn.BatchNorm(axis=-1)"" will cause 10x lower speed on my application than ""nn.BatchNorm(axis=1)"".
However, We often need a ""nn.BatchNorm(axis=-1)"" after ""nn.Dense(flatten=False)"".",1,BatchNorm on axis=-1 is very slower than axis=1,"BatchNorm on axis=-1 is very slower than axis=1 As profiler shows, the ""nn.BatchNorm(axis=-1)"" will cause 10x lower speed on my application than ""nn.BatchNorm(axis=1)"".
However, We often need a ""nn.BatchNorm(axis=-1)"" after ""nn.Dense(flatten=False)""."
incubator-mxnet,1138,"Train-accuracy continues to increase but not for the Validation-accuracy. This is what I have observed from the log. Is this normal or did I miss something?  

I am using the following settings

python example/image-classification/train_imagenet.py --network inception-bn \
--data-dir /media/SSD/imagenet_mxnet/ --batch-size 128 --num-examples 1281167 \
--model-prefix imagenet --kv-store local_allreduce_device --lr-factor 0.9

2016-01-01 21:43:39,380 Node[0] Update[48956]: Change learning rate to 5.90490e-03
2016-01-01 21:43:49,904 Node[0] Epoch[4] Train-accuracy=0.548824
2016-01-01 21:43:49,904 Node[0] Epoch[4] Time cost=20670.702
2016-01-01 21:46:44,073 Node[0] Epoch[4] Validation-accuracy=0.406630

2016-01-02 03:30:58,979 Node[0] Update[58747]: Change learning rate to 5.31441e-03
2016-01-02 03:31:11,608 Node[0] Epoch[5] Train-accuracy=0.577686
2016-01-02 03:31:11,608 Node[0] Epoch[5] Time cost=20667.375
2016-01-02 03:34:05,323 Node[0] Epoch[5] Validation-accuracy=0.404347

2016-01-02 09:18:14,071 Node[0] Update[68538]: Change learning rate to 4.78297e-03
2016-01-02 09:18:28,803 Node[0] Epoch[6] Train-accuracy=0.600828
2016-01-02 09:18:28,803 Node[0] Epoch[6] Time cost=20663.319
2016-01-02 09:21:23,119 Node[0] Epoch[6] Validation-accuracy=0.380495

Thanks for the great tool you guys have developed
",1,Validation-accuracy on imagenet with inception-bn starts to drop after 5 epochs,"Validation-accuracy on imagenet with inception-bn starts to drop after 5 epochs Train-accuracy continues to increase but not for the Validation-accuracy. This is what I have observed from the log. Is this normal or did I miss something?  

I am using the following settings

python example/image-classification/train_imagenet.py --network inception-bn \
--data-dir /media/SSD/imagenet_mxnet/ --batch-size 128 --num-examples 1281167 \
--model-prefix imagenet --kv-store local_allreduce_device --lr-factor 0.9

2016-01-01 21:43:39,380 Node[0] Update[48956]: Change learning rate to 5.90490e-03
2016-01-01 21:43:49,904 Node[0] Epoch[4] Train-accuracy=0.548824
2016-01-01 21:43:49,904 Node[0] Epoch[4] Time cost=20670.702
2016-01-01 21:46:44,073 Node[0] Epoch[4] Validation-accuracy=0.406630

2016-01-02 03:30:58,979 Node[0] Update[58747]: Change learning rate to 5.31441e-03
2016-01-02 03:31:11,608 Node[0] Epoch[5] Train-accuracy=0.577686
2016-01-02 03:31:11,608 Node[0] Epoch[5] Time cost=20667.375
2016-01-02 03:34:05,323 Node[0] Epoch[5] Validation-accuracy=0.404347

2016-01-02 09:18:14,071 Node[0] Update[68538]: Change learning rate to 4.78297e-03
2016-01-02 09:18:28,803 Node[0] Epoch[6] Train-accuracy=0.600828
2016-01-02 09:18:28,803 Node[0] Epoch[6] Time cost=20663.319
2016-01-02 09:21:23,119 Node[0] Epoch[6] Validation-accuracy=0.380495

Thanks for the great tool you guys have developed
"
incubator-mxnet,11763,"
## Description
I run the  with  my own voc dataset. I handle on during the data read like fllow:

![image](https://user-images.githubusercontent.com/3112825/42734787-4d3dd150-887c-11e8-8b9a-0bf9409406f5.png)

![image](https://user-images.githubusercontent.com/3112825/42734807-7c3bbbb6-887c-11e8-9179-abeb78933e8c.png)



## Environment info (Required)



## Steps to reproduce
I write my own VOCDetection, here is the code:

foohttp://gluon-cv.mxnet.io/build/examples_datasets/index.html./transforms
and I replace the VOCDetection in .

## What have you tried to solve it?

1. I have add some display info to check my VOCDetection, It should be ok to produce the batch images and merge labels(bbox\cls label\...).
2. I add display info in  ， and it seem the  is a empty dict and when run the ， It will be hold on and never restore to run.
![image](https://user-images.githubusercontent.com/3112825/42734875-a82954da-887d-11e8-8004-e46abac52a11.png)

",1,"When Train SSD, It hold on during read the data","When Train SSD, It hold on during read the data 
## Description
I run the  with  my own voc dataset. I handle on during the data read like fllow:

![image](https://user-images.githubusercontent.com/3112825/42734787-4d3dd150-887c-11e8-8b9a-0bf9409406f5.png)

![image](https://user-images.githubusercontent.com/3112825/42734807-7c3bbbb6-887c-11e8-9179-abeb78933e8c.png)



## Environment info (Required)



## Steps to reproduce
I write my own VOCDetection, here is the code:

foohttp://gluon-cv.mxnet.io/build/examples_datasets/index.html./transforms
and I replace the VOCDetection in .

## What have you tried to solve it?

1. I have add some display info to check my VOCDetection, It should be ok to produce the batch images and merge labels(bbox\cls label\...).
2. I add display info in  ， and it seem the  is a empty dict and when run the ， It will be hold on and never restore to run.
![image](https://user-images.githubusercontent.com/3112825/42734875-a82954da-887d-11e8-8004-e46abac52a11.png)

"
incubator-mxnet,5747,"@piiswrong I have some questions about :

 * If , is the data shuffled after every epoch? 
 * Speed when using multiple  in different jobs. When I launch a second training job, it uses different CSV file, the training speed drops, is it normal? And why?

",1,Questions about CSVIter,"Questions about CSVIter @piiswrong I have some questions about :

 * If , is the data shuffled after every epoch? 
 * Speed when using multiple  in different jobs. When I launch a second training job, it uses different CSV file, the training speed drops, is it normal? And why?

"
incubator-mxnet,14838,"We have recently found a performance regression on training imagenet with resnet50v1 when upgrading from **cudnn 7.3.1 to 7.5.0**

**Speed droped from ~5800 images/s to ~4800 images/s**

Environment is AWS DLAMI with AMI ID : ami-2dcceb57 (available in us-east)


command:

code at: https://github.com/rahul003/deep-learning-benchmark-mirror/blob/master/mxnet_benchmark/train_imagenet.py

our nightly pip packages were impacted because now we are building with cuddn 7.5.0.
Stable version of mxnet pip packages are not impacted.

I m using this issue to keep track so everyone can be updated.

cc
@szha @DickJC123 @stu1130 @pinaraws",1,regression from cudnn upgrade from 7.3.1 to 7.5.0,"regression from cudnn upgrade from 7.3.1 to 7.5.0 We have recently found a performance regression on training imagenet with resnet50v1 when upgrading from **cudnn 7.3.1 to 7.5.0**

**Speed droped from ~5800 images/s to ~4800 images/s**

Environment is AWS DLAMI with AMI ID : ami-2dcceb57 (available in us-east)


command:

code at: https://github.com/rahul003/deep-learning-benchmark-mirror/blob/master/mxnet_benchmark/train_imagenet.py

our nightly pip packages were impacted because now we are building with cuddn 7.5.0.
Stable version of mxnet pip packages are not impacted.

I m using this issue to keep track so everyone can be updated.

cc
@szha @DickJC123 @stu1130 @pinaraws"
incubator-mxnet,14073,"Currently, given fp16 inputs, nd.LayerNorm/sym.LayerNorm perform reduction in fp16, which losses precision. The reduction should be done in fp32 instead. @sxjscience ",1,Fp16 support for layernorm,"Fp16 support for layernorm Currently, given fp16 inputs, nd.LayerNorm/sym.LayerNorm perform reduction in fp16, which losses precision. The reduction should be done in fp32 instead. @sxjscience "
incubator-mxnet,16891,"## Description
The change that upgraded MKLDNN to 1.0 caused performance (images/sec) to drop by 200 points. 

### Error Message
The through-put performance (images/sec) during training dropped to 1300 images/sec.
Prior to this change the throughput was in the range of 1500-1530 images/sec.


## To Reproduce

The attached gzip file contains the training script that trains resnet18_v2 network on Cifar10 dataset.
[image_classification.tar.gz](https://github.com/apache/incubator-mxnet/files/3881313/image_classification.tar.gz)
The above numbers were measured on C5.18xlarge ubuntu instance.


### Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Build and install the mxnet-mkl pip wheel that contains the above changes on the test machine.
2. Unzip the attached gzip file on the test machine.
3. Install the psutil and gluoncv and Export the KMP_AFFINITY anf OMP_NUM_THREADS variable as below.

4. Run the following command to start the training.



The sample output looks like below.


## Environment
1. c5.18xlarge
2. ubuntu 14.04 LTS


",1,Upgrading MKLDNN to 1.0 causes performance regression.,"Upgrading MKLDNN to 1.0 causes performance regression. ## Description
The change that upgraded MKLDNN to 1.0 caused performance (images/sec) to drop by 200 points. 

### Error Message
The through-put performance (images/sec) during training dropped to 1300 images/sec.
Prior to this change the throughput was in the range of 1500-1530 images/sec.


## To Reproduce

The attached gzip file contains the training script that trains resnet18_v2 network on Cifar10 dataset.
[image_classification.tar.gz](https://github.com/apache/incubator-mxnet/files/3881313/image_classification.tar.gz)
The above numbers were measured on C5.18xlarge ubuntu instance.


### Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Build and install the mxnet-mkl pip wheel that contains the above changes on the test machine.
2. Unzip the attached gzip file on the test machine.
3. Install the psutil and gluoncv and Export the KMP_AFFINITY anf OMP_NUM_THREADS variable as below.

4. Run the following command to start the training.



The sample output looks like below.


## Environment
1. c5.18xlarge
2. ubuntu 14.04 LTS


"
incubator-mxnet,3325,"I training my model with a mpi cluster of 10 machines.  Because the training dataset is very large, distributing the whole  to each machine requires much time and space. So I manually split the  into 10 non-overlap text file such as  . Then I use  to make 10 ImageRecordIO dataset.

When training with multi machine, in each machine it will download  and use it as the source of training iterator. I don't forget to change the parameters  and    as  of the training ImageRecordIter. 
I don't change the validation dataset. I distribute the complete  to each machine.

So I believe the training procedure should be roughly same as when I use only one . 
But the result is disappointing. The training accuracy curve is good, even slightly better than previous. However the validation curve is much worse. 
![image](https://cloud.githubusercontent.com/assets/3807357/18622871/2e7c70e8-7e68-11e6-9d02-0ef70b3edfcf.png)
The blue curves are the training and val curves when I use one complete  while red curves are those when using splited ....
Is there any mistake that I may have?
",1,Low validation accuracy if I split the training data manually when training with multi-machine,"Low validation accuracy if I split the training data manually when training with multi-machine I training my model with a mpi cluster of 10 machines.  Because the training dataset is very large, distributing the whole  to each machine requires much time and space. So I manually split the  into 10 non-overlap text file such as  . Then I use  to make 10 ImageRecordIO dataset.

When training with multi machine, in each machine it will download  and use it as the source of training iterator. I don't forget to change the parameters  and    as  of the training ImageRecordIter. 
I don't change the validation dataset. I distribute the complete  to each machine.

So I believe the training procedure should be roughly same as when I use only one . 
But the result is disappointing. The training accuracy curve is good, even slightly better than previous. However the validation curve is much worse. 
![image](https://cloud.githubusercontent.com/assets/3807357/18622871/2e7c70e8-7e68-11e6-9d02-0ef70b3edfcf.png)
The blue curves are the training and val curves when I use one complete  while red curves are those when using splited ....
Is there any mistake that I may have?
"
incubator-mxnet,10839,"Instead of using the cached Dockerfiles, make a run that downloads and installs everything from scratch. This ensure that all third party dependencies are actually still valid.

See https://github.com/apache/incubator-mxnet/issues/10837 for an example",0,Execute all runs in CI without cache as part of nightly,"Execute all runs in CI without cache as part of nightly Instead of using the cached Dockerfiles, make a run that downloads and installs everything from scratch. This ensure that all third party dependencies are actually still valid.

See https://github.com/apache/incubator-mxnet/issues/10837 for an example"
incubator-mxnet,9335,"I want to use the same sequence of mini-batches to compare the performance of different optimizers.
I used ""mxnet.random.seed(1)"".
However, it only works for the initializer.
For mxnet.gluon.data.DataLoader with shuffle=True, it needs an extra ""import random; random.seed(1);""",0,mxnet.random.seed() doesn't work for mxnet.gluon.data.DataLoader with shuffle=True,"mxnet.random.seed() doesn't work for mxnet.gluon.data.DataLoader with shuffle=True I want to use the same sequence of mini-batches to compare the performance of different optimizers.
I used ""mxnet.random.seed(1)"".
However, it only works for the initializer.
For mxnet.gluon.data.DataLoader with shuffle=True, it needs an extra ""import random; random.seed(1);"""
incubator-mxnet,14704,"Some docstrings can still be improved for better user experience. Adding parameter descriptions and examples in docstrings.

Example:
modopts-mapkvstoreoptimizersgdreset-optimizertruerescaleGradidx2nameforce-initfalse

Below is a list of namespaces that still need to be improved:

- [ ] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] ",0,[clojure][documentation] improve docstrings,"[clojure][documentation] improve docstrings Some docstrings can still be improved for better user experience. Adding parameter descriptions and examples in docstrings.

Example:
modopts-mapkvstoreoptimizersgdreset-optimizertruerescaleGradidx2nameforce-initfalse

Below is a list of namespaces that still need to be improved:

- [ ] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] "
incubator-mxnet,16431,"Thanks to @nswamy for his inputs and design discussions related to this project and @frankfliu for explaining the requirements and the use case from customer perspective.

# Problem Statement

One of the big un-catered for use cases in MXNet is loading a model and being able to run parallel inference on the model from multiple threads while sharing the parameters. There are multiple user requests for the same [[1]](https://github.com/apache/incubator-mxnet/issues/3946). There also has been a lot of confusion around the current state of MXNet with respect to thread safety.

This doc attempts to address three things : 

1. Tries to clarify the current state of MXNet with respect to thread safety.
2. Tries to give an idea of the benefits to expect from adding this feature.
3. Attempts to solve the problem of parallel inference by providing a multi-threaded inference API ( C APIs and frontend APIs in CPP and Python), 

# Current State of MXNet Thread Safety

## MXNet Dependency Engine Thread Safety

Examining MXNet dependency engine code, it looks like it was designed  to be thread safe. Tried to push Convolution op from multiple threads into MXNet Engine, to see if there are any issues with thread safety. Used CPP Package for the same. The script is provided here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_mxnet_op.cpp



The script pushes Convolution op to the engine from multiple threads. You can verify the correctness of the op with this script : 
https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_cached_op_ts_check.py



## MXNet Graph Executor Thread Safety

Removed NaiveEngine only restriction for C Predict API and tried to run multi threaded inference with C Predict API using ThreadedEngine by commenting the check : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/c_api/c_predict_api.cc

When running this example the program core dumps with memory leaks in Graph Executor Bind. This shows that graph executor is not thread safe. 

## Cached Op (Gluon Backend) Thread Safety

Try to create cached op in the main thread and spawn multiple threads to invoke the same cached op inside each of the threads. Here is the script which does the same : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp



Multiple failures seen when I run this: one is in the dmlc ThreadLocalStore [[2]](https://github.com/dmlc/dmlc-core/issues/571),  other is in MXPlanMemory, retrieving forward_ref_count attribute. These errors are because of race condition w.r.t reading and writing of shared states in CachedOp.

# Proposed Solution

### Additions (Prioritized for 1.6)

Proposing to add a minimal thread safe cached op for inference which will be the following :
1. Similar to cached op, except it supports only inference use cases. 
2. Doesn’t support inlining, dynamic shapes, bulking, static alloc. 
3. Use static thread_local variables for GraphInfo which maintains the fwd_graph state, buff which maintains all ndarray states and for op_states. [ There is scope for additional optimization here w.r.t separation of buffers for inputs and params]
4. The above addition means that we can instantiate only one thread safe cached op per process. The frontend API for SymbolBlockThreadSafe needs to be a singleton because of this limitation.

### C API Changes (Prioritized for 1.6)

Adding a new thread_safe flag for MXCreateCachedOpEx. When set to true this should create a thread_safe cached op instead of a cached op.



Add similar thread_safe flag flags to Invoke and Free to invoke thread safe cached op versions instead of the default versions. 



#### Please see the PoC here for details:

1. Thread Safe Cached Op Code : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.h , https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.cc
2. Example Code for invoking Cached Op inference from multiple threads : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp 



#### Use Cases Tested:

1. Create cached op with a single op (Convolution) from main thread. Spawn additional threads and invoke cached op from each thread.
2. Create cached op with a full model (resnet-18) from main thread. Spawn additional threads and invoke cached op from each thread.

### CPP Frontend Changes (Priority for 1.6)

1. Add a singleton SymbolBlock (ThreadSafe version) with an imports API like in python, targeted for Inference.
2. Params will be loaded using ndarray module.
3. Initially only one context is supported but this can be extended to multi context.
4. Forward call will invoke CachedOp passing the input ndarrays and param ndarrays.
5. Initially sparse storage types won’t be supported and casting won’t be supported.
6. Will be added to the contrib API.

@access2rohit will be helping me with the CPP API changes.

### Python Frontend Changes (Lower Priority, Post 1.6)

1. Add a SymbolBlock (threadsafe version, singleton) inheriting the SymbolBlock with imports and forward API. 
2. Here is a PoC: https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/python/mxnet/gluon/contrib/block.py  and an example of how to call it : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
3. The PoC is currently not functioning and hangs randomly. This could be because of WaitForVar and WaitForAll thread safety issues and/or the cross device copy thread safety issues and/or issues with usage of python thread local. This requires some more investigation.

# Existing Issues

1. dmlc-core ThreadLocalStore issue[[2]](https://github.com/dmlc/dmlc-core/issues/571) . Reverting back to MX_THREAD_LOCAL fixes the issue but need to explore additional downsides of reverting back. (HIGH PRIORITY FOR 1.6) : Addressed in (https://github.com/apache/incubator-mxnet/pull/16526)
2. WaitForVar and WaitForAll are not thread safe. (HIGH PRIORITY FOR 1.6). [[3]](https://github.com/apache/incubator-mxnet/issues/16434)
3. Python API Issues mentioned above. (LOWER PRIORITY, POST 1.6).

# Expected Benefits

One big benefit is being able to run inference on the same model with shared params from multiple threads. Current approach is to use multiprocessing library and import mxnet in each process. This saves a lot of memory footprint and improves the throughput for inference on a single machine. To obtain some numbers I wrote a multiprocessing script in python to load model and run inference from multiple processes. 

Please see here for the python script : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
This runs out of memory with 12 parallel inferences. 

When running the same model inference on CPP, please see example here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op_full_model.cpp



This is able to run more than 960 parallel inferences though there is an increased latency with higher number of parallel inferences.


# Model Coverage

|Models Tested|MKLDNN|CUDNN|NO-CUDNN|
| --- | --- | --- | --- |
| resnet-18 | Yes | Yes | Yes |

This is a work in progress list and more models will be added to this list.

# What will not be supported for 1.6 ?

Since, this is a new interface where many things can go wrong, we are starting small here and will incrementally add support. Lot of these features may just work but requires some effort with verification and won't be feasible for 1.6.

1. Only operators tested with the existing model coverage are supported. Other operators (stateful operators, custom operators) not supported.
2. Only dense storage types supported currently.
3. Multi GPU inference not supported currently.
4. Instantiating multiple instances of SymbolBlockThreadsafe is not supported. Can run parallel inference only on one model per process.
5. dynamic shapes not supported.
6. static_alloc and static_shape not supported.
7. Bulking of ops is not supported.
8. This is only for inference use cases, backward pass/training use cases not supported.
9. graph rewrites with subgraph api currently not supported.
10. Python Frontend Changes


# References 

1. https://github.com/apache/incubator-mxnet/issues/3946
2. https://github.com/dmlc/dmlc-core/issues/571
3. https://github.com/apache/incubator-mxnet/issues/16434
",0,[RFC] MXNet Multithreaded Inference Interface,"[RFC] MXNet Multithreaded Inference Interface Thanks to @nswamy for his inputs and design discussions related to this project and @frankfliu for explaining the requirements and the use case from customer perspective.

# Problem Statement

One of the big un-catered for use cases in MXNet is loading a model and being able to run parallel inference on the model from multiple threads while sharing the parameters. There are multiple user requests for the same [[1]](https://github.com/apache/incubator-mxnet/issues/3946). There also has been a lot of confusion around the current state of MXNet with respect to thread safety.

This doc attempts to address three things : 

1. Tries to clarify the current state of MXNet with respect to thread safety.
2. Tries to give an idea of the benefits to expect from adding this feature.
3. Attempts to solve the problem of parallel inference by providing a multi-threaded inference API ( C APIs and frontend APIs in CPP and Python), 

# Current State of MXNet Thread Safety

## MXNet Dependency Engine Thread Safety

Examining MXNet dependency engine code, it looks like it was designed  to be thread safe. Tried to push Convolution op from multiple threads into MXNet Engine, to see if there are any issues with thread safety. Used CPP Package for the same. The script is provided here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_mxnet_op.cpp



The script pushes Convolution op to the engine from multiple threads. You can verify the correctness of the op with this script : 
https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_cached_op_ts_check.py



## MXNet Graph Executor Thread Safety

Removed NaiveEngine only restriction for C Predict API and tried to run multi threaded inference with C Predict API using ThreadedEngine by commenting the check : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/c_api/c_predict_api.cc

When running this example the program core dumps with memory leaks in Graph Executor Bind. This shows that graph executor is not thread safe. 

## Cached Op (Gluon Backend) Thread Safety

Try to create cached op in the main thread and spawn multiple threads to invoke the same cached op inside each of the threads. Here is the script which does the same : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp



Multiple failures seen when I run this: one is in the dmlc ThreadLocalStore [[2]](https://github.com/dmlc/dmlc-core/issues/571),  other is in MXPlanMemory, retrieving forward_ref_count attribute. These errors are because of race condition w.r.t reading and writing of shared states in CachedOp.

# Proposed Solution

### Additions (Prioritized for 1.6)

Proposing to add a minimal thread safe cached op for inference which will be the following :
1. Similar to cached op, except it supports only inference use cases. 
2. Doesn’t support inlining, dynamic shapes, bulking, static alloc. 
3. Use static thread_local variables for GraphInfo which maintains the fwd_graph state, buff which maintains all ndarray states and for op_states. [ There is scope for additional optimization here w.r.t separation of buffers for inputs and params]
4. The above addition means that we can instantiate only one thread safe cached op per process. The frontend API for SymbolBlockThreadSafe needs to be a singleton because of this limitation.

### C API Changes (Prioritized for 1.6)

Adding a new thread_safe flag for MXCreateCachedOpEx. When set to true this should create a thread_safe cached op instead of a cached op.



Add similar thread_safe flag flags to Invoke and Free to invoke thread safe cached op versions instead of the default versions. 



#### Please see the PoC here for details:

1. Thread Safe Cached Op Code : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.h , https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.cc
2. Example Code for invoking Cached Op inference from multiple threads : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp 



#### Use Cases Tested:

1. Create cached op with a single op (Convolution) from main thread. Spawn additional threads and invoke cached op from each thread.
2. Create cached op with a full model (resnet-18) from main thread. Spawn additional threads and invoke cached op from each thread.

### CPP Frontend Changes (Priority for 1.6)

1. Add a singleton SymbolBlock (ThreadSafe version) with an imports API like in python, targeted for Inference.
2. Params will be loaded using ndarray module.
3. Initially only one context is supported but this can be extended to multi context.
4. Forward call will invoke CachedOp passing the input ndarrays and param ndarrays.
5. Initially sparse storage types won’t be supported and casting won’t be supported.
6. Will be added to the contrib API.

@access2rohit will be helping me with the CPP API changes.

### Python Frontend Changes (Lower Priority, Post 1.6)

1. Add a SymbolBlock (threadsafe version, singleton) inheriting the SymbolBlock with imports and forward API. 
2. Here is a PoC: https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/python/mxnet/gluon/contrib/block.py  and an example of how to call it : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
3. The PoC is currently not functioning and hangs randomly. This could be because of WaitForVar and WaitForAll thread safety issues and/or the cross device copy thread safety issues and/or issues with usage of python thread local. This requires some more investigation.

# Existing Issues

1. dmlc-core ThreadLocalStore issue[[2]](https://github.com/dmlc/dmlc-core/issues/571) . Reverting back to MX_THREAD_LOCAL fixes the issue but need to explore additional downsides of reverting back. (HIGH PRIORITY FOR 1.6) : Addressed in (https://github.com/apache/incubator-mxnet/pull/16526)
2. WaitForVar and WaitForAll are not thread safe. (HIGH PRIORITY FOR 1.6). [[3]](https://github.com/apache/incubator-mxnet/issues/16434)
3. Python API Issues mentioned above. (LOWER PRIORITY, POST 1.6).

# Expected Benefits

One big benefit is being able to run inference on the same model with shared params from multiple threads. Current approach is to use multiprocessing library and import mxnet in each process. This saves a lot of memory footprint and improves the throughput for inference on a single machine. To obtain some numbers I wrote a multiprocessing script in python to load model and run inference from multiple processes. 

Please see here for the python script : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
This runs out of memory with 12 parallel inferences. 

When running the same model inference on CPP, please see example here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op_full_model.cpp



This is able to run more than 960 parallel inferences though there is an increased latency with higher number of parallel inferences.


# Model Coverage

|Models Tested|MKLDNN|CUDNN|NO-CUDNN|
| --- | --- | --- | --- |
| resnet-18 | Yes | Yes | Yes |

This is a work in progress list and more models will be added to this list.

# What will not be supported for 1.6 ?

Since, this is a new interface where many things can go wrong, we are starting small here and will incrementally add support. Lot of these features may just work but requires some effort with verification and won't be feasible for 1.6.

1. Only operators tested with the existing model coverage are supported. Other operators (stateful operators, custom operators) not supported.
2. Only dense storage types supported currently.
3. Multi GPU inference not supported currently.
4. Instantiating multiple instances of SymbolBlockThreadsafe is not supported. Can run parallel inference only on one model per process.
5. dynamic shapes not supported.
6. static_alloc and static_shape not supported.
7. Bulking of ops is not supported.
8. This is only for inference use cases, backward pass/training use cases not supported.
9. graph rewrites with subgraph api currently not supported.
10. Python Frontend Changes


# References 

1. https://github.com/apache/incubator-mxnet/issues/3946
2. https://github.com/dmlc/dmlc-core/issues/571
3. https://github.com/apache/incubator-mxnet/issues/16434
"
incubator-mxnet,7445,"@piiswrong, @szha: Now that cuDNN 7 supports CTC loss, perhaps we should discard the current GPU implementation in contrib.ctc_loss (adapted from the WarpCTC implementation) and only use cuDNN for GPU? The main reasons:
1) it requires maintenance effort to ensure the GPU implementation works on new GPU architectures, requiring careful updating of dependencies (like modern gpu). 
2) Users are still reporting problems with memset issues when using the WarpCTC plugin (#6121)

I don't think the maintenance effort is worthwhile if almost every single user training with CUDA will have cuDNN.

What are your thoughts?

",0,Using cuDNN for CTC Loss,"Using cuDNN for CTC Loss @piiswrong, @szha: Now that cuDNN 7 supports CTC loss, perhaps we should discard the current GPU implementation in contrib.ctc_loss (adapted from the WarpCTC implementation) and only use cuDNN for GPU? The main reasons:
1) it requires maintenance effort to ensure the GPU implementation works on new GPU architectures, requiring careful updating of dependencies (like modern gpu). 
2) Users are still reporting problems with memset issues when using the WarpCTC plugin (#6121)

I don't think the maintenance effort is worthwhile if almost every single user training with CUDA will have cuDNN.

What are your thoughts?

"
incubator-mxnet,9937,"My system is Ubuntu 16.04. 
when I run code 

I got the error 


g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/nn/softmax.cc -o build/src/operator/nn/softmax.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/mkl/mkl_memory.cc -o build/src/operator/mkl/mkl_memory.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_broadcast_op_basic.cc -o build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_op_extended.cc -o build/src/operator/tensor/elemwise_binary_op_extended.o
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/base.h:13,
                 from src/operator/nn/./../mxnet_op.h:10,
                 from src/operator/nn/./softmax-inl.h:11,
                 from src/operator/nn/softmax.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/nn/softmax.o' failed
make: *** [build/src/operator/nn/softmax.o] Error 1
make: *** Waiting for unfinished jobs....
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator.h:19,
                 from src/operator/mkl/../operator_common.h:13,
                 from src/operator/mkl/mkl_memory.cc:22:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/mkl/mkl_memory.o' failed
make: *** [build/src/operator/mkl/mkl_memory.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_broadcast_op_basic.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_op_extended.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_op_extended.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_op_extended.o] Error 1


how can I solve this problem",0,fatal error: cblas.h: No such file or directory,"fatal error: cblas.h: No such file or directory My system is Ubuntu 16.04. 
when I run code 

I got the error 


g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/nn/softmax.cc -o build/src/operator/nn/softmax.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/mkl/mkl_memory.cc -o build/src/operator/mkl/mkl_memory.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_broadcast_op_basic.cc -o build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_op_extended.cc -o build/src/operator/tensor/elemwise_binary_op_extended.o
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/base.h:13,
                 from src/operator/nn/./../mxnet_op.h:10,
                 from src/operator/nn/./softmax-inl.h:11,
                 from src/operator/nn/softmax.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/nn/softmax.o' failed
make: *** [build/src/operator/nn/softmax.o] Error 1
make: *** Waiting for unfinished jobs....
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator.h:19,
                 from src/operator/mkl/../operator_common.h:13,
                 from src/operator/mkl/mkl_memory.cc:22:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/mkl/mkl_memory.o' failed
make: *** [build/src/operator/mkl/mkl_memory.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_broadcast_op_basic.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_op_extended.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_op_extended.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_op_extended.o] Error 1


how can I solve this problem"
incubator-mxnet,13743,"In the windows-GPU stage of the CI, different  tests fail.

 fails on commit  but passes after updating README
https://github.com/apache/incubator-mxnet/pull/13595
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13595/9/pipeline


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13681/37/pipeline

Seems to only occur on windows GPU build.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",0,Flaky test in windows GPU CI,"Flaky test in windows GPU CI In the windows-GPU stage of the CI, different  tests fail.

 fails on commit  but passes after updating README
https://github.com/apache/incubator-mxnet/pull/13595
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13595/9/pipeline


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13681/37/pipeline

Seems to only occur on windows GPU build.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,11843,"## Description
The mxnet-to-coreml package under tools/coreml does not have CI and new releases that breaks this package directly affects its customers. (See issue [10349](https://github.com/apache/incubator-mxnet/issues/10349)). We should add tests of this package to our CI system.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
e4134c8270c1b944278b1e0331313074b1d97cc0",0,No CI for tools/coreml package,"No CI for tools/coreml package ## Description
The mxnet-to-coreml package under tools/coreml does not have CI and new releases that breaks this package directly affects its customers. (See issue [10349](https://github.com/apache/incubator-mxnet/issues/10349)). We should add tests of this package to our CI system.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
e4134c8270c1b944278b1e0331313074b1d97cc0"
incubator-mxnet,14484,"## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
",0,Odd behaviour with 'device' kvstore and CUDA illegal memory access errors,"Odd behaviour with 'device' kvstore and CUDA illegal memory access errors ## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
"
incubator-mxnet,14981,"## Description

Test Large Tensor: GPU step is failing with:



see http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTestsForBinaries/detail/master/312/pipeline/144 for the full log
",0,[CI][NightlyTestsForBinaries] Test Large Tensor: GPU Failing,"[CI][NightlyTestsForBinaries] Test Large Tensor: GPU Failing ## Description

Test Large Tensor: GPU step is failing with:



see http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTestsForBinaries/detail/master/312/pipeline/144 for the full log
"
incubator-mxnet,4105,"I want to create a custom iterator in R. As an initial example I will use the MNIST data. 

What I would like to do is an iterator that gets as input the raw data, that would be a matrix of 60000 examples times 784 which is each image expanded in a vector:
 
and whose output, in every iteration, would be a matrix of :

 
The only operation that I have to do inside the iterator is the following:

 
I don´t know if there is a way to reimplement the operator  or  in R. I know that that can be done in python and C++, but not sure how to do it in R. 

The interface should be something like:

 

Any help appreciated :) @piiswrong @thirdwing 
",0,[R] Data augmentation with basic MNIST example,"[R] Data augmentation with basic MNIST example I want to create a custom iterator in R. As an initial example I will use the MNIST data. 

What I would like to do is an iterator that gets as input the raw data, that would be a matrix of 60000 examples times 784 which is each image expanded in a vector:
 
and whose output, in every iteration, would be a matrix of :

 
The only operation that I have to do inside the iterator is the following:

 
I don´t know if there is a way to reimplement the operator  or  in R. I know that that can be done in python and C++, but not sure how to do it in R. 

The interface should be something like:

 

Any help appreciated :) @piiswrong @thirdwing 
"
incubator-mxnet,10101,"Dear all, it would be very useful if one could add NN layers of a gluon custom model inside a list, similar to , something like: 


I can think of many use cases, but one important one is indexing for neuroevolution problems, i.e. using a variable architecture of a specified set of layers. 

Thank you very much for the great work you put into gluon/mxnet. ",0,gluon feature request: proper registration/initialization of layers inside a list (container) for custom (Hybrid)Blocks,"gluon feature request: proper registration/initialization of layers inside a list (container) for custom (Hybrid)Blocks Dear all, it would be very useful if one could add NN layers of a gluon custom model inside a list, similar to , something like: 


I can think of many use cases, but one important one is indexing for neuroevolution problems, i.e. using a variable architecture of a specified set of layers. 

Thank you very much for the great work you put into gluon/mxnet. "
incubator-mxnet,6918,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: CentOS release 6.9 (Final)

Compiler: gcc version 4.9.2 20150212 (Red Hat 4.9.2-6) (GCC)

Package used (Python/R/Scala/Julia): R

MXNet version: 0.10

Or if installed from source: 

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide 3.4

R :
> sessionInfo(package=NULL)
R version 3.4.0 (2017-04-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.9 (Final)

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] drat_0.1.2     compiler_3.4.0 tools_3.4.0


## Error Message:
Please paste the full error message, including stack trace.
Warning message:
package ‘mxnet’ is not available (for R version 3.4.0)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. From R console I entered the following commands:
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
2.
3.

## What have you tried to solve it?

1. Attempted to install from source and received the following error message when running the make rpkg command:

mkdir -p R-package/inst
mkdir -p R-package/inst/libs
cp -rf lib/libmxnet.so R-package/inst/libs
mkdir -p R-package/inst/include
cp -rf include/* R-package/inst/include
cp -rf dmlc-core/include/* R-package/inst/include/
cp -rf nnvm/include/* R-package/inst/include
echo ""import(Rcpp)"" > R-package/NAMESPACE
echo ""import(methods)"" >> R-package/NAMESPACE
R CMD INSTALL R-package
make[1]: Entering directory all'.
make[1]: Leaving directory `/root/mxnet/R-package/src'
No man pages found in package  ‘mxnet’
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/usr/lib64/R/library/mxnet/libs/libmxnet.so':
  libopenblas.so.0: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted

2.
3.
",0,mxnet R 3.4 installation for CentOS release 6.9 (Final),"mxnet R 3.4 installation for CentOS release 6.9 (Final) For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: CentOS release 6.9 (Final)

Compiler: gcc version 4.9.2 20150212 (Red Hat 4.9.2-6) (GCC)

Package used (Python/R/Scala/Julia): R

MXNet version: 0.10

Or if installed from source: 

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide 3.4

R :
> sessionInfo(package=NULL)
R version 3.4.0 (2017-04-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.9 (Final)

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] drat_0.1.2     compiler_3.4.0 tools_3.4.0


## Error Message:
Please paste the full error message, including stack trace.
Warning message:
package ‘mxnet’ is not available (for R version 3.4.0)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. From R console I entered the following commands:
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
2.
3.

## What have you tried to solve it?

1. Attempted to install from source and received the following error message when running the make rpkg command:

mkdir -p R-package/inst
mkdir -p R-package/inst/libs
cp -rf lib/libmxnet.so R-package/inst/libs
mkdir -p R-package/inst/include
cp -rf include/* R-package/inst/include
cp -rf dmlc-core/include/* R-package/inst/include/
cp -rf nnvm/include/* R-package/inst/include
echo ""import(Rcpp)"" > R-package/NAMESPACE
echo ""import(methods)"" >> R-package/NAMESPACE
R CMD INSTALL R-package
make[1]: Entering directory all'.
make[1]: Leaving directory `/root/mxnet/R-package/src'
No man pages found in package  ‘mxnet’
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/usr/lib64/R/library/mxnet/libs/libmxnet.so':
  libopenblas.so.0: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted

2.
3.
"
incubator-mxnet,7272,"https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/83/pipeline/

output:
> [amalgamation] Running shell script
> + tests/ci_build/ci_build.sh cpu make -C amalgamation/ USE_BLAS=openblas MIN=1
> WORKSPACE: /home/jenkins/jenkins-slave/workspace/amalgamation
> CI_DOCKER_EXTRA_PARAMS: 
> COMMAND: make -C amalgamation/ USE_BLAS=openblas MIN=1
> CONTAINER_TYPE: cpu
> BUILD_TAG: jenkins-incubator-mxnet-master-83
> NODE_NAME: mxnet3
> DOCKER CONTAINER NAME: mx-ci.cpu
> PRE_COMMAND: tests/ci_build/with_the_same_user
> 
> Building container (mx-ci.cpu)...
> Sending build context to Docker daemon 59.39 kB
> 
> Step 1/9 : FROM ubuntu:14.04
>  ---> 4a2820e686c4
> Step 2/9 : COPY install/ubuntu_install_core.sh /install/
>  ---> Using cache
>  ---> a2648bbfb7e4
> Step 3/9 : RUN /install/ubuntu_install_core.sh
>  ---> Using cache
>  ---> bd54bb963df0
> Step 4/9 : COPY install/ubuntu_install_python.sh /install/
>  ---> Using cache
>  ---> b79f713d5145
> Step 5/9 : RUN /install/ubuntu_install_python.sh
>  ---> Using cache
>  ---> 570842ae2af2
> Step 6/9 : COPY install/ubuntu_install_scala.sh /install/
>  ---> Using cache
>  ---> 6f8e5f2011ba
> Step 7/9 : RUN /install/ubuntu_install_scala.sh
>  ---> Using cache
>  ---> e2b49cb08c67
> Step 8/9 : COPY install/ubuntu_install_r.sh /install/
>  ---> Using cache
>  ---> f5f990f7f4ac
> Step 9/9 : RUN /install/ubuntu_install_r.sh
>  ---> Using cache
>  ---> d795cd130ad6
> Successfully built d795cd130ad6
> Running 'make -C amalgamation/ USE_BLAS=openblas MIN=1' inside mx-ci.cpu...
> Adding group /workspace/amalgamation'
> g++ -std=c++11 -Wno-unknown-pragmas -Wall -DMSHADOW_USE_CBLAS=0 -DDISABLE_OPENMP=1 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DDMLC_LOG_STACK_TRACE=0 -DMSHADOW_FORCE_STREAM -DMXNET_USE_OPENCV=0 -DMXNET_PREDICT_ONLY=1 -fPIC -o mxnet_predict-all.o -c mxnet_predict-all.cc
> mxnet_predict-all.cc:42:37: fatal error: io/threaded_input_split.h: No such file or directory
>  #include <io/threaded_input_split.h>
>                                      ^
> compilation terminated.
> make: Leaving directory `/workspace/amalgamation'
> make: *** [mxnet_predict-all.o] Error 1",0,jenkins/incubator-mxnet pipeline is broken on the master,"jenkins/incubator-mxnet pipeline is broken on the master https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/83/pipeline/

output:
> [amalgamation] Running shell script
> + tests/ci_build/ci_build.sh cpu make -C amalgamation/ USE_BLAS=openblas MIN=1
> WORKSPACE: /home/jenkins/jenkins-slave/workspace/amalgamation
> CI_DOCKER_EXTRA_PARAMS: 
> COMMAND: make -C amalgamation/ USE_BLAS=openblas MIN=1
> CONTAINER_TYPE: cpu
> BUILD_TAG: jenkins-incubator-mxnet-master-83
> NODE_NAME: mxnet3
> DOCKER CONTAINER NAME: mx-ci.cpu
> PRE_COMMAND: tests/ci_build/with_the_same_user
> 
> Building container (mx-ci.cpu)...
> Sending build context to Docker daemon 59.39 kB
> 
> Step 1/9 : FROM ubuntu:14.04
>  ---> 4a2820e686c4
> Step 2/9 : COPY install/ubuntu_install_core.sh /install/
>  ---> Using cache
>  ---> a2648bbfb7e4
> Step 3/9 : RUN /install/ubuntu_install_core.sh
>  ---> Using cache
>  ---> bd54bb963df0
> Step 4/9 : COPY install/ubuntu_install_python.sh /install/
>  ---> Using cache
>  ---> b79f713d5145
> Step 5/9 : RUN /install/ubuntu_install_python.sh
>  ---> Using cache
>  ---> 570842ae2af2
> Step 6/9 : COPY install/ubuntu_install_scala.sh /install/
>  ---> Using cache
>  ---> 6f8e5f2011ba
> Step 7/9 : RUN /install/ubuntu_install_scala.sh
>  ---> Using cache
>  ---> e2b49cb08c67
> Step 8/9 : COPY install/ubuntu_install_r.sh /install/
>  ---> Using cache
>  ---> f5f990f7f4ac
> Step 9/9 : RUN /install/ubuntu_install_r.sh
>  ---> Using cache
>  ---> d795cd130ad6
> Successfully built d795cd130ad6
> Running 'make -C amalgamation/ USE_BLAS=openblas MIN=1' inside mx-ci.cpu...
> Adding group /workspace/amalgamation'
> g++ -std=c++11 -Wno-unknown-pragmas -Wall -DMSHADOW_USE_CBLAS=0 -DDISABLE_OPENMP=1 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DDMLC_LOG_STACK_TRACE=0 -DMSHADOW_FORCE_STREAM -DMXNET_USE_OPENCV=0 -DMXNET_PREDICT_ONLY=1 -fPIC -o mxnet_predict-all.o -c mxnet_predict-all.cc
> mxnet_predict-all.cc:42:37: fatal error: io/threaded_input_split.h: No such file or directory
>  #include <io/threaded_input_split.h>
>                                      ^
> compilation terminated.
> make: Leaving directory `/workspace/amalgamation'
> make: *** [mxnet_predict-all.o] Error 1"
incubator-mxnet,3622,"I have some problems when I use the ""--exts"" in parametes of im2rec.py.
It's right if I use the default value,but It's error if I use it like --exts=['.jpg','.jpeg'].
Why?
",0,How to use the parameters in im2rec.py?,"How to use the parameters in im2rec.py? I have some problems when I use the ""--exts"" in parametes of im2rec.py.
It's right if I use the default value,but It's error if I use it like --exts=['.jpg','.jpeg'].
Why?
"
incubator-mxnet,1049,"I occur an error when using:
mean.img = as.array(mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]])

Error in mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]] : 
  object of type 'externalptr' is not subsettable

How could I fix it?
",0,mean.img error ,"mean.img error  I occur an error when using:
mean.img = as.array(mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]])

Error in mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]] : 
  object of type 'externalptr' is not subsettable

How could I fix it?
"
incubator-mxnet,8983,"
## Description
I debug conv as  but it will not stop at breakpoint.


## Environment info (Required)
OS: Ubuntu 16.04 xenial

## Build info (Required if built from source)
gcc
mxnet 1.0.0 cpu 

Build config:
DEBUG=1
CUDA=0
CUDNN=0
CUDA_PATH=NONE
make -j$(nproc)

## Error Message:
➜  ~ gdb --args python debug_conv.py
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...done.
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
No source file named incubator-mxnet/src/operator/convolution_v1-inl.h.
Make breakpoint pending on future shared library load? (y or [n]) n
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12340)]
[New Thread 0x7fffe4fa3700 (LWP 12341)]
[New Thread 0x7fffe47a2700 (LWP 12342)]
[New Thread 0x7fffe3fa1700 (LWP 12343)]
[New Thread 0x7fffe37a0700 (LWP 12344)]
[Thread 0x7fffe37a0700 (LWP 12344) exited]
[Thread 0x7fffe3fa1700 (LWP 12343) exited]
[Thread 0x7fffe47a2700 (LWP 12342) exited]
[Thread 0x7fffe4fa3700 (LWP 12341) exited]
[New Thread 0x7fffe47a2700 (LWP 12345)]
[New Thread 0x7fffe37a0700 (LWP 12346)]
[New Thread 0x7fffe4fa3700 (LWP 12347)]
[New Thread 0x7fffe3fa1700 (LWP 12348)]
/home/hl/anaconda2/lib/python2.7/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead
  import OpenSSL.SSL
[11:18:59] src/engine/engine.cc:55: MXNet start using engine: NaiveEngine
[[[[-0.00020103  0.00926307  0.00926307  0.00926307  0.00431658]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.00537269  0.01894068  0.01894068  0.01894068  0.02670578]]]]
[Thread 0x7fffe3fa1700 (LWP 12348) exited]
[Thread 0x7fffe4fa3700 (LWP 12347) exited]
[Thread 0x7fffe47a2700 (LWP 12345) exited]
[Thread 0x7fffe57a4700 (LWP 12340) exited]
[Thread 0x7ffff7fcb700 (LWP 12334) exited]
[Inferior 1 (process 12334) exited normally]
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
Breakpoint 1 at 0x7ffff0b8a90f: incubator-mxnet/src/operator/convolution_v1-inl.h:130. (3 locations)
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12354)]
[New Thread 0x7fffe4fa3700 (LWP 12355)]
[New Thread 0x7fffe47a2700 (LWP 12356)]
[New Thread 0x7fffe3fa1700 (LWP 12357)]
[New Thread 0x7fffe37a0700 (LWP 12358)]
[Thread 0x7fffe37a0700 (LWP 12358) exited]
[Thread 0x7fffe3fa1700 (LWP 12357) exited]
[Thread 0x7fffe47a2700 (LWP 12356) exited]
[Thread 0x7fffe4fa3700 (LWP 12355) exited]
[New Thread 0x7fffe47a2700 (LWP 12359)]
........................

",0,python-howto-debug_conv doesn't work?,"python-howto-debug_conv doesn't work? 
## Description
I debug conv as  but it will not stop at breakpoint.


## Environment info (Required)
OS: Ubuntu 16.04 xenial

## Build info (Required if built from source)
gcc
mxnet 1.0.0 cpu 

Build config:
DEBUG=1
CUDA=0
CUDNN=0
CUDA_PATH=NONE
make -j$(nproc)

## Error Message:
➜  ~ gdb --args python debug_conv.py
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...done.
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
No source file named incubator-mxnet/src/operator/convolution_v1-inl.h.
Make breakpoint pending on future shared library load? (y or [n]) n
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12340)]
[New Thread 0x7fffe4fa3700 (LWP 12341)]
[New Thread 0x7fffe47a2700 (LWP 12342)]
[New Thread 0x7fffe3fa1700 (LWP 12343)]
[New Thread 0x7fffe37a0700 (LWP 12344)]
[Thread 0x7fffe37a0700 (LWP 12344) exited]
[Thread 0x7fffe3fa1700 (LWP 12343) exited]
[Thread 0x7fffe47a2700 (LWP 12342) exited]
[Thread 0x7fffe4fa3700 (LWP 12341) exited]
[New Thread 0x7fffe47a2700 (LWP 12345)]
[New Thread 0x7fffe37a0700 (LWP 12346)]
[New Thread 0x7fffe4fa3700 (LWP 12347)]
[New Thread 0x7fffe3fa1700 (LWP 12348)]
/home/hl/anaconda2/lib/python2.7/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead
  import OpenSSL.SSL
[11:18:59] src/engine/engine.cc:55: MXNet start using engine: NaiveEngine
[[[[-0.00020103  0.00926307  0.00926307  0.00926307  0.00431658]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.00537269  0.01894068  0.01894068  0.01894068  0.02670578]]]]
[Thread 0x7fffe3fa1700 (LWP 12348) exited]
[Thread 0x7fffe4fa3700 (LWP 12347) exited]
[Thread 0x7fffe47a2700 (LWP 12345) exited]
[Thread 0x7fffe57a4700 (LWP 12340) exited]
[Thread 0x7ffff7fcb700 (LWP 12334) exited]
[Inferior 1 (process 12334) exited normally]
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
Breakpoint 1 at 0x7ffff0b8a90f: incubator-mxnet/src/operator/convolution_v1-inl.h:130. (3 locations)
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12354)]
[New Thread 0x7fffe4fa3700 (LWP 12355)]
[New Thread 0x7fffe47a2700 (LWP 12356)]
[New Thread 0x7fffe3fa1700 (LWP 12357)]
[New Thread 0x7fffe37a0700 (LWP 12358)]
[Thread 0x7fffe37a0700 (LWP 12358) exited]
[Thread 0x7fffe3fa1700 (LWP 12357) exited]
[Thread 0x7fffe47a2700 (LWP 12356) exited]
[Thread 0x7fffe4fa3700 (LWP 12355) exited]
[New Thread 0x7fffe47a2700 (LWP 12359)]
........................

"
incubator-mxnet,11703,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",0,test_loss.test_triplet_loss has fixed seed that can mask flakiness,"test_loss.test_triplet_loss has fixed seed that can mask flakiness The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
"
incubator-mxnet,6810,"I am using mxnet to do transfer learning with python code, and encounters error. I checked the data batch generated by my dataiter, it seems to be ok. Here is the error:  

---
Traceback (most recent call last):
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 104, in <module>
    test_train()
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 100, in test_train
    epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 826, in fit
    sym_gen=self.sym_gen)
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 237, in _train_multi_device
    executor_manager.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 412, in load_data_batch
    self.curr_execgrp.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 259, in load_data_batch
    _load_data(data_batch, self.data_arrays)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 95, in _load_data
    _load_general(batch.data, targets)
AttributeError: 'NoneType' object has no attribute 'data'
  
---
Here is the code:

    optimizer = mx.optimizer.SGD(momentum=0.99)  # lr_scheduler=lr_scheduler)
    model = mx.model.FeedForward(
        allow_extra_params=True,
        ctx=dev,
        symbol=network,
        num_epoch=200,
        learning_rate=0.1*1e-2,
        wd=0.0001,
        initializer=mx.init.Load(""./ResNet/resnet-18-0000.params"", default_init=mx.init.Xavier(rnd_type=""gaussian"", factor_type=""in"", magnitude=2)),
        optimizer=optimizer)
    model.fit(X=train_set,
              eval_metric=Auc(),
              kvstore='local_allreduce_device',
              batch_end_callback=mx.callback.Speedometer(batch_size, 10),
              epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))",0,'NoneType' object has no attribute 'data',"'NoneType' object has no attribute 'data' I am using mxnet to do transfer learning with python code, and encounters error. I checked the data batch generated by my dataiter, it seems to be ok. Here is the error:  

---
Traceback (most recent call last):
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 104, in <module>
    test_train()
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 100, in test_train
    epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 826, in fit
    sym_gen=self.sym_gen)
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 237, in _train_multi_device
    executor_manager.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 412, in load_data_batch
    self.curr_execgrp.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 259, in load_data_batch
    _load_data(data_batch, self.data_arrays)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 95, in _load_data
    _load_general(batch.data, targets)
AttributeError: 'NoneType' object has no attribute 'data'
  
---
Here is the code:

    optimizer = mx.optimizer.SGD(momentum=0.99)  # lr_scheduler=lr_scheduler)
    model = mx.model.FeedForward(
        allow_extra_params=True,
        ctx=dev,
        symbol=network,
        num_epoch=200,
        learning_rate=0.1*1e-2,
        wd=0.0001,
        initializer=mx.init.Load(""./ResNet/resnet-18-0000.params"", default_init=mx.init.Xavier(rnd_type=""gaussian"", factor_type=""in"", magnitude=2)),
        optimizer=optimizer)
    model.fit(X=train_set,
              eval_metric=Auc(),
              kvstore='local_allreduce_device',
              batch_end_callback=mx.callback.Speedometer(batch_size, 10),
              epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))"
incubator-mxnet,15658,"We use  to control the profiler's behaviors, i.e. what to profile.
 and  are two parameters to control whether to profile operators called in the two modes respectively. However, it seems currently  is not functioning correctly.

In the screenshot below, we have a simple scrip that has  in symbolic mode and  in imperative mode.  and  are both set to  and we do see both events in .

![Screen Shot 2019-07-25 at 10 55 47 AM](https://user-images.githubusercontent.com/16669457/61897220-78376080-aecb-11e9-82dd-68cff9b83c6d.png)

However, if we set  and  to . The  event is gone, but we still have the  event, which is not the expected behavior.

![Screen Shot 2019-07-25 at 10 56 16 AM](https://user-images.githubusercontent.com/16669457/61897214-753c7000-aecb-11e9-89a6-e876b0b6ccb3.png)

MXNet version: from 1.4 to 1.6 (last night build) (I only tested as far as 1.4)
Python version: 2&3
",0,profile_symbolic flag not working in profiler,"profile_symbolic flag not working in profiler We use  to control the profiler's behaviors, i.e. what to profile.
 and  are two parameters to control whether to profile operators called in the two modes respectively. However, it seems currently  is not functioning correctly.

In the screenshot below, we have a simple scrip that has  in symbolic mode and  in imperative mode.  and  are both set to  and we do see both events in .

![Screen Shot 2019-07-25 at 10 55 47 AM](https://user-images.githubusercontent.com/16669457/61897220-78376080-aecb-11e9-82dd-68cff9b83c6d.png)

However, if we set  and  to . The  event is gone, but we still have the  event, which is not the expected behavior.

![Screen Shot 2019-07-25 at 10 56 16 AM](https://user-images.githubusercontent.com/16669457/61897214-753c7000-aecb-11e9-89a6-e876b0b6ccb3.png)

MXNet version: from 1.4 to 1.6 (last night build) (I only tested as far as 1.4)
Python version: 2&3
"
incubator-mxnet,8016,"Hi. I ran into an mxnet installation GPU validation issue on the Nvidia TX1 (Ubuntu 16.04). I built mxnet from source according to the Device Jetson TX2 GPU directions at:
[https://mxnet.incubator.apache.org/get_started/install.html#validate-mxnet-installation](url)

The CPU validation code works just fine, but the GPU errors (see attached log file):

>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32)


For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
g++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609

Package used (Python/R/Scala/Julia):

MXNet version:
mxnet===0.11.1

Or if installed from source:
git clone https://github.com/dmlc/mxnet.git --recursive

MXNet commit hash ():
ebf1bf9d3a6cef335a5b2c2a37175e9e91f5b546

If you are using python package, please provide
pip (9.0.1)

Python version and distribution:
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
>>> [19:27:21] /home/nvidia/mxnet/dmlc-core/include/dmlc/./logging.h:308: [19:27:21] /home/nvidia/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:110: Check failed: err == cudaSuccess (8 vs. 0) Name: MapPlanKernel ErrStr:invalid device function
(see attached log file)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1. reinstalled
2.
3.

[mxnet-out.log](https://github.com/apache/incubator-mxnet/files/1327872/mxnet-out.log)
",0,mxnet installation GPU validation issue/error,"mxnet installation GPU validation issue/error Hi. I ran into an mxnet installation GPU validation issue on the Nvidia TX1 (Ubuntu 16.04). I built mxnet from source according to the Device Jetson TX2 GPU directions at:
[https://mxnet.incubator.apache.org/get_started/install.html#validate-mxnet-installation](url)

The CPU validation code works just fine, but the GPU errors (see attached log file):

>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32)


For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
g++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609

Package used (Python/R/Scala/Julia):

MXNet version:
mxnet===0.11.1

Or if installed from source:
git clone https://github.com/dmlc/mxnet.git --recursive

MXNet commit hash ():
ebf1bf9d3a6cef335a5b2c2a37175e9e91f5b546

If you are using python package, please provide
pip (9.0.1)

Python version and distribution:
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
>>> [19:27:21] /home/nvidia/mxnet/dmlc-core/include/dmlc/./logging.h:308: [19:27:21] /home/nvidia/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:110: Check failed: err == cudaSuccess (8 vs. 0) Name: MapPlanKernel ErrStr:invalid device function
(see attached log file)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1. reinstalled
2.
3.

[mxnet-out.log](https://github.com/apache/incubator-mxnet/files/1327872/mxnet-out.log)
"
incubator-mxnet,3395,"Hi All MXNET users:

Recently I downloaded the latest MXNET. I tried to train ILSVRC2012 data with MXNET, but I could not train with alexnet and inception-bn network.
If I use inception-bn network, 
../../tools/launch.py -H hosts -n 2 --launcher ssh python train_imagenet.py --network inception-bn --gpus 0,1,2,3 --batch-size 144 --num-epochs 1 --lr 0.05 --lr-factor 0.94 --data-shape 256 --data-dir ../../data/ilsvrc12/ --kv-store dist_sync

it has the following error:
[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/engine/./threaded_engine.h:306: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.

The alexnet has the same error as inception-bn.

Does anyone know why I got these errors? Thanks.

Regards,
Rengan
",0,Checked failed: cuudnnConvolutionForward,"Checked failed: cuudnnConvolutionForward Hi All MXNET users:

Recently I downloaded the latest MXNET. I tried to train ILSVRC2012 data with MXNET, but I could not train with alexnet and inception-bn network.
If I use inception-bn network, 
../../tools/launch.py -H hosts -n 2 --launcher ssh python train_imagenet.py --network inception-bn --gpus 0,1,2,3 --batch-size 144 --num-epochs 1 --lr 0.05 --lr-factor 0.94 --data-shape 256 --data-dir ../../data/ilsvrc12/ --kv-store dist_sync

it has the following error:
[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/engine/./threaded_engine.h:306: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.

The alexnet has the same error as inception-bn.

Does anyone know why I got these errors? Thanks.

Regards,
Rengan
"
incubator-mxnet,15376,"## Description

When trying to fix https://github.com/mli/new-docs/pull/123
I found that html code that should render fine in a markdown file, doesn't get converted when building the site. However, video html codes worked fine.
There's no warning or error. It just skips those lines of code.

Seems like a bug with the new site's build.

Refer to this commit to see the difference of what was there before that didn't work, compared to was did work. https://github.com/mli/new-docs/pull/123/commits/58b88f83b91c31f2fa31a5810f9563ed581a498c",0,beta website doesn't render html tags for images,"beta website doesn't render html tags for images ## Description

When trying to fix https://github.com/mli/new-docs/pull/123
I found that html code that should render fine in a markdown file, doesn't get converted when building the site. However, video html codes worked fine.
There's no warning or error. It just skips those lines of code.

Seems like a bug with the new site's build.

Refer to this commit to see the difference of what was there before that didn't work, compared to was did work. https://github.com/mli/new-docs/pull/123/commits/58b88f83b91c31f2fa31a5810f9563ed581a498c"
incubator-mxnet,3647,"http://mxnet.io/api/python/symbol.html#mxnet.symbol.SequenceMask

It said 

>  If sequence_length is false, then each example in the batch is assumed to have the max sequence length, and this operator becomes the identity operator.

First I think the sequence_length parameter here mentioned should be use_sequence_length.

Then this document means this op works only if I set use_sequence_length is true, otherwise it's just an identity OP. 
Therefore why do we need this parameter? Why it shouldn't be true by default?
",0,Question on SequenceMask OP,"Question on SequenceMask OP http://mxnet.io/api/python/symbol.html#mxnet.symbol.SequenceMask

It said 

>  If sequence_length is false, then each example in the batch is assumed to have the max sequence length, and this operator becomes the identity operator.

First I think the sequence_length parameter here mentioned should be use_sequence_length.

Then this document means this op works only if I set use_sequence_length is true, otherwise it's just an identity OP. 
Therefore why do we need this parameter? Why it shouldn't be true by default?
"
incubator-mxnet,14712,"This is my code

But report a cudnn bug, I also tried nvidia-docker (official) also not work too.
",0,Conv3DTranspose not work in Ubuntu.,"Conv3DTranspose not work in Ubuntu. This is my code

But report a cudnn bug, I also tried nvidia-docker (official) also not work too.
"
incubator-mxnet,3814,"I try to install mxnet for scala-package following the installation guide. After building the shared library, then execute the command: make scalapkg.
But I got an error: 
Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (default) on project mxnet-init_2.11: Execution default of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed. CompileFailed
Anybody knows how to solove it?  Thank you so much.",0,installation error for scala package,"installation error for scala package I try to install mxnet for scala-package following the installation guide. After building the shared library, then execute the command: make scalapkg.
But I got an error: 
Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (default) on project mxnet-init_2.11: Execution default of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed. CompileFailed
Anybody knows how to solove it?  Thank you so much."
incubator-mxnet,7415,"Hi, tried converting a caffe model.
The convert_symbol ran successfully, but the convert_model crashed.
I know the model works fine on caffe. I don't know any details about the model.

## Environment info
Operating System:
Ubuntu 16.04

Package used (Python/R/Scala/Julia):
Python

MXNet commit hash ():
89e3ee3ea7c223db8c65ddd8c94c6e787d7c52df
If you are using python package, please provide

Python version and distribution:
python 2.7

## Error Message:
Please paste the full error message, including stack trace.

converting layer fc6, wmat shape = (22440, 512)fc6_bias not found in arg_shape_dic.
        skipping layer softmaxloss1 of type SoftmaxWithLoss
        skipping layer center_loss_1 of type CenterLoss
Traceback (most recent call last):
  File ""convert_model.py"", line 220, in <module>
    main()
  File ""convert_model.py"", line 216, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 198, in convert_model
    assert len(layer_blobs) == 0
AssertionError

## Steps to reproduce

1. run tools/caffe_converter$ python convert_model.py proto caffemodel filename

",0,Caffe-converter convert_model.py fail,"Caffe-converter convert_model.py fail Hi, tried converting a caffe model.
The convert_symbol ran successfully, but the convert_model crashed.
I know the model works fine on caffe. I don't know any details about the model.

## Environment info
Operating System:
Ubuntu 16.04

Package used (Python/R/Scala/Julia):
Python

MXNet commit hash ():
89e3ee3ea7c223db8c65ddd8c94c6e787d7c52df
If you are using python package, please provide

Python version and distribution:
python 2.7

## Error Message:
Please paste the full error message, including stack trace.

converting layer fc6, wmat shape = (22440, 512)fc6_bias not found in arg_shape_dic.
        skipping layer softmaxloss1 of type SoftmaxWithLoss
        skipping layer center_loss_1 of type CenterLoss
Traceback (most recent call last):
  File ""convert_model.py"", line 220, in <module>
    main()
  File ""convert_model.py"", line 216, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 198, in convert_model
    assert len(layer_blobs) == 0
AssertionError

## Steps to reproduce

1. run tools/caffe_converter$ python convert_model.py proto caffemodel filename

"
incubator-mxnet,11700,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",0,test_loss.test_sample_weight_loss has fixed seed that can mask flakiness,"test_loss.test_sample_weight_loss has fixed seed that can mask flakiness The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
"
incubator-mxnet,12949,"## Description
Sphinx is throwing errors on the  and  modules.

## Error

",0,text contrib module docs errors,"text contrib module docs errors ## Description
Sphinx is throwing errors on the  and  modules.

## Error

"
incubator-mxnet,14437,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I did the following:

git clone --recursive https://github.com/apache/incubator-mxnet.git
cd incubator-mxnet
make -j4



## Error Message:
![image](https://user-images.githubusercontent.com/48436808/54449650-98bb1580-4789-11e9-8eda-33ad937ee9ec.png)

Can someone  tell me how to solve this issue.",0,compile error ,"compile error  Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I did the following:

git clone --recursive https://github.com/apache/incubator-mxnet.git
cd incubator-mxnet
make -j4



## Error Message:
![image](https://user-images.githubusercontent.com/48436808/54449650-98bb1580-4789-11e9-8eda-33ad937ee9ec.png)

Can someone  tell me how to solve this issue."
incubator-mxnet,12087,"
This causes an error in the recent master.

The code has worked in some days ago. I guess #11370 brokes it. According to the API doc, any types with  and  can be used as a Dataset. #11370 is temporal but I think it would be a good idea to avoid breaking existing code. @zhreshold ",0,Python list as a gluon Dataset,"Python list as a gluon Dataset 
This causes an error in the recent master.

The code has worked in some days ago. I guess #11370 brokes it. According to the API doc, any types with  and  can be used as a Dataset. #11370 is temporal but I think it would be a good idea to avoid breaking existing code. @zhreshold "
incubator-mxnet,16560,"## Description
When I use large tensor, it is easy to crash the MXNet kernel.
Using following python code to reproduce:


The error looks like an int32 overflow on shape.size.
Any easy way to fix this out? The only way I found out is to compile MXNet with USE_INT64_TENSOR_SIZE = ON, which is slower than the default one.

## Environment info (Required)
mxnet 1.5.1 (pip3 install)

Package used (Python/R/Scala/Julia):
Python

## Error Message:
",0,It is easy to crash MXNet when tensor goes larger,"It is easy to crash MXNet when tensor goes larger ## Description
When I use large tensor, it is easy to crash the MXNet kernel.
Using following python code to reproduce:


The error looks like an int32 overflow on shape.size.
Any easy way to fix this out? The only way I found out is to compile MXNet with USE_INT64_TENSOR_SIZE = ON, which is slower than the default one.

## Environment info (Required)
mxnet 1.5.1 (pip3 install)

Package used (Python/R/Scala/Julia):
Python

## Error Message:
"
incubator-mxnet,15194,"Assume, I'm a total idiot (indeed, I feel like one, at least like a bloody beginner...)

This whole neural net installation for GPU is a total nightmare. I came here after failing to get tensorflow to run. Seems like it's the same disaster with MXNet. People, it's awesome that these tools are free to use for a hobbyist like me, but not everybody is a professional developer! I will keep learning of course, but this hurdle is just too high at the moment.

This is my whole installation Routine:

Windows 10 Version 10.0.18362.145 64bit (clean install)
R-3.6.0 -> uninstalled and installed R-3.5.2 later
R-Studio 1.2.1335
Rtools35
Nvidia Display Driver 26.21.14.3086 (GTX 1060 3GB)
cuda_9.0.176_win10 -> update to 9.0.176.1 -> 9.0.176.2 -> 9.0.176.3 (
cudnn-9.0-windows10-x64-v7.1.zip -> unzip cudnn64_7.dll to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin
Anaconda3-2019.03-Windows-x86_64 -> downgrade to Anaconda3-5.2.0-Windows-x86_64 after problems with tensorflow -> re-upgrade back later to Anaconda3-2019.03-Windows-x86_64

In R-Studio, I called:

Calling  i get this:

> Error: package or namespace load failed for ‘mxnet’:
>  .onLoad failed in loadNamespace() for 'mxnet', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object 'D:/Benutzer/MyName/Documents/R/win-library/3.5/mxnet/libs/x64/libmxnet.dll':
>   LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden. (German for ""the specified procedure wasn't found"")
> 

Is there any older version that a dumb end user like me can get running by just copying and pasting some lines of R code in the R terminal and execute these?",0,How do I get the smoothest installation experience in R (GPU version)?,"How do I get the smoothest installation experience in R (GPU version)? Assume, I'm a total idiot (indeed, I feel like one, at least like a bloody beginner...)

This whole neural net installation for GPU is a total nightmare. I came here after failing to get tensorflow to run. Seems like it's the same disaster with MXNet. People, it's awesome that these tools are free to use for a hobbyist like me, but not everybody is a professional developer! I will keep learning of course, but this hurdle is just too high at the moment.

This is my whole installation Routine:

Windows 10 Version 10.0.18362.145 64bit (clean install)
R-3.6.0 -> uninstalled and installed R-3.5.2 later
R-Studio 1.2.1335
Rtools35
Nvidia Display Driver 26.21.14.3086 (GTX 1060 3GB)
cuda_9.0.176_win10 -> update to 9.0.176.1 -> 9.0.176.2 -> 9.0.176.3 (
cudnn-9.0-windows10-x64-v7.1.zip -> unzip cudnn64_7.dll to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin
Anaconda3-2019.03-Windows-x86_64 -> downgrade to Anaconda3-5.2.0-Windows-x86_64 after problems with tensorflow -> re-upgrade back later to Anaconda3-2019.03-Windows-x86_64

In R-Studio, I called:

Calling  i get this:

> Error: package or namespace load failed for ‘mxnet’:
>  .onLoad failed in loadNamespace() for 'mxnet', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object 'D:/Benutzer/MyName/Documents/R/win-library/3.5/mxnet/libs/x64/libmxnet.dll':
>   LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden. (German for ""the specified procedure wasn't found"")
> 

Is there any older version that a dumb end user like me can get running by just copying and pasting some lines of R code in the R terminal and execute these?"
incubator-mxnet,1325,"I'm having some trouble compiling the mxnet package in R with GPU support enabled on an Ubuntu machine in an AWS instance. Like many others before, I get the error 



when I run any GPU algorithms in R. However, I know for sure that I have installed CUDA correctly and I compiled mxnet with the settings  



in the config.mk file (which sits in mxnet root) with no compilation errors as well as recompiled the R package with 



Is there something else that I'm missing here?
",0,Compiling MxNet with GPU support in R,"Compiling MxNet with GPU support in R I'm having some trouble compiling the mxnet package in R with GPU support enabled on an Ubuntu machine in an AWS instance. Like many others before, I get the error 



when I run any GPU algorithms in R. However, I know for sure that I have installed CUDA correctly and I compiled mxnet with the settings  



in the config.mk file (which sits in mxnet root) with no compilation errors as well as recompiled the R package with 



Is there something else that I'm missing here?
"
incubator-mxnet,1272,"Is there any way that we could get the position of max pooling operations. For example, [[1,2], [3,4]] to [4], we could get [[0, 0], [0, 1]], thanks
",0,Max Pooling Index,"Max Pooling Index Is there any way that we could get the position of max pooling operations. For example, [[1,2], [3,4]] to [4], we could get [[0, 0], [0, 1]], thanks
"
incubator-mxnet,10694,"## Description
Importing an ONNX model to MXNet errors out.
Model: [FER+ Emotion Recognition](https://github.com/onnx/models/tree/master/emotion_ferplus)
This may be an issue with the ONNX model itself, but it is on the ONNX model zoo so I assume it is tested regularly.

To reproduce:
- Download the ONNX model listed above into the working directory, add signature.json and synset.txt
- Use new MXNet ONNX contrib API to import ONNX model into MXNet

Expected result: emotion-detection sym and params are returned
Actual result: errors out

## Environment info (Required)


File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_model.py"", line 53, in import_model
    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 114, in from_onnx
    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 58, in _convert_operator
    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/op_translations.py"", line 216, in conv
    new_attrs = translation_utils._fix_channels('Convolution', new_attrs, inputs, cls)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/translation_utils.py"", line 172, in _fix_channels
    raise ValueError(""Unable to get channels/units attr from onnx graph."")
ValueError: Unable to get channels/units attr from onnx graph.
`
",0,Importing an ONNX model (from model zoo) to MXNet errors out,"Importing an ONNX model (from model zoo) to MXNet errors out ## Description
Importing an ONNX model to MXNet errors out.
Model: [FER+ Emotion Recognition](https://github.com/onnx/models/tree/master/emotion_ferplus)
This may be an issue with the ONNX model itself, but it is on the ONNX model zoo so I assume it is tested regularly.

To reproduce:
- Download the ONNX model listed above into the working directory, add signature.json and synset.txt
- Use new MXNet ONNX contrib API to import ONNX model into MXNet

Expected result: emotion-detection sym and params are returned
Actual result: errors out

## Environment info (Required)


File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_model.py"", line 53, in import_model
    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 114, in from_onnx
    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 58, in _convert_operator
    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/op_translations.py"", line 216, in conv
    new_attrs = translation_utils._fix_channels('Convolution', new_attrs, inputs, cls)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/translation_utils.py"", line 172, in _fix_channels
    raise ValueError(""Unable to get channels/units attr from onnx graph."")
ValueError: Unable to get channels/units attr from onnx graph.
`
"
incubator-mxnet,14022,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I got ""Segmentation fault: 11"" error when I ran the following command,

""python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1""

Please note: the model was quantized using ""imagenet_gen_qsym.py"" instead of ""imagenet_gen_qsym_mkldnn.py""

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
I am using Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)
INFO:logger:batch size = 64 for inference
INFO:logger:rgb_mean = 123.68,116.779,103.939   
INFO:logger:rgb_std = 1,1,1
INFO:logger:label_name = softmax_label
INFO:logger:Input data shape = (3, 224, 224)
INFO:logger:Dataset for inference: ./data/val_256_q90.rec
[14:01:27] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: ./data/val_256_q90.rec, use 1 threads for decoding..
INFO:logger:Loading symbol from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-5batches-naive-symbol.json
INFO:logger:Loading params from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-0000.params
INFO:logger:Skipping the first 50 batches
INFO:logger:Running model ./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json for inference
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_fully_connected

Segmentation fault: 11

Stack trace returned 10 entries:
[bt] (0) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x381822) [0x7fa65e7af822]
[bt] (1) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x368d87e) [0x7fa661abb87e]
[bt] (2) /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20) [0x7fa6c57fbf20]
[bt] (3) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3bcbe) [0x7fa661369cbe]
[bt] (4) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3c661) [0x7fa66136a661]
[bt] (5) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f5c3d6) [0x7fa66138a3d6]
[bt] (6) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63574) [0x7fa661391574]
[bt] (7) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63c64) [0x7fa661391c64]
[bt] (8) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2260) [0x7fa6612ed940]
[bt] (9) /work/anaconda3/envs/py3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fa6c3f63ec0]
## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

https://github.com/apache/incubator-mxnet/tree/master/example/quantization

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python imagenet_gen_qsym.py --model=imagenet1k-inception-bn --num-calib-batches=5 --calib-mode=naive 
(Note: This command worked fine)
2. python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1 
(Note: This command stopped and returned error)

## What have you tried to solve it?

1.
2.
",0,Segmentation fault during inference with quantization,"Segmentation fault during inference with quantization Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I got ""Segmentation fault: 11"" error when I ran the following command,

""python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1""

Please note: the model was quantized using ""imagenet_gen_qsym.py"" instead of ""imagenet_gen_qsym_mkldnn.py""

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
I am using Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)
INFO:logger:batch size = 64 for inference
INFO:logger:rgb_mean = 123.68,116.779,103.939   
INFO:logger:rgb_std = 1,1,1
INFO:logger:label_name = softmax_label
INFO:logger:Input data shape = (3, 224, 224)
INFO:logger:Dataset for inference: ./data/val_256_q90.rec
[14:01:27] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: ./data/val_256_q90.rec, use 1 threads for decoding..
INFO:logger:Loading symbol from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-5batches-naive-symbol.json
INFO:logger:Loading params from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-0000.params
INFO:logger:Skipping the first 50 batches
INFO:logger:Running model ./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json for inference
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_fully_connected

Segmentation fault: 11

Stack trace returned 10 entries:
[bt] (0) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x381822) [0x7fa65e7af822]
[bt] (1) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x368d87e) [0x7fa661abb87e]
[bt] (2) /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20) [0x7fa6c57fbf20]
[bt] (3) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3bcbe) [0x7fa661369cbe]
[bt] (4) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3c661) [0x7fa66136a661]
[bt] (5) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f5c3d6) [0x7fa66138a3d6]
[bt] (6) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63574) [0x7fa661391574]
[bt] (7) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63c64) [0x7fa661391c64]
[bt] (8) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2260) [0x7fa6612ed940]
[bt] (9) /work/anaconda3/envs/py3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fa6c3f63ec0]
## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

https://github.com/apache/incubator-mxnet/tree/master/example/quantization

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python imagenet_gen_qsym.py --model=imagenet1k-inception-bn --num-calib-batches=5 --calib-mode=naive 
(Note: This command worked fine)
2. python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1 
(Note: This command stopped and returned error)

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,4697,"## Environment info
Operating System: debian testing

Compiler: 

Package used (Python/R/Scala/Julia): Scala 2.11, Spark 2.0.1

MXNet version: 

Or if installed from source:  from master 2017-01-16

MXNet commit hash ():


## Error Message:
2017-01-17 16:20:38,890 ERROR executor.Executor (Logging.scala:logError(91)) - Exception in task 0.0 in stage 1.0 (TID 1)
java.io.NotSerializableException: ml.dmlc.mxnet.Symbol
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at ml.dmlc.mxnet.JavaSerializer.serialize(Serializer.scala:48)
	at ml.dmlc.mxnet.KVStore.setOptimizer(KVStore.scala:187)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at scala.Option.foreach(Option.scala:257)
	at ml.dmlc.mxnet.Model$.trainMultiDevice(Model.scala:259)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:347)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:286)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:294)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:300)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:168)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

## Minimum reproducible example

## Steps to reproduce
run  example

## What have you tried to solve it?
it seems that the commit [[Scala] Bucketing API Support](https://github.com/dmlc/mxnet/commit/4d9ac5b77d3a5ad7b34d69f972386b9ae36d68c6) which adds  to  causes the problem. 
1. since symbol is not used right now, just remove it from  temporarily
2. or convert symbol to json in 
",0,[Scala] Symbol is not serializable,"[Scala] Symbol is not serializable ## Environment info
Operating System: debian testing

Compiler: 

Package used (Python/R/Scala/Julia): Scala 2.11, Spark 2.0.1

MXNet version: 

Or if installed from source:  from master 2017-01-16

MXNet commit hash ():


## Error Message:
2017-01-17 16:20:38,890 ERROR executor.Executor (Logging.scala:logError(91)) - Exception in task 0.0 in stage 1.0 (TID 1)
java.io.NotSerializableException: ml.dmlc.mxnet.Symbol
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at ml.dmlc.mxnet.JavaSerializer.serialize(Serializer.scala:48)
	at ml.dmlc.mxnet.KVStore.setOptimizer(KVStore.scala:187)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at scala.Option.foreach(Option.scala:257)
	at ml.dmlc.mxnet.Model$.trainMultiDevice(Model.scala:259)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:347)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:286)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:294)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:300)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:168)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

## Minimum reproducible example

## Steps to reproduce
run  example

## What have you tried to solve it?
it seems that the commit [[Scala] Bucketing API Support](https://github.com/dmlc/mxnet/commit/4d9ac5b77d3a5ad7b34d69f972386b9ae36d68c6) which adds  to  causes the problem. 
1. since symbol is not used right now, just remove it from  temporarily
2. or convert symbol to json in 
"
incubator-mxnet,9279,"I set export MXNET_BACKWARD_DO_MIRROR=1 while use gluon 
Does this environment work in gluon?
Thanks a lot
",0,should gluon use the sublinear memory,"should gluon use the sublinear memory I set export MXNET_BACKWARD_DO_MIRROR=1 while use gluon 
Does this environment work in gluon?
Thanks a lot
"
incubator-mxnet,887,"Dear All,

I pulled the code again today and fail to build (I have successfully built it before). This is the error I get:

pkg-config --cflags opencvpkg-config --cflags opencvpkg-config --cflags opencv
",0,Latest pull (today Dec 9) fails to build on mac,"Latest pull (today Dec 9) fails to build on mac Dear All,

I pulled the code again today and fail to build (I have successfully built it before). This is the error I get:

pkg-config --cflags opencvpkg-config --cflags opencvpkg-config --cflags opencv
"
incubator-mxnet,7386,"I need  to define a function in .h file for GPU version only, then implenent it in .cu file, 
declaration in .h:

implement in .cu file:

the problem is I am force to declare the same function for CPU version and implement it, or it will compile failed
I just need the function for GPU, How could I get ride of this problem?
 ",0,How could I define function for GPU only?,"How could I define function for GPU only? I need  to define a function in .h file for GPU version only, then implenent it in .cu file, 
declaration in .h:

implement in .cu file:

the problem is I am force to declare the same function for CPU version and implement it, or it will compile failed
I just need the function for GPU, How could I get ride of this problem?
 "
incubator-mxnet,3146,"I want to construct a network which need the spatial pyramid pooling (spp: spatial pyramid pooling in deep convolutional network for visual recognition) operation. Does mxnet has the ready-made spp operation?
",0,Does mxnet has the ready-made spp operation?,"Does mxnet has the ready-made spp operation? I want to construct a network which need the spatial pyramid pooling (spp: spatial pyramid pooling in deep convolutional network for visual recognition) operation. Does mxnet has the ready-made spp operation?
"
incubator-mxnet,5093,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10 64 bit

Compiler: VS2015 C++

Package used (Python/R/Scala/Julia): ----

MXNet version: Latest nightly Windows build 20170221, CUDA 8.0.61, cudnn 8.0v5.1

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFree
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFindCreator
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerUpdate
error LNK2001: unresolved external symbol __imp_MXOptimizerCreateOptimizer

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Just compiled the mlp.cpp sample in a C++ VS2015 solution. This worked in an earlier install from MXNet but based on a version from MxNet.cpp with cudnnv3.1, CUDA 7.5 and VS2013. (entire MXNet version in a separate folder structure).
2.
3.

## What have you tried to solve it?

1. Tried to find where the symbols that cannot be linked are defined. Can't find those in the source code on Github.
2. Googled for a solution
3.
",0,Linker error when building mlp.cpp with VS2015,"Linker error when building mlp.cpp with VS2015 For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10 64 bit

Compiler: VS2015 C++

Package used (Python/R/Scala/Julia): ----

MXNet version: Latest nightly Windows build 20170221, CUDA 8.0.61, cudnn 8.0v5.1

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFree
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFindCreator
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerUpdate
error LNK2001: unresolved external symbol __imp_MXOptimizerCreateOptimizer

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Just compiled the mlp.cpp sample in a C++ VS2015 solution. This worked in an earlier install from MXNet but based on a version from MxNet.cpp with cudnnv3.1, CUDA 7.5 and VS2013. (entire MXNet version in a separate folder structure).
2.
3.

## What have you tried to solve it?

1. Tried to find where the symbols that cannot be linked are defined. Can't find those in the source code on Github.
2. Googled for a solution
3.
"
incubator-mxnet,9357,"I have figured out how to split a layer into 8 gpus by using group2ctx which is a very great feature. I wonder if group2ctx can support to split a layer into multi-machines (eg. 16 gpus on two machine) by doing some easy modifications?

Thanks. @tqchen @piiswrong @mli ",0,can group2ctx be used in multi-machine model parallel situation?,"can group2ctx be used in multi-machine model parallel situation? I have figured out how to split a layer into 8 gpus by using group2ctx which is a very great feature. I wonder if group2ctx can support to split a layer into multi-machines (eg. 16 gpus on two machine) by doing some easy modifications?

Thanks. @tqchen @piiswrong @mli "
incubator-mxnet,5037,"Hi,
I am attempting to load multiple ARK files for training, but I noticed that the numpy.dataIter only takes a single numpy feature matrix and single numpy label vector, is it possible to load multiple data sets??
I couldn't figure this out so I then attempted to concantataneted all my ARK files and created a single numpy matrix and vector for both features and matrix and ended up with this error even though the shapes are the same:

include/mxnet/./tensor_blob.h:742: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements
Traceback (most recent call last):
  File ""am.py"", line 52, in <module>
    train = mx.io.NDArrayIter(featureMat, label=targetMat, batch_size=100)
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 420, in __init__
    self.data = _init_data(data, allow_empty=False, default_name='data')
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 391, in _init_data
    ""should be NDArray or numpy.ndarray"")
TypeError: Invalid type '<type 'numpy.ndarray'>' for data, should be NDArray or numpy.ndarray

The shapes are the same though:
(39673722, 340) : featureMat
(39673722,) : targetVec
",0,Loading multiple files for training ,"Loading multiple files for training  Hi,
I am attempting to load multiple ARK files for training, but I noticed that the numpy.dataIter only takes a single numpy feature matrix and single numpy label vector, is it possible to load multiple data sets??
I couldn't figure this out so I then attempted to concantataneted all my ARK files and created a single numpy matrix and vector for both features and matrix and ended up with this error even though the shapes are the same:

include/mxnet/./tensor_blob.h:742: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements
Traceback (most recent call last):
  File ""am.py"", line 52, in <module>
    train = mx.io.NDArrayIter(featureMat, label=targetMat, batch_size=100)
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 420, in __init__
    self.data = _init_data(data, allow_empty=False, default_name='data')
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 391, in _init_data
    ""should be NDArray or numpy.ndarray"")
TypeError: Invalid type '<type 'numpy.ndarray'>' for data, should be NDArray or numpy.ndarray

The shapes are the same though:
(39673722, 340) : featureMat
(39673722,) : targetVec
"
incubator-mxnet,7560,"[MyData2.zip](https://github.com/apache/incubator-mxnet/files/1242794/MyData2.zip)

Hi, I have a model of a layer that I would like to train, to then use both weights and Bias as a parameter to create a new layer:

DataNeurona<- read.csv(""D:/DATOS_PROYECTO/MyData2.csv"",sep = "","", header = T)



DataNeurona<-as.matrix(DataNeurona)
#Duplico la ultima fila para luego hacer el test con ella:
DataNeurona<-rbind(DataNeurona,DataNeurona[length(DataNeurona[,1]),])

NumTest<-2
train.ind<-c(41:(length(DataNeurona[,1])-NumTest))
train.x<-DataNeurona[train.ind,-(length(DataNeurona[1,]))]
train.y<-DataNeurona[train.ind,length(DataNeurona[1,])]
test.x<-DataNeurona[-c(1:41,train.ind),-length(DataNeurona[1,])]
test.y<-DataNeurona[-c(1:41,train.ind),length(DataNeurona[1,])]

data <- mx.symbol.Variable(""data"")
#w = mx.symbol.Variable('myweight')

fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=50, weights(ww))
act1<-mx.symbol.Activation(fc1,name=""sigmoid1"",act_type=""sigmoid"")

fc2<-mx.symbol.FullyConnected(act1,name=""fc2"",num_hidden=1)
lro=mx.symbol.LinearRegressionOutput(data=fc2, grad.scale=1)
mx.set.seed(0)
train_iter = mx.io.arrayiter(data = t(train.x), label = t(train.y))
model <- mx.model.FeedForward.create(symbol= lro, 
                                     X=train_iter, 
                                     ctx=mx.cpu(2),     
                                     num.round=50,
                                     #optimizer = 
                                     initialize=mx.init.uniform(0.7),
                                     array.batch.size=3,
                                     learning.rate=0.01, 
                                     momentum=0.9,  
                                     eval.metric=mx.metric.mse)


My problem is that I can not find the way to create the layer later with the weights as parameter, 
I have tried with:

1
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights(model$arg.params$fc1_weight))
2


model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params$fc1_weight, bias=model$arg.params$fc1_bias)
3
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params[[fc1_weight]], bias=model$arg.params[[fc1_bias]])
4
model.extract(model, ""weights"")

## ## ### **

**
And I do not quite understand what I do wrong ....
Greeting
",0,Creating a layer-by-layer network,"Creating a layer-by-layer network [MyData2.zip](https://github.com/apache/incubator-mxnet/files/1242794/MyData2.zip)

Hi, I have a model of a layer that I would like to train, to then use both weights and Bias as a parameter to create a new layer:

DataNeurona<- read.csv(""D:/DATOS_PROYECTO/MyData2.csv"",sep = "","", header = T)



DataNeurona<-as.matrix(DataNeurona)
#Duplico la ultima fila para luego hacer el test con ella:
DataNeurona<-rbind(DataNeurona,DataNeurona[length(DataNeurona[,1]),])

NumTest<-2
train.ind<-c(41:(length(DataNeurona[,1])-NumTest))
train.x<-DataNeurona[train.ind,-(length(DataNeurona[1,]))]
train.y<-DataNeurona[train.ind,length(DataNeurona[1,])]
test.x<-DataNeurona[-c(1:41,train.ind),-length(DataNeurona[1,])]
test.y<-DataNeurona[-c(1:41,train.ind),length(DataNeurona[1,])]

data <- mx.symbol.Variable(""data"")
#w = mx.symbol.Variable('myweight')

fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=50, weights(ww))
act1<-mx.symbol.Activation(fc1,name=""sigmoid1"",act_type=""sigmoid"")

fc2<-mx.symbol.FullyConnected(act1,name=""fc2"",num_hidden=1)
lro=mx.symbol.LinearRegressionOutput(data=fc2, grad.scale=1)
mx.set.seed(0)
train_iter = mx.io.arrayiter(data = t(train.x), label = t(train.y))
model <- mx.model.FeedForward.create(symbol= lro, 
                                     X=train_iter, 
                                     ctx=mx.cpu(2),     
                                     num.round=50,
                                     #optimizer = 
                                     initialize=mx.init.uniform(0.7),
                                     array.batch.size=3,
                                     learning.rate=0.01, 
                                     momentum=0.9,  
                                     eval.metric=mx.metric.mse)


My problem is that I can not find the way to create the layer later with the weights as parameter, 
I have tried with:

1
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights(model$arg.params$fc1_weight))
2


model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params$fc1_weight, bias=model$arg.params$fc1_bias)
3
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params[[fc1_weight]], bias=model$arg.params[[fc1_bias]])
4
model.extract(model, ""weights"")

## ## ### **

**
And I do not quite understand what I do wrong ....
Greeting
"
incubator-mxnet,890,"An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPEto NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.
terminate called after throwing an instance of 'dmlc::Error'
  what():  [15:04:06] src/engine/./threaded_engine.h:295: [15:04:06] src/operator/./convolution-inl.h:258: Check failed: (param_.workspace) >= (required_size) 
Minimum workspace size: 666989568 Bytes
Given: 536870912 Bytes
",0,[error] Check failed: (param_.workspace) >= (required_size) ,"[error] Check failed: (param_.workspace) >= (required_size)  An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPEto NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.
terminate called after throwing an instance of 'dmlc::Error'
  what():  [15:04:06] src/engine/./threaded_engine.h:295: [15:04:06] src/operator/./convolution-inl.h:258: Check failed: (param_.workspace) >= (required_size) 
Minimum workspace size: 666989568 Bytes
Given: 536870912 Bytes
"
incubator-mxnet,4223,"i want to print some values of specified locations of a tensor in forward or backward op， is there some function to call or how to implement this function？
",0,how to print values of a tensor？,"how to print values of a tensor？ i want to print some values of specified locations of a tensor in forward or backward op， is there some function to call or how to implement this function？
"
incubator-mxnet,8821,"I use mxnet 0.12 with python2.7 ,win10. For example:
https://github.com/apache/incubator-mxnet/blob/b5648a43955f7d05c0e53c1ab61a58bd402b4416/example/multi-task/example_multi_task.py
I want to test how to use multi label accuracy with this example, but got error:  ""ImportError: No module named get_data""  
I googled, found that this module is a relevant one related to mnist example, but I couldn't find it anymore. 

So could someone fix it, or provided the module?",0,"I can not find the module called ""get_data"" for mxnet 0.12","I can not find the module called ""get_data"" for mxnet 0.12 I use mxnet 0.12 with python2.7 ,win10. For example:
https://github.com/apache/incubator-mxnet/blob/b5648a43955f7d05c0e53c1ab61a58bd402b4416/example/multi-task/example_multi_task.py
I want to test how to use multi label accuracy with this example, but got error:  ""ImportError: No module named get_data""  
I googled, found that this module is a relevant one related to mnist example, but I couldn't find it anymore. 

So could someone fix it, or provided the module?"
incubator-mxnet,9993,"Hi,
sorry,there are some problems with cmake

command I use
$git clone --recursive https://github.com/apache/incubator-mxnet.git
$cd incubator-mxnet/
$mkdir build/Release && cd build/Release
$cmake ../../
$make -j8


- cmake ../../ output log

-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- CMake version '3.5.1' using generator 'Unix Makefiles'
-- Performing Test SUPPORT_CXX11
-- Performing Test SUPPORT_CXX11 - Success
-- Performing Test SUPPORT_CXX0X
-- Performing Test SUPPORT_CXX0X - Success
-- Performing Test SUPPORT_MSSE2
-- Performing Test SUPPORT_MSSE2 - Success
-- CMAKE_BUILD_TYPE is unset, defaulting to Release
-- Detecting Intel(R) MKL: trying mklml_intel
-- Detecting Intel(R) MKL: trying mklml
-- Detecting Intel(R) MKL: trying mkl_rt
CMake Warning at 3rdparty/mkldnn/cmake/MKL.cmake:177 (message):
  Intel(R) MKL not found.  Some performance features may not be available.
  Please run scripts/prepare_mkl.sh to download a minimal set of libraries or
  get a full version from https://software.intel.com/en-us/intel-mkl
Call Stack (most recent call first):
  3rdparty/mkldnn/cmake/OpenMP.cmake:24 (include)
  3rdparty/mkldnn/CMakeLists.txt:57 (include)


-- Try OpenMP C flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Try OpenMP CXX flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Found OpenMP: -fopenmp
-- Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)
-- VTune profiling environment is unset
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for pthread_create
-- Looking for pthread_create - found
-- Found Threads: TRUE
-- Found CUDA: /usr/local/cuda-8.0 (found version ""8.0"")
-- Found OpenBLAS libraries: /usr/lib/libopenblas.so
-- Found OpenBLAS include: /usr/include
-- CUDA detected: 8.0
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
-- Running GPU architecture autodetection
-- Found CUDA arch 5.2 5.2 5.2 5.2
-- Added CUDA NVCC flags for: sm_52
-- Could NOT find Gperftools (missing:  GPERFTOOLS_LIBRARIES GPERFTOOLS_INCLUDE_DIR)
-- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"")
-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
--  OpenCV_LIBS=opencv_core;opencv_highgui;opencv_imgproc;opencv_imgcodecs
-- OpenCV found (/usr/local/share/OpenCV)
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG - Success
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG - Success
-- Performing Test LIBOMP_HAVE_WERROR_FLAG
-- Performing Test LIBOMP_HAVE_WERROR_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG - Success
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG - Success
-- Performing Test LIBOMP_HAVE_MMIC_FLAG
-- Performing Test LIBOMP_HAVE_MMIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_M32_FLAG
-- Performing Test LIBOMP_HAVE_M32_FLAG - Failed
-- Performing Test LIBOMP_HAVE_X_FLAG
-- Performing Test LIBOMP_HAVE_X_FLAG - Success
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG - Success
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG - Success
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG - Success
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG - Success
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG - Success
-- Performing Test LIBOMP_HAVE_FINI_FLAG
-- Performing Test LIBOMP_HAVE_FINI_FLAG - Success
-- Found Perl: /usr/bin/perl (found version ""5.22.1"")
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS - Success
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS - Success
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE - Success
-- Looking for include files windows.h, psapi.h
-- Looking for include files windows.h, psapi.h - not found
-- Looking for EnumProcessModules in psapi
-- Looking for EnumProcessModules in psapi - not found
-- LIBOMP: Operating System     -- Linux
-- LIBOMP: Target Architecture  -- x86_64
-- LIBOMP: Build Type           -- Release
-- LIBOMP: OpenMP Version       -- 50
-- LIBOMP: Library Kind         -- SHARED
-- LIBOMP: Library Type         -- normal
-- LIBOMP: Fortran Modules      -- FALSE
-- LIBOMP: Build                -- 20140926
-- LIBOMP: Use Stats-gathering  -- FALSE
-- LIBOMP: Use Debugger-support -- FALSE
-- LIBOMP: Use ITT notify       -- TRUE
-- LIBOMP: Use OMPT-support     -- FALSE
-- LIBOMP: Use Adaptive locks   -- TRUE
-- LIBOMP: Use quad precision   -- TRUE
-- LIBOMP: Use TSAN-support     -- FALSE
-- LIBOMP: Use Hwloc library    -- FALSE
-- Found PythonInterp: /usr/bin/python (found version ""2.7.12"")
-- Looking for sqrt in m
-- Looking for sqrt in m - found
-- Looking for __atomic_load_1
-- Looking for __atomic_load_1 - not found
-- Looking for __atomic_load_1 in atomic
-- Looking for __atomic_load_1 in atomic - found
-- LIBOMP: Cannot find llvm-lit.
-- LIBOMP: Please put llvm-lit in your PATH, set LIBOMP_LLVM_LIT_EXECUTABLE to its full path or point OPENMP_LLVM_TOOLS_DIR to its directory
CMake Warning at 3rdparty/openmp/runtime/cmake/LibompUtils.cmake:21 (message):
  LIBOMP: The check-libomp target will not be available!
Call Stack (most recent call first):
  3rdparty/openmp/runtime/test/CMakeLists.txt:62 (libomp_warning_say)


-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
-- Found GTest: gtest
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
You have called ADD_LIBRARY for library mxnet without any source files. This typically indicates a problem with your CMakeLists.txt file
-- Configuring done
-- Generating done
-- Build files have been written to: /home/jacky4323/TEST_bmxnet/incubator-mxnet/build/Release

- make -j8 error

[ 56%] Linking CXX executable benchdnn
[ 57%] Linking CXX executable test_convolution_forward_u8s8s32
[ 57%] Built target benchdnn
[ 57%] Built target test_convolution_forward_u8s8s32
[ 57%] Linking CXX executable test_convolution_relu_forward_f32
[ 57%] Built target test_convolution_relu_forward_f32
CMakeFiles/Makefile2:139: recipe for target 'CMakeFiles/mxnet_static.dir/all' failed
make[1]: *** [CMakeFiles/mxnet_static.dir/all] Error 2
Makefile:138: recipe for target 'all' failed
make: *** [all] Error 2
",0,cmake cannot build mxnet,"cmake cannot build mxnet Hi,
sorry,there are some problems with cmake

command I use
$git clone --recursive https://github.com/apache/incubator-mxnet.git
$cd incubator-mxnet/
$mkdir build/Release && cd build/Release
$cmake ../../
$make -j8


- cmake ../../ output log

-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- CMake version '3.5.1' using generator 'Unix Makefiles'
-- Performing Test SUPPORT_CXX11
-- Performing Test SUPPORT_CXX11 - Success
-- Performing Test SUPPORT_CXX0X
-- Performing Test SUPPORT_CXX0X - Success
-- Performing Test SUPPORT_MSSE2
-- Performing Test SUPPORT_MSSE2 - Success
-- CMAKE_BUILD_TYPE is unset, defaulting to Release
-- Detecting Intel(R) MKL: trying mklml_intel
-- Detecting Intel(R) MKL: trying mklml
-- Detecting Intel(R) MKL: trying mkl_rt
CMake Warning at 3rdparty/mkldnn/cmake/MKL.cmake:177 (message):
  Intel(R) MKL not found.  Some performance features may not be available.
  Please run scripts/prepare_mkl.sh to download a minimal set of libraries or
  get a full version from https://software.intel.com/en-us/intel-mkl
Call Stack (most recent call first):
  3rdparty/mkldnn/cmake/OpenMP.cmake:24 (include)
  3rdparty/mkldnn/CMakeLists.txt:57 (include)


-- Try OpenMP C flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Try OpenMP CXX flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Found OpenMP: -fopenmp
-- Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)
-- VTune profiling environment is unset
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for pthread_create
-- Looking for pthread_create - found
-- Found Threads: TRUE
-- Found CUDA: /usr/local/cuda-8.0 (found version ""8.0"")
-- Found OpenBLAS libraries: /usr/lib/libopenblas.so
-- Found OpenBLAS include: /usr/include
-- CUDA detected: 8.0
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
-- Running GPU architecture autodetection
-- Found CUDA arch 5.2 5.2 5.2 5.2
-- Added CUDA NVCC flags for: sm_52
-- Could NOT find Gperftools (missing:  GPERFTOOLS_LIBRARIES GPERFTOOLS_INCLUDE_DIR)
-- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"")
-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
--  OpenCV_LIBS=opencv_core;opencv_highgui;opencv_imgproc;opencv_imgcodecs
-- OpenCV found (/usr/local/share/OpenCV)
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG - Success
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG - Success
-- Performing Test LIBOMP_HAVE_WERROR_FLAG
-- Performing Test LIBOMP_HAVE_WERROR_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG - Success
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG - Success
-- Performing Test LIBOMP_HAVE_MMIC_FLAG
-- Performing Test LIBOMP_HAVE_MMIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_M32_FLAG
-- Performing Test LIBOMP_HAVE_M32_FLAG - Failed
-- Performing Test LIBOMP_HAVE_X_FLAG
-- Performing Test LIBOMP_HAVE_X_FLAG - Success
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG - Success
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG - Success
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG - Success
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG - Success
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG - Success
-- Performing Test LIBOMP_HAVE_FINI_FLAG
-- Performing Test LIBOMP_HAVE_FINI_FLAG - Success
-- Found Perl: /usr/bin/perl (found version ""5.22.1"")
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS - Success
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS - Success
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE - Success
-- Looking for include files windows.h, psapi.h
-- Looking for include files windows.h, psapi.h - not found
-- Looking for EnumProcessModules in psapi
-- Looking for EnumProcessModules in psapi - not found
-- LIBOMP: Operating System     -- Linux
-- LIBOMP: Target Architecture  -- x86_64
-- LIBOMP: Build Type           -- Release
-- LIBOMP: OpenMP Version       -- 50
-- LIBOMP: Library Kind         -- SHARED
-- LIBOMP: Library Type         -- normal
-- LIBOMP: Fortran Modules      -- FALSE
-- LIBOMP: Build                -- 20140926
-- LIBOMP: Use Stats-gathering  -- FALSE
-- LIBOMP: Use Debugger-support -- FALSE
-- LIBOMP: Use ITT notify       -- TRUE
-- LIBOMP: Use OMPT-support     -- FALSE
-- LIBOMP: Use Adaptive locks   -- TRUE
-- LIBOMP: Use quad precision   -- TRUE
-- LIBOMP: Use TSAN-support     -- FALSE
-- LIBOMP: Use Hwloc library    -- FALSE
-- Found PythonInterp: /usr/bin/python (found version ""2.7.12"")
-- Looking for sqrt in m
-- Looking for sqrt in m - found
-- Looking for __atomic_load_1
-- Looking for __atomic_load_1 - not found
-- Looking for __atomic_load_1 in atomic
-- Looking for __atomic_load_1 in atomic - found
-- LIBOMP: Cannot find llvm-lit.
-- LIBOMP: Please put llvm-lit in your PATH, set LIBOMP_LLVM_LIT_EXECUTABLE to its full path or point OPENMP_LLVM_TOOLS_DIR to its directory
CMake Warning at 3rdparty/openmp/runtime/cmake/LibompUtils.cmake:21 (message):
  LIBOMP: The check-libomp target will not be available!
Call Stack (most recent call first):
  3rdparty/openmp/runtime/test/CMakeLists.txt:62 (libomp_warning_say)


-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
-- Found GTest: gtest
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
You have called ADD_LIBRARY for library mxnet without any source files. This typically indicates a problem with your CMakeLists.txt file
-- Configuring done
-- Generating done
-- Build files have been written to: /home/jacky4323/TEST_bmxnet/incubator-mxnet/build/Release

- make -j8 error

[ 56%] Linking CXX executable benchdnn
[ 57%] Linking CXX executable test_convolution_forward_u8s8s32
[ 57%] Built target benchdnn
[ 57%] Built target test_convolution_forward_u8s8s32
[ 57%] Linking CXX executable test_convolution_relu_forward_f32
[ 57%] Built target test_convolution_relu_forward_f32
CMakeFiles/Makefile2:139: recipe for target 'CMakeFiles/mxnet_static.dir/all' failed
make[1]: *** [CMakeFiles/mxnet_static.dir/all] Error 2
Makefile:138: recipe for target 'all' failed
make: *** [all] Error 2
"
incubator-mxnet,10279,"

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/546/pipeline

https://issues.apache.org/jira/browse/MXNET-237",0,Failing test_operator_gpu.test_sparse_quadratic_function and test_flip,"Failing test_operator_gpu.test_sparse_quadratic_function and test_flip 

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/546/pipeline

https://issues.apache.org/jira/browse/MXNET-237"
incubator-mxnet,4155,"2>  symbol.cc
2>     正在创建库 G:/OpenSource/mxnet/build/Release/libmxnet.lib 和对象 G:/OpenSource/mxnet/build/Release/libmxnet.exp
2>  正在生成代码
2>g:\opensource\mxnet\src\engine\threaded_engine.cc(298): fatal error C1001: 编译器中发生内部错误。
2>  (编译器文件“f:\dd\vctools\compiler\utc\src\p2\ehexcept.c”，第 956 行)
2>   要解决此问题，请尝试简化或更改上面所列位置附近的程序。
2>  请选择 Visual C++
2>  “帮助”菜单上的“技术支持”命令，或打开技术支持帮助文件来获得详细信息。
2>LINK : fatal error LNK1257: 代码生成失败
",0," An error occured when I complie mxnet in VS2013, could you tell me how to fix it "," An error occured when I complie mxnet in VS2013, could you tell me how to fix it  2>  symbol.cc
2>     正在创建库 G:/OpenSource/mxnet/build/Release/libmxnet.lib 和对象 G:/OpenSource/mxnet/build/Release/libmxnet.exp
2>  正在生成代码
2>g:\opensource\mxnet\src\engine\threaded_engine.cc(298): fatal error C1001: 编译器中发生内部错误。
2>  (编译器文件“f:\dd\vctools\compiler\utc\src\p2\ehexcept.c”，第 956 行)
2>   要解决此问题，请尝试简化或更改上面所列位置附近的程序。
2>  请选择 Visual C++
2>  “帮助”菜单上的“技术支持”命令，或打开技术支持帮助文件来获得详细信息。
2>LINK : fatal error LNK1257: 代码生成失败
"
incubator-mxnet,14844,"## Description
Tried to build Android_armv7 using ci/build.py and failed.
I runned 
And the error showed as follows:


## Environment info (Required)
OS: Ubuntu 18.04 64bit LTS
MXNet: 1.3.1
Python: 3.6
GPU: NVIDIA GTX1060 6G
CPU: i7-8750H (16G memory)


## What have you tried to solve it?

1. Changed mxnetci dockcross address in 
Previously it is 
Now it is 
2. Set  argument in  to 'mxnetcipinned'
3. Created  and restarted the docker service

4. Used proxy(shadowsocks + proxychains4). BUt it seems that it has nothing to do with my network connection?

## Complete building log


I am wondering if there is anyone who can reproduce this error, or there is just something wrong in my network connection (e.g. GFW)?",0,ci/build.py failed to build MXNet for Android_armv7,"ci/build.py failed to build MXNet for Android_armv7 ## Description
Tried to build Android_armv7 using ci/build.py and failed.
I runned 
And the error showed as follows:


## Environment info (Required)
OS: Ubuntu 18.04 64bit LTS
MXNet: 1.3.1
Python: 3.6
GPU: NVIDIA GTX1060 6G
CPU: i7-8750H (16G memory)


## What have you tried to solve it?

1. Changed mxnetci dockcross address in 
Previously it is 
Now it is 
2. Set  argument in  to 'mxnetcipinned'
3. Created  and restarted the docker service

4. Used proxy(shadowsocks + proxychains4). BUt it seems that it has nothing to do with my network connection?

## Complete building log


I am wondering if there is anyone who can reproduce this error, or there is just something wrong in my network connection (e.g. GFW)?"
incubator-mxnet,9823,"I am using mxnet with CUDA9 + CUDNN7 and distributed training enabled. However, when I re-run the rcnn code in the example, I got the following error:

Traceback (most recent call last):
  File ""train_end2end.py"", line 199, in <module>
    main()
  File ""train_end2end.py"", line 196, in main
    lr=args.lr, lr_step=args.lr_step)
  File ""train_end2end.py"", line 158, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/base_module.py"", line 496, in fit
    self.update_metric(eval_metric, data_batch.label)
  File ""/----/mx-rcnn/rcnn/core/module.py"", line 227, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/module.py"", line 749, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/executor_group.py"", line 616, in update_metric
    eval_metric.update_dict(labels_, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 280, in update_dict
    metric.update_dict(labels, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 108, in update_dict
    self.update(label, pred)
  File ""/----/mx-rcnn/rcnn/core/metric.py"", line 51, in update
    pred_label = mx.ndarray.argmax_channel(pred).asnumpy().astype('int32')
  File ""/----/libs/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1801, in asnumpy
    ctypes.c_size_t(data.size)))
  File ""/----/libs/incubator-mxnet/python/mxnet/base.py"", line 148, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:08:44] src/operator/nn/./cudnn/cudnn_softmax_activation-inl.h:154: Check failed: e == CUDNN_STATUS_SUCCESS (3 vs. 0) cuDNN: CUDNN_STATUS_BAD_PARAM

Stack trace returned 10 entries:
[bt] (0) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::StackTrace()+0x3d) [0x2adc0c3395cd]
[bt] (1) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x2adc0c339a58]
[bt] (2) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::CuDNNSoftmaxActivationOp::Backward(mxnet::OpContext const&, mxnet::TBlob const&, mxnet::TBlob const&, mxnet::OpReqType const&, mxnet::TBlob const&)+0x10b9) [0x2adc0f5c7669]
[bt] (3) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::op::SoftmaxActivationGradCompute<mshadow::gpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0xd4c) [0x2adc0f5c2eac]
[bt] (4) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool)+0x50) [0x2adc0ec4cc40]
[bt] (5) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0x3284653) [0x2adc0ec54653]
[bt] (6)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x2c4) [0x2adc0ec2fcd4]
[bt] (7) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent> const&)+0x103) [0x2adc0ec34253]
[bt] (8) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#3}::operator()() const::{lambda(std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)+0x3e) [0x2adc0ec3448e]
[bt] (9)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::thread::_Impl<std::_Bind_simple<std::function<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> >::_M_run()+0x3b) [0x2adc0ec2e36b]


Can anyone help me with it? Thanks very much!",0,RCNN example fails for using latest mxnet,"RCNN example fails for using latest mxnet I am using mxnet with CUDA9 + CUDNN7 and distributed training enabled. However, when I re-run the rcnn code in the example, I got the following error:

Traceback (most recent call last):
  File ""train_end2end.py"", line 199, in <module>
    main()
  File ""train_end2end.py"", line 196, in main
    lr=args.lr, lr_step=args.lr_step)
  File ""train_end2end.py"", line 158, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/base_module.py"", line 496, in fit
    self.update_metric(eval_metric, data_batch.label)
  File ""/----/mx-rcnn/rcnn/core/module.py"", line 227, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/module.py"", line 749, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/executor_group.py"", line 616, in update_metric
    eval_metric.update_dict(labels_, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 280, in update_dict
    metric.update_dict(labels, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 108, in update_dict
    self.update(label, pred)
  File ""/----/mx-rcnn/rcnn/core/metric.py"", line 51, in update
    pred_label = mx.ndarray.argmax_channel(pred).asnumpy().astype('int32')
  File ""/----/libs/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1801, in asnumpy
    ctypes.c_size_t(data.size)))
  File ""/----/libs/incubator-mxnet/python/mxnet/base.py"", line 148, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:08:44] src/operator/nn/./cudnn/cudnn_softmax_activation-inl.h:154: Check failed: e == CUDNN_STATUS_SUCCESS (3 vs. 0) cuDNN: CUDNN_STATUS_BAD_PARAM

Stack trace returned 10 entries:
[bt] (0) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::StackTrace()+0x3d) [0x2adc0c3395cd]
[bt] (1) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x2adc0c339a58]
[bt] (2) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::CuDNNSoftmaxActivationOp::Backward(mxnet::OpContext const&, mxnet::TBlob const&, mxnet::TBlob const&, mxnet::OpReqType const&, mxnet::TBlob const&)+0x10b9) [0x2adc0f5c7669]
[bt] (3) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::op::SoftmaxActivationGradCompute<mshadow::gpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0xd4c) [0x2adc0f5c2eac]
[bt] (4) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool)+0x50) [0x2adc0ec4cc40]
[bt] (5) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0x3284653) [0x2adc0ec54653]
[bt] (6)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x2c4) [0x2adc0ec2fcd4]
[bt] (7) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent> const&)+0x103) [0x2adc0ec34253]
[bt] (8) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#3}::operator()() const::{lambda(std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)+0x3e) [0x2adc0ec3448e]
[bt] (9)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::thread::_Impl<std::_Bind_simple<std::function<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> >::_M_run()+0x3b) [0x2adc0ec2e36b]


Can anyone help me with it? Thanks very much!"
incubator-mxnet,8898,"    class PReLU(gluon.HybridBlock):
        def __init__(self, *args):
            super(PReLU, self).__init__(*args)
            with self.name_scope():
                self.alpha = self.params.get('alpha', shape=(1,), init=mx.init.Zero())
                self.act = gluon.nn.Activation(activation='relu')

        def hybrid_forward(self, F, x, *args, **kwargs):
            pos = self.act(x)
            neg = F.negative(self.alpha.data()) * self.act(F.negative(x))
            return pos + neg

This custom block only works for non-hybridized models (error below), but would be nice to see this as a default activation option, something similar to this: ""gluon.nn.Activation(activation='prelu')"" - Is this in the plans going forward?

    AssertionError: Argument data must be Symbol instances, but got 
    [ 0.]
    <NDArray 1 @cpu(0)>
",0,PReLU in gluon,"PReLU in gluon     class PReLU(gluon.HybridBlock):
        def __init__(self, *args):
            super(PReLU, self).__init__(*args)
            with self.name_scope():
                self.alpha = self.params.get('alpha', shape=(1,), init=mx.init.Zero())
                self.act = gluon.nn.Activation(activation='relu')

        def hybrid_forward(self, F, x, *args, **kwargs):
            pos = self.act(x)
            neg = F.negative(self.alpha.data()) * self.act(F.negative(x))
            return pos + neg

This custom block only works for non-hybridized models (error below), but would be nice to see this as a default activation option, something similar to this: ""gluon.nn.Activation(activation='prelu')"" - Is this in the plans going forward?

    AssertionError: Argument data must be Symbol instances, but got 
    [ 0.]
    <NDArray 1 @cpu(0)>
"
incubator-mxnet,9117,"The following snippet 


gives



I think that argsort result should be ready to be used as index for matrices with no further conversion.
Please also note that argsort returns an NDAarray of floats and not of ints as one would expect for indexes.
",0,argsort produces an ndarray which cannot be used for indexing an ndarray,"argsort produces an ndarray which cannot be used for indexing an ndarray The following snippet 


gives



I think that argsort result should be ready to be used as index for matrices with no further conversion.
Please also note that argsort returns an NDAarray of floats and not of ints as one would expect for indexes.
"
incubator-mxnet,1102,"I create a new layer with python refered to the example [numpy_softmax.py](https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/numpy_softmax.py.
The fit process is good. But when I tried to load the model from json file there is a segmentation fault. I have known it is caused by the serialization and deserialization of the native python object. What can I do to make sure I can load the model correctly?
",0,Segmentation fault when loading a saved numpy-op model,"Segmentation fault when loading a saved numpy-op model I create a new layer with python refered to the example [numpy_softmax.py](https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/numpy_softmax.py.
The fit process is good. But when I tried to load the model from json file there is a segmentation fault. I have known it is caused by the serialization and deserialization of the native python object. What can I do to make sure I can load the model correctly?
"
incubator-mxnet,3568,"I know this is vague question, but I recently pulled the latest code and all of my models runs half as fast or worse now during training with the same code. My last version came from early March. I was wondering if something about training has been changed which could explain why this happened. I'm using convolutional, pooling, batch normalization, and dense layers with ReLU activations. Thanks!
",0,slowness with new code,"slowness with new code I know this is vague question, but I recently pulled the latest code and all of my models runs half as fast or worse now during training with the same code. My last version came from early March. I was wondering if something about training has been changed which could explain why this happened. I'm using convolutional, pooling, batch normalization, and dense layers with ReLU activations. Thanks!
"
incubator-mxnet,3723,"Now I would like to train the example code _train_cifar10_resnet.py_ with two local workers, is there any existed model average implementation I can directly use? (For example, CNTK has this kind of feature)
Or should I write the corresponding update rules for the kv-store?

Thanks a lot!",0,Does mxnet provide Model Average for distributed training?,"Does mxnet provide Model Average for distributed training? Now I would like to train the example code _train_cifar10_resnet.py_ with two local workers, is there any existed model average implementation I can directly use? (For example, CNTK has this kind of feature)
Or should I write the corresponding update rules for the kv-store?

Thanks a lot!"
incubator-mxnet,2018,"I see some papers about doing OCR without segmentation using CNN and LSTM.

Does mxnet support such work?
",0,example about doing OCR use CNN+RNN,"example about doing OCR use CNN+RNN I see some papers about doing OCR without segmentation using CNN and LSTM.

Does mxnet support such work?
"
incubator-mxnet,16996,"## Description
When input data is smaller than batch size, sometime it errors out with:


## To Reproduce


Using a batch size of 20 succeeds, but larger sizes fail. 

### Steps to reproduce
This is using the 1.6.0 branch
",0,mx.io.NDArrayIter cant pad when size is large,"mx.io.NDArrayIter cant pad when size is large ## Description
When input data is smaller than batch size, sometime it errors out with:


## To Reproduce


Using a batch size of 20 succeeds, but larger sizes fail. 

### Steps to reproduce
This is using the 1.6.0 branch
"
incubator-mxnet,7826,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows

Compiler:

Package used (Python/R/Scala/Julia): Python

MXNet version: master

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. nosetests tests/python/unittest/test_io.py
2.
3.

## What have you tried to solve it?

1.
2.
3.
",0,Enable the test_CSVIter which fails intermittently on windows,"Enable the test_CSVIter which fails intermittently on windows For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows

Compiler:

Package used (Python/R/Scala/Julia): Python

MXNet version: master

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. nosetests tests/python/unittest/test_io.py
2.
3.

## What have you tried to solve it?

1.
2.
3.
"
incubator-mxnet,1801,"Dear all,
Just as the title indicats that I would like to customise the flow of the gradients.
For example,


when updating the parameters, I want to update  only according to the gradient from  while ignoring .
I notice that this might be done via utilising  array, but can anyone give me a specific instruction? Any level will be acceptable for me (python or c++).

Thanks in advance.
",0,Customise control towards the gradient flow,"Customise control towards the gradient flow Dear all,
Just as the title indicats that I would like to customise the flow of the gradients.
For example,


when updating the parameters, I want to update  only according to the gradient from  while ignoring .
I notice that this might be done via utilising  array, but can anyone give me a specific instruction? Any level will be acceptable for me (python or c++).

Thanks in advance.
"
incubator-mxnet,902,"I want to init the fc layer weights alone , how to do ?
",0,how to initialize the weights,"how to initialize the weights I want to init the fc layer weights alone , how to do ?
"
incubator-mxnet,3198,"Lacking of operators is the major disadvantage of MXNet comparing to other frameworks. The current multidimensional array interface follows the  convention. See this [tutorial](http://nbviewer.jupyter.org/github/dmlc/mxnet-notebooks/blob/master/python/basic/ndarray.ipynb) for a quick overview. 

Now we are going to add the rest numpy operators into MXNet, and also fix the existing operators if their are different to the according ones in numpy.

I grabbed numpy's routines from [this page](https://docs.scipy.org/doc/numpy/reference/routines.html). The comparison to MXNet's operators will be listed in a few following issues. 

For an operator, there are 4 states 
- **v** : already done, and it is consistent to numpy
- **p** : partially done. the part should be fixed is on the comments
- **x** : not exists, need to add into mxnet
- **=** : not exists, but will not support in a short time
- **?** : not sure whether x or =, leave for discussion
  We will use separate issues to track each operator category. The schedule is
- [ ] survey the current status, and which operators should be added or fixed.
- [ ] examples codes to implement new operators
- [ ] assign jobs to contributors 

Also some related tasks:
- better operator documents
- better unittest 
- improve neural network related operators 
",0,Check list for more operators,"Check list for more operators Lacking of operators is the major disadvantage of MXNet comparing to other frameworks. The current multidimensional array interface follows the  convention. See this [tutorial](http://nbviewer.jupyter.org/github/dmlc/mxnet-notebooks/blob/master/python/basic/ndarray.ipynb) for a quick overview. 

Now we are going to add the rest numpy operators into MXNet, and also fix the existing operators if their are different to the according ones in numpy.

I grabbed numpy's routines from [this page](https://docs.scipy.org/doc/numpy/reference/routines.html). The comparison to MXNet's operators will be listed in a few following issues. 

For an operator, there are 4 states 
- **v** : already done, and it is consistent to numpy
- **p** : partially done. the part should be fixed is on the comments
- **x** : not exists, need to add into mxnet
- **=** : not exists, but will not support in a short time
- **?** : not sure whether x or =, leave for discussion
  We will use separate issues to track each operator category. The schedule is
- [ ] survey the current status, and which operators should be added or fixed.
- [ ] examples codes to implement new operators
- [ ] assign jobs to contributors 

Also some related tasks:
- better operator documents
- better unittest 
- improve neural network related operators 
"
incubator-mxnet,3915,"Some changes made in API pages, for example, changing the link content of left sidebar, makes auto_module_index.js failed. Now some entries such as ""Symbol Creation API Reference"" has no child level any more. ",0,auto_module_index.js doesn't work properly,"auto_module_index.js doesn't work properly Some changes made in API pages, for example, changing the link content of left sidebar, makes auto_module_index.js failed. Now some entries such as ""Symbol Creation API Reference"" has no child level any more. "
incubator-mxnet,2727,"@tmatas 
I am not sure about using the im2rec.py,
 for example, the file 'im2rec.py' in the folder 'D:/test' and the two class of trainning images(for two classification) in the folders 'D:/test/train1' and 'D:/test/train2', respectively, and the image file is jpeg format.
as for as the example, how to create the rec file for  mx.io.ImageRecordIter with  im2rec.py?  
thanks for your help very much.
",0,about using the im2rec.py,"about using the im2rec.py @tmatas 
I am not sure about using the im2rec.py,
 for example, the file 'im2rec.py' in the folder 'D:/test' and the two class of trainning images(for two classification) in the folders 'D:/test/train1' and 'D:/test/train2', respectively, and the image file is jpeg format.
as for as the example, how to create the rec file for  mx.io.ImageRecordIter with  im2rec.py?  
thanks for your help very much.
"
incubator-mxnet,13441,"It would be nice to add some spec validations to the random namespace https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/random.clj

So that if a user calls a function with the incorrect arguments, it will guide them to the correct form.

Using the  function as in https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/module.clj#L186 and the correct specs would be a great addition to the project.

Addition of unit tests to test a failing case of the spec that an exception is thrown would be great too :)
",0,[Clojure] Add Spec Validations for the Random namespace,"[Clojure] Add Spec Validations for the Random namespace It would be nice to add some spec validations to the random namespace https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/random.clj

So that if a user calls a function with the incorrect arguments, it will guide them to the correct form.

Using the  function as in https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/module.clj#L186 and the correct specs would be a great addition to the project.

Addition of unit tests to test a failing case of the spec that an exception is thrown would be great too :)
"
incubator-mxnet,14895,"On this page: https://github.com/apache/incubator-mxnet/blob/master/docs/install/build_from_source.md

If click the ubuntu hyperlink, it is broken:
https://github.com/apache/incubator-mxnet/blob/master/docs/install/ubuntu_setup.html
",0,[DOC] Build from source link for ubuntu is broken,"[DOC] Build from source link for ubuntu is broken On this page: https://github.com/apache/incubator-mxnet/blob/master/docs/install/build_from_source.md

If click the ubuntu hyperlink, it is broken:
https://github.com/apache/incubator-mxnet/blob/master/docs/install/ubuntu_setup.html
"
incubator-mxnet,6912,"where the tools in your project?
",0,I'm sorry that i cant find the tools?,"I'm sorry that i cant find the tools? where the tools in your project?
"
incubator-mxnet,12030,"For example:

My code is something like above. Both resnet 50 is initialized by the same initializer. However, the outputs of these two softmax are different in the begining, Something likes 27.x vs 21.x

It is very strange I think.",0,What happen when I group two same model together and train it?,"What happen when I group two same model together and train it? For example:

My code is something like above. Both resnet 50 is initialized by the same initializer. However, the outputs of these two softmax are different in the begining, Something likes 27.x vs 21.x

It is very strange I think."
incubator-mxnet,16932,"## Description
Sometimes users may expect Gluon hybridization to magically do things it currently cannot do.
An example is https://github.com/apache/incubator-mxnet/issues/16926, where the user expects  control flow to be incorporated into the hybridized graph.

Instead of silently ignoring the control flow and picking the branch that was selected during the first call to the hybrid network, we should error out or warn the user.",0,Detect unsupported usage of Gluon Hybridization,"Detect unsupported usage of Gluon Hybridization ## Description
Sometimes users may expect Gluon hybridization to magically do things it currently cannot do.
An example is https://github.com/apache/incubator-mxnet/issues/16926, where the user expects  control flow to be incorporated into the hybridized graph.

Instead of silently ignoring the control flow and picking the branch that was selected during the first call to the hybrid network, we should error out or warn the user."
incubator-mxnet,15482,"## Description
 I use mx2onnx onnx_mxnet.export_model to transfer mxnet symbol to onnx . But the moving_mean&moving_var param of Batchnorm is not in the params. So the 

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm usining Python)

## Build info (Required if built from source)

Compiler (gcc):

MXNet commit hash:
(da4b2a82511df)

Build config:


ifndef CC
export CC = gcc
endif
ifndef CXX
export CXX = g++
endif
ifndef NVCC
export NVCC = nvcc
endif

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether to turn on segfault signal handler to log the stack trace
USE_SIGNAL_HANDLER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 1

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
USE_CUDA_PATH = /usr/local/cuda
#USE_CUDA_PATH = NONE

# whether to enable CUDA runtime compilation
ENABLE_CUDA_RTC = 1

# whether use CuDNN R3 library
USE_CUDNN = 1

# whether to use NVTX when profiling
USE_NVTX = 0

#whether to use NCCL library
USE_NCCL = 0
#add the path to NCCL library
USE_NCCL_PATH = NONE

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 1
# Add OpenCV include path, in which the directory  exists
USE_OPENCV_INC_PATH = NONE
# Add OpenCV shared library path, in which the shared library exists
USE_OPENCV_LIB_PATH = NONE

#whether use libjpeg-turbo for image decode without OpenCV wrapper
USE_LIBJPEG_TURBO = 0
#add the path to libjpeg-turbo library
USE_LIBJPEG_TURBO_PATH = NONE

# use openmp for parallelization
USE_OPENMP = 1

# whether use MKL-DNN library: 0 = disabled, 1 = enabled
# if USE_MKLDNN is not defined, MKL-DNN will be enabled by default on x86 Linux.
# you can disable it explicity with USE_MKLDNN = 0
USE_MKLDNN = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# whether use lapack during compilation
# only effective when compiled with blas versions openblas/apple/atlas/mkl
USE_LAPACK = 1

# path to lapack library in case of a non-standard installation
USE_LAPACK_PATH =

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
	USE_F16C=0
else
	USE_SSE=1
endif

#----------------------------
# F16C instruction support for faster arithmetic of fp16 on CPU
#----------------------------
# For distributed training with fp16, this helps even if training on GPUs
# If left empty, checks CPU support and turns it on.
# For cross compilation, please check support for F16C on target device and turn off if necessary.
USE_F16C =

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 0

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# performance settings
#----------------------------
# Use operator tuning
USE_OPERATOR_TUNING = 1

# Use gperftools if found
# Disable because of #8968
USE_GPERFTOOLS = 0

# path to gperftools (tcmalloc) library in case of a non-standard installation
USE_GPERFTOOLS_PATH =

# Link gperftools statically
USE_GPERFTOOLS_STATIC =

# Use JEMalloc if found, and not using gperftools
USE_JEMALLOC = 1

# path to jemalloc library in case of a non-standard installation
USE_JEMALLOC_PATH =

# Link jemalloc statically
USE_JEMALLOC_STATIC =

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

# Use int64_t type to represent the total number of elements in a tensor
# This will cause performance degradation reported in issue #14496
# Set to 1 for large tensor with tensor size greater than INT32_MAX i.e. 2147483647
# Note: the size of each dimension is still bounded by INT32_MAX
USE_INT64_TENSOR_SIZE = 0

# Python executable. Needed for cython target
PYTHON = python

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk


#WARPCTC_PATH = $(HOME)/warp-ctc
WARPCTC_PATH = /home/deep/warp-ctc
MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk

## Error Message:
INFO:root:Converting idx: 0, op: null, name: data
INFO:root:Converting idx: 1, op: null, name: first-3x3-conv-conv2d_weight
INFO:root:Converting idx: 2, op: Convolution, name: first-3x3-conv-conv2d
INFO:root:Converting idx: 3, op: null, name: first-3x3-conv-batchnorm_gamma
INFO:root:Converting idx: 4, op: null, name: first-3x3-conv-batchnorm_beta
INFO:root:Converting idx: 5, op: null, name: first-3x3-conv-batchnorm_moving_mean
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 63, in apport_excepthook
    from apport.fileutils import likely_packaged, get_recent_crashes
  File ""/usr/lib/python3/dist-packages/apport/__init__.py"", line 5, in <module>
    from apport.report import Report
  File ""/usr/lib/python3/dist-packages/apport/report.py"", line 30, in <module>
    import apport.fileutils
  File ""/usr/lib/python3/dist-packages/apport/fileutils.py"", line 23, in <module>
    from apport.packaging_impl import impl as packaging
  File ""/usr/lib/python3/dist-packages/apport/packaging_impl.py"", line 23, in <module>
    import apt
  File ""/usr/lib/python3/dist-packages/apt/__init__.py"", line 23, in <module>
    import apt_pkg
ModuleNotFoundError: No module named 'apt_pkg'

Original exception was:
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'

## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.python3 tran2onnx.py
2.

## What have you tried to solve it?

1.By debugging ,the moving_mean&moving_var  of batchnorm is not in params ,so the converter treat it as input which is not real.
2. There should be code to process the moving_mean&moving_var  of batchnorm indepently.
",0,mx2onnx error  about  batchnorm,"mx2onnx error  about  batchnorm ## Description
 I use mx2onnx onnx_mxnet.export_model to transfer mxnet symbol to onnx . But the moving_mean&moving_var param of Batchnorm is not in the params. So the 

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm usining Python)

## Build info (Required if built from source)

Compiler (gcc):

MXNet commit hash:
(da4b2a82511df)

Build config:


ifndef CC
export CC = gcc
endif
ifndef CXX
export CXX = g++
endif
ifndef NVCC
export NVCC = nvcc
endif

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether to turn on segfault signal handler to log the stack trace
USE_SIGNAL_HANDLER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 1

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
USE_CUDA_PATH = /usr/local/cuda
#USE_CUDA_PATH = NONE

# whether to enable CUDA runtime compilation
ENABLE_CUDA_RTC = 1

# whether use CuDNN R3 library
USE_CUDNN = 1

# whether to use NVTX when profiling
USE_NVTX = 0

#whether to use NCCL library
USE_NCCL = 0
#add the path to NCCL library
USE_NCCL_PATH = NONE

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 1
# Add OpenCV include path, in which the directory  exists
USE_OPENCV_INC_PATH = NONE
# Add OpenCV shared library path, in which the shared library exists
USE_OPENCV_LIB_PATH = NONE

#whether use libjpeg-turbo for image decode without OpenCV wrapper
USE_LIBJPEG_TURBO = 0
#add the path to libjpeg-turbo library
USE_LIBJPEG_TURBO_PATH = NONE

# use openmp for parallelization
USE_OPENMP = 1

# whether use MKL-DNN library: 0 = disabled, 1 = enabled
# if USE_MKLDNN is not defined, MKL-DNN will be enabled by default on x86 Linux.
# you can disable it explicity with USE_MKLDNN = 0
USE_MKLDNN = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# whether use lapack during compilation
# only effective when compiled with blas versions openblas/apple/atlas/mkl
USE_LAPACK = 1

# path to lapack library in case of a non-standard installation
USE_LAPACK_PATH =

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
	USE_F16C=0
else
	USE_SSE=1
endif

#----------------------------
# F16C instruction support for faster arithmetic of fp16 on CPU
#----------------------------
# For distributed training with fp16, this helps even if training on GPUs
# If left empty, checks CPU support and turns it on.
# For cross compilation, please check support for F16C on target device and turn off if necessary.
USE_F16C =

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 0

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# performance settings
#----------------------------
# Use operator tuning
USE_OPERATOR_TUNING = 1

# Use gperftools if found
# Disable because of #8968
USE_GPERFTOOLS = 0

# path to gperftools (tcmalloc) library in case of a non-standard installation
USE_GPERFTOOLS_PATH =

# Link gperftools statically
USE_GPERFTOOLS_STATIC =

# Use JEMalloc if found, and not using gperftools
USE_JEMALLOC = 1

# path to jemalloc library in case of a non-standard installation
USE_JEMALLOC_PATH =

# Link jemalloc statically
USE_JEMALLOC_STATIC =

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

# Use int64_t type to represent the total number of elements in a tensor
# This will cause performance degradation reported in issue #14496
# Set to 1 for large tensor with tensor size greater than INT32_MAX i.e. 2147483647
# Note: the size of each dimension is still bounded by INT32_MAX
USE_INT64_TENSOR_SIZE = 0

# Python executable. Needed for cython target
PYTHON = python

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk


#WARPCTC_PATH = $(HOME)/warp-ctc
WARPCTC_PATH = /home/deep/warp-ctc
MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk

## Error Message:
INFO:root:Converting idx: 0, op: null, name: data
INFO:root:Converting idx: 1, op: null, name: first-3x3-conv-conv2d_weight
INFO:root:Converting idx: 2, op: Convolution, name: first-3x3-conv-conv2d
INFO:root:Converting idx: 3, op: null, name: first-3x3-conv-batchnorm_gamma
INFO:root:Converting idx: 4, op: null, name: first-3x3-conv-batchnorm_beta
INFO:root:Converting idx: 5, op: null, name: first-3x3-conv-batchnorm_moving_mean
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 63, in apport_excepthook
    from apport.fileutils import likely_packaged, get_recent_crashes
  File ""/usr/lib/python3/dist-packages/apport/__init__.py"", line 5, in <module>
    from apport.report import Report
  File ""/usr/lib/python3/dist-packages/apport/report.py"", line 30, in <module>
    import apport.fileutils
  File ""/usr/lib/python3/dist-packages/apport/fileutils.py"", line 23, in <module>
    from apport.packaging_impl import impl as packaging
  File ""/usr/lib/python3/dist-packages/apport/packaging_impl.py"", line 23, in <module>
    import apt
  File ""/usr/lib/python3/dist-packages/apt/__init__.py"", line 23, in <module>
    import apt_pkg
ModuleNotFoundError: No module named 'apt_pkg'

Original exception was:
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'

## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.python3 tran2onnx.py
2.

## What have you tried to solve it?

1.By debugging ,the moving_mean&moving_var  of batchnorm is not in params ,so the converter treat it as input which is not real.
2. There should be code to process the moving_mean&moving_var  of batchnorm indepently.
"
incubator-mxnet,6736,"When  in a call to  of a ,  will try to concatenate the outputs from the different devices along the major axis.

The major axis is computed based on  in the initializer of .

What is the recommended way to set the  of a symbol? Simply pass  when constructing the symbol? Can the attribute be set automatically during module binding?

Setting  is necessary, as it is otherwise , leading to  trying to concatenate along  which will fail if the batch size is not divisible by the number of devices and the symbol outputs a shape (1, batch_size_per_device, X).

I.e. in case of 3 devices and batch size 128, concatenating  along  will fail.",0,DataParallelExecutorGroup: layout handling for symbols,"DataParallelExecutorGroup: layout handling for symbols When  in a call to  of a ,  will try to concatenate the outputs from the different devices along the major axis.

The major axis is computed based on  in the initializer of .

What is the recommended way to set the  of a symbol? Simply pass  when constructing the symbol? Can the attribute be set automatically during module binding?

Setting  is necessary, as it is otherwise , leading to  trying to concatenate along  which will fail if the batch size is not divisible by the number of devices and the symbol outputs a shape (1, batch_size_per_device, X).

I.e. in case of 3 devices and batch size 128, concatenating  along  will fail."
incubator-mxnet,1246,"I find the mxnet add torch support, so I have such question.

@piiswrong 
",0,[torch backend] does torch backend as efficient  as original mxnet's op?,"[torch backend] does torch backend as efficient  as original mxnet's op? I find the mxnet add torch support, so I have such question.

@piiswrong 
"
incubator-mxnet,9853,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/397/pipeline



",0,Flaky test_operator.test_binary_op,"Flaky test_operator.test_binary_op http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/397/pipeline



"
incubator-mxnet,9044,"# Description
Was able to built libmxnet.so, and successfully build the Scala package, but run_gan_mnist.sh fails.

## Environment info (Required)
I had to change diagnose.py:113 to except IOError as e: since FileNotFoundError is only on Python 3.


Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):


MXNet commit hash:
2700ddbbeef212879802f7f0c0812192ec5c2b77

Build config:


## Error Message:


## Minimum reproducible example
https://github.com/apache/incubator-mxnet/blob/master/scala-package/examples/scripts/run_gan_mnist.sh

## Steps to reproduce
1. make -j4
2. make scalapkg

3. make scalatest

4. make scalainstall

5. get the mnist data

6. update run_gan_mnist.sh to be cpu

7. bash run_gan_mnist.sh -1 ../../data ../../tmp


## What have you tried to solve it?

1. Check the links in libmxnet.so are there:

2. Check the built openblas from https://github.com/xianyi/OpenBLAS, but that doesn't seem to be the issue since the cblas function is there:
 
3. Looked at other possibly related issues, like #2184, which was closed and placed in the TODO in #3084 by @javelinjs but that was closed without having been resolved.",0,[scala] run_gan_mnist.sh fails,"[scala] run_gan_mnist.sh fails # Description
Was able to built libmxnet.so, and successfully build the Scala package, but run_gan_mnist.sh fails.

## Environment info (Required)
I had to change diagnose.py:113 to except IOError as e: since FileNotFoundError is only on Python 3.


Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):


MXNet commit hash:
2700ddbbeef212879802f7f0c0812192ec5c2b77

Build config:


## Error Message:


## Minimum reproducible example
https://github.com/apache/incubator-mxnet/blob/master/scala-package/examples/scripts/run_gan_mnist.sh

## Steps to reproduce
1. make -j4
2. make scalapkg

3. make scalatest

4. make scalainstall

5. get the mnist data

6. update run_gan_mnist.sh to be cpu

7. bash run_gan_mnist.sh -1 ../../data ../../tmp


## What have you tried to solve it?

1. Check the links in libmxnet.so are there:

2. Check the built openblas from https://github.com/xianyi/OpenBLAS, but that doesn't seem to be the issue since the cblas function is there:
 
3. Looked at other possibly related issues, like #2184, which was closed and placed in the TODO in #3084 by @javelinjs but that was closed without having been resolved."
incubator-mxnet,12839,"I mentioned in #12822 that something in the README of the Clojure package was off and intended to fix it. However, now that I read the text in a bit more detail, I have some broader questions that might be good to discuss in advance before I come up with some random change.

The main issue with the current version is that as someone not familiar with the package architecture and just starting out with Clojure (that's me currently), you just follow instructions and don't really have a clue what you're doing. Some of the nagging questions while doing that were:

- If I want to use prebuilt jars, what *exactly* do I have to do?

  The fact that some of the instructions I need to follow are under *Cloning the repo and running from source* is rather confusing. I feel that instructions for ""From prebuilt jars"" and ""From source"" should be entirely separate.
  Maybe also good to know would be which possible scenarios there exist. If I should guess I would say (1) everything prebuilt jars, (2) all deps from prebuilt jars, but Clojure package from source, (3-infinity) all possible combinations of prebuilt jars and manual builds for deps, most notably the Scala package and MXNet core.

- Prebuilt jars of what?

  Certainly too much to mention, I guess, but the biggest ones, the Scala package and the base MXNet package would be worth mentioning.

- Where do the instructions end?

  I found it surprising to scroll past the examples to find a header *Build from MXNet Source*, because ""source"" was mentioned earlier already. Are those two things connected?
  One way to make it clear that there are two entirely separate sets of instructions (are there?) is to make headers **Method 1: Use prebuilt jars** and **Method 2: Build from source**.

- The prebuilt Scala package isn't working (#12822, workaround in place now). Can I build it from source but still use a prebuilt jar for MXNet core?

As I mentioned above, I'm not really familiar with the build infrastructure and the Clojure package architecture, so I wouldn't exactly know what to write as instructions. But equipped with some extra knowledge, I certainly could.",0,"[Clojure] Readme: ""Getting Started"" not entirely trivial to follow","[Clojure] Readme: ""Getting Started"" not entirely trivial to follow I mentioned in #12822 that something in the README of the Clojure package was off and intended to fix it. However, now that I read the text in a bit more detail, I have some broader questions that might be good to discuss in advance before I come up with some random change.

The main issue with the current version is that as someone not familiar with the package architecture and just starting out with Clojure (that's me currently), you just follow instructions and don't really have a clue what you're doing. Some of the nagging questions while doing that were:

- If I want to use prebuilt jars, what *exactly* do I have to do?

  The fact that some of the instructions I need to follow are under *Cloning the repo and running from source* is rather confusing. I feel that instructions for ""From prebuilt jars"" and ""From source"" should be entirely separate.
  Maybe also good to know would be which possible scenarios there exist. If I should guess I would say (1) everything prebuilt jars, (2) all deps from prebuilt jars, but Clojure package from source, (3-infinity) all possible combinations of prebuilt jars and manual builds for deps, most notably the Scala package and MXNet core.

- Prebuilt jars of what?

  Certainly too much to mention, I guess, but the biggest ones, the Scala package and the base MXNet package would be worth mentioning.

- Where do the instructions end?

  I found it surprising to scroll past the examples to find a header *Build from MXNet Source*, because ""source"" was mentioned earlier already. Are those two things connected?
  One way to make it clear that there are two entirely separate sets of instructions (are there?) is to make headers **Method 1: Use prebuilt jars** and **Method 2: Build from source**.

- The prebuilt Scala package isn't working (#12822, workaround in place now). Can I build it from source but still use a prebuilt jar for MXNet core?

As I mentioned above, I'm not really familiar with the build infrastructure and the Clojure package architecture, so I wouldn't exactly know what to write as instructions. But equipped with some extra knowledge, I certainly could."
incubator-mxnet,7110,"I was wondering if it was already easy to use mxnet.metric as the loss function in place of defining my own or using the gluon loss. For instance, I would prefer to use the mx.metric perplexity. 

Currently, I am defining my own loss function which calls the perplexity class, but this seems like a feature that would be good to have in gluon.",0,[gluon] Using mxnet evaluation metrics in gluon,"[gluon] Using mxnet evaluation metrics in gluon I was wondering if it was already easy to use mxnet.metric as the loss function in place of defining my own or using the gluon loss. For instance, I would prefer to use the mx.metric perplexity. 

Currently, I am defining my own loss function which calls the perplexity class, but this seems like a feature that would be good to have in gluon."
incubator-mxnet,9068,"win10, mxnet 0.12,python 2.7
For the official example WARPCTC, I am trying to use sym.contrib.ctc_loss instead of baidu WARPCTC, as I am with windows. So I modified . 
 
Noitice that  is what I modified. Then running ,  I get error said: 

I wonder how to fix it.",0,How to use sym.contrib.ctc_loss instead of baidu WARPCTC,"How to use sym.contrib.ctc_loss instead of baidu WARPCTC win10, mxnet 0.12,python 2.7
For the official example WARPCTC, I am trying to use sym.contrib.ctc_loss instead of baidu WARPCTC, as I am with windows. So I modified . 
 
Noitice that  is what I modified. Then running ,  I get error said: 

I wonder how to fix it."
incubator-mxnet,7865,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10

Compiler: VS2015

Package used (Python/R/Scala/Julia):

MXNet version: 0.905

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
The loaded NDArrays in the map (from LoadToMap) do not have the device context 'GPU'. 

## Minimum reproducible example
I use the following code to read params from file:
        m_params_map = NDArray::LoadToMap(fileNamePars);
	m_args_map.clear();
	m_auxs_map.clear();

	int pos = 0;
	for (auto it = m_params_map.begin(); it != m_params_map.end(); ++it)
	{
		const string key = it->first;
		NDArray val = it->second;
		if ((pos = key.find(""arg:"")) != string::npos)
			m_args_map[key.substr(4)] = val; 
		if ((pos = key.find(""aux:"")) != string::npos)
			m_auxs_map[key.substr(4)] = val;
	}
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
",0,How to load params with LoadToMap c++ api and set device contect to GPU?,"How to load params with LoadToMap c++ api and set device contect to GPU? For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10

Compiler: VS2015

Package used (Python/R/Scala/Julia):

MXNet version: 0.905

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
The loaded NDArrays in the map (from LoadToMap) do not have the device context 'GPU'. 

## Minimum reproducible example
I use the following code to read params from file:
        m_params_map = NDArray::LoadToMap(fileNamePars);
	m_args_map.clear();
	m_auxs_map.clear();

	int pos = 0;
	for (auto it = m_params_map.begin(); it != m_params_map.end(); ++it)
	{
		const string key = it->first;
		NDArray val = it->second;
		if ((pos = key.find(""arg:"")) != string::npos)
			m_args_map[key.substr(4)] = val; 
		if ((pos = key.find(""aux:"")) != string::npos)
			m_auxs_map[key.substr(4)] = val;
	}
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
"
incubator-mxnet,14484,"## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
",0,Odd behaviour with 'device' kvstore and CUDA illegal memory access errors,"Odd behaviour with 'device' kvstore and CUDA illegal memory access errors ## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
"
incubator-mxnet,11120,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10656/7/pipeline/



Possibly related to hardcoding ports.",0,Address already in use during tutorial test,"Address already in use during tutorial test http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10656/7/pipeline/



Possibly related to hardcoding ports."
incubator-mxnet,4841,"trying to reproduce the faster-rcnn tutorial as in http://mxnet.io/tutorials/computer_vision/detection.html
running 
python train_alternate.py --gpus 0

yields this error:
Traceback (most recent call last):
  File ""train_alternate.py"", line 7, in <module>
    from rcnn.tools.train_rpn import train_rpn
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/tools/train_rpn.py"", line 7, in <module>
    from ..symbol import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/__init__.py"", line 1, in <module>
    from symbol_vgg import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/symbol_vgg.py"", line 2, in <module>
    import proposal
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/proposal.py"", line 11, in <module>
    from rcnn.processing.bbox_transform import bbox_pred, clip_boxes
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/processing/bbox_transform.py"", line 2, in <module>
    from ..cython.bbox import bbox_overlaps_cython
ImportError: No module named bbox

I've tried searching on bbox module but could not find it anywhere. My mxnet is compiled in ubuntu 16 with cuda and cdnn support",0,No module named bbox when running faster-cnn exampl,"No module named bbox when running faster-cnn exampl trying to reproduce the faster-rcnn tutorial as in http://mxnet.io/tutorials/computer_vision/detection.html
running 
python train_alternate.py --gpus 0

yields this error:
Traceback (most recent call last):
  File ""train_alternate.py"", line 7, in <module>
    from rcnn.tools.train_rpn import train_rpn
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/tools/train_rpn.py"", line 7, in <module>
    from ..symbol import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/__init__.py"", line 1, in <module>
    from symbol_vgg import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/symbol_vgg.py"", line 2, in <module>
    import proposal
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/proposal.py"", line 11, in <module>
    from rcnn.processing.bbox_transform import bbox_pred, clip_boxes
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/processing/bbox_transform.py"", line 2, in <module>
    from ..cython.bbox import bbox_overlaps_cython
ImportError: No module named bbox

I've tried searching on bbox module but could not find it anywhere. My mxnet is compiled in ubuntu 16 with cuda and cdnn support"
incubator-mxnet,7491,"I found that GPUDeviceStorage is not used, however CPUDeviceStorage is used, why is that?",0,GPUDeviceStorage is not used? why?,"GPUDeviceStorage is not used? why? I found that GPUDeviceStorage is not used, however CPUDeviceStorage is used, why is that?"
incubator-mxnet,3517,"I found faster RCNN is supported in mxnet.  Can I train it on multi-GPU with multi-machine ?
",0,Can I train the faster_RCNN with multi-GPU with multi-machine ,"Can I train the faster_RCNN with multi-GPU with multi-machine  I found faster RCNN is supported in mxnet.  Can I train it on multi-GPU with multi-machine ?
"
incubator-mxnet,3058,"how to output loss \ accuray \ or others log info.
if have any  tutorial or demo?
I search fo a long time ,no harvest.
tks.
",0,how to output loss,"how to output loss how to output loss \ accuray \ or others log info.
if have any  tutorial or demo?
I search fo a long time ,no harvest.
tks.
"
incubator-mxnet,2171,"Hi,

I am trying to implement the sequence to sequence model using mxnet. It seems that there is no argmax API for mxnet symbol (http://mxnet.readthedocs.io/en/latest/packages/python/symbol.html). So how should I implement the decoder part when emitting a word after softmax? Any suggestions? 

Thanks.
",0,Symbol argmax API absence,"Symbol argmax API absence Hi,

I am trying to implement the sequence to sequence model using mxnet. It seems that there is no argmax API for mxnet symbol (http://mxnet.readthedocs.io/en/latest/packages/python/symbol.html). So how should I implement the decoder part when emitting a word after softmax? Any suggestions? 

Thanks.
"
incubator-mxnet,10217,"## Description
Building with opencv and cmake causes link errors  on ubuntu
I installed opencv with 


## Environment info (Required)



Package used: N/A 

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc
MXNet commit hash: 09281c76bc215823bc74b34f9ac65d906b741377

Build config:


## Error Message:


Link error
TIFFReadRGBAStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteEncodedStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteScanline@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFNumberOfStrips@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFReadEncodedTile@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFClose@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFOpen@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetField@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetErrorHandler@LIBTIFF_4.0'
collect2: error: ld returned 1 exit status
ninja: build stopped: subcommand failed.
`


## Minimum reproducible example
N/A
## Steps to reproduce
1. cmake -DCMAKE_BUILD_TYPE=Release -DUSE_GPERFTOOLS=OFF -DUSE_DIST_KVSTORE=ON -DUSE_SSE=ON -DUSE_MKLDNN=OFF .. 
",0,Building with OpenCV causes link errors,"Building with OpenCV causes link errors ## Description
Building with opencv and cmake causes link errors  on ubuntu
I installed opencv with 


## Environment info (Required)



Package used: N/A 

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc
MXNet commit hash: 09281c76bc215823bc74b34f9ac65d906b741377

Build config:


## Error Message:


Link error
TIFFReadRGBAStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteEncodedStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteScanline@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFNumberOfStrips@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFReadEncodedTile@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFClose@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFOpen@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetField@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetErrorHandler@LIBTIFF_4.0'
collect2: error: ld returned 1 exit status
ninja: build stopped: subcommand failed.
`


## Minimum reproducible example
N/A
## Steps to reproduce
1. cmake -DCMAKE_BUILD_TYPE=Release -DUSE_GPERFTOOLS=OFF -DUSE_DIST_KVSTORE=ON -DUSE_SSE=ON -DUSE_MKLDNN=OFF .. 
"
incubator-mxnet,14177,"Hi

I have been trying to optimize my models with hybridize and accidentally misspelled an argument to the method. I got the quite interesting message below (using a minimal example):


Although I find this message quite useful, I also found it quite surprising since [the documentation](https://mxnet.incubator.apache.org/versions/master/api/python/gluon/gluon.html?highlight=hybrid#mxnet.gluon.Block.hybridize) only mentions  and .

I am not sure what the effect of the other parameters are and when changing them is appropriate. I am hoping that someone could tell me and I suggest that the documentation be updated to describe the undocumented keyword arguments.",0,Insufficient documentation for .hybridize(),"Insufficient documentation for .hybridize() Hi

I have been trying to optimize my models with hybridize and accidentally misspelled an argument to the method. I got the quite interesting message below (using a minimal example):


Although I find this message quite useful, I also found it quite surprising since [the documentation](https://mxnet.incubator.apache.org/versions/master/api/python/gluon/gluon.html?highlight=hybrid#mxnet.gluon.Block.hybridize) only mentions  and .

I am not sure what the effect of the other parameters are and when changing them is appropriate. I am hoping that someone could tell me and I suggest that the documentation be updated to describe the undocumented keyword arguments."
incubator-mxnet,14755,"## Description
There is a build issue happened on MXNet github repo on Linux if using below command:
 make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl **_### test_**

The build is okay if ""test"" removed.

@TaoLv @pengzhao-intel 

## Environment info (Required)
GCC 4.8.5
CentOS 7.5


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
GCC4.8.5

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)


## What have you tried to solve it?
@zachgk 
The build issue is most likely introduced after commit https://github.com/apache/incubator-mxnet/commit/391a1be260eb75b437ebced6743647b8e9df7802
The commit https://github.com/apache/incubator-mxnet/commit/dc48cd2a5a6460171bf9b842453866e731e6ff7d seems changing the HEAD of 3rdpary/googletest to eb9225c, if I switch the 3rdpary/googletest to previous HEAD ec44c6c , then make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl test can succeed.

",0,"Build on Linux will fail if ""test"" option used","Build on Linux will fail if ""test"" option used ## Description
There is a build issue happened on MXNet github repo on Linux if using below command:
 make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl **_### test_**

The build is okay if ""test"" removed.

@TaoLv @pengzhao-intel 

## Environment info (Required)
GCC 4.8.5
CentOS 7.5


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
GCC4.8.5

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)


## What have you tried to solve it?
@zachgk 
The build issue is most likely introduced after commit https://github.com/apache/incubator-mxnet/commit/391a1be260eb75b437ebced6743647b8e9df7802
The commit https://github.com/apache/incubator-mxnet/commit/dc48cd2a5a6460171bf9b842453866e731e6ff7d seems changing the HEAD of 3rdpary/googletest to eb9225c, if I switch the 3rdpary/googletest to previous HEAD ec44c6c , then make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl test can succeed.

"
incubator-mxnet,1712,"Hi,

I was just wondering how metrics are evaluated at the end of a training epoch and during validation afterwards. Is it the mean metric value per batch? 

If so, at least for validation wouldn't it be more robust to evaluate the metric based off of the prediction values off of the entire eval dataset? One example I can think of is for validation with a dataset that has sparse labels. In some batches, certain labels may not appear, breaking specific metric functions.

Thanks!
",0,Train and Validation Metric Evaluation,"Train and Validation Metric Evaluation Hi,

I was just wondering how metrics are evaluated at the end of a training epoch and during validation afterwards. Is it the mean metric value per batch? 

If so, at least for validation wouldn't it be more robust to evaluate the metric based off of the prediction values off of the entire eval dataset? One example I can think of is for validation with a dataset that has sparse labels. In some batches, certain labels may not appear, breaking specific metric functions.

Thanks!
"
incubator-mxnet,14955,"Now gluon has a  function for calculate total params for a network but don't have a tool for calculate network FLOPs(G).

Why need this?
 - Model FLOPs could straightly measure a network inference speed.
 - Research needed.
 - Some of ops are widely used in many networks like conv, pooling, fc, bn
, relu, softmax.
 - Some of ops are looping many times and have different shape of feature_maps outpus, it's hard to calculate them manually.

But it's hard for calculating all of ops and actually not necessary(Some discussions [here](https://discuss.gluon.ai/t/topic/10228/8)). So I partition them on demand.
 1. Widely used in many networks and most commonly used.[urgent]
    - Conv2d/3d
    - Maxpool2d/3d
    - Avgpool 2d/3d
    - GlobalAvgPool2d/3d
    - FC
    - Relu, LeakyReLU, PReLU, Tanh, Sigmoid
    - BN
    - Softmax
    - RNN(basic rnn is just matrix multiplication, more complicated I don't know, this may need add if anything misses.)
 2. Used somewhere but may not common.[not urgent]
    - Dropout
    - Conv1d, Maxpool1d, Avgpool1d
    - GlobalAvgPool1d
    - ConvTranspose1d/2d/3d (GAN may use this, but for now GAN don't care about FLOPs)
    - UpSampling bilinear/nearest
    - InstanceNorm, LayerNorm
    - L2Normalization
3. May only use once or little times in a model, their FLOPs may based on implement. Not hard to calculate manually.(May not to implement.)
     - ROIPooling
     - Atomic level operation(I didn't see anyone calculate them.)
 4. Need not to implement
    - Loss functions.

Additional interface should be added to make users  for manually defined Blocks.

Welcome to add if anything missing.
Welcome to suggest if anything wrong.",0,[Feature request]Calculate network calculations tools for Gluon.,"[Feature request]Calculate network calculations tools for Gluon. Now gluon has a  function for calculate total params for a network but don't have a tool for calculate network FLOPs(G).

Why need this?
 - Model FLOPs could straightly measure a network inference speed.
 - Research needed.
 - Some of ops are widely used in many networks like conv, pooling, fc, bn
, relu, softmax.
 - Some of ops are looping many times and have different shape of feature_maps outpus, it's hard to calculate them manually.

But it's hard for calculating all of ops and actually not necessary(Some discussions [here](https://discuss.gluon.ai/t/topic/10228/8)). So I partition them on demand.
 1. Widely used in many networks and most commonly used.[urgent]
    - Conv2d/3d
    - Maxpool2d/3d
    - Avgpool 2d/3d
    - GlobalAvgPool2d/3d
    - FC
    - Relu, LeakyReLU, PReLU, Tanh, Sigmoid
    - BN
    - Softmax
    - RNN(basic rnn is just matrix multiplication, more complicated I don't know, this may need add if anything misses.)
 2. Used somewhere but may not common.[not urgent]
    - Dropout
    - Conv1d, Maxpool1d, Avgpool1d
    - GlobalAvgPool1d
    - ConvTranspose1d/2d/3d (GAN may use this, but for now GAN don't care about FLOPs)
    - UpSampling bilinear/nearest
    - InstanceNorm, LayerNorm
    - L2Normalization
3. May only use once or little times in a model, their FLOPs may based on implement. Not hard to calculate manually.(May not to implement.)
     - ROIPooling
     - Atomic level operation(I didn't see anyone calculate them.)
 4. Need not to implement
    - Loss functions.

Additional interface should be added to make users  for manually defined Blocks.

Welcome to add if anything missing.
Welcome to suggest if anything wrong."
incubator-mxnet,9342,"issue:./include/dmlc/./optional.h:67:29: error: 'class dmlc::optional<int>' has no member named 'val'
     std::swap(val, other.val);
I should how to modify?",0,I have a problem in the process of cross compiling,"I have a problem in the process of cross compiling issue:./include/dmlc/./optional.h:67:29: error: 'class dmlc::optional<int>' has no member named 'val'
     std::swap(val, other.val);
I should how to modify?"
incubator-mxnet,945,"Hi,
     I want to perform multi label image classification for my own dataset with mxnet. Here are some questions bother me.
- How to prepare the recordIO database or the index file?
  According to [Extension: Mutliple Labels for a Single Image](https://github.com/dmlc/mxnet/blob/a6b4baf9824bb3f0bfb8ec804d333913b3bbc0c8/doc/python/io.md) , the index file should have a fixed width of label field. What if my labels are not always the same width which is the common occasion. And will the labels of a single image be treated as a vector like (1,0,0,...,1,...0,...,1)? Or how can I prepare a binary vector label for the image data?
- What loss function should I assign to the training phase? Will the  deal with multi-label? Or should I implement a  like loss function?
- What evaluation criteria should I choose for the test or val phase? The accuracy metric is for single label.

Thanks!  
",0,Some questions about multi label image classification in MXNet.,"Some questions about multi label image classification in MXNet. Hi,
     I want to perform multi label image classification for my own dataset with mxnet. Here are some questions bother me.
- How to prepare the recordIO database or the index file?
  According to [Extension: Mutliple Labels for a Single Image](https://github.com/dmlc/mxnet/blob/a6b4baf9824bb3f0bfb8ec804d333913b3bbc0c8/doc/python/io.md) , the index file should have a fixed width of label field. What if my labels are not always the same width which is the common occasion. And will the labels of a single image be treated as a vector like (1,0,0,...,1,...0,...,1)? Or how can I prepare a binary vector label for the image data?
- What loss function should I assign to the training phase? Will the  deal with multi-label? Or should I implement a  like loss function?
- What evaluation criteria should I choose for the test or val phase? The accuracy metric is for single label.

Thanks!  
"
incubator-mxnet,16424,"## Description
I've trained a [NAS searched ShuffleNet related model](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS), which contains some rare operators like Channel Shuffle, hard Swish, hard Sigmoid, etc.. It runs fine on both GPU and raw CPU backend but failed (val_acc = 0.0) on MKL CPU backend. 

## Environment info (Required)



## Background
This ShuffleNet related model has been built by:

| Layers | Ops
| :--------------------- | :-----: |
|Common ops                                | conv, BN, Activation('relu') |
|Concat                                          | concat |
|Shuffle Channel & Slice              | reshape-swapaxes-reshape-slice |
|Hard swish                                   | plusscalar-clip-divscalar-mul |
|Hard sigmoid                               | plusscalar-clip-divscalar |
|Global Average Pooling              | pool |

For how the Shuffle Channel is implemented: 

![alt text](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/images/Channel_Shuffle_and_Split.png?raw=true)

## Error Message
The model was planned to be quantized by using MXNet 1.6.0 (master) [quantization tool](https://github.com/apache/incubator-mxnet/tree/master/example/quantization). The ""error"" occurs when trying to use **MKL backend** to run the raw model before quantization as well as the quantized model.

- Raw model: when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) with MXNet CPU only (no MKL), it works fine


- Raw model: while using the same model and same [code](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) but with MXNet-mkl, it **failed**:


- Quantized model:  interestingly, with MXNet-mkl, the quantization process works smoothly and generates a quantized model. But when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) to verify the quantized model's performance, it **failed again** just like the raw model before quantization.


## Steps to reproduce:
1. Clone the code and the model has been put in there:

2. Reproduce MXNet CPU only **without MKL**:


3. Reproduce **MXNet-mkl** with failed validation accuracy:


",0,[Channel Shuffle / Hard Swish / Hard Sigmoid] running in MKL CPU backend failed,"[Channel Shuffle / Hard Swish / Hard Sigmoid] running in MKL CPU backend failed ## Description
I've trained a [NAS searched ShuffleNet related model](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS), which contains some rare operators like Channel Shuffle, hard Swish, hard Sigmoid, etc.. It runs fine on both GPU and raw CPU backend but failed (val_acc = 0.0) on MKL CPU backend. 

## Environment info (Required)



## Background
This ShuffleNet related model has been built by:

| Layers | Ops
| :--------------------- | :-----: |
|Common ops                                | conv, BN, Activation('relu') |
|Concat                                          | concat |
|Shuffle Channel & Slice              | reshape-swapaxes-reshape-slice |
|Hard swish                                   | plusscalar-clip-divscalar-mul |
|Hard sigmoid                               | plusscalar-clip-divscalar |
|Global Average Pooling              | pool |

For how the Shuffle Channel is implemented: 

![alt text](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/images/Channel_Shuffle_and_Split.png?raw=true)

## Error Message
The model was planned to be quantized by using MXNet 1.6.0 (master) [quantization tool](https://github.com/apache/incubator-mxnet/tree/master/example/quantization). The ""error"" occurs when trying to use **MKL backend** to run the raw model before quantization as well as the quantized model.

- Raw model: when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) with MXNet CPU only (no MKL), it works fine


- Raw model: while using the same model and same [code](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) but with MXNet-mkl, it **failed**:


- Quantized model:  interestingly, with MXNet-mkl, the quantization process works smoothly and generates a quantized model. But when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) to verify the quantized model's performance, it **failed again** just like the raw model before quantization.


## Steps to reproduce:
1. Clone the code and the model has been put in there:

2. Reproduce MXNet CPU only **without MKL**:


3. Reproduce **MXNet-mkl** with failed validation accuracy:


"
incubator-mxnet,13592,"Consider the following (using MXNet release version 1.3.1 on OSX):

returns an array. However:

throws an exception:
 
It may be related to issue #8048.",0,Transpose with MXNET_BACKWARD_DO_MIRROR throws exception,"Transpose with MXNET_BACKWARD_DO_MIRROR throws exception Consider the following (using MXNet release version 1.3.1 on OSX):

returns an array. However:

throws an exception:
 
It may be related to issue #8048."
incubator-mxnet,13438,"## Description
getenv() calls in libc are not threadsafe according to:

https://rachelbythebay.com/w/2017/01/30/env/
and
https://github.com/xianyi/OpenBLAS/issues/716

There are indirect calls to dmlc::GetEnv() all across the mxnet codebase, here are a few:

https://github.com/apache/incubator-mxnet/blob/266de6bef4da5769431557288d41fab2a02e52ca/src/engine/threaded_engine_perdevice.cc#L79
or
https://github.com/apache/incubator-mxnet/blob/5a83b6b563211f430688e41eab4752c6de4ecf22/src/executor/graph_executor.cc#L1194

## Error Message:
/lib64/libc.so.6(+0x35250) [0x7fdc5b99b250]
/lib64/libc.so.6(getenv+0xad) [0x7fdc5b99e0cd]
/opt/amazon/lib/libmxnet.so(_ZN4dmlc6GetEnvIbEET_PKcS1_+0x1b) [0x7fdc4a1bedab]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor10InitOpSegsEv+0x1cb) [0x7fdc4a1b6e0b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor15FinishInitGraphEN4nnvm6SymbolENS2_5GraphEPNS_8ExecutorERKSt13unordered_mapINS2_9NodeEntryENS_7NDArrayENS2_13NodeEntryHashENS2_14NodeEntryEqualESaISt4pairIKS8_S9_EEE+0x71b) [0x7fdc4a1b760b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor4InitEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS4_St4lessISsESaISt4pairIKSsS4_EEERKSt6vectorIS4_SaIS4_EESL_SL_RKSt13unordered_mapISsNS2_6TShapeESt4hashISsESt8equal_toISsESaISA_ISB_SN_EEERKSM_ISsiSP_SR_SaISA_ISB_iEEES11_RKSH_INS_9OpReqType
ESaIS12_EERKSt13unordered_setISsSP_SR_SaISsEEPSH_INS_7NDArrayESaIS1C_EES1F_S1F_PSM_ISsS1C_SP_SR_SaISA_ISB_S1C_EEEPNS_8ExecutorERKSM_INS2_9NodeEntryES1C_NS2_13NodeEntryHashENS2_14NodeEntryEqualESaISA_IKS1M_S1C_EEE+0x75d) [0x7fdc4a1b958d]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet8Executor10SimpleBindEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6vectorIS3_SaIS3_EESK_SK_RKSt13unordered_mapISsNS1_6TShapeESt4hashISsESt8equal_toISsESaIS9_ISA_SM_EEERKSL_ISsiSO_SQ_SaIS9_ISA_iEEES10_RKSG_INS_9OpReqTypeESaI
S11_EERKSt13unordered_setISsSO_SQ_SaISsEEPSG_INS_7NDArrayESaIS1B_EES1E_S1E_PSL_ISsS1B_SO_SQ_SaIS9_ISA_S1B_EEEPS0_+0x1a6) [0x7fdc4a1b9f46]
/opt/amazon/lib/libmxnet.so(MXExecutorSimpleBind+0x1e38) [0x7fdc4a1031a8]
/opt/amazon/python2.7/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7fdc5af9b858]

## Minimum reproducible example
TODO

## Steps to reproduce
TODO
",0,libc getenv is not threadsafe,"libc getenv is not threadsafe ## Description
getenv() calls in libc are not threadsafe according to:

https://rachelbythebay.com/w/2017/01/30/env/
and
https://github.com/xianyi/OpenBLAS/issues/716

There are indirect calls to dmlc::GetEnv() all across the mxnet codebase, here are a few:

https://github.com/apache/incubator-mxnet/blob/266de6bef4da5769431557288d41fab2a02e52ca/src/engine/threaded_engine_perdevice.cc#L79
or
https://github.com/apache/incubator-mxnet/blob/5a83b6b563211f430688e41eab4752c6de4ecf22/src/executor/graph_executor.cc#L1194

## Error Message:
/lib64/libc.so.6(+0x35250) [0x7fdc5b99b250]
/lib64/libc.so.6(getenv+0xad) [0x7fdc5b99e0cd]
/opt/amazon/lib/libmxnet.so(_ZN4dmlc6GetEnvIbEET_PKcS1_+0x1b) [0x7fdc4a1bedab]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor10InitOpSegsEv+0x1cb) [0x7fdc4a1b6e0b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor15FinishInitGraphEN4nnvm6SymbolENS2_5GraphEPNS_8ExecutorERKSt13unordered_mapINS2_9NodeEntryENS_7NDArrayENS2_13NodeEntryHashENS2_14NodeEntryEqualESaISt4pairIKS8_S9_EEE+0x71b) [0x7fdc4a1b760b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor4InitEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS4_St4lessISsESaISt4pairIKSsS4_EEERKSt6vectorIS4_SaIS4_EESL_SL_RKSt13unordered_mapISsNS2_6TShapeESt4hashISsESt8equal_toISsESaISA_ISB_SN_EEERKSM_ISsiSP_SR_SaISA_ISB_iEEES11_RKSH_INS_9OpReqType
ESaIS12_EERKSt13unordered_setISsSP_SR_SaISsEEPSH_INS_7NDArrayESaIS1C_EES1F_S1F_PSM_ISsS1C_SP_SR_SaISA_ISB_S1C_EEEPNS_8ExecutorERKSM_INS2_9NodeEntryES1C_NS2_13NodeEntryHashENS2_14NodeEntryEqualESaISA_IKS1M_S1C_EEE+0x75d) [0x7fdc4a1b958d]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet8Executor10SimpleBindEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6vectorIS3_SaIS3_EESK_SK_RKSt13unordered_mapISsNS1_6TShapeESt4hashISsESt8equal_toISsESaIS9_ISA_SM_EEERKSL_ISsiSO_SQ_SaIS9_ISA_iEEES10_RKSG_INS_9OpReqTypeESaI
S11_EERKSt13unordered_setISsSO_SQ_SaISsEEPSG_INS_7NDArrayESaIS1B_EES1E_S1E_PSL_ISsS1B_SO_SQ_SaIS9_ISA_S1B_EEEPS0_+0x1a6) [0x7fdc4a1b9f46]
/opt/amazon/lib/libmxnet.so(MXExecutorSimpleBind+0x1e38) [0x7fdc4a1031a8]
/opt/amazon/python2.7/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7fdc5af9b858]

## Minimum reproducible example
TODO

## Steps to reproduce
TODO
"
incubator-mxnet,3836,"C:\WinPython\python-2.7.10.amd64\python.exe D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py --root_path H:\data\faster_rcnn --devkit_path H:\data\faster_rcnn\VOCdevkit --frequent 50 --kv_store local --prefix H:\data\faster_rcnn\model\faster-rcnn --pretrained H:\data\faster_rcnn\model\vgg16 --load-epoch 1
INFO:root:Namespace(devkit_path='H:\\data\\faster_rcnn\\VOCdevkit', factor_step=50000, frequent=50, gpu_ids='1,0', image_set='trainval', kv_store='local', load_epoch=1, lr=0.001, mom=0.9, monitor=False, no_flip=False, num_classes=21, num_epoch=10, prefix='H:\\data\\faster_rcnn\\model\\faster-rcnn', pretrained='H:\\data\\faster_rcnn\\model\\vgg16', resume=False, root_path='H:\\data\\faster_rcnn', test_image_set='test', wd=0.0005, work_load_list=None, year='2007')
INFO:root:########## TRAIN FASTER-RCNN WITH APPROXIMATE JOINT END2END #############
('providing maximum shape', [('data', (2, 3, 1000, 1000))], [('label', (1L, 34596L)), ('bbox_target', (1L, 36L, 62L, 62L)), ('bbox_inside_weight', (1L, 36L, 62L, 62L)), ('bbox_outside_weight', (1L, 36L, 62L, 62L)), ('gt_boxes', (2, 500))])
voc_2007_trainval gt roidb loaded from H:\data\faster_rcnn\cache\voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
prepare roidb
Traceback (most recent call last):
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 178, in <module>
    args.work_load_list, args.resume, not args.no_flip, args.factor_step)
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 125, in end2end_train
    arg_params=args, aux_params=auxs, begin_epoch=begin_epoch, num_epoch=num_epoch)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\base_module.py"", line 338, in fit
    for_training=True, force_rebind=force_rebind)
  File ""D:\MyCoding\DeepLearning\test_example\mxnet\example\rcnn\rcnn\module.py"", line 137, in bind
    force_rebind=False, shared_module=None)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\module.py"", line 282, in bind
    grad_req=grad_req, input_types=input_types)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 170, in __init__
    self.label_layouts = self.decide_slices(label_shapes)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 196, in decide_slices
    + (""%s has shape %s"" % (name, shape)))
AssertionError: all data must have the same batch size: batch_size = 2, but label has shape (1L, 34596L)

Process finished with exit code 1


training_end2end",0,"train faster-rcnn use two gpus, error occured like this","train faster-rcnn use two gpus, error occured like this C:\WinPython\python-2.7.10.amd64\python.exe D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py --root_path H:\data\faster_rcnn --devkit_path H:\data\faster_rcnn\VOCdevkit --frequent 50 --kv_store local --prefix H:\data\faster_rcnn\model\faster-rcnn --pretrained H:\data\faster_rcnn\model\vgg16 --load-epoch 1
INFO:root:Namespace(devkit_path='H:\\data\\faster_rcnn\\VOCdevkit', factor_step=50000, frequent=50, gpu_ids='1,0', image_set='trainval', kv_store='local', load_epoch=1, lr=0.001, mom=0.9, monitor=False, no_flip=False, num_classes=21, num_epoch=10, prefix='H:\\data\\faster_rcnn\\model\\faster-rcnn', pretrained='H:\\data\\faster_rcnn\\model\\vgg16', resume=False, root_path='H:\\data\\faster_rcnn', test_image_set='test', wd=0.0005, work_load_list=None, year='2007')
INFO:root:########## TRAIN FASTER-RCNN WITH APPROXIMATE JOINT END2END #############
('providing maximum shape', [('data', (2, 3, 1000, 1000))], [('label', (1L, 34596L)), ('bbox_target', (1L, 36L, 62L, 62L)), ('bbox_inside_weight', (1L, 36L, 62L, 62L)), ('bbox_outside_weight', (1L, 36L, 62L, 62L)), ('gt_boxes', (2, 500))])
voc_2007_trainval gt roidb loaded from H:\data\faster_rcnn\cache\voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
prepare roidb
Traceback (most recent call last):
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 178, in <module>
    args.work_load_list, args.resume, not args.no_flip, args.factor_step)
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 125, in end2end_train
    arg_params=args, aux_params=auxs, begin_epoch=begin_epoch, num_epoch=num_epoch)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\base_module.py"", line 338, in fit
    for_training=True, force_rebind=force_rebind)
  File ""D:\MyCoding\DeepLearning\test_example\mxnet\example\rcnn\rcnn\module.py"", line 137, in bind
    force_rebind=False, shared_module=None)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\module.py"", line 282, in bind
    grad_req=grad_req, input_types=input_types)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 170, in __init__
    self.label_layouts = self.decide_slices(label_shapes)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 196, in decide_slices
    + (""%s has shape %s"" % (name, shape)))
AssertionError: all data must have the same batch size: batch_size = 2, but label has shape (1L, 34596L)

Process finished with exit code 1


training_end2end"
incubator-mxnet,9520,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3

## Environment info (Required)

----------Python Info----------
('Version      :', '2.7.6')
('Compiler     :', 'GCC 4.8.4')
('Build        :', ('default', 'Oct 26 2016 20:30:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
('Version      :', '0.12.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/mxnet')
('Commit Hash   :', 'e0c7906693f0c79b0ce34a4d777c26a6bf1903c1')
----------System Info----------
('Platform     :', 'Linux-4.4.0-64-generic-x86_64-with-Ubuntu-14.04-trusty')
('system       :', 'Linux')
('node         :', 'meter')
('release      :', '4.4.0-64-generic')
('version      :', '#85~14.04.1-Ubuntu SMP Mon Feb 20 12:10:54 UTC 2017')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 94
Stepping:              3
CPU MHz:               4200.000
BogoMIPS:              8016.71
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.6354 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0060 sec, LOAD: 0.5680 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1315 sec, LOAD: 0.9401 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.1766 sec, LOAD: 1.0127 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0067 sec, LOAD: 0.3688 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 1] _ssl.c:510: error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure>, DNS finished in 0.277799129486 sec.


Package used (Python/R/Scala/Julia):
Python 

## Error Message:
BLAS : Program is Terminated. Because you tried to allocate too many memory regions.

## Minimum reproducible example
`
",0,Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3,"Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3 Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3

## Environment info (Required)

----------Python Info----------
('Version      :', '2.7.6')
('Compiler     :', 'GCC 4.8.4')
('Build        :', ('default', 'Oct 26 2016 20:30:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
('Version      :', '0.12.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/mxnet')
('Commit Hash   :', 'e0c7906693f0c79b0ce34a4d777c26a6bf1903c1')
----------System Info----------
('Platform     :', 'Linux-4.4.0-64-generic-x86_64-with-Ubuntu-14.04-trusty')
('system       :', 'Linux')
('node         :', 'meter')
('release      :', '4.4.0-64-generic')
('version      :', '#85~14.04.1-Ubuntu SMP Mon Feb 20 12:10:54 UTC 2017')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 94
Stepping:              3
CPU MHz:               4200.000
BogoMIPS:              8016.71
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.6354 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0060 sec, LOAD: 0.5680 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1315 sec, LOAD: 0.9401 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.1766 sec, LOAD: 1.0127 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0067 sec, LOAD: 0.3688 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 1] _ssl.c:510: error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure>, DNS finished in 0.277799129486 sec.


Package used (Python/R/Scala/Julia):
Python 

## Error Message:
BLAS : Program is Terminated. Because you tried to allocate too many memory regions.

## Minimum reproducible example
`
"
incubator-mxnet,13303,"## Description
mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32""

## Environment info (Required)
Host system: Ubuntu 18.04.1 LTS  4.15.0-38-generic x86_64
Target system: ARM Cortex-A9 CPU


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
arm-buildroot-linux-gnueabihf-gcc-7.3.0

MXNet commit hash:
85fefa8c7291b556057ae685a5883c3f6a175c18

Build config:
-DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF

## Error Message:
>>> mxnet 1.3.0 Building
....
[ 86%] Building C object CMakeFiles/mxnet.dir/dummy.c.o
[ 93%] Built target mxnet_unit_tests
[ 93%] Linking CXX shared library libmxnet.so
[ 93%] Built target mxnet
Scanning dependencies of target cpp_package_op_h
Running: OpWrapperGenerator.py
Traceback (most recent call last):
  File ""OpWrapperGenerator.py"", line 428, in <module>
    raise(e)
OSError: buildroot/output/build/mxnet-1.3.0/libmxnet.so: wrong ELF class: ELFCLASS32
cpp-package/CMakeFiles/cpp_package_op_h.dir/build.make:58: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h' failed
make[4]: *** [cpp-package/CMakeFiles/cpp_package_op_h] Error 1
CMakeFiles/Makefile2:541: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h.dir/all' failed
make[3]: *** [cpp-package/CMakeFiles/cpp_package_op_h.dir/all] Error 2

## Minimum reproducible example + Steps to reproduce
1. Configure Buildroot for target system

2. Add MxNet as a CMake Buildroot package:
MXNET_VERSION:=1.3.0
MXNET_SITE:=https://github.com/apache/incubator-mxnet.git
MXNET_SITE_METHOD = git
MXNET_GIT_SUBMODULES = YES
MXNET_INSTALL_STAGING = YES
MXNET_CONF_OPTS = -DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF
$(eval $(cmake-package))

3. Compile package

## What have you tried to solve it?

1. Checked OpWrapperGenerator.py source code. It tries to invoke Python of the *host* system (x86_64) and perform cdll.libmxnet = cdll.LoadLibrary(sys.argv[1]) for library built for *target*. Eventually host Python know nothing about ARM library format.
",0,"mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32""","mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32"" ## Description
mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32""

## Environment info (Required)
Host system: Ubuntu 18.04.1 LTS  4.15.0-38-generic x86_64
Target system: ARM Cortex-A9 CPU


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
arm-buildroot-linux-gnueabihf-gcc-7.3.0

MXNet commit hash:
85fefa8c7291b556057ae685a5883c3f6a175c18

Build config:
-DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF

## Error Message:
>>> mxnet 1.3.0 Building
....
[ 86%] Building C object CMakeFiles/mxnet.dir/dummy.c.o
[ 93%] Built target mxnet_unit_tests
[ 93%] Linking CXX shared library libmxnet.so
[ 93%] Built target mxnet
Scanning dependencies of target cpp_package_op_h
Running: OpWrapperGenerator.py
Traceback (most recent call last):
  File ""OpWrapperGenerator.py"", line 428, in <module>
    raise(e)
OSError: buildroot/output/build/mxnet-1.3.0/libmxnet.so: wrong ELF class: ELFCLASS32
cpp-package/CMakeFiles/cpp_package_op_h.dir/build.make:58: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h' failed
make[4]: *** [cpp-package/CMakeFiles/cpp_package_op_h] Error 1
CMakeFiles/Makefile2:541: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h.dir/all' failed
make[3]: *** [cpp-package/CMakeFiles/cpp_package_op_h.dir/all] Error 2

## Minimum reproducible example + Steps to reproduce
1. Configure Buildroot for target system

2. Add MxNet as a CMake Buildroot package:
MXNET_VERSION:=1.3.0
MXNET_SITE:=https://github.com/apache/incubator-mxnet.git
MXNET_SITE_METHOD = git
MXNET_GIT_SUBMODULES = YES
MXNET_INSTALL_STAGING = YES
MXNET_CONF_OPTS = -DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF
$(eval $(cmake-package))

3. Compile package

## What have you tried to solve it?

1. Checked OpWrapperGenerator.py source code. It tries to invoke Python of the *host* system (x86_64) and perform cdll.libmxnet = cdll.LoadLibrary(sys.argv[1]) for library built for *target*. Eventually host Python know nothing about ARM library format.
"
incubator-mxnet,6759,"	
How to set MXNET_CPU_WORKER_NTHREADS in R",0,How to set MXNET_CPU_WORKER_NTHREADS in R,"How to set MXNET_CPU_WORKER_NTHREADS in R 	
How to set MXNET_CPU_WORKER_NTHREADS in R"
incubator-mxnet,15138,"In the current tutorial for developing operators in mxnet, https://mxnet.incubator.apache.org/versions/master/faq/add_op_in_backend.html

But it didn't talk about FStatefulCompute and FStatefulComputeEx, which are useful for many CUDNN ops. We should add a section for these two interfaces, and when the states are kept persistent in cached_op. @zheng-da ",0,Tutorial for developing advanced operators,"Tutorial for developing advanced operators In the current tutorial for developing operators in mxnet, https://mxnet.incubator.apache.org/versions/master/faq/add_op_in_backend.html

But it didn't talk about FStatefulCompute and FStatefulComputeEx, which are useful for many CUDNN ops. We should add a section for these two interfaces, and when the states are kept persistent in cached_op. @zheng-da "
incubator-mxnet,15919,"https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/trainer.py#L265-L275
When update_on_kvstore=True, Trainer.set_learning_rate does not modify the learning rate on the remote parameter server",0,Trainer.set_learning_rate is broken when distributed kvstore is used,"Trainer.set_learning_rate is broken when distributed kvstore is used https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/trainer.py#L265-L275
When update_on_kvstore=True, Trainer.set_learning_rate does not modify the learning rate on the remote parameter server"
incubator-mxnet,16508,"https://github.com/apache/incubator-mxnet/tree/master/example/distributed_training-horovod
the examples as follow:

$ mpirun -np 8 \
    -H server1:4,server2:4 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO \
    -mca pml ob1 -mca btl ^openib
    python train.py

this train.py means one of the (gluon_mnist.py、module_mnist.py、resnet50_imagenet.py) ?
can i use gluon_mnist.py instead of train.py?",0,Distributed Training using MXNet with Horovod,"Distributed Training using MXNet with Horovod https://github.com/apache/incubator-mxnet/tree/master/example/distributed_training-horovod
the examples as follow:

$ mpirun -np 8 \
    -H server1:4,server2:4 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO \
    -mca pml ob1 -mca btl ^openib
    python train.py

this train.py means one of the (gluon_mnist.py、module_mnist.py、resnet50_imagenet.py) ?
can i use gluon_mnist.py instead of train.py?"
incubator-mxnet,13439,"Build failure error in http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/2038/pipeline

",0,[Test Failure] R: CPU,"[Test Failure] R: CPU Build failure error in http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/2038/pipeline

"
incubator-mxnet,14203,"os : win10 64bits
compiler : vc2015 64 bits
cuda : cuda92
commit hash: bada8a1961f0da7f01cd9e61d03f280c48083f1b

Bug 1 : openMP required int in for loop

line 515, line 580, line 607 of mxnet_op.h should change to



line 729 of utils.h should change to



line 315, 203, 218, 252 of broad_cast_reduce_inl.h

line 430 of indexing_op.cc

Bug 2 : std::min cannot find overload version

line 340, line 463 of convolution_v1-inl.h should change to 



Bug 3 : C1002 link time code generation

Finding a way to fix it, [this link](https://social.msdn.microsoft.com/Forums/sqlserver/en-US/d2c4bb60-e558-4dc6-a0ba-47611d45bc86/c1002-compiler-is-out-of-heap-space-in-pass-2?forum=vcgeneral) suggest 

""Link Time Code Generation"" should be set to ""Profile Guided Optimization - Optimization (/LTCG:PGOptimize)"" instead of being blank.

Bug 4 : Uncheck ""BUILD_CPP_EXAMPLES"" from cmake-gui, but the cpp examples still include in the project files.",0,[Bug]Cannot compile mxnet on windows,"[Bug]Cannot compile mxnet on windows os : win10 64bits
compiler : vc2015 64 bits
cuda : cuda92
commit hash: bada8a1961f0da7f01cd9e61d03f280c48083f1b

Bug 1 : openMP required int in for loop

line 515, line 580, line 607 of mxnet_op.h should change to



line 729 of utils.h should change to



line 315, 203, 218, 252 of broad_cast_reduce_inl.h

line 430 of indexing_op.cc

Bug 2 : std::min cannot find overload version

line 340, line 463 of convolution_v1-inl.h should change to 



Bug 3 : C1002 link time code generation

Finding a way to fix it, [this link](https://social.msdn.microsoft.com/Forums/sqlserver/en-US/d2c4bb60-e558-4dc6-a0ba-47611d45bc86/c1002-compiler-is-out-of-heap-space-in-pass-2?forum=vcgeneral) suggest 

""Link Time Code Generation"" should be set to ""Profile Guided Optimization - Optimization (/LTCG:PGOptimize)"" instead of being blank.

Bug 4 : Uncheck ""BUILD_CPP_EXAMPLES"" from cmake-gui, but the cpp examples still include in the project files."
incubator-mxnet,6874,"## Environment info
Operating System:
This error was raised on Ubuntu 14.04, Windows 10 and Mac OS X El Capitan(10.11.6)

Compiler:
gcc / Visual Studio 2013 / clang-omp

Package used:
Python

MXNet version:
0.10.1(installed from source)

Python version and distribution:
2.7.6(installed by apt-get) for Ubuntu.
2.7.12(from python.org) for Windows and Mac OS.

## Error Message:
(on Mac OS)


## Minimum reproducible example
(this code runs fine on MXNet 0.9.5, but not on 0.10.1)


## Steps to reproduce
Just run the python code above.
",0,"mx.symbol.softmax_cross_entropy() raises error ""Not enough argument to call operator softmax_cross_entropy""","mx.symbol.softmax_cross_entropy() raises error ""Not enough argument to call operator softmax_cross_entropy"" ## Environment info
Operating System:
This error was raised on Ubuntu 14.04, Windows 10 and Mac OS X El Capitan(10.11.6)

Compiler:
gcc / Visual Studio 2013 / clang-omp

Package used:
Python

MXNet version:
0.10.1(installed from source)

Python version and distribution:
2.7.6(installed by apt-get) for Ubuntu.
2.7.12(from python.org) for Windows and Mac OS.

## Error Message:
(on Mac OS)


## Minimum reproducible example
(this code runs fine on MXNet 0.9.5, but not on 0.10.1)


## Steps to reproduce
Just run the python code above.
"
incubator-mxnet,16960,"## Description
Conversion fails on large matrices.

### Error Message
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/utils.py"", line 146, in array
    return _array(source_array, ctx=ctx, dtype=dtype)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 2505, in array
    arr[:] = source_array
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 449, in __setitem__
    self._set_nd_basic_indexing(key, value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 715, in _set_nd_basic_indexing
    self._sync_copyfrom(value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 881, in _sync_copyfrom
    ctypes.c_size_t(source_array.size)))
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/base.py"", line 253, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [19:09:04] src/ndarray/ndarray_function.cc:51: Check failed: size == to->Size() (-294967296 vs. 4000000000) : copying size mismatch, from: 18446744072529682432 bytes, to: 16000000000 bytes.
Stack trace:
  [bt] (0) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2795cb) [0x7efff4d2c5cb]
  [bt] (1) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x259399b) [0x7efff704699b]
  [bt] (2) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::NDArray::SyncCopyFromCPU(void const*, unsigned long) const+0x284) [0x7efff6fe5934]
  [bt] (3) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXNDArraySyncCopyFromCPU+0x2b) [0x7efff6d8ebcb]
  [bt] (4) /usr/lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0059bbacec]
  [bt] (5) /usr/lib64/libffi.so.6(ffi_call+0x1f5) [0x7f0059bba615]
  [bt] (6) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2a0) [0x7f0059dcd290]
  [bt] (7) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x9586) [0x7f0059dc6586]
  [bt] (8) /usr/lib64/libpython3.6m.so.1.0(_PyObject_FastCallDict+0x90) [0x7f0061bce7e0]


### Steps to reproduce
T= nd.array(np.random.randn(5000000,800))
(Paste the commands you ran that produced the error.)

## What have you tried to solve it?

1. workaround: If you convert in smaller chunks and concatenate the ndarray to create the final mxnet



",0,large numpy array to mxnet ndarray conversion,"large numpy array to mxnet ndarray conversion ## Description
Conversion fails on large matrices.

### Error Message
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/utils.py"", line 146, in array
    return _array(source_array, ctx=ctx, dtype=dtype)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 2505, in array
    arr[:] = source_array
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 449, in __setitem__
    self._set_nd_basic_indexing(key, value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 715, in _set_nd_basic_indexing
    self._sync_copyfrom(value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 881, in _sync_copyfrom
    ctypes.c_size_t(source_array.size)))
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/base.py"", line 253, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [19:09:04] src/ndarray/ndarray_function.cc:51: Check failed: size == to->Size() (-294967296 vs. 4000000000) : copying size mismatch, from: 18446744072529682432 bytes, to: 16000000000 bytes.
Stack trace:
  [bt] (0) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2795cb) [0x7efff4d2c5cb]
  [bt] (1) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x259399b) [0x7efff704699b]
  [bt] (2) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::NDArray::SyncCopyFromCPU(void const*, unsigned long) const+0x284) [0x7efff6fe5934]
  [bt] (3) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXNDArraySyncCopyFromCPU+0x2b) [0x7efff6d8ebcb]
  [bt] (4) /usr/lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0059bbacec]
  [bt] (5) /usr/lib64/libffi.so.6(ffi_call+0x1f5) [0x7f0059bba615]
  [bt] (6) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2a0) [0x7f0059dcd290]
  [bt] (7) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x9586) [0x7f0059dc6586]
  [bt] (8) /usr/lib64/libpython3.6m.so.1.0(_PyObject_FastCallDict+0x90) [0x7f0061bce7e0]


### Steps to reproduce
T= nd.array(np.random.randn(5000000,800))
(Paste the commands you ran that produced the error.)

## What have you tried to solve it?

1. workaround: If you convert in smaller chunks and concatenate the ndarray to create the final mxnet



"
incubator-mxnet,13199,"## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using Python)

## Error Message:


## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

Forward once before starting the thread.
",0,Namescope is None when hybridize in multi-threading environment. AttributeError: 'NoneType' object has no attribute '__exit__',"Namescope is None when hybridize in multi-threading environment. AttributeError: 'NoneType' object has no attribute '__exit__' ## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using Python)

## Error Message:


## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

Forward once before starting the thread.
"
incubator-mxnet,9381,"I'm looking at the build status for each commit on MXNet master and noticed that perl test failed once a few weeks ago. Was this already fixed? @sergeykolychev 


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/74/pipeline ",0,(Flaky?) perl test failure ,"(Flaky?) perl test failure  I'm looking at the build status for each commit on MXNet master and noticed that perl test failed once a few weeks ago. Was this already fixed? @sergeykolychev 


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/74/pipeline "
incubator-mxnet,16214,"test_sync_batchnorm behaves differently when there are different number of gpu devices on the machine. It fails on p3.8xlarge but when num_devices are 1 or 2, the test passes.

",0,test_sync_batchnorm failure on p3.8xlarge,"test_sync_batchnorm failure on p3.8xlarge test_sync_batchnorm behaves differently when there are different number of gpu devices on the machine. It fails on p3.8xlarge but when num_devices are 1 or 2, the test passes.

"
incubator-mxnet,14681,"Currently, the best(?) way to load huge dataset in mxnet is implement a dataloader. However, this need the ability to easily random access the ""i-th"" example, becauce ""__index__"" need to be overwrite.

Huge data(too huge to save on disk) usually stored in remote side (example hdfs) with several small datapart. Each datapart which can be easily load in to memory contains maybe millions of examples. So random access is difficult because this need the ability of random access different datapart and the datapart were saved in hdfs.

I think a good Dataloader for this situation is:
 1. First random choose a datapart
 2. Shuffle the small datapart
 3. train

 
",0,suggestion: a different random dataloader,"suggestion: a different random dataloader Currently, the best(?) way to load huge dataset in mxnet is implement a dataloader. However, this need the ability to easily random access the ""i-th"" example, becauce ""__index__"" need to be overwrite.

Huge data(too huge to save on disk) usually stored in remote side (example hdfs) with several small datapart. Each datapart which can be easily load in to memory contains maybe millions of examples. So random access is difficult because this need the ability of random access different datapart and the datapart were saved in hdfs.

I think a good Dataloader for this situation is:
 1. First random choose a datapart
 2. Shuffle the small datapart
 3. train

 
"
incubator-mxnet,15112,"**PyInstaller** bundles a Python application and all its dependencies into a single package. It support Windows/Linux and Mac OS. We can publish our app rapidly on these platforms by PyInstaller.
However, mxnet cannot be packaged as a dependency. So I think we should make MXNet to be compatible with PyInstaller.
P.S:  and  can be directly packaged with PyInstaller. I've tested on Windows.",0,[Feature Request] Make mxnet be available to published by PyInstaller,"[Feature Request] Make mxnet be available to published by PyInstaller **PyInstaller** bundles a Python application and all its dependencies into a single package. It support Windows/Linux and Mac OS. We can publish our app rapidly on these platforms by PyInstaller.
However, mxnet cannot be packaged as a dependency. So I think we should make MXNet to be compatible with PyInstaller.
P.S:  and  can be directly packaged with PyInstaller. I've tested on Windows."
incubator-mxnet,13838,"Brew has updated opencv so that when you do  you get opencv4 which is not compatible with current master.

All of the current install docs for OSX say to use  as a prereq - so this will impact new users trying out MXNet.

It is particularly problematic because there is no way to brew install the 3.4 version - details are here https://github.com/Homebrew/homebrew-core/issues/35869

There is currently a PR in the works to address the compatibility with opencv 4.0 
https://github.com/apache/incubator-mxnet/pull/13559. This issue is to raise the awareness that it is impacting the project now.",0,[OSX] Brew install opencv breaks master,"[OSX] Brew install opencv breaks master Brew has updated opencv so that when you do  you get opencv4 which is not compatible with current master.

All of the current install docs for OSX say to use  as a prereq - so this will impact new users trying out MXNet.

It is particularly problematic because there is no way to brew install the 3.4 version - details are here https://github.com/Homebrew/homebrew-core/issues/35869

There is currently a PR in the works to address the compatibility with opencv 4.0 
https://github.com/apache/incubator-mxnet/pull/13559. This issue is to raise the awareness that it is impacting the project now."
incubator-mxnet,14366,"Appeared in https://github.com/apache/incubator-mxnet/pull/14321 
See logs at
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fcentos-gpu/detail/PR-14321/6/pipeline 
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14321/5/pipeline 
",0,Flaky test test_with_random_seed,"Flaky test test_with_random_seed Appeared in https://github.com/apache/incubator-mxnet/pull/14321 
See logs at
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fcentos-gpu/detail/PR-14321/6/pipeline 
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14321/5/pipeline 
"
incubator-mxnet,9436,"## Description
Output from topk operator is positional 0s and 1s. It would be more standard with Numpy NDArray and other DL framework, if the return values are Boolean (True / False).

Similarly, since MXNet NDArray wants to be closer to behavior of Numpy NDArray operations, it would be good to support Boolean types as output for conditional operators.

This functionality will also help Apache MXNet backend for Keras2",0,Support boolean outputs for topk operator,"Support boolean outputs for topk operator ## Description
Output from topk operator is positional 0s and 1s. It would be more standard with Numpy NDArray and other DL framework, if the return values are Boolean (True / False).

Similarly, since MXNet NDArray wants to be closer to behavior of Numpy NDArray operations, it would be good to support Boolean types as output for conditional operators.

This functionality will also help Apache MXNet backend for Keras2"
incubator-mxnet,17033,"## Description
(A clear and concise description of what the bug is.)

Hello, i am using Cython to generate dynamic library files of mxnet project. But if i run my project through these dymanic library files, the problem AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree' sometimes occurs, exactly the problem does not always come up.  It is strange that the problem comes up after all my code was executed.

Cython version 0.29.14
python version 3.5.2
mxnet version 1.5.1.post0

### Error Message
(Paste the complete error message, including stack trace.)

Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'

## To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

",0,AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree',"AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree' ## Description
(A clear and concise description of what the bug is.)

Hello, i am using Cython to generate dynamic library files of mxnet project. But if i run my project through these dymanic library files, the problem AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree' sometimes occurs, exactly the problem does not always come up.  It is strange that the problem comes up after all my code was executed.

Cython version 0.29.14
python version 3.5.2
mxnet version 1.5.1.post0

### Error Message
(Paste the complete error message, including stack trace.)

Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'

## To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

"
incubator-mxnet,12062,"
## Description
DMLC_PS_ROOT_URI is ip or hostname , but when use the hostname instead of ip , it reports ""bind failed"" in the src/van.cc

## Environment info (Required)



Package used (Python/R/Scala/Julia):
python


## Build info (Required if built from source)

gcc

MXNet commit hash:
3df9bf802021d5aa67c609c6736acee94aaf3a48

Build config:
the same as doc https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=CPU

## Error Message:
(Paste the complete error message, including stack trace.)

[17:46:11] /home/tusimple/incubator-mxnet/dmlc-core/include/dmlc/./logging.h:308: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

Traceback (most recent call last):
  File ""train_mnist.py"", line 25, in <module>
    from common import find_mxnet, fit
  File ""/home/tusimple/incubator-mxnet/example/image-classification/common/find_mxnet.py"", line 20, in <module>
    import mxnet as mx
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/__init__.py"", line 56, in <module>
    from . import kvstore_server
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 85, in <module>
    _init_kvstore_server_module()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 82, in _init_kvstore_server_module
    server.run()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 73, in run
    check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/base.py"", line 146, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

## Minimum reproducible example
1 scheduler 1 server 1 worker

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.export DMLC_PS_ROOT_URI=tusimple-System-Product-Name; export DMLC_ROLE=scheduler; export DMLC_PS_ROOT_PORT=9001; export DMLC_NUM_WORKER=1; export DMLC_NUM_SERVER=1;
2.python train_mnist.py

## What have you tried to solve it?

1.i replaced the DMLC_PS_ROOT_URI with ip and it works well
",0,DMLC_PS_ROOT_URI using hostname failed in distributed training,"DMLC_PS_ROOT_URI using hostname failed in distributed training 
## Description
DMLC_PS_ROOT_URI is ip or hostname , but when use the hostname instead of ip , it reports ""bind failed"" in the src/van.cc

## Environment info (Required)



Package used (Python/R/Scala/Julia):
python


## Build info (Required if built from source)

gcc

MXNet commit hash:
3df9bf802021d5aa67c609c6736acee94aaf3a48

Build config:
the same as doc https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=CPU

## Error Message:
(Paste the complete error message, including stack trace.)

[17:46:11] /home/tusimple/incubator-mxnet/dmlc-core/include/dmlc/./logging.h:308: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

Traceback (most recent call last):
  File ""train_mnist.py"", line 25, in <module>
    from common import find_mxnet, fit
  File ""/home/tusimple/incubator-mxnet/example/image-classification/common/find_mxnet.py"", line 20, in <module>
    import mxnet as mx
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/__init__.py"", line 56, in <module>
    from . import kvstore_server
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 85, in <module>
    _init_kvstore_server_module()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 82, in _init_kvstore_server_module
    server.run()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 73, in run
    check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/base.py"", line 146, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

## Minimum reproducible example
1 scheduler 1 server 1 worker

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.export DMLC_PS_ROOT_URI=tusimple-System-Product-Name; export DMLC_ROLE=scheduler; export DMLC_PS_ROOT_PORT=9001; export DMLC_NUM_WORKER=1; export DMLC_NUM_SERVER=1;
2.python train_mnist.py

## What have you tried to solve it?

1.i replaced the DMLC_PS_ROOT_URI with ip and it works well
"
incubator-mxnet,7080,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: AWS Deep Learning AMI

Package used (Python/R/Scala/Julia): python

Or if installed from source:

MXNet commit hash ():  8c81ee48c197dd66276fa8d4008cbad0dcd2c8fb

If you are using python package, please provide 

Python version and distribution: python 2.7


## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. run the following code:


## What have you tried to solve it?

1. This is due to the recent change of using (src/operator/elemwise_op_common.h) for  backward pass which reduces the number of copies. This however, failed to copy the gradient across devices. It could probably solved by registering  attribute for inplace updates. 
",0,simple_bind elemwise_add with group2ctx fails,"simple_bind elemwise_add with group2ctx fails For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: AWS Deep Learning AMI

Package used (Python/R/Scala/Julia): python

Or if installed from source:

MXNet commit hash ():  8c81ee48c197dd66276fa8d4008cbad0dcd2c8fb

If you are using python package, please provide 

Python version and distribution: python 2.7


## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. run the following code:


## What have you tried to solve it?

1. This is due to the recent change of using (src/operator/elemwise_op_common.h) for  backward pass which reduces the number of copies. This however, failed to copy the gradient across devices. It could probably solved by registering  attribute for inplace updates. 
"
incubator-mxnet,10968,"    There seems to be some mistakes in NDArray::Save(dmlc::Stream *strm) (File: ndarray.cc, Line: 1587~1651) and NDArray::Load(dmlc::Stream *strm) (File:ndarray.cc, Line: 1700~1781). 
    This issue may cause a CUDA: invalid device ordinal with following two steps:
        1. Save a ndarray on gpu(1) in a machine with two gpu card;
        2. Load the ndarray in another machine with only one gpu card the program.

    I find the problem is that in function NDArray::Save the context of ndarray will be saved into stream  and in function   NDArray::Load the data loaded into memory will be converted to the context saved by  NDArray::Save. Why the context is saved in NDArray::Save? To improve portability of saved params, I think it's better to remove these operations to avoid load ndarray in specific device while initializing. ",0,[Discussion][NDArray]Discuss about NDArray::Save and NDArray::Load,"[Discussion][NDArray]Discuss about NDArray::Save and NDArray::Load     There seems to be some mistakes in NDArray::Save(dmlc::Stream *strm) (File: ndarray.cc, Line: 1587~1651) and NDArray::Load(dmlc::Stream *strm) (File:ndarray.cc, Line: 1700~1781). 
    This issue may cause a CUDA: invalid device ordinal with following two steps:
        1. Save a ndarray on gpu(1) in a machine with two gpu card;
        2. Load the ndarray in another machine with only one gpu card the program.

    I find the problem is that in function NDArray::Save the context of ndarray will be saved into stream  and in function   NDArray::Load the data loaded into memory will be converted to the context saved by  NDArray::Save. Why the context is saved in NDArray::Save? To improve portability of saved params, I think it's better to remove these operations to avoid load ndarray in specific device while initializing. "
incubator-mxnet,16319,"## Description

Sphinx builds of the Python API docs have the following warning(s):


## How to reproduce
You can run into the problem following these steps.

1. Run a ""lite"" binary build.


2. Run the Python API docs build:
",0,[python docs] multiple broken cross links in tutorials,"[python docs] multiple broken cross links in tutorials ## Description

Sphinx builds of the Python API docs have the following warning(s):


## How to reproduce
You can run into the problem following these steps.

1. Run a ""lite"" binary build.


2. Run the Python API docs build:
"
incubator-mxnet,16187,"## Description
symbol.contrib.cond operator does not support custom operator execution.

## Environment info (Required)




I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce
Run code above

## What have you tried to solve it?

1. Replace custom operator with no-operator (or built-in operator) - works (see comment in hybrid_forward

I suspect it has something to do with custom operators being executed imperatively (?)
Might be related to #12154 , #11641 and #16182 .

*I'm not sure that the custom operator implementation is not missing something, I attached an example with simple identity custom operator (which doesn't work).",0,symbol.contrib.cond does not support custom operator execution,"symbol.contrib.cond does not support custom operator execution ## Description
symbol.contrib.cond operator does not support custom operator execution.

## Environment info (Required)




I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce
Run code above

## What have you tried to solve it?

1. Replace custom operator with no-operator (or built-in operator) - works (see comment in hybrid_forward

I suspect it has something to do with custom operators being executed imperatively (?)
Might be related to #12154 , #11641 and #16182 .

*I'm not sure that the custom operator implementation is not missing something, I attached an example with simple identity custom operator (which doesn't work)."
incubator-mxnet,16333,"## Description
When using official mxnet docker image on cloud server and without docker on a local server, the inference result is different. The input is exactly the same.

## Environment info (Required)
docker on cloud server: cuda9.0, cuda drive 418 (host machine), mxnet 1.4.0
local server: cuda9.0, cuda drive 396, mxnet 1.3.0",0,mxnet docker gives different inference output,"mxnet docker gives different inference output ## Description
When using official mxnet docker image on cloud server and without docker on a local server, the inference result is different. The input is exactly the same.

## Environment info (Required)
docker on cloud server: cuda9.0, cuda drive 418 (host machine), mxnet 1.4.0
local server: cuda9.0, cuda drive 396, mxnet 1.3.0"
incubator-mxnet,7933,"I have successfully converted the squeezenet and resnet50 models from the examples to CoreML using mxnet-to-coreml. However, when converting a model after fine-tuning using my own data, the predictions are seemingly random. The model is fine-tuned using finetune.py from the examples. The model performs well prior to conversion to CoreML. After conversion to CoreML, the model predicts the same probabilities regardless of the image. The pre-trained model I'm using for fine-tuning is the imagenet11k-places resnet50 model.

I've tried:

1. subtracting channel biases as is performed during fine-tuning. (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779}')

2. subtracting channel biases and scaling 1/255  (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}')

3. subtracting scaled channel biases because I was unsure about when coreml performed the scaling  (--pre-processing-arguments='{""image_input_names"":[""data""],""red_bias"":0.485019,""blue_bias"":0.407603,""green_bias"":0.457956, ""image_scale"":0.00392156862}')

4. not scaling or biasing channels

Has anyone successfully converted a model after fine-tuning using a different data set? Any ideas would be greatly appreciated. I'm fairly certain there's something simple that I'm overlooking... 

I've also examined the converted model using Model_pb2 to make sure the preprocessing flags are being respected, and they appear to be:

print(model.neuralNetworkClassifier.preprocessing)

[featureName: ""data""
scaler {
  channelScale: 0.00380000006407
  blueBias: 103.939
  greenBias: 116.779
  redBias: 123.68
}
]

here's the entire cmd line: 

mxnet_coreml_converter.py --model-prefix='imagenet11k-places-resnet-50' --epoch=47 --input-shape='{""data"":""3,224,224""}' --mode=classifier --class-labels myclass_labels.txt --output-file=""mxnetimagenet11kplaces50resnet.mlmodel""  --pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}'

",0,CoreML conversion with finetuned model ,"CoreML conversion with finetuned model  I have successfully converted the squeezenet and resnet50 models from the examples to CoreML using mxnet-to-coreml. However, when converting a model after fine-tuning using my own data, the predictions are seemingly random. The model is fine-tuned using finetune.py from the examples. The model performs well prior to conversion to CoreML. After conversion to CoreML, the model predicts the same probabilities regardless of the image. The pre-trained model I'm using for fine-tuning is the imagenet11k-places resnet50 model.

I've tried:

1. subtracting channel biases as is performed during fine-tuning. (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779}')

2. subtracting channel biases and scaling 1/255  (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}')

3. subtracting scaled channel biases because I was unsure about when coreml performed the scaling  (--pre-processing-arguments='{""image_input_names"":[""data""],""red_bias"":0.485019,""blue_bias"":0.407603,""green_bias"":0.457956, ""image_scale"":0.00392156862}')

4. not scaling or biasing channels

Has anyone successfully converted a model after fine-tuning using a different data set? Any ideas would be greatly appreciated. I'm fairly certain there's something simple that I'm overlooking... 

I've also examined the converted model using Model_pb2 to make sure the preprocessing flags are being respected, and they appear to be:

print(model.neuralNetworkClassifier.preprocessing)

[featureName: ""data""
scaler {
  channelScale: 0.00380000006407
  blueBias: 103.939
  greenBias: 116.779
  redBias: 123.68
}
]

here's the entire cmd line: 

mxnet_coreml_converter.py --model-prefix='imagenet11k-places-resnet-50' --epoch=47 --input-shape='{""data"":""3,224,224""}' --mode=classifier --class-labels myclass_labels.txt --output-file=""mxnetimagenet11kplaces50resnet.mlmodel""  --pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}'

"
incubator-mxnet,16188,"## Description
symbol.contrib.cond operator does not support the build-in operators round, floor and ceil (and probably some more).

## Environment info (Required)


I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce

1. Run the code above. hybrid_forward has few lines with comment if it's working or not (uncomment lines to see more examples)

## What have you tried to solve it?
N/A

Might be related to #12154 , #11641 , #16182 and #16187 . I keep those issues separate because I'm not sure the cause is the same.
",0,symbol.contrib.cond does not support some built-in operators,"symbol.contrib.cond does not support some built-in operators ## Description
symbol.contrib.cond operator does not support the build-in operators round, floor and ceil (and probably some more).

## Environment info (Required)


I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce

1. Run the code above. hybrid_forward has few lines with comment if it's working or not (uncomment lines to see more examples)

## What have you tried to solve it?
N/A

Might be related to #12154 , #11641 , #16182 and #16187 . I keep those issues separate because I'm not sure the cause is the same.
"
incubator-mxnet,12126,"Platform independent API (without using nvidia-smi) for querying GPU memory.
C implementation is provided by @sbodenstein  in this PR - https://github.com/apache/incubator-mxnet/pull/12083#pullrequestreview-145347358
",0,[Feature Request] Utility API for querying GPU memory,"[Feature Request] Utility API for querying GPU memory Platform independent API (without using nvidia-smi) for querying GPU memory.
C implementation is provided by @sbodenstein  in this PR - https://github.com/apache/incubator-mxnet/pull/12083#pullrequestreview-145347358
"
incubator-mxnet,16674,"## Description
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-cpu/detail/PR-16671/2/pipeline


### Error Message

# To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

",0,Garbage ctx.dev_mask seen in Clojure CPU Integration CI run,"Garbage ctx.dev_mask seen in Clojure CPU Integration CI run ## Description
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-cpu/detail/PR-16671/2/pipeline


### Error Message

# To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

"
incubator-mxnet,10549,"## Description
I'd like to build mxnet for Scala on Windows from source. I can build libmxnet.dll successfully, but there are no instructions how to build scala-package on Windows. [Instruction page](https://mxnet.incubator.apache.org/install/windows_setup.html#install-the-mxnet-package-for-scala)
refers to make only.

Could you provide instructions relevant for windows or mxnet-scala.dll?

## Environment info (Required)

Windows 10.
mxnet 1.1.0


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
Visual Studio 14 2015 Win64

MXNet commit hash: ""07a83a0325a3d782513a04f47d711710972cb144""

Build config:
mxnet_option(USE_CPP_PACKAGE      ""Build C++ Package"" ON)

## Steps to reproduce
1. Build libmxnet.dll
2. Try to build scala-package??

## What have you tried to solve it?

1. I tried to compile dll from files in 
scala-package\native\src
but failed to resolve all dependencies correctly
",0,scala-package 1.1.0 build instruction Windows VS2015,"scala-package 1.1.0 build instruction Windows VS2015 ## Description
I'd like to build mxnet for Scala on Windows from source. I can build libmxnet.dll successfully, but there are no instructions how to build scala-package on Windows. [Instruction page](https://mxnet.incubator.apache.org/install/windows_setup.html#install-the-mxnet-package-for-scala)
refers to make only.

Could you provide instructions relevant for windows or mxnet-scala.dll?

## Environment info (Required)

Windows 10.
mxnet 1.1.0


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
Visual Studio 14 2015 Win64

MXNet commit hash: ""07a83a0325a3d782513a04f47d711710972cb144""

Build config:
mxnet_option(USE_CPP_PACKAGE      ""Build C++ Package"" ON)

## Steps to reproduce
1. Build libmxnet.dll
2. Try to build scala-package??

## What have you tried to solve it?

1. I tried to compile dll from files in 
scala-package\native\src
but failed to resolve all dependencies correctly
"
incubator-mxnet,12683,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Unit tests pulling data from data.dmlc.ml and randomly failing
## Environment info (Required)
Jenkins:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1676/pipeline 
",0,tests still pulling data from data.dmlc.ml and are randomly failing,"tests still pulling data from data.dmlc.ml and are randomly failing Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Unit tests pulling data from data.dmlc.ml and randomly failing
## Environment info (Required)
Jenkins:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1676/pipeline 
"
incubator-mxnet,13100,"## Description
Hybridizing creates superfluous backward ops in some conditions. This is bad, as these ops may consequently trigger a storage fallback. In the example below, no gradient for  is requested. Still  is generated and consequently a storage fallback occurs.
Note that this example works without storage fallback in the imperative and symbolic API (for imperative, just remove hybridize. For symbolic, see https://github.com/apache/incubator-mxnet/blob/master/example/sparse/factorization_machine/model.py#L39 )

## Environment info (Required)
mxnet
floatnp.floatingnp.float64 == np.dtype(float).type

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run above code example. Note the storage fallback that occurs.
2. Remove the  line. Note that the storage fallback disappears.

",0,Hybridization generates superfluous backward ops that may induce storage fallbacks ,"Hybridization generates superfluous backward ops that may induce storage fallbacks  ## Description
Hybridizing creates superfluous backward ops in some conditions. This is bad, as these ops may consequently trigger a storage fallback. In the example below, no gradient for  is requested. Still  is generated and consequently a storage fallback occurs.
Note that this example works without storage fallback in the imperative and symbolic API (for imperative, just remove hybridize. For symbolic, see https://github.com/apache/incubator-mxnet/blob/master/example/sparse/factorization_machine/model.py#L39 )

## Environment info (Required)
mxnet
floatnp.floatingnp.float64 == np.dtype(float).type

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run above code example. Note the storage fallback that occurs.
2. Remove the  line. Note that the storage fallback disappears.

"
incubator-mxnet,11255,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I have installed the **Anaconda3 and installed the mxnet-cu90** by pip but the training speed is very slow

and I find that ,the data reading speed is much slow , when reading image data and decoding the binary data by imdecode , **the GPU usage is below 30%**, I guess that, the speed bottleneck of the speed is data reading.

multi-gpu and single gpu are the same slow 
## Environment info (Required)
Ubuntu16.04
P100


python diagnose.py

Package used (Python/R/Scala/Julia):
I'm using Anaconda3 python3.6
MXNet 1.2.0

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)
pip install mxnet-cu90
## Error Message:
(Paste the complete error message, including stack trace.)
No error, but the speed is slow, GPU usage is low
![default](https://user-images.githubusercontent.com/12196464/41327683-f5f6506e-6ef6-11e8-9650-cd2add427809.png)

traiing is slow
![default](https://user-images.githubusercontent.com/12196464/41327726-1cb087f6-6ef7-11e8-86dd-42978e275253.png)


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.Training with mxnet and P100
2.

## What have you tried to solve it?

1. installed python3, python2, pytthon2 encoutered the same problem
2.
",0,P100 + MXNet is slow,"P100 + MXNet is slow Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I have installed the **Anaconda3 and installed the mxnet-cu90** by pip but the training speed is very slow

and I find that ,the data reading speed is much slow , when reading image data and decoding the binary data by imdecode , **the GPU usage is below 30%**, I guess that, the speed bottleneck of the speed is data reading.

multi-gpu and single gpu are the same slow 
## Environment info (Required)
Ubuntu16.04
P100


python diagnose.py

Package used (Python/R/Scala/Julia):
I'm using Anaconda3 python3.6
MXNet 1.2.0

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)
pip install mxnet-cu90
## Error Message:
(Paste the complete error message, including stack trace.)
No error, but the speed is slow, GPU usage is low
![default](https://user-images.githubusercontent.com/12196464/41327683-f5f6506e-6ef6-11e8-9650-cd2add427809.png)

traiing is slow
![default](https://user-images.githubusercontent.com/12196464/41327726-1cb087f6-6ef7-11e8-86dd-42978e275253.png)


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.Training with mxnet and P100
2.

## What have you tried to solve it?

1. installed python3, python2, pytthon2 encoutered the same problem
2.
"
incubator-mxnet,13853,"Opening issue on behalf of @adwivedi on the discussion forum (https://discuss.mxnet.io/t/error-while-running-the-mxnet-spark-examples-and-test-cases/2720).

### Quotes from the thread...

I am trying to run the mxnet in distributed mode using spark as implemented here : https://github.com/apache/incubator-mxnet/tree/master/scala-package/spark

but I am not able to run the examples and/or tests.

The commented tests in the file : https://github.com/apache/incubator-mxnet/blob/master/scala-package/spark/src/test/scala/org/apache/mxnet/spark/MXNetGeneralSuite.scala keep running into the following error. I get the same error when I try to run the examples in the repo.



I have seen this error generally when there’s a mismatch between the scala versions in the api, but in this case I am using the using the pom file that’s in the project and not including any external libraries.
I have also looked at the pom file but I’ve not found any lib that might have a mismatch in this case, all the libraries in pom are 2.11 version

I am building it from source, running it with this vm parameter : -



to let it find the native library.",0,Error while running the mxnet spark examples and test cases,"Error while running the mxnet spark examples and test cases Opening issue on behalf of @adwivedi on the discussion forum (https://discuss.mxnet.io/t/error-while-running-the-mxnet-spark-examples-and-test-cases/2720).

### Quotes from the thread...

I am trying to run the mxnet in distributed mode using spark as implemented here : https://github.com/apache/incubator-mxnet/tree/master/scala-package/spark

but I am not able to run the examples and/or tests.

The commented tests in the file : https://github.com/apache/incubator-mxnet/blob/master/scala-package/spark/src/test/scala/org/apache/mxnet/spark/MXNetGeneralSuite.scala keep running into the following error. I get the same error when I try to run the examples in the repo.



I have seen this error generally when there’s a mismatch between the scala versions in the api, but in this case I am using the using the pom file that’s in the project and not including any external libraries.
I have also looked at the pom file but I’ve not found any lib that might have a mismatch in this case, all the libraries in pom are 2.11 version

I am building it from source, running it with this vm parameter : -



to let it find the native library."
incubator-mxnet,9763,"Hi everyone, I am working on a C++ project which needs to use mxnet for CNN inference. I set  and compiled mxnet source code myself.

In my C++ program, I only include  at first but got errors like below:


It is caused by [](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/base.h#L31) which includes  and  inside it.

Thus, I have to add a lot more dirs to avoid the similar errors:


Just want to ask if it is possible to make the mxnet C++ api easier to use?

For instance, the mxnet cpp package folder only contains:
* : all header files necessary for C++ development;
* : all libraries necessary for C++ development (i.e. libmxnet.so);",0,Too many header files need to be included when using C++ api,"Too many header files need to be included when using C++ api Hi everyone, I am working on a C++ project which needs to use mxnet for CNN inference. I set  and compiled mxnet source code myself.

In my C++ program, I only include  at first but got errors like below:


It is caused by [](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/base.h#L31) which includes  and  inside it.

Thus, I have to add a lot more dirs to avoid the similar errors:


Just want to ask if it is possible to make the mxnet C++ api easier to use?

For instance, the mxnet cpp package folder only contains:
* : all header files necessary for C++ development;
* : all libraries necessary for C++ development (i.e. libmxnet.so);"
incubator-mxnet,15165,Looks like that file cannot be found when building the latest trunk,0, Cannot open include file: 'cub/cub.cuh': No such file or directory, Cannot open include file: 'cub/cub.cuh': No such file or directory Looks like that file cannot be found when building the latest trunk
incubator-mxnet,10668,"I used to use a plugin like this to restart builds using a keyword trigger like . Could be handy.

@marcoabreu 

plugin: https://plugins.jenkins.io/github-pr-comment-build",0,[feature request] Jenkins build restartable from comments in the PR,"[feature request] Jenkins build restartable from comments in the PR I used to use a plugin like this to restart builds using a keyword trigger like . Could be handy.

@marcoabreu 

plugin: https://plugins.jenkins.io/github-pr-comment-build"
incubator-mxnet,16793,"## Description
Current design of DeepNumpy's random module follows native numpy in terms of the interpretation of the parameter .
More specifically,  indicates the final output size of the sampling operation. Parameter tensors, if narrower or smaller than , will be automatically broadcast to the output's shape.
However, this mechanism makes I.I.D sampling little bit tricky, for example:

Problem would arise in symbolic model, as the shape of  and  cannot be obtained in the frontend.

## Solution

The following  function could resolve this issue. (modified from: https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/random/dist_common.h#L143)



Notice that the  function could stay the same.

The modified sampling method is now able to produce the following result:


",0,[Numpy] [WIP] [RFC] Sample_n op for DeepNumpy,"[Numpy] [WIP] [RFC] Sample_n op for DeepNumpy ## Description
Current design of DeepNumpy's random module follows native numpy in terms of the interpretation of the parameter .
More specifically,  indicates the final output size of the sampling operation. Parameter tensors, if narrower or smaller than , will be automatically broadcast to the output's shape.
However, this mechanism makes I.I.D sampling little bit tricky, for example:

Problem would arise in symbolic model, as the shape of  and  cannot be obtained in the frontend.

## Solution

The following  function could resolve this issue. (modified from: https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/random/dist_common.h#L143)



Notice that the  function could stay the same.

The modified sampling method is now able to produce the following result:


"
incubator-mxnet,12894,"## Description
Training SSD networks with LeakyReLU (rrelu) activation causes the training to crash. I have tried different networks and vgg16_reduced.py as well. It always crashes

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python


## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
gcc

MXNet commit hash:
74638105f5480349cf57cda40a37475d626dbf41

Build config:
make -j4 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:


## Minimum reproducible example
In vgg16_reduced.py in example/ssd/symbol, make the following changes as shown below.

Replacing LeakyReLU with activations at other positions also causes the training to crash

## Steps to reproduce
python train.py --gpus 0,1 --batch-size 32 --pretrained '' 

## What have you tried to solve it?
I have had to replace LeakyReLU(rrelu) with other activations to get around this issue.
",0,Training crash SSD with LeakyReLU(rrelu),"Training crash SSD with LeakyReLU(rrelu) ## Description
Training SSD networks with LeakyReLU (rrelu) activation causes the training to crash. I have tried different networks and vgg16_reduced.py as well. It always crashes

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python


## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
gcc

MXNet commit hash:
74638105f5480349cf57cda40a37475d626dbf41

Build config:
make -j4 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:


## Minimum reproducible example
In vgg16_reduced.py in example/ssd/symbol, make the following changes as shown below.

Replacing LeakyReLU with activations at other positions also causes the training to crash

## Steps to reproduce
python train.py --gpus 0,1 --batch-size 32 --pretrained '' 

## What have you tried to solve it?
I have had to replace LeakyReLU(rrelu) with other activations to get around this issue.
"
incubator-mxnet,9574,"## Description
Running mobilenet

## Environment info (Required)



## Build info (Required if built from source)
clang
MXNet commit hash:

20253d5ce821ac012e2483b5dfb15bb5b7202f6d (Update test_gluon_model_zoo.py (#9539))

## Minimum reproducible example
### run_mobilenet.py


## Steps to reproduce


## What have you tried to solve it?

1. We will try to run Massif to see where the memory is going",0,Large host memory usage when using GPU with mobilenets,"Large host memory usage when using GPU with mobilenets ## Description
Running mobilenet

## Environment info (Required)



## Build info (Required if built from source)
clang
MXNet commit hash:

20253d5ce821ac012e2483b5dfb15bb5b7202f6d (Update test_gluon_model_zoo.py (#9539))

## Minimum reproducible example
### run_mobilenet.py


## Steps to reproduce


## What have you tried to solve it?

1. We will try to run Massif to see where the memory is going"
incubator-mxnet,10207,"## Description
1. khatri_rao was prematurely added to mx.nd/mx.sym namespace instead of contrib namespace which happened in https://github.com/apache/incubator-mxnet/pull/7781/files#r176510540.
2. khatri_rao doesn't have GPU version.

Given that this PR was merged last year, this feature has made its way into releases already. To resolve, we need to do one of the following:
1. mark the released op as deprecated and move it back to contrib in the next major version.
2. move forward: a) one more pass of vetting on the API design (cc @piiswrong), and then 2) implement the GPU version.

cc @cswiercz ",0,mxnet.ndarray.khatri_rao needs GPU version,"mxnet.ndarray.khatri_rao needs GPU version ## Description
1. khatri_rao was prematurely added to mx.nd/mx.sym namespace instead of contrib namespace which happened in https://github.com/apache/incubator-mxnet/pull/7781/files#r176510540.
2. khatri_rao doesn't have GPU version.

Given that this PR was merged last year, this feature has made its way into releases already. To resolve, we need to do one of the following:
1. mark the released op as deprecated and move it back to contrib in the next major version.
2. move forward: a) one more pass of vetting on the API design (cc @piiswrong), and then 2) implement the GPU version.

cc @cswiercz "
incubator-mxnet,5677,"The Constant initializer only overrides the _init_weight method. Consequently, there is no good way to use existing initializers to initialize the values for bias terms, which always are set to zero.

Example code


The same is true for Uniform, and Normal, and while an argument could be made that *typically* when Uniform and Normal are used, biases are set to zero, this current design results in very unexpected behavior. If I apply a Constant, Uniform, or Normal, initializer to a variable, my expectation is that it will actually initialize the variable in that way! Only through digging into the source code is it apparent that this expectation is violated and even if it was made more apparent in the documentation, I don't think that's the right design anyway. The functions should work as you would expect from their name. If someone wants to treat bias terms uniquely, they should use a Mixed initializer to explicitly state that difference. Or, if initing bias to zero is common enough, allow that mode with a flag in the constructor of these initializers, so it's still explicit, but simpler than using Mixed.

For more complex initialization strategies, it makes sense that it's variable dependent.",0,Constant Initializer only works on keys ending with weight,"Constant Initializer only works on keys ending with weight The Constant initializer only overrides the _init_weight method. Consequently, there is no good way to use existing initializers to initialize the values for bias terms, which always are set to zero.

Example code


The same is true for Uniform, and Normal, and while an argument could be made that *typically* when Uniform and Normal are used, biases are set to zero, this current design results in very unexpected behavior. If I apply a Constant, Uniform, or Normal, initializer to a variable, my expectation is that it will actually initialize the variable in that way! Only through digging into the source code is it apparent that this expectation is violated and even if it was made more apparent in the documentation, I don't think that's the right design anyway. The functions should work as you would expect from their name. If someone wants to treat bias terms uniquely, they should use a Mixed initializer to explicitly state that difference. Or, if initing bias to zero is common enough, allow that mode with a flag in the constructor of these initializers, so it's still explicit, but simpler than using Mixed.

For more complex initialization strategies, it makes sense that it's variable dependent."
incubator-mxnet,16868,"## Description

Checking the validity of parameters is crucial many operators, especially in distribution related Ops. (see references for the implementations of torch and tensorflow)

I implement an operator called , which takes a boolean tensor and an error message as input and then checks if all the elements are true, if not, raises exception with given message. It will return a scalar tensor  if none of the elements is false.

However, this Op fails in symbolic mode, as the output of this Op is neither returned to users nor used as the input for other Ops, causing the engine to completely ignore the check Op. In short, exception is not raised.

@leezu provides a workaround like this:

This approach works well, exception got thrown out as expected.

However, this method is not convenient when the  is buried in function called inside the hybrid_forward, e.g:

In such case, it becomes quite difficult to manually turn the  tensor into a return value.

--------------

Another solution could be the  op in control flow, which unfortunately, seems to be out of maintenance.

I believe, the simplest way is to have some kinds of mechanism that force MXNet to evaluate a particular OP.

I'm open to other solutions . (It would be great to implement this feature using only the existing infrastructure)

## References
- https://pytorch.org/docs/stable/_modules/torch/distributions/constraints.html#Constraint
- https://github.com/tensorflow/probability/blob/84cdabcdea19ce20d044fb7809b5742b953c9688/tensorflow_probability/python/internal/assert_util.py",0,[Numpy] Infrastructure for implementing constraint check,"[Numpy] Infrastructure for implementing constraint check ## Description

Checking the validity of parameters is crucial many operators, especially in distribution related Ops. (see references for the implementations of torch and tensorflow)

I implement an operator called , which takes a boolean tensor and an error message as input and then checks if all the elements are true, if not, raises exception with given message. It will return a scalar tensor  if none of the elements is false.

However, this Op fails in symbolic mode, as the output of this Op is neither returned to users nor used as the input for other Ops, causing the engine to completely ignore the check Op. In short, exception is not raised.

@leezu provides a workaround like this:

This approach works well, exception got thrown out as expected.

However, this method is not convenient when the  is buried in function called inside the hybrid_forward, e.g:

In such case, it becomes quite difficult to manually turn the  tensor into a return value.

--------------

Another solution could be the  op in control flow, which unfortunately, seems to be out of maintenance.

I believe, the simplest way is to have some kinds of mechanism that force MXNet to evaluate a particular OP.

I'm open to other solutions . (It would be great to implement this feature using only the existing infrastructure)

## References
- https://pytorch.org/docs/stable/_modules/torch/distributions/constraints.html#Constraint
- https://github.com/tensorflow/probability/blob/84cdabcdea19ce20d044fb7809b5742b953c9688/tensorflow_probability/python/internal/assert_util.py"
incubator-mxnet,14916,"Hi, there!
It seems that the current mxnet could not convert basic CNN models like alexnet, resnet from pytorch simply because the shape in ONNX is defined as a Tensor rather than attribute (which is mentioned [here](https://github.com/apache/incubator-mxnet/issues/13395#issuecomment-443304545)).

Are there any specific plans of solving this problem ?

Notice that the error could even occur when it is not a dynamic reshape. A simple script to produce is like below

Error message is

",0,"Failed to convert pytorch networks with ""torch.view()"" to mxnet with ONNX","Failed to convert pytorch networks with ""torch.view()"" to mxnet with ONNX Hi, there!
It seems that the current mxnet could not convert basic CNN models like alexnet, resnet from pytorch simply because the shape in ONNX is defined as a Tensor rather than attribute (which is mentioned [here](https://github.com/apache/incubator-mxnet/issues/13395#issuecomment-443304545)).

Are there any specific plans of solving this problem ?

Notice that the error could even occur when it is not a dynamic reshape. A simple script to produce is like below

Error message is

"
incubator-mxnet,12736,"## Description

liblapack not found when trying to build mxnet wheel from ci/build.py for the jetson framework on a host computer. Installed wheel on Jetson to see what would happen and lapack supported functions returned errors, did not build correctly, as expected. 

## Environment info (Required)
Running the build.py on Ubuntu 16.04 (more info below)
Docker version 18.06.1-ce 

What to do:
1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py
2. Run the script using  and paste its output here. 

$ sudo python diagnose.py 
----------Python Info----------
('Version      :', '2.7.12')
('Compiler     :', 'GCC 5.4.0 20160609')
('Build        :', ('default', 'Dec  4 2017 14:50:18'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '18.0')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
No MXNet installed.
----------System Info----------
('Platform     :', 'Linux-4.15.0-34-generic-x86_64-with-Ubuntu-16.04-xenial')
('system       :', 'Linux')
('node         :', 'cfa-System-Product-Name')
('release      :', '4.15.0-34-generic')
('version      :', '#37~16.04.1-Ubuntu SMP Tue Aug 28 10:44:06 UTC 2018')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 158
Model name:            Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz
Stepping:              9
CPU MHz:               4297.817
CPU max MHz:           4500.0000
CPU min MHz:           800.0000
BogoMIPS:              8400.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0063 sec, LOAD: 0.4813 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0086 sec, LOAD: 0.3699 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1589 sec, LOAD: 0.9135 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0258 sec, LOAD: 0.0875 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0778 sec, LOAD: 0.6933 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1163 sec, LOAD: 0.6141 sec.


Package used (Python/R/Scala/Julia):
Python 2 (Listed above)


## Build info (Required if built from source)
Cloned the repository 10/3/2018

MXNet commit hash:
bcd24f85457821f9c0ce17d60e545a252a87a5ae

Build config:
Standard config.mk, copied from the crosscompile.jetson.mk

## Error Message: (Including some of preceding output)
build.py: 2018-10-04 13:04:06,562 Executing the equivalent of:
docker \
	run \
	--cap-add \
	SYS_PTRACE \
	--rm \
	--shm-size=500m \
	-v \
	/home/cfa/mxnet-1.3:/work/mxnet \
	-v \
	/home/cfa/mxnet-1.3/build:/work/build \
	-v \
	/tmp/ci_ccache:/work/ccache \
	-u \
	0:0 \
	-e \
	CCACHE_MAXSIZE=500G \
	-e \
	CCACHE_TEMPDIR=/tmp/ccache \
	-e \
	CCACHE_DIR=/work/ccache \
	-e \
	CCACHE_LOGFILE=/tmp/ccache.log \
	-ti \
	mxnetci/build.jetson \
	/work/mxnet/ci/docker/runtime_functions.sh \
	build_jetson

build.py: 2018-10-04 13:04:07,016 Started container: f3dad0aa9232
+ NOSE_COVERAGE_ARGUMENTS='--with-coverage --cover-inclusive --cover-xml --cover-branches --cover-package=mxnet'
+ set +x
+ pushd .
/work/mxnet /work/mxnet
+ cp make/crosscompile.jetson.mk ./config.mk
++ nproc
+ make -j8
Makefile:180: ""USE_LAPACK disabled because libraries were not found""


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce

1. cloned the repo to mxnet-1.3
2. $ cd mxnet-1.3
3. $ sudo time ci/build.py -p jetson


## What have you tried to solve it?

1. Tried symbolically linking the liblapack.so and liblapack.a files to the main mxnet-1.3 folder on my host computer, tried hard copying as well.

How do I enable lapack for the ci/build.py method to make the .whl file to install on a Jetson TX2?
",0,"Running build.py to generate .whl for Jetson, no LAPACK lib found","Running build.py to generate .whl for Jetson, no LAPACK lib found ## Description

liblapack not found when trying to build mxnet wheel from ci/build.py for the jetson framework on a host computer. Installed wheel on Jetson to see what would happen and lapack supported functions returned errors, did not build correctly, as expected. 

## Environment info (Required)
Running the build.py on Ubuntu 16.04 (more info below)
Docker version 18.06.1-ce 

What to do:
1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py
2. Run the script using  and paste its output here. 

$ sudo python diagnose.py 
----------Python Info----------
('Version      :', '2.7.12')
('Compiler     :', 'GCC 5.4.0 20160609')
('Build        :', ('default', 'Dec  4 2017 14:50:18'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '18.0')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
No MXNet installed.
----------System Info----------
('Platform     :', 'Linux-4.15.0-34-generic-x86_64-with-Ubuntu-16.04-xenial')
('system       :', 'Linux')
('node         :', 'cfa-System-Product-Name')
('release      :', '4.15.0-34-generic')
('version      :', '#37~16.04.1-Ubuntu SMP Tue Aug 28 10:44:06 UTC 2018')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 158
Model name:            Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz
Stepping:              9
CPU MHz:               4297.817
CPU max MHz:           4500.0000
CPU min MHz:           800.0000
BogoMIPS:              8400.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0063 sec, LOAD: 0.4813 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0086 sec, LOAD: 0.3699 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1589 sec, LOAD: 0.9135 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0258 sec, LOAD: 0.0875 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0778 sec, LOAD: 0.6933 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1163 sec, LOAD: 0.6141 sec.


Package used (Python/R/Scala/Julia):
Python 2 (Listed above)


## Build info (Required if built from source)
Cloned the repository 10/3/2018

MXNet commit hash:
bcd24f85457821f9c0ce17d60e545a252a87a5ae

Build config:
Standard config.mk, copied from the crosscompile.jetson.mk

## Error Message: (Including some of preceding output)
build.py: 2018-10-04 13:04:06,562 Executing the equivalent of:
docker \
	run \
	--cap-add \
	SYS_PTRACE \
	--rm \
	--shm-size=500m \
	-v \
	/home/cfa/mxnet-1.3:/work/mxnet \
	-v \
	/home/cfa/mxnet-1.3/build:/work/build \
	-v \
	/tmp/ci_ccache:/work/ccache \
	-u \
	0:0 \
	-e \
	CCACHE_MAXSIZE=500G \
	-e \
	CCACHE_TEMPDIR=/tmp/ccache \
	-e \
	CCACHE_DIR=/work/ccache \
	-e \
	CCACHE_LOGFILE=/tmp/ccache.log \
	-ti \
	mxnetci/build.jetson \
	/work/mxnet/ci/docker/runtime_functions.sh \
	build_jetson

build.py: 2018-10-04 13:04:07,016 Started container: f3dad0aa9232
+ NOSE_COVERAGE_ARGUMENTS='--with-coverage --cover-inclusive --cover-xml --cover-branches --cover-package=mxnet'
+ set +x
+ pushd .
/work/mxnet /work/mxnet
+ cp make/crosscompile.jetson.mk ./config.mk
++ nproc
+ make -j8
Makefile:180: ""USE_LAPACK disabled because libraries were not found""


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce

1. cloned the repo to mxnet-1.3
2. $ cd mxnet-1.3
3. $ sudo time ci/build.py -p jetson


## What have you tried to solve it?

1. Tried symbolically linking the liblapack.so and liblapack.a files to the main mxnet-1.3 folder on my host computer, tried hard copying as well.

How do I enable lapack for the ci/build.py method to make the .whl file to install on a Jetson TX2?
"
incubator-mxnet,14349,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)
installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails
with module not found


## Environment info (Required)
pip freeze has
mxnet==1.3.1
numpy==1.14.3

-

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) : Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

 import mxnet as mx
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\__init__.py"", line 24, in <module>
    from .context import Context, current_context, cpu, gpu, cpu_pinned
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\context.py"", line 24, in <module>
    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 213, in <module>
    _LIB = _load_lib()
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 204, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. import mxnet as mx
2.

## What have you tried to solve it?

1.
2.
",0,installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails,"installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)
installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails
with module not found


## Environment info (Required)
pip freeze has
mxnet==1.3.1
numpy==1.14.3

-

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) : Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

 import mxnet as mx
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\__init__.py"", line 24, in <module>
    from .context import Context, current_context, cpu, gpu, cpu_pinned
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\context.py"", line 24, in <module>
    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 213, in <module>
    _LIB = _load_lib()
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 204, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. import mxnet as mx
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,9755,"The Core API's [IO](https://github.com/apache/incubator-mxnet/tree/master/src/io) isn't being updated to incude [NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/io.py#L544), which forces developers for the other languages to write equivalants. If  were in the Core API like , , , etc, then it would be called by all languages through each language's MXDataIter wrapper. 

 was first introduced as [NumpyIter](https://github.com/apache/incubator-mxnet/blob/f6327ecf86d8a169ec1277c1e7809ed14f89b0c0/python/mxnet/io.py#L83) by @sneakerkg in 2015, but evolved into a general numeric vector iterator that is useful in languages other than Python, such as in R, which defined but doesn't implement an [R NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L92) as seen in the comments:

It would make more sense to have  in the Core, so it can be called by [R's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L53). Then it could also be accessed by [Scala's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io//MXDataIter.scala). But instead, they had to code and test their own [Scala NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io/NDArrayIter.scala). The C++ API doesn’t even mention  and only has the [C++ MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/io.h). ",0,Feature request: move NDArrayiter to Core API,"Feature request: move NDArrayiter to Core API The Core API's [IO](https://github.com/apache/incubator-mxnet/tree/master/src/io) isn't being updated to incude [NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/io.py#L544), which forces developers for the other languages to write equivalants. If  were in the Core API like , , , etc, then it would be called by all languages through each language's MXDataIter wrapper. 

 was first introduced as [NumpyIter](https://github.com/apache/incubator-mxnet/blob/f6327ecf86d8a169ec1277c1e7809ed14f89b0c0/python/mxnet/io.py#L83) by @sneakerkg in 2015, but evolved into a general numeric vector iterator that is useful in languages other than Python, such as in R, which defined but doesn't implement an [R NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L92) as seen in the comments:

It would make more sense to have  in the Core, so it can be called by [R's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L53). Then it could also be accessed by [Scala's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io//MXDataIter.scala). But instead, they had to code and test their own [Scala NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io/NDArrayIter.scala). The C++ API doesn’t even mention  and only has the [C++ MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/io.h). "
incubator-mxnet,16656,"NFO: 56358:  2019-10-28 08:26:33: main_crack_segmentation.py:382 * segmentation crack...
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/module/base_module.py:66: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
  warnings.warn(msg)
*** Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9a764bc7e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9a764c537a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9a764c953c]
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so(MXExecutorReshape+0x1de7)[0x7f99c3a2d5e7]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c)[0x7f9a0cfcfe40]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb)[0x7f9a0cfcf8ab]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f)[0x7f9a0d1df3df]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82)[0x7f9a0d1e3d82]
/usr/bin/python(PyEval_EvalFrameEx+0x578d)[0x4c166d]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4d57a3]
/usr/bin/python(PyObject_Call+0x3e)[0x4a587e]
/usr/bin/python(PyEval_EvalFrameEx+0x263e)[0x4be51e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python[0x54aae7]
/usr/bin/python(PyEval_EvalFrameEx+0x5f3e)[0x4c1e1e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python(PyRun_SimpleFileExFlags+0x186)[0x4e41a6]
/usr/bin/python(Py_Main+0x54e)[0x4938ce]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f9a76465830]
/usr/bin/python(_start+0x29)[0x493299]
======= Memory map: ========
00400000-006de000 r-xp 00000000 08:21 62529595                           /usr/bin/python2.7
008dd000-008de000 r--p 002dd000 08:21 62529595                           /usr/bin/python2.7
008de000-00955000 rw-p 002de000 08:21 62529595                           /usr/bin/python2.7
00955000-00978000 rw-p 00000000 00:00 0 
00fae000-2d86a000 rw-p 00000000 00:00 0                                  [heap]
200000000-200200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200200000-200400000 ---p 00000000 00:00 0 
200400000-200404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200404000-200600000 ---p 00000000 00:00 0 
200600000-200a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200a00000-201800000 ---p 00000000 00:00 0 
201800000-201804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201804000-201a00000 ---p 00000000 00:00 0 
201a00000-201e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201e00000-202c00000 ---p 00000000 00:00 0 
202c00000-202c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
202c04000-202e00000 ---p 00000000 00:00 0 
202e00000-203200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
203200000-204000000 ---p 00000000 00:00 0 
204000000-204004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204004000-204200000 ---p 00000000 00:00 0 
204200000-204600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204600000-205400000 ---p 00000000 00:00 0 
205400000-205404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205404000-205600000 ---p 00000000 00:00 0 
205600000-205a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205a00000-206800000 ---p 00000000 00:00 0 
206800000-206804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206804000-206a00000 ---p 00000000 00:00 0 
206a00000-206e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206e00000-207c00000 ---p 00000000 00:00 0 
207c00000-207c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
207c04000-207e00000 ---p 00000000 00:00 0 
207e00000-208200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
208200000-209000000 ---p 00000000 00:00 0 
209000000-209004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209004000-209200000 ---p 00000000 00:00 0 
209200000-209600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209600000-20a400000 ---p 00000000 00:00 0 
20a400000-20a404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20a404000-20a600000 ---p 00000000 00:00 0 
20a600000-20aa00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa00000-20aa04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa04000-20ac00000 ---p 00000000 00:00 0 
20ac00000-20b000000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b000000-20b004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b004000-20b200000 ---p 00000000 00:00 0 
20b200000-20b600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b600000-20b604000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b604000-20b800000 ---p 00000000 00:00 0 
20b800000-20bc00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc00000-20bc04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc04000-20be00000 ---p 00000000 00:00 0 
20be00000-20c200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c200000-20c204000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c204000-20c400000 ---p 00000000 00:00 0 
20c400000-20c800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c800000-20c804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c804000-20ca00000 ---p 00000000 00:00 0 
20ca00000-20ce00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce00000-20ce04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce04000-20d000000 ---p 00000000 00:00 0 
20d000000-20d400000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d400000-20d600000 ---p 00000000 00:00 0 
20d600000-20d800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d800000-c00200000 ---p 00000000 00:00 0 
10000000000-10b04000000 ---p 00000000 00:00 0 
7f9823829000-7f9834000000 rw-p 00000000 00:00 0 
7f9834000000-7f9834022000 rw-p 00000000 00:00 0 
7f9834022000-7f9838000000 ---p 00000000 00:00 0 
7f9838000000-7f983a08a000 rw-p 00000000 00:00 0 
7f983a08a000-7f983c000000 ---p 00000000 00:00 0 
7f983c000000-7f983c022000 rw-p 00000000 00:00 0 
7f983c022000-7f9840000000 ---p 00000000 00:00 0 
7f9842807000-7f9849009000 rw-p 00000000 00:00 0 
7f984d7fe000-7f9854000000 rw-p 00000000 00:00 0 
7f9854000000-7f98569b9000 rw-p 00000000 00:00 0 
7f98569b9000-7f9858000000 ---p 00000000 00:00 0 
7f985c000000-7f985db22000 rw-p 00000000 00:00 0 
7f985db22000-7f9860000000 ---p 00000000 00:00 0 
7f9864000000-7f9866f05000 rw-p 00000000 00:00 0 
7f9866f05000-7f9868000000 ---p 00000000 00:00 0 
7f9868000000-7f986be05000 rw-p 00000000 00:00 0 
7f986be05000-7f986c000000 ---p 00000000 00:00 0 
7f986c000000-7f986ff25000 rw-p 00000000 00:00 0 
7f986ff25000-7f9870000000 ---p 00000000 00:00 0 
7f9870200000-7f9870800000 ---p 00000000 00:00 0 
7f98709fd000-7f98709fe000 ---p 00000000 00:00 0 
7f98709fe000-7f98711fe000 rw-p 00000000 00:00 0 
7f98711fe000-7f98711ff000 ---p 00000000 00:00 0 
7f98711ff000-7f98719ff000 rw-p 00000000 00:00 0 
7f98721fd000-7f98721fe000 ---p 00000000 00:00 0 
7f98721fe000-7f98729fe000 rw-p 00000000 00:00 0 
7f98729fe000-7f98729ff000 ---p 00000000 00:00 0 
7f98729ff000-7f98731ff000 rw-p 00000000 00:00 0 
7f98731ff000-7f9873200000 ---p 00000000 00:00 0 
7f9873200000-7f9873a00000 rw-p 00000000 00:00 0 
7f9873a00000-7f9874000000 ---p 00000000 00:00 0 
7f9874000000-7f9877da7000 rw-p 00000000 00:00 0 
7f9877da7000-7f9878000000 ---p 00000000 00:00 0 
7f9878200000-7f9878400000 ---p 00000000 00:00 0 
7f98785ff000-7f9878600000 ---p 00000000 00:00 0 
7f9878600000-7f9878e00000 rw-p 00000000 00:00 0 
7f9878e00000-7f9894000000 ---p 00000000 00:00 0 
7f9894000000-7f9898091000 rw-p 00000000 00:00 0 
7f9898091000-7f989c000000 ---p 00000000 00:00 0 
7f989c000000-7f989ffff000 rw-p 00000000 00:00 0 
7f989ffff000-7f98a0000000 ---p 00000000 00:00 0 
7f98a0000000-7f98a3f49000 rw-p 00000000 00:00 0 
7f98a3f49000-7f98a4000000 ---p 00000000 00:00 0 
7f98a4000000-7f98a7fce000 rw-p 00000000 00:00 0 
7f98a7fce000-7f98a8000000 ---p 00000000 00:00 0 
7f98a8000000-7f98abfee000 rw-p 00000000 00:00 0 
7f98abfee000-7f98ac000000 ---p 00000000 00:00 0 
7f98ac000000-7f98aff87000 rw-p 00000000 00:00 0 
7f98aff87000-7f98b0000000 ---p 00000000 00:00 0 
7f98b0000000-7f98b4000000 rw-p 00000000 00:00 0 
7f98b4000000-7f98b7efc000 rw-p 00000000 00:00 0 
7f98b7efc000-7f98b8000000 ---p 00000000 00:00 0 
7f98b8000000-7f98bc000000 rw-p 00000000 00:00 0 
7f98bc000000-7f98bd0a3000 rw-p 00000000 00:00 0 
7f98bd0a3000-7f98c0000000 ---p 00000000 00:00 0 
7f98c0000000-7f98c4000000 rw-p 00000000 00:00 0 
7f98c4000000-7f98c7ffe000 rw-p 00000000 00:00 0 
7f98c7ffe000-7f98c8000000 ---p 00000000 00:00 0 
7f98c8000000-7f98cbffd000 rw-p 00000000 00:00 0 
7f98cbffd000-7f98cc000000 ---p 00000000 00:00 0 
7f98cc000000-7f98d0000000 rw-p 00000000 00:00 0 
7f98d0000000-7f98d8000000 ---p 00000000 00:00 0 
7f98d8000000-7f98d8021000 rw-p 00000000 00:00 0 
7f98d8021000-7f98dc000000 ---p 00000000 00:00 0 
7f98dc200000-7f98e0000000 ---p 00000000 00:00 0 
7f98e0000000-7f98e0021000 rw-p 00000000 00:00 0 
7f98e0021000-7f98e4000000 ---p 00000000 00:00 0 
7f98e4200000-7f98e4e00000 ---p 00000000 00:00 0 
7f98e4ffe000-7f98eaffe000 ---p 00000000 00:00 0 
7f98eaffe000-7f98f4000000 rw-p 00000000 00:00 0 
7f98f4000000-7f98f4022000 rw-p 00000000 00:00 0 
7f98f4022000-7f98f8000000 ---p 00000000 00:00 0 
7f98f8000000-7f98f8022000 rw-p 00000000 00:00 0 
7f98f8022000-7f98fc000000 ---p 00000000 00:00 0 
7f98fc000000-7f98fc022000 rw-p 00000000 00:00 0 
7f98fc022000-7f9900000000 ---p 00000000 00:00 0 
7f9900200000-7f9900800000 ---p 00000000 00:00 0 
7f99009fc000-7f9904000000 rw-p 00000000 00:00 0 
7f9904000000-7f9904022000 rw-p 00000000 00:00 0 
7f9904022000-7f9908000000 ---p 00000000 00:00 0 
7f9908248000-7f9909d4b000 rw-p 00000000 00:00 0 
7f9909d4b000-7f9909d54000 r-xp 00000000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909d54000-7f9909f53000 ---p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f53000-7f9909f54000 r--p 00008000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f54000-7f9909f56000 rw-p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f56000-7f9909f57000 ---p 00000000 00:00 0 
7f9909f57000-7f990a757000 rw-p 00000000 00:00 0 
7f990a757000-7f990a767000 r-xp 00000000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a767000-7f990a966000 ---p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a966000-7f990a967000 r--p 0000f000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a967000-7f990a96a000 rw-p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a96a000-7f990a97b000 r-xp 00000000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990a97b000-7f990ab7a000 ---p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7a000-7f990ab7b000 r--p 00010000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7b000-7f990ab7e000 rw-p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7e000-7f990ab7f000 rw-p 00000000 00:00 0 
7f990ab7f000-7f990ab83000 r-xp 00000000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ab83000-7f990ad82000 ---p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad82000-7f990ad83000 r--p 00003000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad83000-7f990ad84000 rw-p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad84000-7f990ad8f000 r-xp 00000000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990ad8f000-7f990af8e000 ---p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8e000-7f990af8f000 r--p 0000a000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8f000-7f990af91000 rw-p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af91000-7f990afa7000 r-xp 00000000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990afa7000-7f990b1a6000 ---p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a6000-7f990b1a7000 r--p 00015000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a7000-7f990b1aa000 rw-p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1aa000-7f990b1bf000 r-xp 00000000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b1bf000-7f990b3be000 ---p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3be000-7f990b3bf000 r--p 00014000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3bf000-7f990b3c2000 rw-p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3c2000-7f990b3c3000 rw-p 00000000 00:00 0 
7f990b3c3000-7f990b3d0000 r-xp 00000000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b3d0000-7f990b5cf000 ---p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5cf000-7f990b5d0000 r--p 0000c000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d0000-7f990b5d2000 rw-p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d2000-7f990b5e6000 r-xp 00000000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b5e6000-7f990b7e5000 ---p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e5000-7f990b7e6000 r--p 00013000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e6000-7f990b7e9000 rw-p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e9000-7f990b7f0000 r-xp 00000000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b7f0000-7f990b9ef000 ---p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9ef000-7f990b9f0000 r--p 00006000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f0000-7f990b9f1000 rw-p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f1000-7f990b9fc000 r-xp 00000000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990b9fc000-7f990bbfb000 ---p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfb000-7f990bbfc000 r--p 0000a000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfc000-7f990bbfd000 rw-p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfd000-7f990bc25000 r-xp 00000000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990bc25000-7f990be25000 ---p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be25000-7f990be26000 r--p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be26000-7f990be2e000 rw-p 00029000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be2e000-7f990be2f000 rw-p 00000000 00:00 0 
7f990be2f000-7f990be43000 r-xp 00000000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990be43000-7f990c042000 ---p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c042000-7f990c043000 r--p 00013000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c043000-7f990c046000 rw-p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c046000-7f990c047000 rw-p 00000000 00:00 0 
7f990c047000-7f990c05c000 r-xp 00000000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c05c000-7f990c25c000 ---p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25c000-7f990c25d000 r--p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25d000-7f990c260000 rw-p 00016000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c260000-7f990c267000 r-xp 00000000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c267000-7f990c466000 ---p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c466000-7f990c467000 r--p 00006000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c467000-7f990c468000 rw-p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c468000-7f990c469000 rw-p 00000000 00:00 0 
7f990c469000-7f990c47a000 r-xp 00000000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c47a000-7f990c679000 ---p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c679000-7f990c67a000 r--p 00010000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67a000-7f990c67c000 rw-p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67c000-7f990c67d000 rw-p 00000000 00:00 0 
7f990c67d000-7f990c686000 r-xp 00000000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c686000-7f990c885000 ---p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c885000-7f990c886000 r--p 00008000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c886000-7f990c887000 rw-p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c887000-7f990c8cb000 r-xp 00000000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990c8cb000-7f990caca000 ---p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990caca000-7f990cacb000 r--p 00043000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cacb000-7f990cad5000 rw-p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cad5000-7f990caf3000 r-xp 00000000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990caf3000-7f990ccf2000 ---p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf2000-7f990ccf3000 r--p 0001d000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf3000-7f990ccf4000 rw-p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf4000-7f990ccf5000 rw-p 00000000 00:00 0 
7f990ccf5000-7f990cd1c000 r-xp 00000000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cd1c000-7f990cf1c000 ---p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1c000-7f990cf1d000 r--p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1d000-7f990cf1f000 rw-p 00028000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1f000-7f990cf35000 r-xp 00000000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990cf35000-7f990d134000 ---p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d134000-7f990d135000 r--p 00015000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d135000-7f990d138000 rw-p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d138000-7f990d142000 r-xp 00000000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d142000-7f990d341000 ---p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d341000-7f990d342000 r--p 00009000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d342000-7f990d344000 rw-p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d344000-7f990d351000 r-xp 00000000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d351000-7f990d550000 ---p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d550000-7f990d551000 r--p 0000c000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d551000-7f990d552000 rw-p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d552000-7f990d559000 r-xp 00000000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d559000-7f990d758000 ---p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d758000-7f990d759000 r--p 00006000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d759000-7f990d75a000 rw-p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d75a000-7f990d75c000 r-xp 00000000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d75c000-7f990d95b000 ---p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95b000-7f990d95c000 r--p 00001000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95c000-7f990d95d000 rw-p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95d000-7f990dbf1000 r-xp 00000000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990dbf1000-7f990ddf0000 ---p 00294000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf0000-7f990ddf5000 r--p 00293000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf5000-7f990ddfa000 rw-p 00298000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddfa000-7f990ddfb000 rw-p 00000000 00:00 0 
7f990ddfb000-7f990de03000 r-xp 00000000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990de03000-7f990e002000 ---p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e002000-7f990e003000 r--p 00007000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e003000-7f990e004000 rw-p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e004000-7f993a004000 rw-p 00000000 00:00 0 
7f993a004000-7f993a005000 ---p 00000000 00:00 0 
7f993a005000-7f993a805000 rw-p 00000000 00:00 0 
7f993a805000-7f993a806000 ---p 00000000 00:00 0 
7f993a806000-7f993b006000 rw-p 00000000 00:00 0 
7f993b006000-7f993b007000 ---p 00000000 00:00 0 
7f993b007000-7f993b807000 rw-p 00000000 00:00 0 
7f993b807000-7f993b808000 ---p 00000000 00:00 0 
7f993b808000-7f993c008000 rw-p 00000000 00:00 0 
7f993c400000-7f993c600000 ---p 00000000 00:00 0 
7f993c60a000-7f993f80b000 rw-p 00000000 00:00 0 
7f993fc00000-7f993fe00000 ---p 00000000 00:00 0 
7f993fe00000-7f9940000000 rw-s 00000000 00:05 206094999                  /dev/zero (deleted)
7f994000c000-7f994200c000 rw-p 00000000 00:00 0 
7f9942400000-7f9942600000 ---p 00000000 00:00 0 
7f994260d000-7f994580f000 rw-p 00000000 00:00 0 
7f9945c00000-7f9946000000 ---p 00000000 00:00 0 
7f9946010000-7f9948010000 rw-p 00000000 00:00 0 
7f9948216000-7f994f81b000 rw-p 00000000 00:00 0 
7f994fc00000-7f994fe00000 rw-s 00000000 00:05 206094998                  /dev/zero (deleted)
7f994fe00000-7f9950000000 ---p 00000000 00:00 0 
7f995001c000-7f995601c000 rw-p 00000000 00:00 0 
7f995601c000-7f995601d000 ---p 00000000 00:00 0 
7f995601d000-7f995881d000 rw-p 00000000 00:00 0 
7f995881d000-7f995881e000 ---p 00000000 00:00 0 
7f995881e000-7f995f01e000 rw-p 00000000 00:00 0 
7f995f400000-7f995f600000 ---p 00000000 00:00 0 
7f995f71f000-7f9962020000 rw-p 00000000 00:00 0 
7f9962400000-7f9962800000 ---p 00000000 00:00 0 
7f9962821000-7f9964821000 rw-p 00000000 00:00 0 
7f9964c00000-7f9965000000 ---p 00000000 00:00 0 
7f9965022000-7f9967022000 rw-p 00000000 00:00 0 
7f9967400000-7f9967800000 ---p 00000000 00:00 0 
7f9967823000-7f9969823000 rw-p 00000000 00:00 0 
7f9969c00000-7f9969ed6000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9969ed6000-7f996a000000 ---p 00000000 00:00 0 
7f996a024000-7f996c024000 rw-p 00000000 00:00 0 
7f996c400000-7f996c600000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996c600000-7f996c800000 rw-s 00000000 00:05 206139044                  /dev/zero (deleted)
7f996c825000-7f996e825000 rw-p 00000000 00:00 0 
7f996ec00000-7f996ee00000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996ee00000-7f996f000000 rw-s 00000000 00:05 206139043                  /dev/zero (deleted)
7f996f026000-7f9971026000 rw-p 00000000 00:00 0 
7f9971026000-7f9971027000 ---p 00000000 00:00 0 
7f9971027000-7f9973827000 rw-p 00000000 00:00 0 
7f9973c00000-7f9973e00000 ---p 00000000 00:00 0 
7f9973e29000-7f997902a000 rw-p 00000000 00:00 0 
7f997902d000-7f997d02e000 rw-p 00000000 00:00 0 
7f997d02e000-7f997d02f000 ---p 00000000 00:00 0 
7f997d02f000-7f997f82f000 rw-p 00000000 00:00 0 
7f997f82f000-7f997f830000 ---p 00000000 00:00 0 
7f997f830000-7f9984030000 rw-p 00000000 00:00 0 
7f9984400000-7f9984600000 ---p 00000000 00:00 0 
7f9984731000-7f9987032000 rw-p 00000000 00:00 0 
7f9987171000-7f998c034000 rw-p 00000000 00:00 0 
7f998c0b2000-7f9996038000 rw-p 00000000 00:00 0 
7f9996038000-7f99978ee000 r-xp 00000000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f99978ee000-7f9997aed000 ---p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aed000-7f9997aee000 r--p 018b5000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aee000-7f9997aef000 rw-p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aef000-7f9997af2000 r-xp 00000000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997af2000-7f9997cf1000 ---p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf1000-7f9997cf2000 r--p 00002000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf2000-7f9997cf3000 rw-p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf3000-7f9997e72000 r-xp 00000000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9997e72000-7f9998072000 ---p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998072000-7f9998082000 r--p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998082000-7f9998083000 rw-p 0018f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998083000-7f9998087000 rw-p 00000000 00:00 0 
7f9998087000-7f9998091000 r-xp 00000000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998091000-7f9998290000 ---p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998290000-7f9998291000 r--p 00009000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998291000-7f9998292000 rw-p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998292000-7f9998295000 r-xp 00000000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998295000-7f9998494000 ---p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998494000-7f9998495000 r--p 00002000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998495000-7f9998496000 rw-p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998496000-7f99984c2000 r-xp 00000000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99984c2000-7f99986c1000 ---p 0002c000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c1000-7f99986c3000 r--p 0002b000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c3000-7f99986c4000 rw-p 0002d000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c4000-7f99986c5000 rw-p 00000000 00:00 0 
7f99986c5000-7f9998788000 r-xp 00000000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998788000-7f9998988000 ---p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998988000-7f9998995000 r--p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998995000-7f9998997000 rw-p 000d0000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998997000-7f99989a9000 r-xp 00000000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f99989a9000-7f9998ba9000 ---p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998ba9000-7f9998baa000 r--p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998baa000-7f9998bab000 rw-p 00013000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998bab000-7f9998bcc000 r-xp 00000000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998bcc000-7f9998dcb000 ---p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcb000-7f9998dcc000 r--p 00020000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcc000-7f9998dcd000 rw-p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcd000-7f9998dd3000 r-xp 00000000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998dd3000-7f9998fd3000 ---p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd3000-7f9998fd4000 r--p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd4000-7f9998fd5000 rw-p 00007000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd5000-7f9998ff9000 r-xp 00000000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f9998ff9000-7f99991f8000 ---p 00024000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991f8000-7f99991fa000 r--p 00023000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fa000-7f99991fb000 rw-p 00025000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fb000-7f999920c000 r-xp 00000000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999920c000-7f999940c000 ---p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940c000-7f999940d000 r--p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940d000-7f999940e000 rw-p 00012000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940e000-7f999943f000 r-xp 00000000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999943f000-7f999963f000 ---p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999963f000-7f9999640000 r--p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999640000-7f9999641000 rw-p 00032000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999641000-7f999969a000 r-xp 00000000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f999969a000-7f9999899000 ---p 00059000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f9999899000-7f99998a3000 r--p 00058000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a3000-7f99998a5000 rw-p 00062000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a5000-7f9999a56000 r-xp 00000000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999a56000-7f9999c55000 ---p 001b1000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c55000-7f9999c5d000 r--p 001b0000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5d000-7f9999c5f000 rw-p 001b8000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5f000-7f9999c60000 rw-p 00000000 00:00 0 
7f9999c60000-7f9999cdf000 r-xp 00000000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999cdf000-7f9999ede000 ---p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ede000-7f9999edf000 r--p 0007e000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999edf000-7f9999ee0000 rw-p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ee0000-7f9999f14000 r-xp 00000000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f9999f14000-7f999a113000 ---p 00034000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a113000-7f999a115000 r--p 00033000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a115000-7f999a116000 rw-p 00035000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a116000-7f999a148000 r-xp 00000000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a148000-7f999a347000 ---p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a347000-7f999a348000 r--p 00031000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a348000-7f999a349000 rw-p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a349000-7f999a390000 r-xp 00000000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a390000-7f999a58f000 ---p 00047000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a58f000-7f999a591000 r--p 00046000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a591000-7f999a593000 rw-p 00048000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a593000-7f999a66a000 r-xp 00000000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a66a000-7f999a86a000 ---p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86a000-7f999a86b000 r--p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86b000-7f999a873000 rw-p 000d8000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a873000-7f999a874000 rw-p 00000000 00:00 0 
7f999a874000-7f999a8ef000 r-xp 00000000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999a8ef000-7f999aaee000 ---p 0007b000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaee000-7f999aaf0000 r--p 0007a000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf0000-7f999aaf4000 rw-p 0007c000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf4000-7f999aafb000 r-xp 00000000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999aafb000-7f999acfb000 ---p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfb000-7f999acfc000 r--p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfc000-7f999acfd000 rw-p 00008000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfd000-7f999ad07000 r-xp 00000000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999ad07000-7f999af06000 ---p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af06000-7f999af07000 r--p 00009000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af07000-7f999af08000 rw-p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af08000-7f999af36000 r-xp 00000000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999af36000-7f999b135000 ---p 0002e000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b135000-7f999b137000 r--p 0002d000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b137000-7f999b138000 rw-p 0002f000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b138000-7f999b16d000 rw-p 00000000 00:00 0 
7f999b16d000-7f999b192000 r-xp 00000000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b192000-7f999b392000 ---p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b392000-7f999b394000 r--p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b394000-7f999b395000 rw-p 00027000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b395000-7f999b3e7000 rw-p 00000000 00:00 0 
7f999b3e7000-7f999b449000 r-xp 00000000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b449000-7f999b649000 ---p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b649000-7f999b64a000 r--p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64a000-7f999b64f000 rw-p 00063000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64f000-7f999b650000 rw-p 00000000 00:00 0 
7f999b650000-7f999b658000 r-xp 00000000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b658000-7f999b857000 ---p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b857000-7f999b858000 r--p 00007000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b858000-7f999b859000 rw-p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b859000-7f999b8b5000 r-xp 00000000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999b8b5000-7f999bab5000 ---p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab5000-7f999bab6000 r--p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab6000-7f999bab7000 rw-p 0005d000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab7000-7f999bace000 r-xp 00000000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bace000-7f999bcce000 ---p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcce000-7f999bccf000 r--p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bccf000-7f999bcd0000 rw-p 00018000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcd0000-7f999bcd2000 rw-p 00000000 00:00 0 
7f999bcd2000-7f999bcf1000 r-xp 00000000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bcf1000-7f999bef0000 ---p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef0000-7f999bef1000 r--p 0001e000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef1000-7f999bef2000 rw-p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef2000-7f999bef4000 rw-p 00000000 00:00 0 
7f999bef4000-7f999befc000 r-xp 00000000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999befc000-7f999c0fc000 ---p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fc000-7f999c0fd000 r--p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fd000-7f999c0fe000 rw-p 00009000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fe000-7f99a3f2c000 r-xp 00000000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a3f2c000-7f99a412c000 ---p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a412c000-7f99a413b000 rw-p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a413b000-7f99a419f000 rw-p 00000000 00:00 0 
7f99a419f000-7f99b77d1000 r-xp 00000000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b77d1000-7f99b79d1000 ---p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b79d1000-7f99b7a4c000 rw-p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b7a4c000-7f99b7ade000 rw-p 00000000 00:00 0 
7f99b7ade000-7f99bc48d000 r-xp 00000000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc48d000-7f99bc68d000 ---p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc68d000-7f99bc6c7000 rw-p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc6c7000-7f99bc6d9000 rw-p 00000000 00:00 0 
7f99bc6d9000-7f99beb62000 r-xp 00000000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99beb62000-7f99bed61000 ---p 02489000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99bed61000-7f99c0133000 rw-p 02488000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99c0133000-7f99c063d000 rw-p 00000000 00:00 0 
7f99c063d000-7f99d02b3000 r-xp 00000000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d02b3000-7f99d04b3000 ---p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04b3000-7f99d04ed000 r--p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04ed000-7f99d0511000 rw-p 0fcb0000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d0511000-7f99d1029000 rw-p 00000000 00:00 0 
7f99d1029000-7f99d102e000 r-xp 00000000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d102e000-7f99d122d000 ---p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122d000-7f99d122e000 r--p 00004000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122e000-7f99d122f000 rw-p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122f000-7f99d1231000 r-xp 00000000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1231000-7f99d1431000 ---p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1431000-7f99d1432000 r--p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1432000-7f99d1433000 rw-p 00003000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1433000-7f99d1454000 r-xp 00000000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1454000-7f99d1653000 ---p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1653000-7f99d1654000 r--p 00020000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1654000-7f99d1655000 rw-p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1655000-7f99d1659000 r-xp 00000000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1659000-7f99d1858000 ---p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1858000-7f99d1859000 r--p 00003000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1859000-7f99d185a000 rw-p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d185a000-7f99d18c8000 r-xp 00000000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d18c8000-7f99d1ac8000 ---p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac8000-7f99d1ac9000 r--p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac9000-7f99d1aca000 rw-p 0006f000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1aca000-7f99d1bff000 r-xp 00000000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1bff000-7f99d1dff000 ---p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1dff000-7f99d1e00000 r--p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e00000-7f99d1e04000 rw-p 00136000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e04000-7f99d1e15000 r-xp 00000000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d1e15000-7f99d2014000 ---p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2014000-7f99d2015000 r--p 00010000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2015000-7f99d2016000 rw-p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2016000-7f99d201f000 r-xp 00000000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d201f000-7f99d221e000 ---p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221e000-7f99d221f000 r--p 00008000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221f000-7f99d2220000 rw-p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d2220000-7f99d2236000 r-xp 00000000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2236000-7f99d2435000 ---p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2435000-7f99d2436000 r--p 00015000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2436000-7f99d2437000 rw-p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2437000-7f99d243a000 rw-p 00000000 00:00 0 
7f99d243a000-7f99d2441000 r-xp 00000000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2441000-7f99d2640000 ---p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2640000-7f99d2641000 r--p 00006000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2641000-7f99d2642000 rw-p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2642000-7f99d2751000 r-xp 00000000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2751000-7f99d2950000 ---p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2950000-7f99d2951000 r--p 0010e000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2951000-7f99d2952000 rw-p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2952000-7f99d2953000 rw-p 00000000 00:00 0 
7f99d2953000-7f99d2954000 r-xp 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2954000-7f99d2b53000 ---p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b53000-7f99d2b54000 r--p 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b54000-7f99d2b55000 rw-p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b55000-7f99d2e4e000 r-xp 00000000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d2e4e000-7f99d304e000 ---p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d304e000-7f99d3051000 rw-p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3051000-7f99d3058000 rw-p 00000000 00:00 0 
7f99d3058000-7f99d3059000 rw-p 0032c000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3059000-7f99d3073000 r-xp 00000000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3073000-7f99d3273000 ---p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3273000-7f99d3275000 rw-p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3275000-7f99d3277000 rw-p 0001d000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3277000-7f99d328d000 r-xp 00000000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d328d000-7f99d348c000 ---p 00016000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348c000-7f99d348d000 rw-p 00015000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348d000-7f99d35ff000 r-xp 00000000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d35ff000-7f99d37ff000 ---p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d37ff000-7f99d3809000 r--p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d3809000-7f99d380b000 rw-p 0017c000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d380b000-7f99d380f000 rw-p 00000000 00:00 0 
7f99d380f000-7f99d3b0b000 r-xp 00000000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b0b000-7f99d3b1b000 ---p 002fc000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b1b000-7f99d3b47000 rw-p 0030c000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b47000-7f99d3d0a000 ---p 00338000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d0a000-7f99d3d1a000 rw-p 002fb000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d1a000-7f99d3d1b000 rw-p 00000000 00:00 0 
7f99d3d1b000-7f99d4823000 r-xp 00000000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4823000-7f99d4a23000 ---p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a23000-7f99d4a7c000 rw-p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a7c000-7f99d4a7e000 rw-p 00000000 00:00 0 
7f99d4a7e000-7f99d4bac000 rw-p 00b61000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4bac000-7f99d57cb000 r-xp 00000000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d57cb000-7f99d59cb000 ---p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d59cb000-7f99d5a2a000 rw-p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d5a2a000-7f99d6208000 rw-p 00000000 00:00 0 
7f99d6208000-7f99d6218000 rw-p 00c7f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d6218000-7f99d7c28000 r-xp 00000000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7c28000-7f99d7e28000 ---p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7e28000-7f99d7ec1000 rw-p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7ec1000-7f99d7f7f000 rw-p 00000000 00:00 0 
7f99d7f7f000-7f99d8000000 rw-p 01aaa000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d8000000-7f99d8021000 rw-p 00000000 00:00 0 
7f99d8021000-7f99dc000000 ---p 00000000 00:00 0 
7f99dc000000-7f99dc021000 rw-p 00000000 00:00 0 
7f99dc021000-7f99e0000000 ---p 00000000 00:00 0 
7f99e0000000-7f99e0021000 rw-p 00000000 00:00 0 
7f99e0021000-7f99e4000000 ---p 00000000 00:00 0 
7f99e414c000-7f99e4153000 r-xp 00000000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4153000-7f99e4352000 ---p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4352000-7f99e4353000 r--p 00006000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4353000-7f99e4354000 rw-p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4354000-7f99e4378000 r-xp 00000000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4378000-7f99e4578000 ---p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4578000-7f99e4581000 rw-p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4581000-7f99e4601000 r-xp 00000000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4601000-7f99e4800000 ---p 00080000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4800000-7f99e4802000 rw-p 0007f000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4802000-7f99e480a000 rw-p 00000000 00:00 0 
7f99e480a000-7f99e480c000 rw-p 00082000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e480c000-7f99e4869000 r-xp 00000000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4869000-7f99e4a69000 ---p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a69000-7f99e4a74000 rw-p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a74000-7f99e4a83000 rw-p 00000000 00:00 0 
7f99e4a83000-7f99e4a87000 rw-p 00069000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a87000-7f99e4ca4000 r-xp 00000000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ca4000-7f99e4ea4000 ---p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ea4000-7f99e4ee4000 rw-p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ee4000-7f99e4ef8000 r-xp 00000000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e4ef8000-7f99e50f7000 ---p 00014000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f7000-7f99e50f8000 rw-p 00013000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f8000-7f99e50f9000 rw-p 00015000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f9000-7f99e50fa000 ---p 00000000 00:00 0 
7f99e50fa000-7f99e58fa000 rw-p 00000000 00:00 0 
7f99e58fa000-7f99e58fb000 ---p 00000000 00:00 0 
7f99e58fb000-7f99e60fb000 rw-p 00000000 00:00 0 
7f99e60fb000-7f99e60fc000 ---p 00000000 00:00 0 
7f99e60fc000-7f99e68fc000 rw-p 00000000 00:00 0 
7f99e68fc000-7f99e6900000 r-xp 00000000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6900000-7f99e6aff000 ---p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6aff000-7f99e6b00000 r--p 00003000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b00000-7f99e6b02000 rw-p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b02000-7f99e6b82000 rw-p 00000000 00:00 0 
7f99e6c02000-7f99e6dc2000 rw-p 00000000 00:00 0 
7f99e6dc2000-7f99e6de8000 r-xp 00000000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6de8000-7f99e6fe8000 ---p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fe8000-7f99e6fea000 r--p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fea000-7f99e6feb000 rw-p 00028000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6feb000-7f99e6ffa000 r-xp 00000000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e6ffa000-7f99e71f9000 ---p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71f9000-7f99e71fa000 r--p 0000e000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fa000-7f99e71fc000 rw-p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fc000-7f99e727c000 rw-p 00000000 00:00 0 
7f99e727c000-7f99e73fc000 rw-p 00000000 00:00 0 
7f99e73fc000-7f99e7408000 r-xp 00000000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7408000-7f99e7607000 ---p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7607000-7f99e7608000 r--p 0000b000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7608000-7f99e7609000 rw-p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7609000-7f99e7689000 rw-p 00000000 00:00 0 
7f99e7689000-7f99e76e7000 r-xp 00000000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e76e7000-7f99e78e7000 ---p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78e7000-7f99e78eb000 r--p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78eb000-7f99e78f2000 rw-p 00062000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78f2000-7f99e7907000 r-xp 00000000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7907000-7f99e7b06000 ---p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b06000-7f99e7b07000 r--p 00014000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b07000-7f99e7b0b000 rw-p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b0b000-7f99e7ccb000 rw-p 00000000 00:00 0 
7f99e7ccc000-7f99e7d0c000 rw-p 00000000 00:00 0 
7f99e7d0c000-7f99e7d10000 r-xp 00000000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7d10000-7f99e7f0f000 ---p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f0f000-7f99e7f10000 r--p 00003000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f10000-7f99e7f11000 rw-p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f11000-7f99e8051000 rw-p 00000000 00:00 0 
7f99e8051000-7f99e8102000 r-xp 00000000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8102000-7f99e8301000 ---p 000b1000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8301000-7f99e8326000 rw-p 000b0000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8326000-7f99e8368000 rw-p 00000000 00:00 0 
7f99e8368000-7f99e8371000 r-xp 00000000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8371000-7f99e8571000 ---p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8571000-7f99e8572000 rw-p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8572000-7f99e85f2000 rw-p 00000000 00:00 0 
7f99e85f2000-7f99e85f3000 r-xp 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e85f3000-7f99e87f2000 ---p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f2000-7f99e87f3000 r--p 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f3000-7f99e87f4000 rw-p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f4000-7f99e8874000 rw-p 00000000 00:00 0 
7f99e8874000-7f99e889f000 r-xp 00000000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e889f000-7f99e8a9e000 ---p 0002b000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8a9e000-7f99e8aa0000 rw-p 0002a000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa0000-7f99e8aa3000 rw-p 000d2000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa3000-7f99e8aa7000 r-xp 00000000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8aa7000-7f99e8ca7000 ---p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca7000-7f99e8ca8000 rw-p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca8000-7f99e8caa000 rw-p 00019000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8caa000-7f99e8cea000 rw-p 00000000 00:00 0 
7f99e8cea000-7f99e8d09000 r-xp 00000000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8d09000-7f99e8f08000 ---p 0001f000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f08000-7f99e8f0a000 rw-p 0001e000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f0a000-7f9a0cfca000 rw-p 00000000 00:00 0 
7f9a0cfca000-7f9a0cfd1000 r-xp 00000000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0cfd1000-7f9a0d1d0000 ---p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d0000-7f9a0d1d1000 r--p 00006000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d1000-7f9a0d1d2000 rw-p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d2000-7f9a0d1f0000 r-xp 00000000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d1f0000-7f9a0d3ef000 ---p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3ef000-7f9a0d3f0000 r--p 0001d000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f0000-7f9a0d3f4000 rw-p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f4000-7f9a0d434000 rw-p 00000000 00:00 0 
7f9a0d434000-7f9a0d435000 ---p 00000000 00:00 0 
7f9a0d435000-7f9a0dc35000 rw-p 00000000 00:00 0 
7f9a0de25000-7f9a0e4a8000 rw-p 00000000 00:00 0 
7f9a0e4a8000-7f9a0e4ac000 r-xp 00000000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e4ac000-7f9a0e6ab000 ---p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ab000-7f9a0e6ac000 r--p 00003000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ac000-7f9a0e6ad000 rw-p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ad000-7f9a0e6df000 r-xp 00000000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e6df000-7f9a0e8df000 ---p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8df000-7f9a0e8e0000 rw-p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e0000-7f9a0e8e1000 rw-p 00034000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e1000-7f9a0e970000 r-xp 00000000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0e970000-7f9a0eb70000 ---p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb70000-7f9a0eb74000 rw-p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb74000-7f9a0eb7c000 rw-p 00094000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb7c000-7f9a0ebc3000 r-xp 00000000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0ebc3000-7f9a0edc3000 ---p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc3000-7f9a0edc5000 rw-p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc5000-7f9a0edc7000 rw-p 0004a000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc7000-7f9a0ee18000 r-xp 00000000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0ee18000-7f9a0f018000 ---p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f018000-7f9a0f019000 rw-p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f019000-7f9a0f01b000 rw-p 00053000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f01b000-7f9a0f099000 r-xp 00000000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f099000-7f9a0f299000 ---p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f299000-7f9a0f2af000 rw-p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f2af000-7f9a0f2b5000 r-xp 00000000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f2b5000-7f9a0f4b4000 ---p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b4000-7f9a0f4b5000 r--p 00005000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b5000-7f9a0f4b6000 rw-p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b6000-7f9a0f4b8000 r-xp 00000000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f4b8000-7f9a0f6b8000 ---p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b8000-7f9a0f6b9000 r--p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b9000-7f9a0f6ba000 rw-p 00003000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6ba000-7f9a0f759000 r-xp 00000000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f759000-7f9a0f959000 ---p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f959000-7f9a0f961000 r--p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f961000-7f9a0f962000 rw-p 000a7000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f962000-7f9a0fa06000 r-xp 00000000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fa06000-7f9a0fc05000 ---p 000a4000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc05000-7f9a0fc0b000 r--p 000a3000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0b000-7f9a0fc0c000 rw-p 000a9000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0c000-7f9a0fc1b000 r-xp 00000000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fc1b000-7f9a0fe1a000 ---p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1a000-7f9a0fe1b000 r--p 0000e000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1b000-7f9a0fe1c000 rw-p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1c000-7f9a0ff3f000 r-xp 00000000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a0ff3f000-7f9a1013e000 ---p 00123000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1013e000-7f9a10149000 r--p 00122000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a10149000-7f9a1014b000 rw-p 0012d000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1014b000-7f9a1014c000 rw-p 00000000 00:00 0 
7f9a1014c000-7f9a10193000 r-xp 00000000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10193000-7f9a10392000 ---p 00047000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10392000-7f9a10394000 r--p 00046000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10394000-7f9a10395000 rw-p 00048000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10395000-7f9a103df000 r-xp 00000000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a103df000-7f9a105df000 ---p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105df000-7f9a105e2000 r--p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e2000-7f9a105e3000 rw-p 0004d000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e3000-7f9a1062d000 r-xp 00000000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1062d000-7f9a1082d000 ---p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082d000-7f9a1082e000 r--p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082e000-7f9a1082f000 rw-p 0004b000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082f000-7f9a1096e000 rw-p 00000000 00:00 0 
7f9a1096e000-7f9a10989000 r-xp 00000000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10989000-7f9a10b88000 ---p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b88000-7f9a10b89000 r--p 0001a000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b89000-7f9a10b8a000 rw-p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b8a000-7f9a10bd2000 r-xp 00000000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10bd2000-7f9a10dd1000 ---p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd1000-7f9a10dd2000 r--p 00047000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd2000-7f9a10dd3000 rw-p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd3000-7f9a10ded000 r-xp 00000000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10ded000-7f9a10fec000 ---p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fec000-7f9a10fed000 r--p 00019000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fed000-7f9a10fee000 rw-p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fee000-7f9a10ffb000 r-xp 00000000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a10ffb000-7f9a111fa000 ---p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fa000-7f9a111fb000 r--p 0000c000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fb000-7f9a111fc000 rw-p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fc000-7f9a11241000 r-xp 00000000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11241000-7f9a11441000 ---p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11441000-7f9a11442000 r--p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11442000-7f9a11443000 rw-p 00046000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11443000-7f9a11471000 rw-p 00000000 00:00 0 
7f9a11471000-7f9a11493000 r-xp 00000000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11493000-7f9a11692000 ---p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11692000-7f9a11693000 r--p 00021000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11693000-7f9a11694000 rw-p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11694000-7f9a116dd000 r-xp 00000000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a116dd000-7f9a118dc000 ---p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dc000-7f9a118dd000 r--p 00048000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dd000-7f9a118de000 rw-p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118de000-7f9a119af000 r-xp 00000000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a119af000-7f9a11baf000 ---p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11baf000-7f9a11bb1000 r--p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb1000-7f9a11bb2000 rw-p 000d3000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb2000-7f9a11bb3000 rw-p 00000000 00:00 0 
7f9a11bb3000-7f9a11bbf000 r-xp 00000000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11bbf000-7f9a11dbe000 ---p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbe000-7f9a11dbf000 r--p 0000b000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbf000-7f9a11dc0000 rw-p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dc0000-7f9a11dc7000 r-xp 00000000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11dc7000-7f9a11fc6000 ---p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc6000-7f9a11fc7000 r--p 00006000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc7000-7f9a11fc8000 rw-p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc8000-7f9a159f9000 r-xp 00000000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a159f9000-7f9a15bf9000 ---p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15bf9000-7f9a15c35000 rw-p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15c35000-7f9a17c45000 rw-p 00000000 00:00 0 
7f9a17dd4000-7f9a17deb000 r-xp 00000000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17deb000-7f9a17feb000 ---p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17feb000-7f9a17fec000 r--p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fec000-7f9a17fed000 rw-p 00018000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fed000-7f9a18006000 r-xp 00000000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18006000-7f9a18205000 ---p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18205000-7f9a18206000 r--p 00018000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18206000-7f9a18207000 rw-p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18207000-7f9a18245000 r-xp 00000000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18245000-7f9a18444000 ---p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18444000-7f9a18445000 r--p 0003d000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18445000-7f9a18446000 rw-p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18446000-7f9a3a446000 rw-p 00000000 00:00 0 
7f9a3a550000-7f9a3a56e000 r-xp 00000000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a56e000-7f9a3a76d000 ---p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76d000-7f9a3a76e000 r--p 0001d000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76e000-7f9a3a76f000 rw-p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76f000-7f9a3a773000 rw-p 00000000 00:00 0 
7f9a3a773000-7f9a3a79d000 r-xp 00000000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a79d000-7f9a3a99c000 ---p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99c000-7f9a3a99d000 r--p 00029000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99d000-7f9a3a99e000 rw-p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99e000-7f9a3aa2b000 r-xp 00000000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3aa2b000-7f9a3ac2a000 ---p 0008d000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac2a000-7f9a3ac46000 r--p 0008c000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac46000-7f9a3ac47000 rw-p 000a8000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac47000-7f9a3ec47000 rw-p 00000000 00:00 0 
7f9a3edfb000-7f9a3f01a000 r-xp 00000000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f01a000-7f9a3f219000 ---p 0021f000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f219000-7f9a3f21b000 r--p 0021e000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21b000-7f9a3f21c000 rw-p 00220000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21c000-7f9a3f21f000 rw-p 00000000 00:00 0 
7f9a3f21f000-7f9a3f247000 r-xp 00000000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f247000-7f9a3f446000 ---p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f446000-7f9a3f447000 r--p 00027000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f447000-7f9a3f448000 rw-p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f448000-7f9a41448000 rw-p 00000000 00:00 0 
7f9a4148d000-7f9a414e6000 r-xp 00000000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a414e6000-7f9a416e6000 ---p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e6000-7f9a416e7000 r--p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e7000-7f9a416e9000 rw-p 0005a000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e9000-7f9a41811000 r-xp 00000000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41811000-7f9a41a10000 ---p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a10000-7f9a41a11000 r--p 00127000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a11000-7f9a41a12000 rw-p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a12000-7f9a41a8d000 rw-p 00000000 00:00 0 
7f9a41a8d000-7f9a4249a000 r-xp 00000000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4249a000-7f9a42699000 ---p 00a0d000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a42699000-7f9a4269c000 r--p 00a0c000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269c000-7f9a4269f000 rw-p 00a0f000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269f000-7f9a426ac000 rw-p 00000000 00:00 0 
7f9a426ac000-7f9a4274d000 r-xp 00000000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4274d000-7f9a4294c000 ---p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294c000-7f9a4294d000 r--p 000a0000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294d000-7f9a42957000 rw-p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a42957000-7f9a429c0000 rw-p 00000000 00:00 0 
7f9a429c0000-7f9a42a37000 r-xp 00000000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42a37000-7f9a42c36000 ---p 00077000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c36000-7f9a42c3f000 r--p 00076000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c3f000-7f9a42c4b000 rw-p 0007f000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c4b000-7f9a44c4b000 rw-p 00000000 00:00 0 
7f9a44d20000-7f9a44d3b000 r-xp 00000000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44d3b000-7f9a44f3a000 ---p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3a000-7f9a44f3b000 r--p 0001a000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3b000-7f9a44f3c000 rw-p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3c000-7f9a44f56000 r-xp 00000000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a44f56000-7f9a45156000 ---p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45156000-7f9a45158000 r--p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45158000-7f9a45159000 rw-p 0001c000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45159000-7f9a45162000 r-xp 00000000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45162000-7f9a45361000 ---p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45361000-7f9a45362000 r--p 00008000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45362000-7f9a45367000 rw-p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45367000-7f9a4537e000 r-xp 00000000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4537e000-7f9a4557d000 ---p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557d000-7f9a4557e000 r--p 00016000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557e000-7f9a4557f000 rw-p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557f000-7f9a4558c000 r-xp 00000000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4558c000-7f9a4578c000 ---p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578c000-7f9a4578d000 r--p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578d000-7f9a4578e000 rw-p 0000e000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578e000-7f9a457ac000 r-xp 00000000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a457ac000-7f9a459ac000 ---p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ac000-7f9a459ad000 r--p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ad000-7f9a459ae000 rw-p 0001f000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ae000-7f9a459c6000 r-xp 00000000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a459c6000-7f9a45bc5000 ---p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc5000-7f9a45bc6000 r--p 00017000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc6000-7f9a45bc7000 rw-p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc7000-7f9a45c34000 r-xp 00000000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45c34000-7f9a45e34000 ---p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e34000-7f9a45e35000 r--p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e35000-7f9a45e36000 rw-p 0006e000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e36000-7f9a45e38000 r-xp 00000000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a45e38000-7f9a46037000 ---p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46037000-7f9a46038000 r--p 00001000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46038000-7f9a46039000 rw-p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46039000-7f9a46042000 r-xp 00000000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46042000-7f9a46241000 ---p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46241000-7f9a46242000 r--p 00008000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46242000-7f9a46243000 rw-p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46243000-7f9a4624d000 r-xp 00000000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4624d000-7f9a4644c000 ---p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644c000-7f9a4644d000 r--p 00009000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644d000-7f9a4644e000 rw-p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644e000-7f9a4844e000 rw-p 00000000 00:00 0 
7f9a48485000-7f9a48626000 rw-p 00000000 00:00 0 
7f9a48626000-7f9a48635000 r-xp 00000000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48635000-7f9a48834000 ---p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48834000-7f9a48835000 r--p 0000e000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48835000-7f9a48836000 rw-p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48836000-7f9a48838000 r-xp 00000000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48838000-7f9a48a37000 ---p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a37000-7f9a48a38000 r--p 00001000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a38000-7f9a48a39000 rw-p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a39000-7f9a48a76000 r-xp 00000000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48a76000-7f9a48c75000 ---p 0003d000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c75000-7f9a48c77000 r--p 0003c000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c77000-7f9a48c7c000 rw-p 0003e000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c7c000-7f9a48cc5000 r-xp 00000000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48cc5000-7f9a48ec5000 ---p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec5000-7f9a48ec7000 r--p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec7000-7f9a48ec8000 rw-p 0004b000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec8000-7f9a48edc000 r-xp 00000000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a48edc000-7f9a490dc000 ---p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dc000-7f9a490dd000 r--p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dd000-7f9a490de000 rw-p 00015000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490de000-7f9a4925e000 r-xp 00000000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4925e000-7f9a4945e000 ---p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4945e000-7f9a49462000 r--p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49462000-7f9a49464000 rw-p 00184000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49464000-7f9a49466000 rw-p 00000000 00:00 0 
7f9a49466000-7f9a49487000 r-xp 00000000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49487000-7f9a49686000 ---p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49686000-7f9a49687000 r--p 00020000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49687000-7f9a49688000 rw-p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49688000-7f9a49796000 r-xp 00000000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49796000-7f9a49996000 ---p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49996000-7f9a49999000 r--p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49999000-7f9a4999a000 rw-p 00111000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a4999a000-7f9a4999c000 rw-p 00000000 00:00 0 
7f9a4999c000-7f9a499be000 r-xp 00000000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a499be000-7f9a49bbd000 ---p 00022000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bbd000-7f9a49bc0000 r--p 00021000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc0000-7f9a49bc1000 rw-p 00024000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc1000-7f9a4ba25000 r-xp 00000000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4ba25000-7f9a4bc24000 ---p 01e64000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc24000-7f9a4bc2a000 r--p 01e63000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc2a000-7f9a4bc3c000 rw-p 01e69000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc3c000-7f9a4dc55000 rw-p 00000000 00:00 0 
7f9a4dc7a000-7f9a4ddba000 rw-p 00000000 00:00 0 
7f9a4ddba000-7f9a4ddc6000 r-xp 00000000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4ddc6000-7f9a4dfc5000 ---p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc5000-7f9a4dfc6000 r--p 0000b000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc6000-7f9a4dfc7000 rw-p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc7000-7f9a4dfca000 r-xp 00000000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4dfca000-7f9a4e1c9000 ---p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1c9000-7f9a4e1ca000 r--p 00002000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1ca000-7f9a4e1cb000 rw-p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1cb000-7f9a4e1d0000 r-xp 00000000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e1d0000-7f9a4e3d0000 ---p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d0000-7f9a4e3d1000 r--p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d1000-7f9a4e3d2000 rw-p 00006000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d2000-7f9a4e3ed000 r-xp 00000000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e3ed000-7f9a4e5ec000 ---p 0001b000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ec000-7f9a4e5ef000 r--p 0001a000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ef000-7f9a4e5f0000 rw-p 0001d000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5f0000-7f9a4e5fb000 r-xp 00000000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e5fb000-7f9a4e7fa000 ---p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fa000-7f9a4e7fb000 r--p 0000a000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fb000-7f9a4e7fe000 rw-p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fe000-7f9a4e81f000 r-xp 00000000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4e81f000-7f9a4ea1e000 ---p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1e000-7f9a4ea1f000 r--p 00020000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1f000-7f9a4ea20000 rw-p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea20000-7f9a4ea30000 r-xp 00000000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ea30000-7f9a4ec30000 ---p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec30000-7f9a4ec31000 r--p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec31000-7f9a4ec32000 rw-p 00011000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec32000-7f9a4ec37000 r-xp 00000000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ec37000-7f9a4ee36000 ---p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee36000-7f9a4ee37000 r--p 00004000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee37000-7f9a4ee38000 rw-p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee38000-7f9a4ee3c000 r-xp 00000000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4ee3c000-7f9a4f03b000 ---p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03b000-7f9a4f03c000 r--p 00003000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03c000-7f9a4f03d000 rw-p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03d000-7f9a4f054000 r-xp 00000000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f054000-7f9a4f253000 ---p 00017000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f253000-7f9a4f255000 r--p 00016000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f255000-7f9a4f256000 rw-p 00018000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f256000-7f9a4f257000 r-xp 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f257000-7f9a4f456000 ---p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f456000-7f9a4f457000 r--p 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f457000-7f9a4f458000 rw-p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f458000-7f9a51458000 rw-p 00000000 00:00 0 
7f9a5145f000-7f9a5161f000 rw-p 00000000 00:00 0 
7f9a5161f000-7f9a51624000 r-xp 00000000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51624000-7f9a51823000 ---p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51823000-7f9a51824000 r--p 00004000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51824000-7f9a51825000 rw-p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51825000-7f9a51827000 r-xp 00000000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51827000-7f9a51a26000 ---p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a26000-7f9a51a27000 r--p 00001000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a27000-7f9a51a28000 rw-p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a28000-7f9a51a54000 r-xp 00000000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51a54000-7f9a51c53000 ---p 0002c000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c53000-7f9a51c57000 r--p 0002b000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c57000-7f9a51c58000 rw-p 0002f000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c58000-7f9a57c59000 rw-p 00000000 00:00 0 
7f9a57c8d000-7f9a57e4d000 rw-p 00000000 00:00 0 
7f9a57e4d000-7f9a57e4e000 r-xp 00000000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a57e4e000-7f9a5804e000 ---p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804e000-7f9a5804f000 r--p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804f000-7f9a58050000 rw-p 00002000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a58050000-7f9a58055000 r-xp 00000000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58055000-7f9a58255000 ---p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58255000-7f9a58256000 r--p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58256000-7f9a58257000 rw-p 00006000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58257000-7f9a58259000 r-xp 00000000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58259000-7f9a58458000 ---p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58458000-7f9a58459000 r--p 00001000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58459000-7f9a5845a000 rw-p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a5845a000-7f9a5a45a000 rw-p 00000000 00:00 0 
7f9a5a48d000-7f9a5a5cd000 rw-p 00000000 00:00 0 
7f9a5a5cd000-7f9a5a5cf000 r-xp 00000000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a5cf000-7f9a5a7ce000 ---p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7ce000-7f9a5a7cf000 r--p 00001000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7cf000-7f9a5a7d0000 rw-p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7d0000-7f9a5a80e000 r-xp 00000000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5a80e000-7f9a5aa0d000 ---p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0d000-7f9a5aa0e000 r--p 0003d000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0e000-7f9a5aa0f000 rw-p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0f000-7f9a5aa4c000 r-xp 00000000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5aa4c000-7f9a5ac4b000 ---p 0003d000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac4b000-7f9a5ac56000 rw-p 0003c000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac56000-7f9a5cc5b000 rw-p 00000000 00:00 0 
7f9a5cc5e000-7f9a5cd9e000 rw-p 00000000 00:00 0 
7f9a5cd9e000-7f9a5ce23000 r-xp 00000000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5ce23000-7f9a5d022000 ---p 00085000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d022000-7f9a5d024000 r--p 00084000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d024000-7f9a5d025000 rw-p 00086000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d025000-7f9a5d02d000 rw-p 00000000 00:00 0 
7f9a5d02d000-7f9a5db5e000 r-xp 00000000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5db5e000-7f9a5dd5d000 ---p 00b31000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd5d000-7f9a5dd88000 r--p 00b30000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd88000-7f9a5ddab000 rw-p 00b5b000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5ddab000-7f9a6045e000 rw-p 00000000 00:00 0 
7f9a60471000-7f9a604c7000 r-xp 00000000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a604c7000-7f9a606c6000 ---p 00056000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606c6000-7f9a606cc000 r--p 00055000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cc000-7f9a606cd000 rw-p 0005b000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cd000-7f9a606e0000 rw-p 00000000 00:00 0 
7f9a606e0000-7f9a608b6000 r-xp 00000000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a608b6000-7f9a60ab6000 ---p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60ab6000-7f9a60aca000 r--p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60aca000-7f9a60adf000 rw-p 001ea000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60adf000-7f9a60ae4000 r-xp 00000000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ae4000-7f9a60ce3000 ---p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce3000-7f9a60ce4000 r--p 00004000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce4000-7f9a60ce5000 rw-p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce5000-7f9a60d1a000 r-xp 00000000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60d1a000-7f9a60f19000 ---p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f19000-7f9a60f1a000 r--p 00034000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1a000-7f9a60f1b000 rw-p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1b000-7f9a60f5b000 rw-p 00000000 00:00 0 
7f9a60f5b000-7f9a60fb8000 r-xp 00000000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a60fb8000-7f9a611b7000 ---p 0005d000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b7000-7f9a611b9000 r--p 0005c000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b9000-7f9a611bf000 rw-p 0005e000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611bf000-7f9a611c2000 r-xp 00000000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a611c2000-7f9a613c1000 ---p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c1000-7f9a613c2000 r--p 00002000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c2000-7f9a613c3000 rw-p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c3000-7f9a61415000 r-xp 00000000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61415000-7f9a61614000 ---p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61614000-7f9a61615000 r--p 00051000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61615000-7f9a61616000 rw-p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61616000-7f9a61a54000 r-xp 00000000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61a54000-7f9a61c53000 ---p 0043e000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c53000-7f9a61c5a000 r--p 0043d000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5a000-7f9a61c5e000 rw-p 00444000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5e000-7f9a63c61000 rw-p 00000000 00:00 0 
7f9a63c9f000-7f9a63cdf000 rw-p 00000000 00:00 0 
7f9a63cdf000-7f9a63d8f000 r-xp 00000000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63d8f000-7f9a63f8e000 ---p 000b0000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f8e000-7f9a63f92000 r--p 000af000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f92000-7f9a63f94000 rw-p 000b3000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f94000-7f9a6415e000 r-xp 00000000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6415e000-7f9a6435d000 ---p 001ca000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6435d000-7f9a64360000 r--p 001c9000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64360000-7f9a64461000 rw-p 001cc000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64461000-7f9a66462000 rw-p 00000000 00:00 0 
7f9a6648e000-7f9a6650e000 rw-p 00000000 00:00 0 
7f9a6650e000-7f9a66550000 r-xp 00000000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66550000-7f9a6674f000 ---p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a6674f000-7f9a66750000 r--p 00041000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66750000-7f9a66751000 rw-p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66751000-7f9a6679b000 r-xp 00000000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6679b000-7f9a6699a000 ---p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699a000-7f9a6699b000 r--p 00049000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699b000-7f9a6699f000 rw-p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699f000-7f9a669a6000 rw-p 00000000 00:00 0 
7f9a669a6000-7f9a66a17000 r-xp 00000000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66a17000-7f9a66c17000 ---p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c17000-7f9a66c18000 r--p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c18000-7f9a66c1b000 rw-p 00072000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c1b000-7f9a68045000 r-xp 00000000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68045000-7f9a68244000 ---p 0142a000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68244000-7f9a683ee000 rw-p 01429000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a683ee000-7f9a6a466000 rw-p 00000000 00:00 0 
7f9a6a46c000-7f9a6a5ac000 rw-p 00000000 00:00 0 
7f9a6a5ac000-7f9a6a5d0000 r-xp 00000000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a5d0000-7f9a6a7cf000 ---p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7cf000-7f9a6a7d0000 r--p 00023000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d0000-7f9a6a7d1000 rw-p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d1000-7f9a6a828000 r-xp 00000000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6a828000-7f9a6aa28000 ---p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa28000-7f9a6aa29000 r--p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa29000-7f9a6aa2a000 rw-p 00058000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa2a000-7f9a6aa61000 r-xp 00000000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6aa61000-7f9a6ac61000 ---p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac61000-7f9a6ac62000 r--p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac62000-7f9a6ac64000 rw-p 00038000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac64000-7f9a70c67000 rw-p 00000000 00:00 0 
7f9a70c79000-7f9a70db9000 rw-p 00000000 00:00 0 
7f9a70db9000-7f9a70e29000 r-xp 00000000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a70e29000-7f9a71028000 ---p 00070000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a71028000-7f9a7102b000 r--p 0006f000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102b000-7f9a7102c000 rw-p 00072000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102c000-7f9a7102d000 rw-p 00000000 00:00 0 
7f9a7102d000-7f9a71156000 r-xp 00000000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71156000-7f9a71355000 ---p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71355000-7f9a71356000 r--p 00128000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71356000-7f9a71358000 rw-p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71358000-7f9a71b9a000 r-xp 00000000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71b9a000-7f9a71d99000 ---p 00842000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71d99000-7f9a71eea000 rw-p 00841000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71eea000-7f9a71ef8000 rw-p 00000000 00:00 0 
7f9a71ef8000-7f9a720e8000 r-xp 00000000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a720e8000-7f9a722e7000 ---p 001f0000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722e7000-7f9a722ed000 r--p 001ef000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ed000-7f9a722ee000 rw-p 001f5000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ee000-7f9a72383000 rw-p 00000000 00:00 0 
7f9a72383000-7f9a723d1000 r-xp 00000000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a723d1000-7f9a725d0000 ---p 0004e000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d0000-7f9a725d3000 r--p 0004d000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d3000-7f9a725d4000 rw-p 00050000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d4000-7f9a727f1000 r-xp 00000000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a727f1000-7f9a729f1000 ---p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f1000-7f9a729f5000 r--p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f5000-7f9a729fc000 rw-p 00221000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729fc000-7f9a729fe000 rw-p 00000000 00:00 0 
7f9a729fe000-7f9a72a67000 r-xp 00000000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72a67000-7f9a72c66000 ---p 00069000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c66000-7f9a72c6a000 rw-p 00068000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c6a000-7f9a72c6b000 rw-p 00000000 00:00 0 
7f9a72c6b000-7f9a72d5b000 r-xp 00000000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72d5b000-7f9a72f5a000 ---p 000f0000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5a000-7f9a72f5c000 rw-p 000ef000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5c000-7f9a72f5d000 rw-p 00000000 00:00 0 
7f9a72f5d000-7f9a72f65000 rw-p 000f2000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f65000-7f9a74a65000 r-xp 00000000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74a65000-7f9a74c65000 ---p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c65000-7f9a74c7e000 rw-p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c7e000-7f9a74c89000 rw-p 00000000 00:00 0 
7f9a74c89000-7f9a74d01000 rw-p 01beb000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74d01000-7f9a75088000 r-xp 00000000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75088000-7f9a75287000 ---p 00387000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75287000-7f9a752a6000 rw-p 00386000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752a6000-7f9a752c7000 rw-p 00000000 00:00 0 
7f9a752c7000-7f9a752ce000 rw-p 012b0000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752ce000-7f9a7534e000 rw-p 00000000 00:00 0 
7f9a7534e000-7f9a75569000 r-xp 00000000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75569000-7f9a75768000 ---p 0021b000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75768000-7f9a75784000 r--p 0021a000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75784000-7f9a75790000 rw-p 00236000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75790000-7f9a75793000 rw-p 00000000 00:00 0 
7f9a75793000-7f9a75799000 r-xp 00000000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75799000-7f9a75998000 ---p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75998000-7f9a75999000 r--p 00005000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75999000-7f9a7599a000 rw-p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a7599b000-7f9a75b1b000 rw-p 00000000 00:00 0 
7f9a75b1b000-7f9a75c23000 r-xp 00000000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75c23000-7f9a75e22000 ---p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e22000-7f9a75e23000 r--p 00107000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e23000-7f9a75e24000 rw-p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e24000-7f9a75e3d000 r-xp 00000000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a75e3d000-7f9a7603c000 ---p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603c000-7f9a7603d000 r--p 00018000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603d000-7f9a7603e000 rw-p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603e000-7f9a76040000 r-xp 00000000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76040000-7f9a7623f000 ---p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a7623f000-7f9a76240000 r--p 00001000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76240000-7f9a76241000 rw-p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76241000-7f9a76244000 r-xp 00000000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76244000-7f9a76443000 ---p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76443000-7f9a76444000 r--p 00002000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76444000-7f9a76445000 rw-p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76445000-7f9a76605000 r-xp 00000000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76605000-7f9a76805000 ---p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76805000-7f9a76809000 r--p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76809000-7f9a7680b000 rw-p 001c4000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a7680b000-7f9a7680f000 rw-p 00000000 00:00 0 
7f9a7680f000-7f9a76827000 r-xp 00000000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76827000-7f9a76a26000 ---p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a26000-7f9a76a27000 r--p 00017000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a27000-7f9a76a28000 rw-p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a28000-7f9a76a2c000 rw-p 00000000 00:00 0 
7f9a76a2c000-7f9a76a52000 r-xp 00000000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76a8a000-7f9a76a8b000 rw-p 00000000 00:00 0 
7f9a76a8b000-7f9a76a8c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8c000-7f9a76a8d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76a8d000-7f9a76a8e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8e000-7f9a76b4e000 rw-p 00000000 00:00 0 
7f9a76b4e000-7f9a76b4f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b4f000-7f9a76b50000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b50000-7f9a76b51000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b51000-7f9a76b52000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b52000-7f9a76b70000 r-xp 00000000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b70000-7f9a76b71000 r--p 0001d000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b71000-7f9a76b72000 rw-p 0001e000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b72000-7f9a76b73000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b73000-7f9a76b74000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b74000-7f9a76b75000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b75000-7f9a76b76000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b76000-7f9a76b77000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b77000-7f9a76b78000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b78000-7f9a76b79000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b79000-7f9a76b7a000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7a000-7f9a76b7b000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7b000-7f9a76b7c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7c000-7f9a76b7d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7d000-7f9a76b7e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7e000-7f9a76b7f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7f000-7f9a76c44000 rw-p 00000000 00:00 0 
7f9a76c44000-7f9a76c45000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c45000-7f9a76c46000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c46000-7f9a76c47000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c47000-7f9a76c48000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c48000-7f9a76c49000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c49000-7f9a76c4a000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4a000-7f9a76c4b000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4b000-7f9a76c4c000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4c000-7f9a76c4d000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4d000-7f9a76c4e000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4e000-7f9a76c4f000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4f000-7f9a76c50000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c50000-7f9a76c51000 rwxp 00000000 00:00 0 
7f9a76c51000-7f9a76c52000 r--p 00025000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c52000-7f9a76c53000 rw-p 00026000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c53000-7f9a76c54000 rw-p 00000000 00:00 0 
7fff2cb1b000-7fff2cb3c000 rw-p 00000000 00:00 0                          [stack]
7fff2cb80000-7fff2cb83000 r--p 00000000 00:00 0                          [vvar]
7fff2cb83000-7fff2cb85000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
bash: line 1: 56358 Aborted                 (core dumped) env ""JETBRAINS_REMOTE_RUN""=""1"" ""LIBRARY_ROOTS""=""C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1227070294;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/graphviz-0.8.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-554785109;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/370154233;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-518999124;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/idna-2.6-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/chardet-3.0.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201544331;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/724150857;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-154863933;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1227933812;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-125940560;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/2085782652;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201545290;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452379848;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1405239563;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1171821208;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/530511828;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/427714987;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-541471831;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1437370484;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/17574554;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-669732926;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452463671;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/662605150;C:/Users/chenhuizhen/.PyCharm2018.3/system/python_stubs/823358608;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/python-skeletons;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2and3;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2and3"" ""PYDEVD_LOAD_VALUES_ASYNC""=""True"" ""PYTHONPATH""=""/opt/kd-pavement-crackseg:/root/.pycharm_helpers/pycharm_matplotlib_backend:/root/.pycharm_helpers/third_party/thriftpy:/root/.pycharm_helpers/pydev:C:/Users/chenhuizhen/.PyCharm2018.3/system/cythonExtensions:/opt/kd-pavement-crackseg"" ""PYTHONIOENCODING""=""UTF-8"" ""PYTHONDONTWRITEBYTECODE""=""1"" ""IPYTHONENABLE""=""True"" ""PYCHARM_MATPLOTLIB_PORT""=""64619"" ""PYCHARM_HOSTED""=""1"" ""PYTHONUNBUFFERED""=""1"" ""IDE_PROJECT_ROOTS""=""/opt/kd-pavement-crackseg"" '/usr/bin/python' '-u' '/root/.pycharm_helpers/pydev/pydevd.py' '--multiproc' '--qt-support=auto' '--client' '0.0.0.0' '--port' '44975' '--file' '/opt/kd-pavement-crackseg/main_crack_segmentation.py'

Process finished with exit code 134
",0,"When I use different size inference, self.reshape()  Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0","When I use different size inference, self.reshape()  Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0 NFO: 56358:  2019-10-28 08:26:33: main_crack_segmentation.py:382 * segmentation crack...
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/module/base_module.py:66: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
  warnings.warn(msg)
*** Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9a764bc7e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9a764c537a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9a764c953c]
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so(MXExecutorReshape+0x1de7)[0x7f99c3a2d5e7]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c)[0x7f9a0cfcfe40]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb)[0x7f9a0cfcf8ab]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f)[0x7f9a0d1df3df]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82)[0x7f9a0d1e3d82]
/usr/bin/python(PyEval_EvalFrameEx+0x578d)[0x4c166d]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4d57a3]
/usr/bin/python(PyObject_Call+0x3e)[0x4a587e]
/usr/bin/python(PyEval_EvalFrameEx+0x263e)[0x4be51e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python[0x54aae7]
/usr/bin/python(PyEval_EvalFrameEx+0x5f3e)[0x4c1e1e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python(PyRun_SimpleFileExFlags+0x186)[0x4e41a6]
/usr/bin/python(Py_Main+0x54e)[0x4938ce]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f9a76465830]
/usr/bin/python(_start+0x29)[0x493299]
======= Memory map: ========
00400000-006de000 r-xp 00000000 08:21 62529595                           /usr/bin/python2.7
008dd000-008de000 r--p 002dd000 08:21 62529595                           /usr/bin/python2.7
008de000-00955000 rw-p 002de000 08:21 62529595                           /usr/bin/python2.7
00955000-00978000 rw-p 00000000 00:00 0 
00fae000-2d86a000 rw-p 00000000 00:00 0                                  [heap]
200000000-200200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200200000-200400000 ---p 00000000 00:00 0 
200400000-200404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200404000-200600000 ---p 00000000 00:00 0 
200600000-200a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200a00000-201800000 ---p 00000000 00:00 0 
201800000-201804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201804000-201a00000 ---p 00000000 00:00 0 
201a00000-201e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201e00000-202c00000 ---p 00000000 00:00 0 
202c00000-202c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
202c04000-202e00000 ---p 00000000 00:00 0 
202e00000-203200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
203200000-204000000 ---p 00000000 00:00 0 
204000000-204004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204004000-204200000 ---p 00000000 00:00 0 
204200000-204600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204600000-205400000 ---p 00000000 00:00 0 
205400000-205404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205404000-205600000 ---p 00000000 00:00 0 
205600000-205a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205a00000-206800000 ---p 00000000 00:00 0 
206800000-206804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206804000-206a00000 ---p 00000000 00:00 0 
206a00000-206e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206e00000-207c00000 ---p 00000000 00:00 0 
207c00000-207c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
207c04000-207e00000 ---p 00000000 00:00 0 
207e00000-208200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
208200000-209000000 ---p 00000000 00:00 0 
209000000-209004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209004000-209200000 ---p 00000000 00:00 0 
209200000-209600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209600000-20a400000 ---p 00000000 00:00 0 
20a400000-20a404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20a404000-20a600000 ---p 00000000 00:00 0 
20a600000-20aa00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa00000-20aa04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa04000-20ac00000 ---p 00000000 00:00 0 
20ac00000-20b000000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b000000-20b004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b004000-20b200000 ---p 00000000 00:00 0 
20b200000-20b600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b600000-20b604000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b604000-20b800000 ---p 00000000 00:00 0 
20b800000-20bc00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc00000-20bc04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc04000-20be00000 ---p 00000000 00:00 0 
20be00000-20c200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c200000-20c204000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c204000-20c400000 ---p 00000000 00:00 0 
20c400000-20c800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c800000-20c804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c804000-20ca00000 ---p 00000000 00:00 0 
20ca00000-20ce00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce00000-20ce04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce04000-20d000000 ---p 00000000 00:00 0 
20d000000-20d400000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d400000-20d600000 ---p 00000000 00:00 0 
20d600000-20d800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d800000-c00200000 ---p 00000000 00:00 0 
10000000000-10b04000000 ---p 00000000 00:00 0 
7f9823829000-7f9834000000 rw-p 00000000 00:00 0 
7f9834000000-7f9834022000 rw-p 00000000 00:00 0 
7f9834022000-7f9838000000 ---p 00000000 00:00 0 
7f9838000000-7f983a08a000 rw-p 00000000 00:00 0 
7f983a08a000-7f983c000000 ---p 00000000 00:00 0 
7f983c000000-7f983c022000 rw-p 00000000 00:00 0 
7f983c022000-7f9840000000 ---p 00000000 00:00 0 
7f9842807000-7f9849009000 rw-p 00000000 00:00 0 
7f984d7fe000-7f9854000000 rw-p 00000000 00:00 0 
7f9854000000-7f98569b9000 rw-p 00000000 00:00 0 
7f98569b9000-7f9858000000 ---p 00000000 00:00 0 
7f985c000000-7f985db22000 rw-p 00000000 00:00 0 
7f985db22000-7f9860000000 ---p 00000000 00:00 0 
7f9864000000-7f9866f05000 rw-p 00000000 00:00 0 
7f9866f05000-7f9868000000 ---p 00000000 00:00 0 
7f9868000000-7f986be05000 rw-p 00000000 00:00 0 
7f986be05000-7f986c000000 ---p 00000000 00:00 0 
7f986c000000-7f986ff25000 rw-p 00000000 00:00 0 
7f986ff25000-7f9870000000 ---p 00000000 00:00 0 
7f9870200000-7f9870800000 ---p 00000000 00:00 0 
7f98709fd000-7f98709fe000 ---p 00000000 00:00 0 
7f98709fe000-7f98711fe000 rw-p 00000000 00:00 0 
7f98711fe000-7f98711ff000 ---p 00000000 00:00 0 
7f98711ff000-7f98719ff000 rw-p 00000000 00:00 0 
7f98721fd000-7f98721fe000 ---p 00000000 00:00 0 
7f98721fe000-7f98729fe000 rw-p 00000000 00:00 0 
7f98729fe000-7f98729ff000 ---p 00000000 00:00 0 
7f98729ff000-7f98731ff000 rw-p 00000000 00:00 0 
7f98731ff000-7f9873200000 ---p 00000000 00:00 0 
7f9873200000-7f9873a00000 rw-p 00000000 00:00 0 
7f9873a00000-7f9874000000 ---p 00000000 00:00 0 
7f9874000000-7f9877da7000 rw-p 00000000 00:00 0 
7f9877da7000-7f9878000000 ---p 00000000 00:00 0 
7f9878200000-7f9878400000 ---p 00000000 00:00 0 
7f98785ff000-7f9878600000 ---p 00000000 00:00 0 
7f9878600000-7f9878e00000 rw-p 00000000 00:00 0 
7f9878e00000-7f9894000000 ---p 00000000 00:00 0 
7f9894000000-7f9898091000 rw-p 00000000 00:00 0 
7f9898091000-7f989c000000 ---p 00000000 00:00 0 
7f989c000000-7f989ffff000 rw-p 00000000 00:00 0 
7f989ffff000-7f98a0000000 ---p 00000000 00:00 0 
7f98a0000000-7f98a3f49000 rw-p 00000000 00:00 0 
7f98a3f49000-7f98a4000000 ---p 00000000 00:00 0 
7f98a4000000-7f98a7fce000 rw-p 00000000 00:00 0 
7f98a7fce000-7f98a8000000 ---p 00000000 00:00 0 
7f98a8000000-7f98abfee000 rw-p 00000000 00:00 0 
7f98abfee000-7f98ac000000 ---p 00000000 00:00 0 
7f98ac000000-7f98aff87000 rw-p 00000000 00:00 0 
7f98aff87000-7f98b0000000 ---p 00000000 00:00 0 
7f98b0000000-7f98b4000000 rw-p 00000000 00:00 0 
7f98b4000000-7f98b7efc000 rw-p 00000000 00:00 0 
7f98b7efc000-7f98b8000000 ---p 00000000 00:00 0 
7f98b8000000-7f98bc000000 rw-p 00000000 00:00 0 
7f98bc000000-7f98bd0a3000 rw-p 00000000 00:00 0 
7f98bd0a3000-7f98c0000000 ---p 00000000 00:00 0 
7f98c0000000-7f98c4000000 rw-p 00000000 00:00 0 
7f98c4000000-7f98c7ffe000 rw-p 00000000 00:00 0 
7f98c7ffe000-7f98c8000000 ---p 00000000 00:00 0 
7f98c8000000-7f98cbffd000 rw-p 00000000 00:00 0 
7f98cbffd000-7f98cc000000 ---p 00000000 00:00 0 
7f98cc000000-7f98d0000000 rw-p 00000000 00:00 0 
7f98d0000000-7f98d8000000 ---p 00000000 00:00 0 
7f98d8000000-7f98d8021000 rw-p 00000000 00:00 0 
7f98d8021000-7f98dc000000 ---p 00000000 00:00 0 
7f98dc200000-7f98e0000000 ---p 00000000 00:00 0 
7f98e0000000-7f98e0021000 rw-p 00000000 00:00 0 
7f98e0021000-7f98e4000000 ---p 00000000 00:00 0 
7f98e4200000-7f98e4e00000 ---p 00000000 00:00 0 
7f98e4ffe000-7f98eaffe000 ---p 00000000 00:00 0 
7f98eaffe000-7f98f4000000 rw-p 00000000 00:00 0 
7f98f4000000-7f98f4022000 rw-p 00000000 00:00 0 
7f98f4022000-7f98f8000000 ---p 00000000 00:00 0 
7f98f8000000-7f98f8022000 rw-p 00000000 00:00 0 
7f98f8022000-7f98fc000000 ---p 00000000 00:00 0 
7f98fc000000-7f98fc022000 rw-p 00000000 00:00 0 
7f98fc022000-7f9900000000 ---p 00000000 00:00 0 
7f9900200000-7f9900800000 ---p 00000000 00:00 0 
7f99009fc000-7f9904000000 rw-p 00000000 00:00 0 
7f9904000000-7f9904022000 rw-p 00000000 00:00 0 
7f9904022000-7f9908000000 ---p 00000000 00:00 0 
7f9908248000-7f9909d4b000 rw-p 00000000 00:00 0 
7f9909d4b000-7f9909d54000 r-xp 00000000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909d54000-7f9909f53000 ---p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f53000-7f9909f54000 r--p 00008000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f54000-7f9909f56000 rw-p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f56000-7f9909f57000 ---p 00000000 00:00 0 
7f9909f57000-7f990a757000 rw-p 00000000 00:00 0 
7f990a757000-7f990a767000 r-xp 00000000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a767000-7f990a966000 ---p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a966000-7f990a967000 r--p 0000f000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a967000-7f990a96a000 rw-p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a96a000-7f990a97b000 r-xp 00000000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990a97b000-7f990ab7a000 ---p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7a000-7f990ab7b000 r--p 00010000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7b000-7f990ab7e000 rw-p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7e000-7f990ab7f000 rw-p 00000000 00:00 0 
7f990ab7f000-7f990ab83000 r-xp 00000000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ab83000-7f990ad82000 ---p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad82000-7f990ad83000 r--p 00003000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad83000-7f990ad84000 rw-p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad84000-7f990ad8f000 r-xp 00000000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990ad8f000-7f990af8e000 ---p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8e000-7f990af8f000 r--p 0000a000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8f000-7f990af91000 rw-p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af91000-7f990afa7000 r-xp 00000000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990afa7000-7f990b1a6000 ---p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a6000-7f990b1a7000 r--p 00015000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a7000-7f990b1aa000 rw-p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1aa000-7f990b1bf000 r-xp 00000000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b1bf000-7f990b3be000 ---p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3be000-7f990b3bf000 r--p 00014000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3bf000-7f990b3c2000 rw-p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3c2000-7f990b3c3000 rw-p 00000000 00:00 0 
7f990b3c3000-7f990b3d0000 r-xp 00000000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b3d0000-7f990b5cf000 ---p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5cf000-7f990b5d0000 r--p 0000c000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d0000-7f990b5d2000 rw-p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d2000-7f990b5e6000 r-xp 00000000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b5e6000-7f990b7e5000 ---p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e5000-7f990b7e6000 r--p 00013000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e6000-7f990b7e9000 rw-p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e9000-7f990b7f0000 r-xp 00000000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b7f0000-7f990b9ef000 ---p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9ef000-7f990b9f0000 r--p 00006000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f0000-7f990b9f1000 rw-p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f1000-7f990b9fc000 r-xp 00000000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990b9fc000-7f990bbfb000 ---p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfb000-7f990bbfc000 r--p 0000a000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfc000-7f990bbfd000 rw-p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfd000-7f990bc25000 r-xp 00000000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990bc25000-7f990be25000 ---p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be25000-7f990be26000 r--p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be26000-7f990be2e000 rw-p 00029000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be2e000-7f990be2f000 rw-p 00000000 00:00 0 
7f990be2f000-7f990be43000 r-xp 00000000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990be43000-7f990c042000 ---p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c042000-7f990c043000 r--p 00013000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c043000-7f990c046000 rw-p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c046000-7f990c047000 rw-p 00000000 00:00 0 
7f990c047000-7f990c05c000 r-xp 00000000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c05c000-7f990c25c000 ---p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25c000-7f990c25d000 r--p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25d000-7f990c260000 rw-p 00016000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c260000-7f990c267000 r-xp 00000000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c267000-7f990c466000 ---p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c466000-7f990c467000 r--p 00006000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c467000-7f990c468000 rw-p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c468000-7f990c469000 rw-p 00000000 00:00 0 
7f990c469000-7f990c47a000 r-xp 00000000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c47a000-7f990c679000 ---p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c679000-7f990c67a000 r--p 00010000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67a000-7f990c67c000 rw-p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67c000-7f990c67d000 rw-p 00000000 00:00 0 
7f990c67d000-7f990c686000 r-xp 00000000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c686000-7f990c885000 ---p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c885000-7f990c886000 r--p 00008000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c886000-7f990c887000 rw-p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c887000-7f990c8cb000 r-xp 00000000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990c8cb000-7f990caca000 ---p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990caca000-7f990cacb000 r--p 00043000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cacb000-7f990cad5000 rw-p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cad5000-7f990caf3000 r-xp 00000000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990caf3000-7f990ccf2000 ---p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf2000-7f990ccf3000 r--p 0001d000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf3000-7f990ccf4000 rw-p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf4000-7f990ccf5000 rw-p 00000000 00:00 0 
7f990ccf5000-7f990cd1c000 r-xp 00000000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cd1c000-7f990cf1c000 ---p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1c000-7f990cf1d000 r--p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1d000-7f990cf1f000 rw-p 00028000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1f000-7f990cf35000 r-xp 00000000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990cf35000-7f990d134000 ---p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d134000-7f990d135000 r--p 00015000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d135000-7f990d138000 rw-p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d138000-7f990d142000 r-xp 00000000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d142000-7f990d341000 ---p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d341000-7f990d342000 r--p 00009000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d342000-7f990d344000 rw-p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d344000-7f990d351000 r-xp 00000000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d351000-7f990d550000 ---p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d550000-7f990d551000 r--p 0000c000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d551000-7f990d552000 rw-p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d552000-7f990d559000 r-xp 00000000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d559000-7f990d758000 ---p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d758000-7f990d759000 r--p 00006000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d759000-7f990d75a000 rw-p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d75a000-7f990d75c000 r-xp 00000000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d75c000-7f990d95b000 ---p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95b000-7f990d95c000 r--p 00001000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95c000-7f990d95d000 rw-p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95d000-7f990dbf1000 r-xp 00000000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990dbf1000-7f990ddf0000 ---p 00294000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf0000-7f990ddf5000 r--p 00293000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf5000-7f990ddfa000 rw-p 00298000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddfa000-7f990ddfb000 rw-p 00000000 00:00 0 
7f990ddfb000-7f990de03000 r-xp 00000000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990de03000-7f990e002000 ---p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e002000-7f990e003000 r--p 00007000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e003000-7f990e004000 rw-p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e004000-7f993a004000 rw-p 00000000 00:00 0 
7f993a004000-7f993a005000 ---p 00000000 00:00 0 
7f993a005000-7f993a805000 rw-p 00000000 00:00 0 
7f993a805000-7f993a806000 ---p 00000000 00:00 0 
7f993a806000-7f993b006000 rw-p 00000000 00:00 0 
7f993b006000-7f993b007000 ---p 00000000 00:00 0 
7f993b007000-7f993b807000 rw-p 00000000 00:00 0 
7f993b807000-7f993b808000 ---p 00000000 00:00 0 
7f993b808000-7f993c008000 rw-p 00000000 00:00 0 
7f993c400000-7f993c600000 ---p 00000000 00:00 0 
7f993c60a000-7f993f80b000 rw-p 00000000 00:00 0 
7f993fc00000-7f993fe00000 ---p 00000000 00:00 0 
7f993fe00000-7f9940000000 rw-s 00000000 00:05 206094999                  /dev/zero (deleted)
7f994000c000-7f994200c000 rw-p 00000000 00:00 0 
7f9942400000-7f9942600000 ---p 00000000 00:00 0 
7f994260d000-7f994580f000 rw-p 00000000 00:00 0 
7f9945c00000-7f9946000000 ---p 00000000 00:00 0 
7f9946010000-7f9948010000 rw-p 00000000 00:00 0 
7f9948216000-7f994f81b000 rw-p 00000000 00:00 0 
7f994fc00000-7f994fe00000 rw-s 00000000 00:05 206094998                  /dev/zero (deleted)
7f994fe00000-7f9950000000 ---p 00000000 00:00 0 
7f995001c000-7f995601c000 rw-p 00000000 00:00 0 
7f995601c000-7f995601d000 ---p 00000000 00:00 0 
7f995601d000-7f995881d000 rw-p 00000000 00:00 0 
7f995881d000-7f995881e000 ---p 00000000 00:00 0 
7f995881e000-7f995f01e000 rw-p 00000000 00:00 0 
7f995f400000-7f995f600000 ---p 00000000 00:00 0 
7f995f71f000-7f9962020000 rw-p 00000000 00:00 0 
7f9962400000-7f9962800000 ---p 00000000 00:00 0 
7f9962821000-7f9964821000 rw-p 00000000 00:00 0 
7f9964c00000-7f9965000000 ---p 00000000 00:00 0 
7f9965022000-7f9967022000 rw-p 00000000 00:00 0 
7f9967400000-7f9967800000 ---p 00000000 00:00 0 
7f9967823000-7f9969823000 rw-p 00000000 00:00 0 
7f9969c00000-7f9969ed6000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9969ed6000-7f996a000000 ---p 00000000 00:00 0 
7f996a024000-7f996c024000 rw-p 00000000 00:00 0 
7f996c400000-7f996c600000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996c600000-7f996c800000 rw-s 00000000 00:05 206139044                  /dev/zero (deleted)
7f996c825000-7f996e825000 rw-p 00000000 00:00 0 
7f996ec00000-7f996ee00000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996ee00000-7f996f000000 rw-s 00000000 00:05 206139043                  /dev/zero (deleted)
7f996f026000-7f9971026000 rw-p 00000000 00:00 0 
7f9971026000-7f9971027000 ---p 00000000 00:00 0 
7f9971027000-7f9973827000 rw-p 00000000 00:00 0 
7f9973c00000-7f9973e00000 ---p 00000000 00:00 0 
7f9973e29000-7f997902a000 rw-p 00000000 00:00 0 
7f997902d000-7f997d02e000 rw-p 00000000 00:00 0 
7f997d02e000-7f997d02f000 ---p 00000000 00:00 0 
7f997d02f000-7f997f82f000 rw-p 00000000 00:00 0 
7f997f82f000-7f997f830000 ---p 00000000 00:00 0 
7f997f830000-7f9984030000 rw-p 00000000 00:00 0 
7f9984400000-7f9984600000 ---p 00000000 00:00 0 
7f9984731000-7f9987032000 rw-p 00000000 00:00 0 
7f9987171000-7f998c034000 rw-p 00000000 00:00 0 
7f998c0b2000-7f9996038000 rw-p 00000000 00:00 0 
7f9996038000-7f99978ee000 r-xp 00000000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f99978ee000-7f9997aed000 ---p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aed000-7f9997aee000 r--p 018b5000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aee000-7f9997aef000 rw-p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aef000-7f9997af2000 r-xp 00000000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997af2000-7f9997cf1000 ---p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf1000-7f9997cf2000 r--p 00002000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf2000-7f9997cf3000 rw-p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf3000-7f9997e72000 r-xp 00000000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9997e72000-7f9998072000 ---p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998072000-7f9998082000 r--p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998082000-7f9998083000 rw-p 0018f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998083000-7f9998087000 rw-p 00000000 00:00 0 
7f9998087000-7f9998091000 r-xp 00000000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998091000-7f9998290000 ---p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998290000-7f9998291000 r--p 00009000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998291000-7f9998292000 rw-p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998292000-7f9998295000 r-xp 00000000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998295000-7f9998494000 ---p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998494000-7f9998495000 r--p 00002000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998495000-7f9998496000 rw-p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998496000-7f99984c2000 r-xp 00000000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99984c2000-7f99986c1000 ---p 0002c000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c1000-7f99986c3000 r--p 0002b000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c3000-7f99986c4000 rw-p 0002d000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c4000-7f99986c5000 rw-p 00000000 00:00 0 
7f99986c5000-7f9998788000 r-xp 00000000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998788000-7f9998988000 ---p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998988000-7f9998995000 r--p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998995000-7f9998997000 rw-p 000d0000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998997000-7f99989a9000 r-xp 00000000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f99989a9000-7f9998ba9000 ---p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998ba9000-7f9998baa000 r--p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998baa000-7f9998bab000 rw-p 00013000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998bab000-7f9998bcc000 r-xp 00000000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998bcc000-7f9998dcb000 ---p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcb000-7f9998dcc000 r--p 00020000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcc000-7f9998dcd000 rw-p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcd000-7f9998dd3000 r-xp 00000000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998dd3000-7f9998fd3000 ---p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd3000-7f9998fd4000 r--p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd4000-7f9998fd5000 rw-p 00007000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd5000-7f9998ff9000 r-xp 00000000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f9998ff9000-7f99991f8000 ---p 00024000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991f8000-7f99991fa000 r--p 00023000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fa000-7f99991fb000 rw-p 00025000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fb000-7f999920c000 r-xp 00000000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999920c000-7f999940c000 ---p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940c000-7f999940d000 r--p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940d000-7f999940e000 rw-p 00012000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940e000-7f999943f000 r-xp 00000000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999943f000-7f999963f000 ---p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999963f000-7f9999640000 r--p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999640000-7f9999641000 rw-p 00032000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999641000-7f999969a000 r-xp 00000000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f999969a000-7f9999899000 ---p 00059000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f9999899000-7f99998a3000 r--p 00058000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a3000-7f99998a5000 rw-p 00062000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a5000-7f9999a56000 r-xp 00000000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999a56000-7f9999c55000 ---p 001b1000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c55000-7f9999c5d000 r--p 001b0000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5d000-7f9999c5f000 rw-p 001b8000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5f000-7f9999c60000 rw-p 00000000 00:00 0 
7f9999c60000-7f9999cdf000 r-xp 00000000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999cdf000-7f9999ede000 ---p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ede000-7f9999edf000 r--p 0007e000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999edf000-7f9999ee0000 rw-p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ee0000-7f9999f14000 r-xp 00000000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f9999f14000-7f999a113000 ---p 00034000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a113000-7f999a115000 r--p 00033000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a115000-7f999a116000 rw-p 00035000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a116000-7f999a148000 r-xp 00000000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a148000-7f999a347000 ---p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a347000-7f999a348000 r--p 00031000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a348000-7f999a349000 rw-p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a349000-7f999a390000 r-xp 00000000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a390000-7f999a58f000 ---p 00047000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a58f000-7f999a591000 r--p 00046000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a591000-7f999a593000 rw-p 00048000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a593000-7f999a66a000 r-xp 00000000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a66a000-7f999a86a000 ---p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86a000-7f999a86b000 r--p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86b000-7f999a873000 rw-p 000d8000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a873000-7f999a874000 rw-p 00000000 00:00 0 
7f999a874000-7f999a8ef000 r-xp 00000000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999a8ef000-7f999aaee000 ---p 0007b000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaee000-7f999aaf0000 r--p 0007a000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf0000-7f999aaf4000 rw-p 0007c000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf4000-7f999aafb000 r-xp 00000000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999aafb000-7f999acfb000 ---p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfb000-7f999acfc000 r--p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfc000-7f999acfd000 rw-p 00008000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfd000-7f999ad07000 r-xp 00000000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999ad07000-7f999af06000 ---p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af06000-7f999af07000 r--p 00009000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af07000-7f999af08000 rw-p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af08000-7f999af36000 r-xp 00000000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999af36000-7f999b135000 ---p 0002e000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b135000-7f999b137000 r--p 0002d000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b137000-7f999b138000 rw-p 0002f000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b138000-7f999b16d000 rw-p 00000000 00:00 0 
7f999b16d000-7f999b192000 r-xp 00000000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b192000-7f999b392000 ---p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b392000-7f999b394000 r--p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b394000-7f999b395000 rw-p 00027000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b395000-7f999b3e7000 rw-p 00000000 00:00 0 
7f999b3e7000-7f999b449000 r-xp 00000000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b449000-7f999b649000 ---p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b649000-7f999b64a000 r--p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64a000-7f999b64f000 rw-p 00063000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64f000-7f999b650000 rw-p 00000000 00:00 0 
7f999b650000-7f999b658000 r-xp 00000000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b658000-7f999b857000 ---p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b857000-7f999b858000 r--p 00007000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b858000-7f999b859000 rw-p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b859000-7f999b8b5000 r-xp 00000000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999b8b5000-7f999bab5000 ---p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab5000-7f999bab6000 r--p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab6000-7f999bab7000 rw-p 0005d000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab7000-7f999bace000 r-xp 00000000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bace000-7f999bcce000 ---p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcce000-7f999bccf000 r--p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bccf000-7f999bcd0000 rw-p 00018000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcd0000-7f999bcd2000 rw-p 00000000 00:00 0 
7f999bcd2000-7f999bcf1000 r-xp 00000000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bcf1000-7f999bef0000 ---p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef0000-7f999bef1000 r--p 0001e000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef1000-7f999bef2000 rw-p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef2000-7f999bef4000 rw-p 00000000 00:00 0 
7f999bef4000-7f999befc000 r-xp 00000000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999befc000-7f999c0fc000 ---p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fc000-7f999c0fd000 r--p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fd000-7f999c0fe000 rw-p 00009000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fe000-7f99a3f2c000 r-xp 00000000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a3f2c000-7f99a412c000 ---p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a412c000-7f99a413b000 rw-p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a413b000-7f99a419f000 rw-p 00000000 00:00 0 
7f99a419f000-7f99b77d1000 r-xp 00000000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b77d1000-7f99b79d1000 ---p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b79d1000-7f99b7a4c000 rw-p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b7a4c000-7f99b7ade000 rw-p 00000000 00:00 0 
7f99b7ade000-7f99bc48d000 r-xp 00000000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc48d000-7f99bc68d000 ---p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc68d000-7f99bc6c7000 rw-p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc6c7000-7f99bc6d9000 rw-p 00000000 00:00 0 
7f99bc6d9000-7f99beb62000 r-xp 00000000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99beb62000-7f99bed61000 ---p 02489000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99bed61000-7f99c0133000 rw-p 02488000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99c0133000-7f99c063d000 rw-p 00000000 00:00 0 
7f99c063d000-7f99d02b3000 r-xp 00000000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d02b3000-7f99d04b3000 ---p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04b3000-7f99d04ed000 r--p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04ed000-7f99d0511000 rw-p 0fcb0000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d0511000-7f99d1029000 rw-p 00000000 00:00 0 
7f99d1029000-7f99d102e000 r-xp 00000000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d102e000-7f99d122d000 ---p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122d000-7f99d122e000 r--p 00004000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122e000-7f99d122f000 rw-p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122f000-7f99d1231000 r-xp 00000000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1231000-7f99d1431000 ---p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1431000-7f99d1432000 r--p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1432000-7f99d1433000 rw-p 00003000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1433000-7f99d1454000 r-xp 00000000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1454000-7f99d1653000 ---p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1653000-7f99d1654000 r--p 00020000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1654000-7f99d1655000 rw-p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1655000-7f99d1659000 r-xp 00000000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1659000-7f99d1858000 ---p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1858000-7f99d1859000 r--p 00003000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1859000-7f99d185a000 rw-p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d185a000-7f99d18c8000 r-xp 00000000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d18c8000-7f99d1ac8000 ---p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac8000-7f99d1ac9000 r--p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac9000-7f99d1aca000 rw-p 0006f000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1aca000-7f99d1bff000 r-xp 00000000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1bff000-7f99d1dff000 ---p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1dff000-7f99d1e00000 r--p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e00000-7f99d1e04000 rw-p 00136000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e04000-7f99d1e15000 r-xp 00000000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d1e15000-7f99d2014000 ---p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2014000-7f99d2015000 r--p 00010000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2015000-7f99d2016000 rw-p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2016000-7f99d201f000 r-xp 00000000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d201f000-7f99d221e000 ---p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221e000-7f99d221f000 r--p 00008000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221f000-7f99d2220000 rw-p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d2220000-7f99d2236000 r-xp 00000000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2236000-7f99d2435000 ---p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2435000-7f99d2436000 r--p 00015000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2436000-7f99d2437000 rw-p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2437000-7f99d243a000 rw-p 00000000 00:00 0 
7f99d243a000-7f99d2441000 r-xp 00000000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2441000-7f99d2640000 ---p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2640000-7f99d2641000 r--p 00006000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2641000-7f99d2642000 rw-p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2642000-7f99d2751000 r-xp 00000000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2751000-7f99d2950000 ---p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2950000-7f99d2951000 r--p 0010e000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2951000-7f99d2952000 rw-p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2952000-7f99d2953000 rw-p 00000000 00:00 0 
7f99d2953000-7f99d2954000 r-xp 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2954000-7f99d2b53000 ---p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b53000-7f99d2b54000 r--p 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b54000-7f99d2b55000 rw-p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b55000-7f99d2e4e000 r-xp 00000000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d2e4e000-7f99d304e000 ---p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d304e000-7f99d3051000 rw-p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3051000-7f99d3058000 rw-p 00000000 00:00 0 
7f99d3058000-7f99d3059000 rw-p 0032c000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3059000-7f99d3073000 r-xp 00000000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3073000-7f99d3273000 ---p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3273000-7f99d3275000 rw-p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3275000-7f99d3277000 rw-p 0001d000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3277000-7f99d328d000 r-xp 00000000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d328d000-7f99d348c000 ---p 00016000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348c000-7f99d348d000 rw-p 00015000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348d000-7f99d35ff000 r-xp 00000000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d35ff000-7f99d37ff000 ---p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d37ff000-7f99d3809000 r--p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d3809000-7f99d380b000 rw-p 0017c000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d380b000-7f99d380f000 rw-p 00000000 00:00 0 
7f99d380f000-7f99d3b0b000 r-xp 00000000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b0b000-7f99d3b1b000 ---p 002fc000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b1b000-7f99d3b47000 rw-p 0030c000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b47000-7f99d3d0a000 ---p 00338000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d0a000-7f99d3d1a000 rw-p 002fb000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d1a000-7f99d3d1b000 rw-p 00000000 00:00 0 
7f99d3d1b000-7f99d4823000 r-xp 00000000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4823000-7f99d4a23000 ---p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a23000-7f99d4a7c000 rw-p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a7c000-7f99d4a7e000 rw-p 00000000 00:00 0 
7f99d4a7e000-7f99d4bac000 rw-p 00b61000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4bac000-7f99d57cb000 r-xp 00000000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d57cb000-7f99d59cb000 ---p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d59cb000-7f99d5a2a000 rw-p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d5a2a000-7f99d6208000 rw-p 00000000 00:00 0 
7f99d6208000-7f99d6218000 rw-p 00c7f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d6218000-7f99d7c28000 r-xp 00000000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7c28000-7f99d7e28000 ---p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7e28000-7f99d7ec1000 rw-p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7ec1000-7f99d7f7f000 rw-p 00000000 00:00 0 
7f99d7f7f000-7f99d8000000 rw-p 01aaa000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d8000000-7f99d8021000 rw-p 00000000 00:00 0 
7f99d8021000-7f99dc000000 ---p 00000000 00:00 0 
7f99dc000000-7f99dc021000 rw-p 00000000 00:00 0 
7f99dc021000-7f99e0000000 ---p 00000000 00:00 0 
7f99e0000000-7f99e0021000 rw-p 00000000 00:00 0 
7f99e0021000-7f99e4000000 ---p 00000000 00:00 0 
7f99e414c000-7f99e4153000 r-xp 00000000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4153000-7f99e4352000 ---p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4352000-7f99e4353000 r--p 00006000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4353000-7f99e4354000 rw-p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4354000-7f99e4378000 r-xp 00000000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4378000-7f99e4578000 ---p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4578000-7f99e4581000 rw-p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4581000-7f99e4601000 r-xp 00000000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4601000-7f99e4800000 ---p 00080000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4800000-7f99e4802000 rw-p 0007f000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4802000-7f99e480a000 rw-p 00000000 00:00 0 
7f99e480a000-7f99e480c000 rw-p 00082000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e480c000-7f99e4869000 r-xp 00000000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4869000-7f99e4a69000 ---p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a69000-7f99e4a74000 rw-p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a74000-7f99e4a83000 rw-p 00000000 00:00 0 
7f99e4a83000-7f99e4a87000 rw-p 00069000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a87000-7f99e4ca4000 r-xp 00000000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ca4000-7f99e4ea4000 ---p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ea4000-7f99e4ee4000 rw-p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ee4000-7f99e4ef8000 r-xp 00000000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e4ef8000-7f99e50f7000 ---p 00014000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f7000-7f99e50f8000 rw-p 00013000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f8000-7f99e50f9000 rw-p 00015000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f9000-7f99e50fa000 ---p 00000000 00:00 0 
7f99e50fa000-7f99e58fa000 rw-p 00000000 00:00 0 
7f99e58fa000-7f99e58fb000 ---p 00000000 00:00 0 
7f99e58fb000-7f99e60fb000 rw-p 00000000 00:00 0 
7f99e60fb000-7f99e60fc000 ---p 00000000 00:00 0 
7f99e60fc000-7f99e68fc000 rw-p 00000000 00:00 0 
7f99e68fc000-7f99e6900000 r-xp 00000000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6900000-7f99e6aff000 ---p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6aff000-7f99e6b00000 r--p 00003000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b00000-7f99e6b02000 rw-p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b02000-7f99e6b82000 rw-p 00000000 00:00 0 
7f99e6c02000-7f99e6dc2000 rw-p 00000000 00:00 0 
7f99e6dc2000-7f99e6de8000 r-xp 00000000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6de8000-7f99e6fe8000 ---p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fe8000-7f99e6fea000 r--p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fea000-7f99e6feb000 rw-p 00028000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6feb000-7f99e6ffa000 r-xp 00000000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e6ffa000-7f99e71f9000 ---p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71f9000-7f99e71fa000 r--p 0000e000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fa000-7f99e71fc000 rw-p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fc000-7f99e727c000 rw-p 00000000 00:00 0 
7f99e727c000-7f99e73fc000 rw-p 00000000 00:00 0 
7f99e73fc000-7f99e7408000 r-xp 00000000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7408000-7f99e7607000 ---p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7607000-7f99e7608000 r--p 0000b000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7608000-7f99e7609000 rw-p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7609000-7f99e7689000 rw-p 00000000 00:00 0 
7f99e7689000-7f99e76e7000 r-xp 00000000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e76e7000-7f99e78e7000 ---p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78e7000-7f99e78eb000 r--p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78eb000-7f99e78f2000 rw-p 00062000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78f2000-7f99e7907000 r-xp 00000000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7907000-7f99e7b06000 ---p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b06000-7f99e7b07000 r--p 00014000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b07000-7f99e7b0b000 rw-p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b0b000-7f99e7ccb000 rw-p 00000000 00:00 0 
7f99e7ccc000-7f99e7d0c000 rw-p 00000000 00:00 0 
7f99e7d0c000-7f99e7d10000 r-xp 00000000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7d10000-7f99e7f0f000 ---p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f0f000-7f99e7f10000 r--p 00003000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f10000-7f99e7f11000 rw-p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f11000-7f99e8051000 rw-p 00000000 00:00 0 
7f99e8051000-7f99e8102000 r-xp 00000000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8102000-7f99e8301000 ---p 000b1000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8301000-7f99e8326000 rw-p 000b0000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8326000-7f99e8368000 rw-p 00000000 00:00 0 
7f99e8368000-7f99e8371000 r-xp 00000000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8371000-7f99e8571000 ---p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8571000-7f99e8572000 rw-p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8572000-7f99e85f2000 rw-p 00000000 00:00 0 
7f99e85f2000-7f99e85f3000 r-xp 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e85f3000-7f99e87f2000 ---p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f2000-7f99e87f3000 r--p 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f3000-7f99e87f4000 rw-p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f4000-7f99e8874000 rw-p 00000000 00:00 0 
7f99e8874000-7f99e889f000 r-xp 00000000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e889f000-7f99e8a9e000 ---p 0002b000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8a9e000-7f99e8aa0000 rw-p 0002a000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa0000-7f99e8aa3000 rw-p 000d2000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa3000-7f99e8aa7000 r-xp 00000000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8aa7000-7f99e8ca7000 ---p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca7000-7f99e8ca8000 rw-p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca8000-7f99e8caa000 rw-p 00019000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8caa000-7f99e8cea000 rw-p 00000000 00:00 0 
7f99e8cea000-7f99e8d09000 r-xp 00000000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8d09000-7f99e8f08000 ---p 0001f000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f08000-7f99e8f0a000 rw-p 0001e000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f0a000-7f9a0cfca000 rw-p 00000000 00:00 0 
7f9a0cfca000-7f9a0cfd1000 r-xp 00000000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0cfd1000-7f9a0d1d0000 ---p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d0000-7f9a0d1d1000 r--p 00006000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d1000-7f9a0d1d2000 rw-p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d2000-7f9a0d1f0000 r-xp 00000000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d1f0000-7f9a0d3ef000 ---p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3ef000-7f9a0d3f0000 r--p 0001d000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f0000-7f9a0d3f4000 rw-p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f4000-7f9a0d434000 rw-p 00000000 00:00 0 
7f9a0d434000-7f9a0d435000 ---p 00000000 00:00 0 
7f9a0d435000-7f9a0dc35000 rw-p 00000000 00:00 0 
7f9a0de25000-7f9a0e4a8000 rw-p 00000000 00:00 0 
7f9a0e4a8000-7f9a0e4ac000 r-xp 00000000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e4ac000-7f9a0e6ab000 ---p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ab000-7f9a0e6ac000 r--p 00003000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ac000-7f9a0e6ad000 rw-p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ad000-7f9a0e6df000 r-xp 00000000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e6df000-7f9a0e8df000 ---p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8df000-7f9a0e8e0000 rw-p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e0000-7f9a0e8e1000 rw-p 00034000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e1000-7f9a0e970000 r-xp 00000000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0e970000-7f9a0eb70000 ---p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb70000-7f9a0eb74000 rw-p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb74000-7f9a0eb7c000 rw-p 00094000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb7c000-7f9a0ebc3000 r-xp 00000000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0ebc3000-7f9a0edc3000 ---p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc3000-7f9a0edc5000 rw-p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc5000-7f9a0edc7000 rw-p 0004a000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc7000-7f9a0ee18000 r-xp 00000000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0ee18000-7f9a0f018000 ---p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f018000-7f9a0f019000 rw-p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f019000-7f9a0f01b000 rw-p 00053000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f01b000-7f9a0f099000 r-xp 00000000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f099000-7f9a0f299000 ---p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f299000-7f9a0f2af000 rw-p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f2af000-7f9a0f2b5000 r-xp 00000000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f2b5000-7f9a0f4b4000 ---p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b4000-7f9a0f4b5000 r--p 00005000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b5000-7f9a0f4b6000 rw-p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b6000-7f9a0f4b8000 r-xp 00000000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f4b8000-7f9a0f6b8000 ---p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b8000-7f9a0f6b9000 r--p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b9000-7f9a0f6ba000 rw-p 00003000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6ba000-7f9a0f759000 r-xp 00000000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f759000-7f9a0f959000 ---p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f959000-7f9a0f961000 r--p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f961000-7f9a0f962000 rw-p 000a7000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f962000-7f9a0fa06000 r-xp 00000000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fa06000-7f9a0fc05000 ---p 000a4000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc05000-7f9a0fc0b000 r--p 000a3000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0b000-7f9a0fc0c000 rw-p 000a9000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0c000-7f9a0fc1b000 r-xp 00000000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fc1b000-7f9a0fe1a000 ---p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1a000-7f9a0fe1b000 r--p 0000e000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1b000-7f9a0fe1c000 rw-p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1c000-7f9a0ff3f000 r-xp 00000000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a0ff3f000-7f9a1013e000 ---p 00123000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1013e000-7f9a10149000 r--p 00122000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a10149000-7f9a1014b000 rw-p 0012d000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1014b000-7f9a1014c000 rw-p 00000000 00:00 0 
7f9a1014c000-7f9a10193000 r-xp 00000000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10193000-7f9a10392000 ---p 00047000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10392000-7f9a10394000 r--p 00046000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10394000-7f9a10395000 rw-p 00048000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10395000-7f9a103df000 r-xp 00000000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a103df000-7f9a105df000 ---p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105df000-7f9a105e2000 r--p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e2000-7f9a105e3000 rw-p 0004d000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e3000-7f9a1062d000 r-xp 00000000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1062d000-7f9a1082d000 ---p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082d000-7f9a1082e000 r--p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082e000-7f9a1082f000 rw-p 0004b000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082f000-7f9a1096e000 rw-p 00000000 00:00 0 
7f9a1096e000-7f9a10989000 r-xp 00000000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10989000-7f9a10b88000 ---p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b88000-7f9a10b89000 r--p 0001a000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b89000-7f9a10b8a000 rw-p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b8a000-7f9a10bd2000 r-xp 00000000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10bd2000-7f9a10dd1000 ---p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd1000-7f9a10dd2000 r--p 00047000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd2000-7f9a10dd3000 rw-p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd3000-7f9a10ded000 r-xp 00000000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10ded000-7f9a10fec000 ---p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fec000-7f9a10fed000 r--p 00019000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fed000-7f9a10fee000 rw-p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fee000-7f9a10ffb000 r-xp 00000000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a10ffb000-7f9a111fa000 ---p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fa000-7f9a111fb000 r--p 0000c000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fb000-7f9a111fc000 rw-p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fc000-7f9a11241000 r-xp 00000000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11241000-7f9a11441000 ---p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11441000-7f9a11442000 r--p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11442000-7f9a11443000 rw-p 00046000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11443000-7f9a11471000 rw-p 00000000 00:00 0 
7f9a11471000-7f9a11493000 r-xp 00000000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11493000-7f9a11692000 ---p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11692000-7f9a11693000 r--p 00021000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11693000-7f9a11694000 rw-p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11694000-7f9a116dd000 r-xp 00000000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a116dd000-7f9a118dc000 ---p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dc000-7f9a118dd000 r--p 00048000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dd000-7f9a118de000 rw-p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118de000-7f9a119af000 r-xp 00000000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a119af000-7f9a11baf000 ---p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11baf000-7f9a11bb1000 r--p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb1000-7f9a11bb2000 rw-p 000d3000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb2000-7f9a11bb3000 rw-p 00000000 00:00 0 
7f9a11bb3000-7f9a11bbf000 r-xp 00000000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11bbf000-7f9a11dbe000 ---p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbe000-7f9a11dbf000 r--p 0000b000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbf000-7f9a11dc0000 rw-p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dc0000-7f9a11dc7000 r-xp 00000000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11dc7000-7f9a11fc6000 ---p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc6000-7f9a11fc7000 r--p 00006000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc7000-7f9a11fc8000 rw-p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc8000-7f9a159f9000 r-xp 00000000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a159f9000-7f9a15bf9000 ---p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15bf9000-7f9a15c35000 rw-p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15c35000-7f9a17c45000 rw-p 00000000 00:00 0 
7f9a17dd4000-7f9a17deb000 r-xp 00000000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17deb000-7f9a17feb000 ---p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17feb000-7f9a17fec000 r--p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fec000-7f9a17fed000 rw-p 00018000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fed000-7f9a18006000 r-xp 00000000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18006000-7f9a18205000 ---p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18205000-7f9a18206000 r--p 00018000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18206000-7f9a18207000 rw-p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18207000-7f9a18245000 r-xp 00000000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18245000-7f9a18444000 ---p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18444000-7f9a18445000 r--p 0003d000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18445000-7f9a18446000 rw-p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18446000-7f9a3a446000 rw-p 00000000 00:00 0 
7f9a3a550000-7f9a3a56e000 r-xp 00000000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a56e000-7f9a3a76d000 ---p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76d000-7f9a3a76e000 r--p 0001d000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76e000-7f9a3a76f000 rw-p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76f000-7f9a3a773000 rw-p 00000000 00:00 0 
7f9a3a773000-7f9a3a79d000 r-xp 00000000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a79d000-7f9a3a99c000 ---p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99c000-7f9a3a99d000 r--p 00029000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99d000-7f9a3a99e000 rw-p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99e000-7f9a3aa2b000 r-xp 00000000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3aa2b000-7f9a3ac2a000 ---p 0008d000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac2a000-7f9a3ac46000 r--p 0008c000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac46000-7f9a3ac47000 rw-p 000a8000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac47000-7f9a3ec47000 rw-p 00000000 00:00 0 
7f9a3edfb000-7f9a3f01a000 r-xp 00000000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f01a000-7f9a3f219000 ---p 0021f000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f219000-7f9a3f21b000 r--p 0021e000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21b000-7f9a3f21c000 rw-p 00220000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21c000-7f9a3f21f000 rw-p 00000000 00:00 0 
7f9a3f21f000-7f9a3f247000 r-xp 00000000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f247000-7f9a3f446000 ---p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f446000-7f9a3f447000 r--p 00027000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f447000-7f9a3f448000 rw-p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f448000-7f9a41448000 rw-p 00000000 00:00 0 
7f9a4148d000-7f9a414e6000 r-xp 00000000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a414e6000-7f9a416e6000 ---p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e6000-7f9a416e7000 r--p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e7000-7f9a416e9000 rw-p 0005a000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e9000-7f9a41811000 r-xp 00000000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41811000-7f9a41a10000 ---p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a10000-7f9a41a11000 r--p 00127000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a11000-7f9a41a12000 rw-p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a12000-7f9a41a8d000 rw-p 00000000 00:00 0 
7f9a41a8d000-7f9a4249a000 r-xp 00000000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4249a000-7f9a42699000 ---p 00a0d000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a42699000-7f9a4269c000 r--p 00a0c000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269c000-7f9a4269f000 rw-p 00a0f000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269f000-7f9a426ac000 rw-p 00000000 00:00 0 
7f9a426ac000-7f9a4274d000 r-xp 00000000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4274d000-7f9a4294c000 ---p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294c000-7f9a4294d000 r--p 000a0000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294d000-7f9a42957000 rw-p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a42957000-7f9a429c0000 rw-p 00000000 00:00 0 
7f9a429c0000-7f9a42a37000 r-xp 00000000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42a37000-7f9a42c36000 ---p 00077000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c36000-7f9a42c3f000 r--p 00076000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c3f000-7f9a42c4b000 rw-p 0007f000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c4b000-7f9a44c4b000 rw-p 00000000 00:00 0 
7f9a44d20000-7f9a44d3b000 r-xp 00000000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44d3b000-7f9a44f3a000 ---p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3a000-7f9a44f3b000 r--p 0001a000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3b000-7f9a44f3c000 rw-p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3c000-7f9a44f56000 r-xp 00000000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a44f56000-7f9a45156000 ---p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45156000-7f9a45158000 r--p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45158000-7f9a45159000 rw-p 0001c000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45159000-7f9a45162000 r-xp 00000000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45162000-7f9a45361000 ---p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45361000-7f9a45362000 r--p 00008000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45362000-7f9a45367000 rw-p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45367000-7f9a4537e000 r-xp 00000000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4537e000-7f9a4557d000 ---p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557d000-7f9a4557e000 r--p 00016000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557e000-7f9a4557f000 rw-p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557f000-7f9a4558c000 r-xp 00000000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4558c000-7f9a4578c000 ---p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578c000-7f9a4578d000 r--p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578d000-7f9a4578e000 rw-p 0000e000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578e000-7f9a457ac000 r-xp 00000000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a457ac000-7f9a459ac000 ---p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ac000-7f9a459ad000 r--p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ad000-7f9a459ae000 rw-p 0001f000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ae000-7f9a459c6000 r-xp 00000000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a459c6000-7f9a45bc5000 ---p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc5000-7f9a45bc6000 r--p 00017000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc6000-7f9a45bc7000 rw-p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc7000-7f9a45c34000 r-xp 00000000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45c34000-7f9a45e34000 ---p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e34000-7f9a45e35000 r--p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e35000-7f9a45e36000 rw-p 0006e000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e36000-7f9a45e38000 r-xp 00000000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a45e38000-7f9a46037000 ---p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46037000-7f9a46038000 r--p 00001000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46038000-7f9a46039000 rw-p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46039000-7f9a46042000 r-xp 00000000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46042000-7f9a46241000 ---p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46241000-7f9a46242000 r--p 00008000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46242000-7f9a46243000 rw-p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46243000-7f9a4624d000 r-xp 00000000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4624d000-7f9a4644c000 ---p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644c000-7f9a4644d000 r--p 00009000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644d000-7f9a4644e000 rw-p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644e000-7f9a4844e000 rw-p 00000000 00:00 0 
7f9a48485000-7f9a48626000 rw-p 00000000 00:00 0 
7f9a48626000-7f9a48635000 r-xp 00000000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48635000-7f9a48834000 ---p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48834000-7f9a48835000 r--p 0000e000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48835000-7f9a48836000 rw-p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48836000-7f9a48838000 r-xp 00000000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48838000-7f9a48a37000 ---p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a37000-7f9a48a38000 r--p 00001000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a38000-7f9a48a39000 rw-p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a39000-7f9a48a76000 r-xp 00000000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48a76000-7f9a48c75000 ---p 0003d000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c75000-7f9a48c77000 r--p 0003c000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c77000-7f9a48c7c000 rw-p 0003e000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c7c000-7f9a48cc5000 r-xp 00000000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48cc5000-7f9a48ec5000 ---p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec5000-7f9a48ec7000 r--p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec7000-7f9a48ec8000 rw-p 0004b000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec8000-7f9a48edc000 r-xp 00000000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a48edc000-7f9a490dc000 ---p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dc000-7f9a490dd000 r--p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dd000-7f9a490de000 rw-p 00015000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490de000-7f9a4925e000 r-xp 00000000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4925e000-7f9a4945e000 ---p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4945e000-7f9a49462000 r--p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49462000-7f9a49464000 rw-p 00184000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49464000-7f9a49466000 rw-p 00000000 00:00 0 
7f9a49466000-7f9a49487000 r-xp 00000000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49487000-7f9a49686000 ---p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49686000-7f9a49687000 r--p 00020000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49687000-7f9a49688000 rw-p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49688000-7f9a49796000 r-xp 00000000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49796000-7f9a49996000 ---p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49996000-7f9a49999000 r--p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49999000-7f9a4999a000 rw-p 00111000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a4999a000-7f9a4999c000 rw-p 00000000 00:00 0 
7f9a4999c000-7f9a499be000 r-xp 00000000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a499be000-7f9a49bbd000 ---p 00022000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bbd000-7f9a49bc0000 r--p 00021000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc0000-7f9a49bc1000 rw-p 00024000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc1000-7f9a4ba25000 r-xp 00000000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4ba25000-7f9a4bc24000 ---p 01e64000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc24000-7f9a4bc2a000 r--p 01e63000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc2a000-7f9a4bc3c000 rw-p 01e69000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc3c000-7f9a4dc55000 rw-p 00000000 00:00 0 
7f9a4dc7a000-7f9a4ddba000 rw-p 00000000 00:00 0 
7f9a4ddba000-7f9a4ddc6000 r-xp 00000000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4ddc6000-7f9a4dfc5000 ---p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc5000-7f9a4dfc6000 r--p 0000b000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc6000-7f9a4dfc7000 rw-p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc7000-7f9a4dfca000 r-xp 00000000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4dfca000-7f9a4e1c9000 ---p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1c9000-7f9a4e1ca000 r--p 00002000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1ca000-7f9a4e1cb000 rw-p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1cb000-7f9a4e1d0000 r-xp 00000000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e1d0000-7f9a4e3d0000 ---p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d0000-7f9a4e3d1000 r--p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d1000-7f9a4e3d2000 rw-p 00006000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d2000-7f9a4e3ed000 r-xp 00000000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e3ed000-7f9a4e5ec000 ---p 0001b000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ec000-7f9a4e5ef000 r--p 0001a000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ef000-7f9a4e5f0000 rw-p 0001d000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5f0000-7f9a4e5fb000 r-xp 00000000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e5fb000-7f9a4e7fa000 ---p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fa000-7f9a4e7fb000 r--p 0000a000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fb000-7f9a4e7fe000 rw-p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fe000-7f9a4e81f000 r-xp 00000000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4e81f000-7f9a4ea1e000 ---p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1e000-7f9a4ea1f000 r--p 00020000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1f000-7f9a4ea20000 rw-p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea20000-7f9a4ea30000 r-xp 00000000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ea30000-7f9a4ec30000 ---p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec30000-7f9a4ec31000 r--p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec31000-7f9a4ec32000 rw-p 00011000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec32000-7f9a4ec37000 r-xp 00000000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ec37000-7f9a4ee36000 ---p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee36000-7f9a4ee37000 r--p 00004000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee37000-7f9a4ee38000 rw-p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee38000-7f9a4ee3c000 r-xp 00000000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4ee3c000-7f9a4f03b000 ---p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03b000-7f9a4f03c000 r--p 00003000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03c000-7f9a4f03d000 rw-p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03d000-7f9a4f054000 r-xp 00000000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f054000-7f9a4f253000 ---p 00017000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f253000-7f9a4f255000 r--p 00016000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f255000-7f9a4f256000 rw-p 00018000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f256000-7f9a4f257000 r-xp 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f257000-7f9a4f456000 ---p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f456000-7f9a4f457000 r--p 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f457000-7f9a4f458000 rw-p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f458000-7f9a51458000 rw-p 00000000 00:00 0 
7f9a5145f000-7f9a5161f000 rw-p 00000000 00:00 0 
7f9a5161f000-7f9a51624000 r-xp 00000000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51624000-7f9a51823000 ---p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51823000-7f9a51824000 r--p 00004000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51824000-7f9a51825000 rw-p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51825000-7f9a51827000 r-xp 00000000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51827000-7f9a51a26000 ---p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a26000-7f9a51a27000 r--p 00001000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a27000-7f9a51a28000 rw-p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a28000-7f9a51a54000 r-xp 00000000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51a54000-7f9a51c53000 ---p 0002c000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c53000-7f9a51c57000 r--p 0002b000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c57000-7f9a51c58000 rw-p 0002f000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c58000-7f9a57c59000 rw-p 00000000 00:00 0 
7f9a57c8d000-7f9a57e4d000 rw-p 00000000 00:00 0 
7f9a57e4d000-7f9a57e4e000 r-xp 00000000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a57e4e000-7f9a5804e000 ---p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804e000-7f9a5804f000 r--p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804f000-7f9a58050000 rw-p 00002000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a58050000-7f9a58055000 r-xp 00000000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58055000-7f9a58255000 ---p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58255000-7f9a58256000 r--p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58256000-7f9a58257000 rw-p 00006000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58257000-7f9a58259000 r-xp 00000000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58259000-7f9a58458000 ---p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58458000-7f9a58459000 r--p 00001000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58459000-7f9a5845a000 rw-p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a5845a000-7f9a5a45a000 rw-p 00000000 00:00 0 
7f9a5a48d000-7f9a5a5cd000 rw-p 00000000 00:00 0 
7f9a5a5cd000-7f9a5a5cf000 r-xp 00000000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a5cf000-7f9a5a7ce000 ---p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7ce000-7f9a5a7cf000 r--p 00001000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7cf000-7f9a5a7d0000 rw-p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7d0000-7f9a5a80e000 r-xp 00000000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5a80e000-7f9a5aa0d000 ---p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0d000-7f9a5aa0e000 r--p 0003d000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0e000-7f9a5aa0f000 rw-p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0f000-7f9a5aa4c000 r-xp 00000000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5aa4c000-7f9a5ac4b000 ---p 0003d000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac4b000-7f9a5ac56000 rw-p 0003c000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac56000-7f9a5cc5b000 rw-p 00000000 00:00 0 
7f9a5cc5e000-7f9a5cd9e000 rw-p 00000000 00:00 0 
7f9a5cd9e000-7f9a5ce23000 r-xp 00000000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5ce23000-7f9a5d022000 ---p 00085000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d022000-7f9a5d024000 r--p 00084000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d024000-7f9a5d025000 rw-p 00086000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d025000-7f9a5d02d000 rw-p 00000000 00:00 0 
7f9a5d02d000-7f9a5db5e000 r-xp 00000000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5db5e000-7f9a5dd5d000 ---p 00b31000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd5d000-7f9a5dd88000 r--p 00b30000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd88000-7f9a5ddab000 rw-p 00b5b000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5ddab000-7f9a6045e000 rw-p 00000000 00:00 0 
7f9a60471000-7f9a604c7000 r-xp 00000000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a604c7000-7f9a606c6000 ---p 00056000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606c6000-7f9a606cc000 r--p 00055000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cc000-7f9a606cd000 rw-p 0005b000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cd000-7f9a606e0000 rw-p 00000000 00:00 0 
7f9a606e0000-7f9a608b6000 r-xp 00000000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a608b6000-7f9a60ab6000 ---p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60ab6000-7f9a60aca000 r--p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60aca000-7f9a60adf000 rw-p 001ea000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60adf000-7f9a60ae4000 r-xp 00000000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ae4000-7f9a60ce3000 ---p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce3000-7f9a60ce4000 r--p 00004000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce4000-7f9a60ce5000 rw-p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce5000-7f9a60d1a000 r-xp 00000000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60d1a000-7f9a60f19000 ---p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f19000-7f9a60f1a000 r--p 00034000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1a000-7f9a60f1b000 rw-p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1b000-7f9a60f5b000 rw-p 00000000 00:00 0 
7f9a60f5b000-7f9a60fb8000 r-xp 00000000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a60fb8000-7f9a611b7000 ---p 0005d000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b7000-7f9a611b9000 r--p 0005c000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b9000-7f9a611bf000 rw-p 0005e000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611bf000-7f9a611c2000 r-xp 00000000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a611c2000-7f9a613c1000 ---p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c1000-7f9a613c2000 r--p 00002000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c2000-7f9a613c3000 rw-p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c3000-7f9a61415000 r-xp 00000000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61415000-7f9a61614000 ---p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61614000-7f9a61615000 r--p 00051000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61615000-7f9a61616000 rw-p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61616000-7f9a61a54000 r-xp 00000000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61a54000-7f9a61c53000 ---p 0043e000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c53000-7f9a61c5a000 r--p 0043d000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5a000-7f9a61c5e000 rw-p 00444000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5e000-7f9a63c61000 rw-p 00000000 00:00 0 
7f9a63c9f000-7f9a63cdf000 rw-p 00000000 00:00 0 
7f9a63cdf000-7f9a63d8f000 r-xp 00000000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63d8f000-7f9a63f8e000 ---p 000b0000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f8e000-7f9a63f92000 r--p 000af000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f92000-7f9a63f94000 rw-p 000b3000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f94000-7f9a6415e000 r-xp 00000000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6415e000-7f9a6435d000 ---p 001ca000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6435d000-7f9a64360000 r--p 001c9000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64360000-7f9a64461000 rw-p 001cc000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64461000-7f9a66462000 rw-p 00000000 00:00 0 
7f9a6648e000-7f9a6650e000 rw-p 00000000 00:00 0 
7f9a6650e000-7f9a66550000 r-xp 00000000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66550000-7f9a6674f000 ---p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a6674f000-7f9a66750000 r--p 00041000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66750000-7f9a66751000 rw-p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66751000-7f9a6679b000 r-xp 00000000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6679b000-7f9a6699a000 ---p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699a000-7f9a6699b000 r--p 00049000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699b000-7f9a6699f000 rw-p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699f000-7f9a669a6000 rw-p 00000000 00:00 0 
7f9a669a6000-7f9a66a17000 r-xp 00000000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66a17000-7f9a66c17000 ---p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c17000-7f9a66c18000 r--p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c18000-7f9a66c1b000 rw-p 00072000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c1b000-7f9a68045000 r-xp 00000000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68045000-7f9a68244000 ---p 0142a000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68244000-7f9a683ee000 rw-p 01429000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a683ee000-7f9a6a466000 rw-p 00000000 00:00 0 
7f9a6a46c000-7f9a6a5ac000 rw-p 00000000 00:00 0 
7f9a6a5ac000-7f9a6a5d0000 r-xp 00000000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a5d0000-7f9a6a7cf000 ---p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7cf000-7f9a6a7d0000 r--p 00023000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d0000-7f9a6a7d1000 rw-p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d1000-7f9a6a828000 r-xp 00000000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6a828000-7f9a6aa28000 ---p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa28000-7f9a6aa29000 r--p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa29000-7f9a6aa2a000 rw-p 00058000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa2a000-7f9a6aa61000 r-xp 00000000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6aa61000-7f9a6ac61000 ---p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac61000-7f9a6ac62000 r--p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac62000-7f9a6ac64000 rw-p 00038000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac64000-7f9a70c67000 rw-p 00000000 00:00 0 
7f9a70c79000-7f9a70db9000 rw-p 00000000 00:00 0 
7f9a70db9000-7f9a70e29000 r-xp 00000000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a70e29000-7f9a71028000 ---p 00070000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a71028000-7f9a7102b000 r--p 0006f000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102b000-7f9a7102c000 rw-p 00072000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102c000-7f9a7102d000 rw-p 00000000 00:00 0 
7f9a7102d000-7f9a71156000 r-xp 00000000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71156000-7f9a71355000 ---p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71355000-7f9a71356000 r--p 00128000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71356000-7f9a71358000 rw-p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71358000-7f9a71b9a000 r-xp 00000000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71b9a000-7f9a71d99000 ---p 00842000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71d99000-7f9a71eea000 rw-p 00841000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71eea000-7f9a71ef8000 rw-p 00000000 00:00 0 
7f9a71ef8000-7f9a720e8000 r-xp 00000000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a720e8000-7f9a722e7000 ---p 001f0000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722e7000-7f9a722ed000 r--p 001ef000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ed000-7f9a722ee000 rw-p 001f5000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ee000-7f9a72383000 rw-p 00000000 00:00 0 
7f9a72383000-7f9a723d1000 r-xp 00000000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a723d1000-7f9a725d0000 ---p 0004e000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d0000-7f9a725d3000 r--p 0004d000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d3000-7f9a725d4000 rw-p 00050000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d4000-7f9a727f1000 r-xp 00000000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a727f1000-7f9a729f1000 ---p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f1000-7f9a729f5000 r--p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f5000-7f9a729fc000 rw-p 00221000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729fc000-7f9a729fe000 rw-p 00000000 00:00 0 
7f9a729fe000-7f9a72a67000 r-xp 00000000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72a67000-7f9a72c66000 ---p 00069000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c66000-7f9a72c6a000 rw-p 00068000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c6a000-7f9a72c6b000 rw-p 00000000 00:00 0 
7f9a72c6b000-7f9a72d5b000 r-xp 00000000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72d5b000-7f9a72f5a000 ---p 000f0000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5a000-7f9a72f5c000 rw-p 000ef000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5c000-7f9a72f5d000 rw-p 00000000 00:00 0 
7f9a72f5d000-7f9a72f65000 rw-p 000f2000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f65000-7f9a74a65000 r-xp 00000000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74a65000-7f9a74c65000 ---p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c65000-7f9a74c7e000 rw-p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c7e000-7f9a74c89000 rw-p 00000000 00:00 0 
7f9a74c89000-7f9a74d01000 rw-p 01beb000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74d01000-7f9a75088000 r-xp 00000000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75088000-7f9a75287000 ---p 00387000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75287000-7f9a752a6000 rw-p 00386000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752a6000-7f9a752c7000 rw-p 00000000 00:00 0 
7f9a752c7000-7f9a752ce000 rw-p 012b0000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752ce000-7f9a7534e000 rw-p 00000000 00:00 0 
7f9a7534e000-7f9a75569000 r-xp 00000000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75569000-7f9a75768000 ---p 0021b000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75768000-7f9a75784000 r--p 0021a000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75784000-7f9a75790000 rw-p 00236000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75790000-7f9a75793000 rw-p 00000000 00:00 0 
7f9a75793000-7f9a75799000 r-xp 00000000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75799000-7f9a75998000 ---p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75998000-7f9a75999000 r--p 00005000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75999000-7f9a7599a000 rw-p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a7599b000-7f9a75b1b000 rw-p 00000000 00:00 0 
7f9a75b1b000-7f9a75c23000 r-xp 00000000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75c23000-7f9a75e22000 ---p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e22000-7f9a75e23000 r--p 00107000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e23000-7f9a75e24000 rw-p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e24000-7f9a75e3d000 r-xp 00000000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a75e3d000-7f9a7603c000 ---p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603c000-7f9a7603d000 r--p 00018000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603d000-7f9a7603e000 rw-p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603e000-7f9a76040000 r-xp 00000000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76040000-7f9a7623f000 ---p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a7623f000-7f9a76240000 r--p 00001000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76240000-7f9a76241000 rw-p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76241000-7f9a76244000 r-xp 00000000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76244000-7f9a76443000 ---p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76443000-7f9a76444000 r--p 00002000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76444000-7f9a76445000 rw-p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76445000-7f9a76605000 r-xp 00000000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76605000-7f9a76805000 ---p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76805000-7f9a76809000 r--p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76809000-7f9a7680b000 rw-p 001c4000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a7680b000-7f9a7680f000 rw-p 00000000 00:00 0 
7f9a7680f000-7f9a76827000 r-xp 00000000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76827000-7f9a76a26000 ---p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a26000-7f9a76a27000 r--p 00017000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a27000-7f9a76a28000 rw-p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a28000-7f9a76a2c000 rw-p 00000000 00:00 0 
7f9a76a2c000-7f9a76a52000 r-xp 00000000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76a8a000-7f9a76a8b000 rw-p 00000000 00:00 0 
7f9a76a8b000-7f9a76a8c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8c000-7f9a76a8d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76a8d000-7f9a76a8e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8e000-7f9a76b4e000 rw-p 00000000 00:00 0 
7f9a76b4e000-7f9a76b4f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b4f000-7f9a76b50000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b50000-7f9a76b51000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b51000-7f9a76b52000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b52000-7f9a76b70000 r-xp 00000000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b70000-7f9a76b71000 r--p 0001d000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b71000-7f9a76b72000 rw-p 0001e000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b72000-7f9a76b73000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b73000-7f9a76b74000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b74000-7f9a76b75000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b75000-7f9a76b76000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b76000-7f9a76b77000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b77000-7f9a76b78000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b78000-7f9a76b79000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b79000-7f9a76b7a000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7a000-7f9a76b7b000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7b000-7f9a76b7c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7c000-7f9a76b7d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7d000-7f9a76b7e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7e000-7f9a76b7f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7f000-7f9a76c44000 rw-p 00000000 00:00 0 
7f9a76c44000-7f9a76c45000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c45000-7f9a76c46000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c46000-7f9a76c47000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c47000-7f9a76c48000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c48000-7f9a76c49000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c49000-7f9a76c4a000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4a000-7f9a76c4b000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4b000-7f9a76c4c000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4c000-7f9a76c4d000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4d000-7f9a76c4e000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4e000-7f9a76c4f000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4f000-7f9a76c50000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c50000-7f9a76c51000 rwxp 00000000 00:00 0 
7f9a76c51000-7f9a76c52000 r--p 00025000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c52000-7f9a76c53000 rw-p 00026000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c53000-7f9a76c54000 rw-p 00000000 00:00 0 
7fff2cb1b000-7fff2cb3c000 rw-p 00000000 00:00 0                          [stack]
7fff2cb80000-7fff2cb83000 r--p 00000000 00:00 0                          [vvar]
7fff2cb83000-7fff2cb85000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
bash: line 1: 56358 Aborted                 (core dumped) env ""JETBRAINS_REMOTE_RUN""=""1"" ""LIBRARY_ROOTS""=""C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1227070294;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/graphviz-0.8.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-554785109;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/370154233;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-518999124;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/idna-2.6-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/chardet-3.0.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201544331;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/724150857;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-154863933;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1227933812;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-125940560;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/2085782652;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201545290;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452379848;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1405239563;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1171821208;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/530511828;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/427714987;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-541471831;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1437370484;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/17574554;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-669732926;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452463671;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/662605150;C:/Users/chenhuizhen/.PyCharm2018.3/system/python_stubs/823358608;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/python-skeletons;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2and3;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2and3"" ""PYDEVD_LOAD_VALUES_ASYNC""=""True"" ""PYTHONPATH""=""/opt/kd-pavement-crackseg:/root/.pycharm_helpers/pycharm_matplotlib_backend:/root/.pycharm_helpers/third_party/thriftpy:/root/.pycharm_helpers/pydev:C:/Users/chenhuizhen/.PyCharm2018.3/system/cythonExtensions:/opt/kd-pavement-crackseg"" ""PYTHONIOENCODING""=""UTF-8"" ""PYTHONDONTWRITEBYTECODE""=""1"" ""IPYTHONENABLE""=""True"" ""PYCHARM_MATPLOTLIB_PORT""=""64619"" ""PYCHARM_HOSTED""=""1"" ""PYTHONUNBUFFERED""=""1"" ""IDE_PROJECT_ROOTS""=""/opt/kd-pavement-crackseg"" '/usr/bin/python' '-u' '/root/.pycharm_helpers/pydev/pydevd.py' '--multiproc' '--qt-support=auto' '--client' '0.0.0.0' '--port' '44975' '--file' '/opt/kd-pavement-crackseg/main_crack_segmentation.py'

Process finished with exit code 134
"
incubator-mxnet,11879,"Scala has many warnings due to different dependencies requiring different versions of Scala such as the below. One option is to consider using Scala 2.12(needs analysis if it breaks compatibility.

",0,[MXNet-Scala] Scala Build produces warnings.,"[MXNet-Scala] Scala Build produces warnings. Scala has many warnings due to different dependencies requiring different versions of Scala such as the below. One option is to consider using Scala 2.12(needs analysis if it breaks compatibility.

"
incubator-mxnet,8444,"I built mxnet with cpp, and copied libmxnet.so and libmxnet_static.a to my project as well as the headers, but when build the error says:


What exactly why this happened?",0,/include/mxnet-cpp/operator.hpp:157:31: error:        expected ';' at end of declaration   std::vector<NDArray> outputs{output};,"/include/mxnet-cpp/operator.hpp:157:31: error:        expected ';' at end of declaration   std::vector<NDArray> outputs{output}; I built mxnet with cpp, and copied libmxnet.so and libmxnet_static.a to my project as well as the headers, but when build the error says:


What exactly why this happened?"
incubator-mxnet,2710,"Hi All,

Is there support for elastic SGD ?
",0,elastic SGD,"elastic SGD Hi All,

Is there support for elastic SGD ?
"
incubator-mxnet,16515,"When I run the MXNet C++Interface example [image-classification-predict.cc](https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) in windows7 with visual studio 14 2015, it cannot exits normally.

If I comment the mxnet predictor free api , then it exit successfully.


",0,"MXNet C++Interface, run image-classification-predict.cc example cannot exits normally","MXNet C++Interface, run image-classification-predict.cc example cannot exits normally When I run the MXNet C++Interface example [image-classification-predict.cc](https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) in windows7 with visual studio 14 2015, it cannot exits normally.

If I comment the mxnet predictor free api , then it exit successfully.


"
incubator-mxnet,11654,"For #11631, the build is passing: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11631/8/pipeline, but the status of the PR is not updated.
![screen shot 2018-07-11 at 2 16 43 pm](https://user-images.githubusercontent.com/11465736/42599755-20d30ab4-8515-11e8-903c-d92e93eab429.png)
",0,CI Problem: Build status not reflected on PR,"CI Problem: Build status not reflected on PR For #11631, the build is passing: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11631/8/pipeline, but the status of the PR is not updated.
![screen shot 2018-07-11 at 2 16 43 pm](https://user-images.githubusercontent.com/11465736/42599755-20d30ab4-8515-11e8-903c-d92e93eab429.png)
"
incubator-mxnet,11462,"## Description
For small batch, sparse linear classification uses all CPU, but throughput is small. 


## Environment info (Required)
Machine used: AWS AMI, c5.9xlarge,
steps to repro:
1. pip2 install mxnet-mkl
2. git clone mxnet
3. in directory , run 

We see throughput is around 600 samples/sec. I tried to set up things like . It seems that after setting this, the CPU usage reduces (only half of the cores are used), but the throughput is not reduced. This is even the case when I setting . 


## Question
How should I set things up to increase the throughput of the linear classfication training for a single machine with multiple cores? Or does MXNet currently not optimize in this direction (i.e. not using things like Hogwild!). Thanks in advance. 

with @lcytzk
",0,throughput of sparse linear classification is small with small batch size,"throughput of sparse linear classification is small with small batch size ## Description
For small batch, sparse linear classification uses all CPU, but throughput is small. 


## Environment info (Required)
Machine used: AWS AMI, c5.9xlarge,
steps to repro:
1. pip2 install mxnet-mkl
2. git clone mxnet
3. in directory , run 

We see throughput is around 600 samples/sec. I tried to set up things like . It seems that after setting this, the CPU usage reduces (only half of the cores are used), but the throughput is not reduced. This is even the case when I setting . 


## Question
How should I set things up to increase the throughput of the linear classfication training for a single machine with multiple cores? Or does MXNet currently not optimize in this direction (i.e. not using things like Hogwild!). Thanks in advance. 

with @lcytzk
"
incubator-mxnet,4449,"Environment info

Operating System: Win7 64

Compiler: VS 2013 12.0.3 Update 4

3rd Library : cudnn 4, openblas, opencv2, cuda 7.5

MXNet version: yajiedesign GPU release: 2016-12-29,2016-11-25,2016-09-09

Python version and distribution: Anaconda python 2.7.11

Error info:
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

Description:

1. CNN module can be run quickly and produce good results with GPU. cudnn has been put into C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5. I think cudnn is OK

2. run rnn_cell_demo.py, error shows : 
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

3. I  change many many prebuilt yajiedesign  version, error occurs still.

In addition, I would appreciate that RNN corresponding models and symbols, such like codes in bucket_io.py, can be programmed into standard mxnet library and more easily to use. It means,  just compose several existed symbol, then  I  can wrap input samples, labels and  get complete char-RNN model  or speech rnn model.

An ideal assumption:
data = mx.sym.SequenceVariable(name='data',bucket=[5,10,15])
...
rnn = mx.sym.RNN(name='rnn',data=...,num_filter=...)",0,Error occured when runing rnn_cell_demo.py with yajiedesign mxnet release,"Error occured when runing rnn_cell_demo.py with yajiedesign mxnet release Environment info

Operating System: Win7 64

Compiler: VS 2013 12.0.3 Update 4

3rd Library : cudnn 4, openblas, opencv2, cuda 7.5

MXNet version: yajiedesign GPU release: 2016-12-29,2016-11-25,2016-09-09

Python version and distribution: Anaconda python 2.7.11

Error info:
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

Description:

1. CNN module can be run quickly and produce good results with GPU. cudnn has been put into C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5. I think cudnn is OK

2. run rnn_cell_demo.py, error shows : 
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

3. I  change many many prebuilt yajiedesign  version, error occurs still.

In addition, I would appreciate that RNN corresponding models and symbols, such like codes in bucket_io.py, can be programmed into standard mxnet library and more easily to use. It means,  just compose several existed symbol, then  I  can wrap input samples, labels and  get complete char-RNN model  or speech rnn model.

An ideal assumption:
data = mx.sym.SequenceVariable(name='data',bucket=[5,10,15])
...
rnn = mx.sym.RNN(name='rnn',data=...,num_filter=...)"
incubator-mxnet,3685,"I followed the tutorial http://mxnet.io/how_to/multi_devices.html#distributed-training-with-multiple-machines to try to train example/image-classification/train_mnist.py. I failed with launcher mpi and ssh. I can successfully run the script it never trains nor does it report any error. It just stuck there until I kill it manually.
I set environment variables on all of the nodes:
export DMLC_INTERFACE=em3
export PS_VERBOSE=2

hosts:
158.1xx.x.80
158.1xx.x.81

SSH:
While the script is running, training processes are distributed to remover servers... Nothing happens afterwards. 
$ ../../tools/launch.py --launcher ssh -n 2 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:16:55] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9091, is_recovery=0
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=50368, is_recovery=0 } }
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=51877, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:22:15,238 INFO Stop luancher

Then I try to increase the number of worker:
$ ../../tools/launch.py --launcher ssh -n 4 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:25:19] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9092, is_recovery=0
[17:25:24] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=36202, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=52936, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=45130, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:28:41,265 INFO Stop luancher
I find that all roles are assigned to 158.1xx.x.80 only, is it normal?

MPI(Open MPI 1.10.1):
Training processes can't even launch at remote server... 
$../../tools/launch.py --launcher mpi -n 4 -s 1 -H hosts python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
2016-11-01 17:35:05,797 INFO Start 4 workers by mpirun
[17:35:06] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.182.9.80, port=9091, is_recovery=0
2016-11-01 17:49:08,476 INFO Stop luancher

I've tested other MPI applications, they work fine. MPI bandwidth test can reach up to 105.93MB/sec.

Am I missing anything that makes training on multiple nodes fail? Please help. The document gives little info about this situation. Thanks in advance!
",0,"Cannot train on multiple nodes, because port blocked by firewall","Cannot train on multiple nodes, because port blocked by firewall I followed the tutorial http://mxnet.io/how_to/multi_devices.html#distributed-training-with-multiple-machines to try to train example/image-classification/train_mnist.py. I failed with launcher mpi and ssh. I can successfully run the script it never trains nor does it report any error. It just stuck there until I kill it manually.
I set environment variables on all of the nodes:
export DMLC_INTERFACE=em3
export PS_VERBOSE=2

hosts:
158.1xx.x.80
158.1xx.x.81

SSH:
While the script is running, training processes are distributed to remover servers... Nothing happens afterwards. 
$ ../../tools/launch.py --launcher ssh -n 2 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:16:55] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9091, is_recovery=0
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=50368, is_recovery=0 } }
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=51877, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:22:15,238 INFO Stop luancher

Then I try to increase the number of worker:
$ ../../tools/launch.py --launcher ssh -n 4 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:25:19] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9092, is_recovery=0
[17:25:24] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=36202, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=52936, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=45130, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:28:41,265 INFO Stop luancher
I find that all roles are assigned to 158.1xx.x.80 only, is it normal?

MPI(Open MPI 1.10.1):
Training processes can't even launch at remote server... 
$../../tools/launch.py --launcher mpi -n 4 -s 1 -H hosts python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
2016-11-01 17:35:05,797 INFO Start 4 workers by mpirun
[17:35:06] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.182.9.80, port=9091, is_recovery=0
2016-11-01 17:49:08,476 INFO Stop luancher

I've tested other MPI applications, they work fine. MPI bandwidth test can reach up to 105.93MB/sec.

Am I missing anything that makes training on multiple nodes fail? Please help. The document gives little info about this situation. Thanks in advance!
"
incubator-mxnet,8741,"## Description
The default install of MXNet currently hangs when running most types of inference with a particular setup on C5 instances.  Any setup that has the openblas library that is, for example, installed with Ubuntu 14.04 will have this issue.  This issue may be effecting all hardware with Skylake architecture, but it is deterministically failing on C5s.

## Environment info (Required)
Ubuntu 14.04

## Steps to Reproduce:
Launch a C5 instance type with Docker support.
Build the following Dockerfile:


Package used (Python/R/Scala/Julia):
Perl for the test.  Also verified it fails with the same stack in Python.

MXNet commit hash:
fd45517614842bfa1d32d1ba54a200eb4a0dd377

## Error Message:
Only one frame with symbols on the stack:


## What have you tried to solve it?

1.   New builds of openblas fix the issue.
2.  Copying openblas build that ships with Ubuntu 16.04 fixes the issue.

## TODOs:
*  Test to see if this effects all skylake and new CPUs.
*  Contact openblas and attempt to get a fix.
*  Create a minimum reproducible example that calls openblas directly (bypass mxnet code) and pass the MRT to openblas.
*  Modify our internal docker images to use Ubuntu 16.04 as a default base.",0,Inference with openblas and Ubuntu 14.04 hangs on C5 instances.,"Inference with openblas and Ubuntu 14.04 hangs on C5 instances. ## Description
The default install of MXNet currently hangs when running most types of inference with a particular setup on C5 instances.  Any setup that has the openblas library that is, for example, installed with Ubuntu 14.04 will have this issue.  This issue may be effecting all hardware with Skylake architecture, but it is deterministically failing on C5s.

## Environment info (Required)
Ubuntu 14.04

## Steps to Reproduce:
Launch a C5 instance type with Docker support.
Build the following Dockerfile:


Package used (Python/R/Scala/Julia):
Perl for the test.  Also verified it fails with the same stack in Python.

MXNet commit hash:
fd45517614842bfa1d32d1ba54a200eb4a0dd377

## Error Message:
Only one frame with symbols on the stack:


## What have you tried to solve it?

1.   New builds of openblas fix the issue.
2.  Copying openblas build that ships with Ubuntu 16.04 fixes the issue.

## TODOs:
*  Test to see if this effects all skylake and new CPUs.
*  Contact openblas and attempt to get a fix.
*  Create a minimum reproducible example that calls openblas directly (bypass mxnet code) and pass the MRT to openblas.
*  Modify our internal docker images to use Ubuntu 16.04 as a default base."
incubator-mxnet,9193,"I build mxnet with use_nccl=1 and USE_NCCL_PATH = /usr/local/lib
The version of mnxet is 1.0
The version of nccl is 1.3.4
The file in /usr/local/lib is 


When I run test_nccl.py, it seems stop at multi gpus tests.
I set NCCL_DEBUG=INFO, the output is below. And the program seems stop at here and won't going on.

The usage of gpu was like below.
",0,How to use nccl kvstore,"How to use nccl kvstore I build mxnet with use_nccl=1 and USE_NCCL_PATH = /usr/local/lib
The version of mnxet is 1.0
The version of nccl is 1.3.4
The file in /usr/local/lib is 


When I run test_nccl.py, it seems stop at multi gpus tests.
I set NCCL_DEBUG=INFO, the output is below. And the program seems stop at here and won't going on.

The usage of gpu was like below.
"
incubator-mxnet,2192,"Hello I wanted to do something with mx.sym.sum.

I have 2 outputs that I want to diff and sum.
leg1 and leg2 are outputs of FullyConnected
minibatch size = 128



How can I tell the sum symbol to take into account to sum per row instead of summing the whole matrix ?
",0,does mx.sym.sum take batch size into account ?,"does mx.sym.sum take batch size into account ? Hello I wanted to do something with mx.sym.sum.

I have 2 outputs that I want to diff and sum.
leg1 and leg2 are outputs of FullyConnected
minibatch size = 128



How can I tell the sum symbol to take into account to sum per row instead of summing the whole matrix ?
"
incubator-mxnet,13664,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",0,Dj,"Dj Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,4224,"## Environment info
Operating System:  ubuntu14.04

Compiler:  gcc4.8.4

Package used (Python/R/Scala/Julia):Python

MXNet version:  0.7.0

Or if installed from source:  yes

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:   2.7.6

If you are using R package, please provide

R :

## Error Message:

faster rcnn train error when I python train_end2end.py

I have downsize the VOC2007 train sets to1096 images,my 980 have 4G MEMORY, but it still report out of memory, I want to know how to solve this problem.Thank you!

yx@yx-X8DTL:~/mxnet/example/mx-rcnn-master$ python train_end2end.pyCalled with argument: Namespace(begin_epoch=0, dataset='PascalVOC', dataset_path='data/VOCdevkit', end_epoch=10, epoch=1, flip=True, frequent=20, gpus='0', image_set='2007_trainval', kvstore='device', lr=0.001, lr_step=50000, network='vgg', prefix='model/e2e', pretrained='model/vgg16', resume=False, root_path='data', work_load_list=None)
{'EPS': 1e-14,
'IMAGE_STRIDE': 0,
'PIXEL_MEANS': array([[[ 123.68 , 116.779, 103.939]]]),
'SCALES': [(600, 1000)],
'TEST': {'BATCH_IMAGES': 1,
'HAS_RPN': False,
'NMS': 0.3,
'RPN_MIN_SIZE': 16,
'RPN_NMS_THRESH': 0.7,
'RPN_POST_NMS_TOP_N': 300,
'RPN_PRE_NMS_TOP_N': 6000},
'TRAIN': {'BATCH_IMAGES': 1,
'BATCH_ROIS': 128,
'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
'BBOX_NORMALIZATION_PRECOMPUTED': True,
'BBOX_REGRESSION_THRESH': 0.5,
'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
'BBOX_WEIGHTS': array([ 1., 1., 1., 1.]),
'BG_THRESH_HI': 0.5,
'BG_THRESH_LO': 0.0,
'END2END': True,
'FG_FRACTION': 0.25,
'FG_THRESH': 0.5,
'RPN_BATCH_SIZE': 256,
'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
'RPN_CLOBBER_POSITIVES': False,
'RPN_FG_FRACTION': 0.5,
'RPN_MIN_SIZE': 16,
'RPN_NEGATIVE_OVERLAP': 0.3,
'RPN_NMS_THRESH': 0.7,
'RPN_POSITIVE_OVERLAP': 0.7,
'RPN_POSITIVE_WEIGHT': -1.0,
'RPN_POST_NMS_TOP_N': 6000,
'RPN_PRE_NMS_TOP_N': 12000}}
num_images 1096
voc_2007_trainval gt roidb loaded from data/cache/voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
[20:41:11] src/engine/engine.cc:36: MXNet start using engine: NaiveEngine
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
'blockgrad0_output': (1L, 128L),
'cls_prob_reshape_output': (1L, 128L, 21L),
'rpn_bbox_loss_output': (1L, 36L, 37L, 50L),
'rpn_cls_prob_output': (1L, 2L, 333L, 50L)}
[20:41:15] /home/yx/mxnet/dmlc-core/include/dmlc/./logging.h:235: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
Traceback (most recent call last):
File ""train_end2end.py"", line 185, in 
main()
File ""train_end2end.py"", line 182, in main
lr=args.lr, lr_step=args.lr_step)
File ""train_end2end.py"", line 133, in train_net
arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/base_module.py"", line 379, in fit
self.update()
File ""/home/yx/mxnet/example/mx-rcnn-master/rcnn/core/module.py"", line 183, in update
self._curr_module.update()
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/module.py"", line 419, in update
kvstore=self._kvstore)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.py"", line 115, in _update_params
updater(index*num_device+k, g, w)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 822, in updater
optimizer.update(index, weight, grad, states[index])
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 298, in update
grad = grad * self.rescale_grad
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 138, in mul
return multiply(self, other)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 744, in multiply
None)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 655, in _ufunc_helper
return lfn_scalar(lhs, float(rhs))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 1263, in generic_ndarray_function
c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.py"", line 77, in check_call
raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
terminate called without an active exception
已放弃 (核心已转储)
## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.python train_end2end.py
2.
3.

## What have you tried to solve it?

1.Downsize the train sets, but the same error still occur.
2.
3.
",0,cudaMalloc failed: out of memory,"cudaMalloc failed: out of memory ## Environment info
Operating System:  ubuntu14.04

Compiler:  gcc4.8.4

Package used (Python/R/Scala/Julia):Python

MXNet version:  0.7.0

Or if installed from source:  yes

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:   2.7.6

If you are using R package, please provide

R :

## Error Message:

faster rcnn train error when I python train_end2end.py

I have downsize the VOC2007 train sets to1096 images,my 980 have 4G MEMORY, but it still report out of memory, I want to know how to solve this problem.Thank you!

yx@yx-X8DTL:~/mxnet/example/mx-rcnn-master$ python train_end2end.pyCalled with argument: Namespace(begin_epoch=0, dataset='PascalVOC', dataset_path='data/VOCdevkit', end_epoch=10, epoch=1, flip=True, frequent=20, gpus='0', image_set='2007_trainval', kvstore='device', lr=0.001, lr_step=50000, network='vgg', prefix='model/e2e', pretrained='model/vgg16', resume=False, root_path='data', work_load_list=None)
{'EPS': 1e-14,
'IMAGE_STRIDE': 0,
'PIXEL_MEANS': array([[[ 123.68 , 116.779, 103.939]]]),
'SCALES': [(600, 1000)],
'TEST': {'BATCH_IMAGES': 1,
'HAS_RPN': False,
'NMS': 0.3,
'RPN_MIN_SIZE': 16,
'RPN_NMS_THRESH': 0.7,
'RPN_POST_NMS_TOP_N': 300,
'RPN_PRE_NMS_TOP_N': 6000},
'TRAIN': {'BATCH_IMAGES': 1,
'BATCH_ROIS': 128,
'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
'BBOX_NORMALIZATION_PRECOMPUTED': True,
'BBOX_REGRESSION_THRESH': 0.5,
'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
'BBOX_WEIGHTS': array([ 1., 1., 1., 1.]),
'BG_THRESH_HI': 0.5,
'BG_THRESH_LO': 0.0,
'END2END': True,
'FG_FRACTION': 0.25,
'FG_THRESH': 0.5,
'RPN_BATCH_SIZE': 256,
'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
'RPN_CLOBBER_POSITIVES': False,
'RPN_FG_FRACTION': 0.5,
'RPN_MIN_SIZE': 16,
'RPN_NEGATIVE_OVERLAP': 0.3,
'RPN_NMS_THRESH': 0.7,
'RPN_POSITIVE_OVERLAP': 0.7,
'RPN_POSITIVE_WEIGHT': -1.0,
'RPN_POST_NMS_TOP_N': 6000,
'RPN_PRE_NMS_TOP_N': 12000}}
num_images 1096
voc_2007_trainval gt roidb loaded from data/cache/voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
[20:41:11] src/engine/engine.cc:36: MXNet start using engine: NaiveEngine
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
'blockgrad0_output': (1L, 128L),
'cls_prob_reshape_output': (1L, 128L, 21L),
'rpn_bbox_loss_output': (1L, 36L, 37L, 50L),
'rpn_cls_prob_output': (1L, 2L, 333L, 50L)}
[20:41:15] /home/yx/mxnet/dmlc-core/include/dmlc/./logging.h:235: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
Traceback (most recent call last):
File ""train_end2end.py"", line 185, in 
main()
File ""train_end2end.py"", line 182, in main
lr=args.lr, lr_step=args.lr_step)
File ""train_end2end.py"", line 133, in train_net
arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/base_module.py"", line 379, in fit
self.update()
File ""/home/yx/mxnet/example/mx-rcnn-master/rcnn/core/module.py"", line 183, in update
self._curr_module.update()
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/module.py"", line 419, in update
kvstore=self._kvstore)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.py"", line 115, in _update_params
updater(index*num_device+k, g, w)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 822, in updater
optimizer.update(index, weight, grad, states[index])
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 298, in update
grad = grad * self.rescale_grad
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 138, in mul
return multiply(self, other)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 744, in multiply
None)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 655, in _ufunc_helper
return lfn_scalar(lhs, float(rhs))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 1263, in generic_ndarray_function
c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.py"", line 77, in check_call
raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
terminate called without an active exception
已放弃 (核心已转储)
## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.python train_end2end.py
2.
3.

## What have you tried to solve it?

1.Downsize the train sets, but the same error still occur.
2.
3.
"
incubator-mxnet,15254,"# mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1?
> i'm used  maven packages and check it

## ENV
* Java version:


* Maven version:


* cuda version:


* nvidia version:


* os:


## Check and Test


* for errors:  ?:


* for my compute:
",0,mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1?,"mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1? # mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1?
> i'm used  maven packages and check it

## ENV
* Java version:


* Maven version:


* cuda version:


* nvidia version:


* os:


## Check and Test


* for errors:  ?:


* for my compute:
"
incubator-mxnet,9962,"
for example, I want to group 2 outputs, and then split them in loss, how could I do it?  just return a list can not work, it will encounter error in Loss, since forward need symbol or ndarray
@piiswrong ",0,how to group 2 or more outputs in gluon just like sym.Group(),"how to group 2 or more outputs in gluon just like sym.Group() 
for example, I want to group 2 outputs, and then split them in loss, how could I do it?  just return a list can not work, it will encounter error in Loss, since forward need symbol or ndarray
@piiswrong "
incubator-mxnet,15514,"when trying to build latest head, dmlc.dll is being generated, but not dmlc.lib (using ms visual studio 2015). Therefore, building mxnet dll fails with

1>------ Build started: Project: mxnet, Configuration: Release x64 ------
1>LINK : fatal error LNK1181: cannot open input file '3rdparty\dmlc-core\Release\dmlc.lib'",0,dmlc.lib is not generated,"dmlc.lib is not generated when trying to build latest head, dmlc.dll is being generated, but not dmlc.lib (using ms visual studio 2015). Therefore, building mxnet dll fails with

1>------ Build started: Project: mxnet, Configuration: Release x64 ------
1>LINK : fatal error LNK1181: cannot open input file '3rdparty\dmlc-core\Release\dmlc.lib'"
incubator-mxnet,15201,"We are referrencing tensorrt and quantization in a few tutorials / blog posts etc though they do not appear under the contrib section of the docs. It would be great to add them.

@aaronmarkham ",0,Add tensorrt and quantization in the docs of the website,"Add tensorrt and quantization in the docs of the website We are referrencing tensorrt and quantization in a few tutorials / blog posts etc though they do not appear under the contrib section of the docs. It would be great to add them.

@aaronmarkham "
incubator-mxnet,14828,"Hi, please help me
i use im2rec.py
so when i do so
python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label

i get the error

opencv@opencv-virtual-machine:~$ python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label
Creating .rec file from /home/opencv/Downloads/test/dog.lst in /home/opencv/Downloads/test
multiprocessing not available, fall back to single threaded encoding
imread read blank (None) image for file: /home/opencv/./data/img/h_87.jpg
Traceback (most recent call last):
File “Downloads/im2rec.py”, line 386, in 
record.write_idx(item[0], s)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 285, in write_idx
self.write(buf)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 135, in write
ctypes.c_size_t(len(buf))))
TypeError: object of type ‘NoneType’ has no len()

What does it mean
here 87.jpg
https://images.guru/i/iPYR",0,TypeError: object of type ‘NoneType’ has no len(),"TypeError: object of type ‘NoneType’ has no len() Hi, please help me
i use im2rec.py
so when i do so
python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label

i get the error

opencv@opencv-virtual-machine:~$ python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label
Creating .rec file from /home/opencv/Downloads/test/dog.lst in /home/opencv/Downloads/test
multiprocessing not available, fall back to single threaded encoding
imread read blank (None) image for file: /home/opencv/./data/img/h_87.jpg
Traceback (most recent call last):
File “Downloads/im2rec.py”, line 386, in 
record.write_idx(item[0], s)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 285, in write_idx
self.write(buf)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 135, in write
ctypes.c_size_t(len(buf))))
TypeError: object of type ‘NoneType’ has no len()

What does it mean
here 87.jpg
https://images.guru/i/iPYR"
incubator-mxnet,12480,"## Description

When installing mxnet in my python3 virtualenv, I get the following error:



## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using python)

## Error Message:



## Steps to reproduce

1. ",0,Cannot install mxnet: Could not find a version that satisfies the requirement mxnet,"Cannot install mxnet: Could not find a version that satisfies the requirement mxnet ## Description

When installing mxnet in my python3 virtualenv, I get the following error:



## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using python)

## Error Message:



## Steps to reproduce

1. "
incubator-mxnet,9538,"I Initialize a key in kvstore.

I want to init key 3 with another shape in a same program. How can I reinitialize this key? Or is there any method to remove this key in kvstore?
",0,How can I reinitialize a key in kvstore?,"How can I reinitialize a key in kvstore? I Initialize a key in kvstore.

I want to init key 3 with another shape in a same program. How can I reinitialize this key? Or is there any method to remove this key in kvstore?
"
incubator-mxnet,207,"hi all,

I tried to install on my mac 10.10 to first run a demo on small datasets. I deleted the -fopenmp as suggested in XGBoost. I got the libmxnet.so and libmxnet.a in the lib/ folder. But I still failed to run the example/mnist.py as suggested by the tutorial. It reported ""dynamic module does not define init function"". What should I do next to solve this problem? Do you guys have a tutorial for installing on mac? Thanks a lot
",0,"Building fail on mac 10.10, ""dynamic module does not define init function""","Building fail on mac 10.10, ""dynamic module does not define init function"" hi all,

I tried to install on my mac 10.10 to first run a demo on small datasets. I deleted the -fopenmp as suggested in XGBoost. I got the libmxnet.so and libmxnet.a in the lib/ folder. But I still failed to run the example/mnist.py as suggested by the tutorial. It reported ""dynamic module does not define init function"". What should I do next to solve this problem? Do you guys have a tutorial for installing on mac? Thanks a lot
"
incubator-mxnet,11289,"This test is currently disabled since the test requires an instance with 4 GPUs which is not available in the MXNet CI at the moment. 
Adding a new instance type is on the roadmap. ",0,[Nightly Tests] Enable KVStore Single Node Test,"[Nightly Tests] Enable KVStore Single Node Test This test is currently disabled since the test requires an instance with 4 GPUs which is not available in the MXNet CI at the moment. 
Adding a new instance type is on the roadmap. "
incubator-mxnet,2125,"I am using today's github latest commit (up to b5a369384e566490211cfb458bc9936d6c2a5678 ) but I had the following error. Seems like   function is damaged?



gives


",0,TypeError: create() got an unexpected keyword argument 'top_k' ?,"TypeError: create() got an unexpected keyword argument 'top_k' ? I am using today's github latest commit (up to b5a369384e566490211cfb458bc9936d6c2a5678 ) but I had the following error. Seems like   function is damaged?



gives


"
incubator-mxnet,1127,"hi, 

I specific 2 gpus devices in command likes this,  . 
The file train_mnist.py is an example provided with source code.

Then I check the gpus status via command nvidia-smi,

it show likes,
![gpu](https://cloud.githubusercontent.com/assets/4373620/12064726/811420c6-b005-11e5-96fe-6bdaa550d571.png)

Those process name 'python' are issued by the command above.

Someone please help to look into this. 
",0,The gpu cores actually in use do not match with what I set in command ,"The gpu cores actually in use do not match with what I set in command  hi, 

I specific 2 gpus devices in command likes this,  . 
The file train_mnist.py is an example provided with source code.

Then I check the gpus status via command nvidia-smi,

it show likes,
![gpu](https://cloud.githubusercontent.com/assets/4373620/12064726/811420c6-b005-11e5-96fe-6bdaa550d571.png)

Those process name 'python' are issued by the command above.

Someone please help to look into this. 
"
incubator-mxnet,7970,"MNIST data loader fails unless ""resources"" package is manually installed.

Should ""resources"" package be a dependency installed along with mxnet?

## Environment info
Operating System:
Mac OS 10.12.6

Compiler:
Package used (Python/R/Scala/Julia):
Python 3.6.1
[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]

MXNet version:
0.11.0

## Error Message:
Running code in Straight Dope book,  mx.gluon.data.DataLoader fails to download MNIST data set unless python package ""resources"" is manually installed.

See https://github.com/zackchase/mxnet-the-straight-dope/issues/229


",0,"MNIST data loader requires Python ""resources"" package to be installed","MNIST data loader requires Python ""resources"" package to be installed MNIST data loader fails unless ""resources"" package is manually installed.

Should ""resources"" package be a dependency installed along with mxnet?

## Environment info
Operating System:
Mac OS 10.12.6

Compiler:
Package used (Python/R/Scala/Julia):
Python 3.6.1
[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]

MXNet version:
0.11.0

## Error Message:
Running code in Straight Dope book,  mx.gluon.data.DataLoader fails to download MNIST data set unless python package ""resources"" is manually installed.

See https://github.com/zackchase/mxnet-the-straight-dope/issues/229


"
incubator-mxnet,6186,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu 12.04
Compiler:
g++-4.8 nvcc
Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:
from source
MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :
src/operator/./cudnn_deconvolution-inl.h(124): error: identifier ""out"" is undefined
 detected during instantiation of ""mxnet::op::CuDNNDeconvolutionOp<DType>::CuDNNDeconvolutionOp(mxnet::op::DeconvolutionParam, int, int, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const mxnet::Context &) [with DType=float]"" 
src/operator/deconvolution.cu(47): here

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. make 


## What have you tried to solve it?

1. line 136 out.dptr_  change to out_ptr,  line  258 gwmat.dptr_ also 
then can compile, but I don't know whether it is correct.",0,cudnn_deconvolution-inl.h,"cudnn_deconvolution-inl.h For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu 12.04
Compiler:
g++-4.8 nvcc
Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:
from source
MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :
src/operator/./cudnn_deconvolution-inl.h(124): error: identifier ""out"" is undefined
 detected during instantiation of ""mxnet::op::CuDNNDeconvolutionOp<DType>::CuDNNDeconvolutionOp(mxnet::op::DeconvolutionParam, int, int, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const mxnet::Context &) [with DType=float]"" 
src/operator/deconvolution.cu(47): here

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. make 


## What have you tried to solve it?

1. line 136 out.dptr_  change to out_ptr,  line  258 gwmat.dptr_ also 
then can compile, but I don't know whether it is correct."
incubator-mxnet,5059,"Hi,
      I find there are some problems in updating the param num_update in optimizer.py.
For example,
      In the first iter, the first grad gets the lr when the num_update is 0 https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264 , and then it updates the num_update to 1, so the next grad and others will get the lr  when the num_update is 1,.
     In the second iter, the num_update of the first grad is 1, and others will be 2.
     ........ 
     This may lead to different grads get different lr. It doesn't matter if we use MultiFactorScheduler to get lr https://github.com/dmlc/mxnet/blob/master/python/mxnet/lr_scheduler.py#L85 . However, It does matter if we use other schedulers such as poly scheduler https://github.com/BVLC/caffe/blob/master/src/caffe/solvers/sgd_solver.cpp#L20 .  

    I think the function _update_count should be changed to       https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L136:
         if index not in self._index_update_count:
            self._index_update_count[index] = self.begin_num_update
        self.num_update = self._index_update_count[index]
        self._index_update_count[index] += 1

and there should be changed to  https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264
        self._update_count(index)
         lr = self._get_lr(index)
        wd = self._get_wd(index)




          
",0,some questions about the param num_update in optimizer.py,"some questions about the param num_update in optimizer.py Hi,
      I find there are some problems in updating the param num_update in optimizer.py.
For example,
      In the first iter, the first grad gets the lr when the num_update is 0 https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264 , and then it updates the num_update to 1, so the next grad and others will get the lr  when the num_update is 1,.
     In the second iter, the num_update of the first grad is 1, and others will be 2.
     ........ 
     This may lead to different grads get different lr. It doesn't matter if we use MultiFactorScheduler to get lr https://github.com/dmlc/mxnet/blob/master/python/mxnet/lr_scheduler.py#L85 . However, It does matter if we use other schedulers such as poly scheduler https://github.com/BVLC/caffe/blob/master/src/caffe/solvers/sgd_solver.cpp#L20 .  

    I think the function _update_count should be changed to       https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L136:
         if index not in self._index_update_count:
            self._index_update_count[index] = self.begin_num_update
        self.num_update = self._index_update_count[index]
        self._index_update_count[index] += 1

and there should be changed to  https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264
        self._update_count(index)
         lr = self._get_lr(index)
        wd = self._get_wd(index)




          
"
incubator-mxnet,817,"Hi, I've got a 'Segmentation fault' when I try to use a pre-trained model to do  operation. The model is converted from [vgg16](http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel) Caffe model by the tool in mxnet.  And the code works if I comment out the last line.
This is the code:



This is what I got from gdb

![gdb](http://r.loli.io/NBNF3i.png)
",0,Segmentation fault when using 'simple_bind',"Segmentation fault when using 'simple_bind' Hi, I've got a 'Segmentation fault' when I try to use a pre-trained model to do  operation. The model is converted from [vgg16](http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel) Caffe model by the tool in mxnet.  And the code works if I comment out the last line.
This is the code:



This is what I got from gdb

![gdb](http://r.loli.io/NBNF3i.png)
"
incubator-mxnet,5062,"i implement  gradient normalization clip as followed in file optimizer.py

is it right?",0,some question about implementing gradient normalization clip,"some question about implementing gradient normalization clip i implement  gradient normalization clip as followed in file optimizer.py

is it right?"
incubator-mxnet,5580,"say if I have a layer need some input parameters e.g. size = 10 .
How to set that in Custom Operator? I didnt see any examples in 
http://mxnet.io/how_to/new_op.html",0,How to create a Custom Operator with extra parameters in Python?,"How to create a Custom Operator with extra parameters in Python? say if I have a layer need some input parameters e.g. size = 10 .
How to set that in Custom Operator? I didnt see any examples in 
http://mxnet.io/how_to/new_op.html"
incubator-mxnet,16249,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The link obtained when searching on google/duckduckgo for mxnet gluon is 
https://mxnet.incubator.apache.org/versions/master/gluon/
The link however appears to lead to a ""Not found"" error. 


## Steps to reproduce
Paste https://mxnet.incubator.apache.org/versions/master/gluon/ into a web browser
",0,links broken for https://mxnet.incubator.apache.org/versions/master/gluon/,"links broken for https://mxnet.incubator.apache.org/versions/master/gluon/ Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The link obtained when searching on google/duckduckgo for mxnet gluon is 
https://mxnet.incubator.apache.org/versions/master/gluon/
The link however appears to lead to a ""Not found"" error. 


## Steps to reproduce
Paste https://mxnet.incubator.apache.org/versions/master/gluon/ into a web browser
"
incubator-mxnet,10476,"Try to use MXNET_TEST_SEED=1117986172
",0,Flaky test for test_operator.test_reduce,"Flaky test for test_operator.test_reduce Try to use MXNET_TEST_SEED=1117986172
"
incubator-mxnet,10919,"gluon.Block  method should accept not only strings, but also pathlib.Path types that are new in python 3.
",0,gluon.Block load_params method does not accept python3 pathlib.Path,"gluon.Block load_params method does not accept python3 pathlib.Path gluon.Block  method should accept not only strings, but also pathlib.Path types that are new in python 3.
"
incubator-mxnet,11165,"We use ImageIter to read jpg files,.
batch_size was set to 512. 
MXNET_CPU_WORKER_NTHREADS set to 48
It use about 0.35s per batch.
But it only use about 0.0618s per batch when we use ImageRecordIter to read rec file.

Why ImageIter is too slow?
Does too many augmenters called in python affect this speed?
Does MXNet has an interface can do all the task include read,decode,resize,crop,tanspose,rgb_mean in c++?",0,ImageIter much slower than ImageRecordIter,"ImageIter much slower than ImageRecordIter We use ImageIter to read jpg files,.
batch_size was set to 512. 
MXNET_CPU_WORKER_NTHREADS set to 48
It use about 0.35s per batch.
But it only use about 0.0618s per batch when we use ImageRecordIter to read rec file.

Why ImageIter is too slow?
Does too many augmenters called in python affect this speed?
Does MXNet has an interface can do all the task include read,decode,resize,crop,tanspose,rgb_mean in c++?"
incubator-mxnet,2968,"i have trained resnet-50 in imanget, top1 error is 25.41% and top-5 error is 7.93%, which is not very good, so do anyone reproduced it now? hope somebody can release the model for study other task~
(my code is in https://github.com/tornadomeet/ResNet, it support both imagnet and cifar training with different depth. )
",0,Training ResNet on imagenet,"Training ResNet on imagenet i have trained resnet-50 in imanget, top1 error is 25.41% and top-5 error is 7.93%, which is not very good, so do anyone reproduced it now? hope somebody can release the model for study other task~
(my code is in https://github.com/tornadomeet/ResNet, it support both imagnet and cifar training with different depth. )
"
incubator-mxnet,17109,"Scope:

1. SymbolBlock equivalent in C/C++, unify the executor implementation for symbol/module and the one for gluon blocks
2. migrate other versions of inference API
",0,[mxnet 2.0][item 3.2] Unify Executor ,"[mxnet 2.0][item 3.2] Unify Executor  Scope:

1. SymbolBlock equivalent in C/C++, unify the executor implementation for symbol/module and the one for gluon blocks
2. migrate other versions of inference API
"
incubator-mxnet,7684,"I try to follow The Custom Iterator section's code in the tutorial page at  https://mxnet.incubator.apache.org/tutorials/basic/data.html.  But I found these two line are never executed!
data = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_data, self.data_gen)]
label = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_label, self.label_gen)]
My python's version is python3.5 and mxnet is 0.95.
Does any could help to fix this problem?",0,Python3.5 MXNet doesn't execute for loop！！,"Python3.5 MXNet doesn't execute for loop！！ I try to follow The Custom Iterator section's code in the tutorial page at  https://mxnet.incubator.apache.org/tutorials/basic/data.html.  But I found these two line are never executed!
data = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_data, self.data_gen)]
label = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_label, self.label_gen)]
My python's version is python3.5 and mxnet is 0.95.
Does any could help to fix this problem?"
incubator-mxnet,8542,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
The dependency here on www.csie.ntu.edu.tw should be changed to be hosted on our own S3 bucket.  See https://github.com/apache/incubator-mxnet/blob/master/tests/python/unittest/test_io.py#L218 ",0,Remove dependency on http://www.csie.ntu.edu.tw for LibSVMIter test,"Remove dependency on http://www.csie.ntu.edu.tw for LibSVMIter test Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
The dependency here on www.csie.ntu.edu.tw should be changed to be hosted on our own S3 bucket.  See https://github.com/apache/incubator-mxnet/blob/master/tests/python/unittest/test_io.py#L218 "
incubator-mxnet,5153,"When I run the End2End Captcha Recognition (OCR) example, get a segmentation fault.
This is the original blog [url](http://blog.xlvector.net/2016-05/mxnet-ocr-cnn/)
**I changed the devs, from gpu to cpu, for lack of  hardware[gpu]**
Below is the main code:



## Environment info

Operating System:
virtual machine
Linux Mint 18[base on Ubuntu 16.04], 64bit
Compiler:
gcc 5.4.0
Package used (Python/R/Scala/Julia):
Python 2.7.12
MXNet version:
get from git master[2017-2-23]
If you are using python package, please provide
opencv 3.2

## Error Message:
### run in PyCharm
>Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
### gdb py-bt
>Traceback (most recent call first):
  File ""test-g.py"", line 56, in __iter__
    img = cv2.imdecode(img, cv2.IMREAD_COLOR)
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 236, in _train_multi_device
    for data_batch in train_data:
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 816, in fit
    sym_gen=self.sym_gen)
  File ""test-g.py"", line 135, in <module>
    model.fit(X = data_train, eval_data = data_test, eval_metric = Accuracy, batch_end_callback=mx.callback.Speedometer(32, 50),)
### gdb bt
>#0  0x0000000000000000 in ?? ()
#1  0x00007ffff18149ee in cv::imdecode(cv::_InputArray const&, int) ()
   from /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4
#2  0x00007fffd9728f92 in pyopencv_cv_imdecode(_object*, _object*, _object*) ()
   from /usr/lib/python2.7/dist-packages/cv2.so
#3  0x00000000004c468a in call_function (oparg=<optimized out>, 
    pp_stack=0x7fffffffd440) at ../Python/ceval.c:4350
#4  PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#5  0x00000000004dddca in gen_send_ex.isra.0.lto_priv ()
    at ../Objects/genobject.c:85
#6  0x00000000004c4c6f in PyEval_EvalFrameEx () at ../Python/ceval.c:2806
#7  0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#8  0x00000000004ca099 in fast_function (nk=17, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd7e0, 
    func=<function at remote 0x7fffd4b0c488>) at ../Python/ceval.c:4445
#9  call_function (oparg=<optimized out>, pp_stack=0x7fffffffd7e0)
    at ../Python/ceval.c:4370
#10 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#11 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#12 0x00000000004ca099 in fast_function (nk=4, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd9f0, 
    func=<function at remote 0x7fffd4b0d0c8>) at ../Python/ceval.c:4445
#13 call_function (oparg=<optimized out>, pp_stack=0x7fffffffd9f0)
---Type <return> to continue, or q <return> to quit---
    at ../Python/ceval.c:4370
#14 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#15 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#16 0x00000000004c2509 in PyEval_EvalCode (co=<optimized out>, 
    globals=<optimized out>, locals=<optimized out>) at ../Python/ceval.c:669
#17 0x00000000004f1def in run_mod.lto_priv () at ../Python/pythonrun.c:1376
#18 0x00000000004ec652 in PyRun_FileExFlags () at ../Python/pythonrun.c:1362
#19 0x00000000004eae31 in PyRun_SimpleFileExFlags ()
    at ../Python/pythonrun.c:948
#20 0x000000000049e14a in Py_Main () at ../Modules/main.c:640
#21 0x00007ffff7811830 in __libc_start_main (main=0x49dab0 <main>, argc=2, 
    argv=0x7fffffffde38, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7fffffffde28)
    at ../csu/libc-start.c:291
#22 0x000000000049d9d9 in _start ()


## What have you tried to solve it?

I find the point of interrupte is .
So I split this part to another file, only generate img from captcha module, and decode it by opencv.
It can run well.
But when I run the example, with mxnet, decode by opencv will be segmentation fault.

What's wrong?
",0,End2End Captcha Recognition (OCR) [Segmentation fault],"End2End Captcha Recognition (OCR) [Segmentation fault] When I run the End2End Captcha Recognition (OCR) example, get a segmentation fault.
This is the original blog [url](http://blog.xlvector.net/2016-05/mxnet-ocr-cnn/)
**I changed the devs, from gpu to cpu, for lack of  hardware[gpu]**
Below is the main code:



## Environment info

Operating System:
virtual machine
Linux Mint 18[base on Ubuntu 16.04], 64bit
Compiler:
gcc 5.4.0
Package used (Python/R/Scala/Julia):
Python 2.7.12
MXNet version:
get from git master[2017-2-23]
If you are using python package, please provide
opencv 3.2

## Error Message:
### run in PyCharm
>Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
### gdb py-bt
>Traceback (most recent call first):
  File ""test-g.py"", line 56, in __iter__
    img = cv2.imdecode(img, cv2.IMREAD_COLOR)
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 236, in _train_multi_device
    for data_batch in train_data:
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 816, in fit
    sym_gen=self.sym_gen)
  File ""test-g.py"", line 135, in <module>
    model.fit(X = data_train, eval_data = data_test, eval_metric = Accuracy, batch_end_callback=mx.callback.Speedometer(32, 50),)
### gdb bt
>#0  0x0000000000000000 in ?? ()
#1  0x00007ffff18149ee in cv::imdecode(cv::_InputArray const&, int) ()
   from /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4
#2  0x00007fffd9728f92 in pyopencv_cv_imdecode(_object*, _object*, _object*) ()
   from /usr/lib/python2.7/dist-packages/cv2.so
#3  0x00000000004c468a in call_function (oparg=<optimized out>, 
    pp_stack=0x7fffffffd440) at ../Python/ceval.c:4350
#4  PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#5  0x00000000004dddca in gen_send_ex.isra.0.lto_priv ()
    at ../Objects/genobject.c:85
#6  0x00000000004c4c6f in PyEval_EvalFrameEx () at ../Python/ceval.c:2806
#7  0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#8  0x00000000004ca099 in fast_function (nk=17, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd7e0, 
    func=<function at remote 0x7fffd4b0c488>) at ../Python/ceval.c:4445
#9  call_function (oparg=<optimized out>, pp_stack=0x7fffffffd7e0)
    at ../Python/ceval.c:4370
#10 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#11 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#12 0x00000000004ca099 in fast_function (nk=4, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd9f0, 
    func=<function at remote 0x7fffd4b0d0c8>) at ../Python/ceval.c:4445
#13 call_function (oparg=<optimized out>, pp_stack=0x7fffffffd9f0)
---Type <return> to continue, or q <return> to quit---
    at ../Python/ceval.c:4370
#14 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#15 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#16 0x00000000004c2509 in PyEval_EvalCode (co=<optimized out>, 
    globals=<optimized out>, locals=<optimized out>) at ../Python/ceval.c:669
#17 0x00000000004f1def in run_mod.lto_priv () at ../Python/pythonrun.c:1376
#18 0x00000000004ec652 in PyRun_FileExFlags () at ../Python/pythonrun.c:1362
#19 0x00000000004eae31 in PyRun_SimpleFileExFlags ()
    at ../Python/pythonrun.c:948
#20 0x000000000049e14a in Py_Main () at ../Modules/main.c:640
#21 0x00007ffff7811830 in __libc_start_main (main=0x49dab0 <main>, argc=2, 
    argv=0x7fffffffde38, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7fffffffde28)
    at ../csu/libc-start.c:291
#22 0x000000000049d9d9 in _start ()


## What have you tried to solve it?

I find the point of interrupte is .
So I split this part to another file, only generate img from captcha module, and decode it by opencv.
It can run well.
But when I run the example, with mxnet, decode by opencv will be segmentation fault.

What's wrong?
"
incubator-mxnet,8969,"Here are a couple of issues in incubator-mxnet/example/image-classification/benchmark_score.py.

Both prevent the script from running.

--> Issue #1
def get_symbol(network, batch_size):
    image_shape = (3,299,299) if network == 'inception-v3' else (3,224,224)
    num_layers = 0

get_symbol() for vgg16 doesn't accept a zero value for the number of layers.
Quick fix: insert this after ""num_layers = 0""
if network=='vgg':
    num_layers=16
Or use the same solution as for resnet (split and extract number of layers)

--> Issue #2
devs = [mx.gpu(0)] if len(get_gpus()) > 0 else []

get_gpus() relies on nvidia-smi which is not installed on machines that don't have GPUs (say, c4 instances on AWS).
",0,A couple of issues in benchmark_score.py,"A couple of issues in benchmark_score.py Here are a couple of issues in incubator-mxnet/example/image-classification/benchmark_score.py.

Both prevent the script from running.

--> Issue #1
def get_symbol(network, batch_size):
    image_shape = (3,299,299) if network == 'inception-v3' else (3,224,224)
    num_layers = 0

get_symbol() for vgg16 doesn't accept a zero value for the number of layers.
Quick fix: insert this after ""num_layers = 0""
if network=='vgg':
    num_layers=16
Or use the same solution as for resnet (split and extract number of layers)

--> Issue #2
devs = [mx.gpu(0)] if len(get_gpus()) > 0 else []

get_gpus() relies on nvidia-smi which is not installed on machines that don't have GPUs (say, c4 instances on AWS).
"
incubator-mxnet,2555,"recent problem... perhaps due to the recent changes in code.


",0,OSError: exception: stack overflow,"OSError: exception: stack overflow recent problem... perhaps due to the recent changes in code.


"
incubator-mxnet,10012,"The top level README.md has two links to logos that point to builds.apache.org which is now deprecated. These must point to the new CI
This should be fixed similar to this PR - https://github.com/apache/incubator-mxnet/pull/9908
",0,[Bug] There are two broken links on the top level README.md file which point to the old CI,"[Bug] There are two broken links on the top level README.md file which point to the old CI The top level README.md has two links to logos that point to builds.apache.org which is now deprecated. These must point to the new CI
This should be fixed similar to this PR - https://github.com/apache/incubator-mxnet/pull/9908
"
incubator-mxnet,11708,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",0,test_ndarray.test_cached has fixed seed that can mask flakiness,"test_ndarray.test_cached has fixed seed that can mask flakiness The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
"
incubator-mxnet,12377,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1529/pipeline

",0,Flaky test: test_mkldnn.test_activation,"Flaky test: test_mkldnn.test_activation http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1529/pipeline

"
incubator-mxnet,9758,"I want to write a custom operation in python, the output shape is unknown before running 'forward()'. So how to write the 'infer_shape()' function? It seems I must infer the output shape from the input shape, but without the input data. ",0,unknown output shape before inference,"unknown output shape before inference I want to write a custom operation in python, the output shape is unknown before running 'forward()'. So how to write the 'infer_shape()' function? It seems I must infer the output shape from the input shape, but without the input data. "
incubator-mxnet,1306,"Hello everyone,

My datasets is MNIST, I used the CNN algorithm to practice ML.

And I found the reference tutorial, [page 6 and 7](http://web.pdx.edu/~jduh/courses/Archive/geog481w07/Students/Ludwig_ImageConvolution.pdf).

<img width=""569"" alt=""2016-01-18 5 06 26"" src=""https://cloud.githubusercontent.com/assets/6274807/12387422/62b5a3e2-be07-11e5-8096-75c6f40987bc.png"">

I guess the default kernel is all '1' instances in a matrix. How to make the smoothly kernel like above slide.

This is the MXNet code with R.



Best,
Salmon.
",0,How to make a smooth kernel in Convolution Neural Networks?,"How to make a smooth kernel in Convolution Neural Networks? Hello everyone,

My datasets is MNIST, I used the CNN algorithm to practice ML.

And I found the reference tutorial, [page 6 and 7](http://web.pdx.edu/~jduh/courses/Archive/geog481w07/Students/Ludwig_ImageConvolution.pdf).

<img width=""569"" alt=""2016-01-18 5 06 26"" src=""https://cloud.githubusercontent.com/assets/6274807/12387422/62b5a3e2-be07-11e5-8096-75c6f40987bc.png"">

I guess the default kernel is all '1' instances in a matrix. How to make the smoothly kernel like above slide.

This is the MXNet code with R.



Best,
Salmon.
"
incubator-mxnet,5590,"It appears that calling one callback seem destroy the value in BatchEndParam.

Using callbacks like:


Results in the following log:

> INFO:root:Epoch[0] Batch [10]   Speed: 60.70 samples/sec        Train-accuracy=0.122869
> INFO:root:Epoch[0] Batch [20]   Speed: 60.85 samples/sec        Train-accuracy=0.157031
> INFO:root:Epoch[0] Batch [20]   Speed: 61.00 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [30]   Speed: 61.01 samples/sec        Train-accuracy=0.164844
> INFO:root:Epoch[0] Batch [40]   Speed: 61.20 samples/sec        Train-accuracy=0.191406
> INFO:root:Epoch[0] Batch [40]   Speed: 61.39 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [50]   Speed: 60.78 samples/sec        Train-accuracy=0.194531
> INFO:root:Epoch[0] Batch [60]   Speed: 60.84 samples/sec        Train-accuracy=0.221875
> INFO:root:Epoch[0] Batch [60]   Speed: 60.90 samples/sec        Train-accuracy=nan",0,callbacks destroy 'value' in BatchEndParam for subsequent callbacks of that type,"callbacks destroy 'value' in BatchEndParam for subsequent callbacks of that type It appears that calling one callback seem destroy the value in BatchEndParam.

Using callbacks like:


Results in the following log:

> INFO:root:Epoch[0] Batch [10]   Speed: 60.70 samples/sec        Train-accuracy=0.122869
> INFO:root:Epoch[0] Batch [20]   Speed: 60.85 samples/sec        Train-accuracy=0.157031
> INFO:root:Epoch[0] Batch [20]   Speed: 61.00 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [30]   Speed: 61.01 samples/sec        Train-accuracy=0.164844
> INFO:root:Epoch[0] Batch [40]   Speed: 61.20 samples/sec        Train-accuracy=0.191406
> INFO:root:Epoch[0] Batch [40]   Speed: 61.39 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [50]   Speed: 60.78 samples/sec        Train-accuracy=0.194531
> INFO:root:Epoch[0] Batch [60]   Speed: 60.84 samples/sec        Train-accuracy=0.221875
> INFO:root:Epoch[0] Batch [60]   Speed: 60.90 samples/sec        Train-accuracy=nan"
incubator-mxnet,11897,"i want to fixed all the layer's parameter  befor 'fc7'layer,and i change the code like this:


but when i run using pretrained model ,and save a checkpoint after one epoch,,,i compare the model and the pretrained model,,,i find that the layers' parameters before 'fc7'layer also changed,,,i don't know why,,,can anyone please help me.",0,why fixed_param_names in module have no use,"why fixed_param_names in module have no use i want to fixed all the layer's parameter  befor 'fc7'layer,and i change the code like this:


but when i run using pretrained model ,and save a checkpoint after one epoch,,,i compare the model and the pretrained model,,,i find that the layers' parameters before 'fc7'layer also changed,,,i don't know why,,,can anyone please help me."
incubator-mxnet,13274,"## Description
R test failing intermitently

## Environment info (Required)
Test failing on CI and could be flaky

For R user, please provide R :

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13266/1/pipeline

Have been observing above behavior on multiple PRs
",0,R test failing intermitently,"R test failing intermitently ## Description
R test failing intermitently

## Environment info (Required)
Test failing on CI and could be flaky

For R user, please provide R :

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13266/1/pipeline

Have been observing above behavior on multiple PRs
"
incubator-mxnet,3758,If someone here has successfully installed the GPU version of MXNET (gpu version for R) could please post instructions....the instructions for install do not work... ,0,Windows 10 Pro & MXNET GPU (For R Environment),Windows 10 Pro & MXNET GPU (For R Environment) If someone here has successfully installed the GPU version of MXNET (gpu version for R) could please post instructions....the instructions for install do not work... 
incubator-mxnet,8042,"Hai,

Is there is any utility which converts network written in mxnet  *.json format to mxnet symbols level code? Any options are available kindly let us know.",0,Convert network written in json format to mxnet symbol code?,"Convert network written in json format to mxnet symbol code? Hai,

Is there is any utility which converts network written in mxnet  *.json format to mxnet symbols level code? Any options are available kindly let us know."
incubator-mxnet,2732,"How do I limit  using  to only use one cpu core on a multicore machine in R?
",0,R: How to limit mxnet to one cpu core?,"R: How to limit mxnet to one cpu core? How do I limit  using  to only use one cpu core on a multicore machine in R?
"
incubator-mxnet,4029,"Hi,

I'm using a CNN in R to perform image classification with K different classes. However, I want to try another approach and do a ""one vs all"" classification with each label, so one label would be 1 and the rest would be 0.

My question is, what output layer should I use? If I use mx.symbol.SoftmaxOutput after a FullyConnected layer with one neuron is useless because it always predict 1 or even NaN for every example. LinearRegressionOutput gives a similar result.

My basic idea is that I need an output layer that performs 0.5 threshold on the single output neuron from the last FullyConnected layer.

Sorry if this is a dumb question, I'm still new to this field.
Thanks in advanced.",0,One vs All Classification,"One vs All Classification Hi,

I'm using a CNN in R to perform image classification with K different classes. However, I want to try another approach and do a ""one vs all"" classification with each label, so one label would be 1 and the rest would be 0.

My question is, what output layer should I use? If I use mx.symbol.SoftmaxOutput after a FullyConnected layer with one neuron is useless because it always predict 1 or even NaN for every example. LinearRegressionOutput gives a similar result.

My basic idea is that I need an output layer that performs 0.5 threshold on the single output neuron from the last FullyConnected layer.

Sorry if this is a dumb question, I'm still new to this field.
Thanks in advanced."
incubator-mxnet,2506,"Exception: Unknown Layer BatchNorm!
",0,caffe_converter resnet error batchnorm,"caffe_converter resnet error batchnorm Exception: Unknown Layer BatchNorm!
"
incubator-mxnet,16937,"## Description

Very weird problem:

Expected output:




What deepNumpy outputs:







",0,[Numpy] Zero-size tensor add zero-size sum raises exception,"[Numpy] Zero-size tensor add zero-size sum raises exception ## Description

Very weird problem:

Expected output:




What deepNumpy outputs:







"
incubator-mxnet,715,"Say like binary classification  example , where each instance is sparse .
",0,Could we give one text classification example ?,"Could we give one text classification example ? Say like binary classification  example , where each instance is sparse .
"
incubator-mxnet,919,"Such as convolution, sometimes we don't need do it on all the image but only on small and sparse places.
Sparse operation can avoid unnecessary calculations. It can improve the performance on the ARM or CPU drastically.
",0,Sparse Operators should be on the formal schedule,"Sparse Operators should be on the formal schedule Such as convolution, sometimes we don't need do it on all the image but only on small and sparse places.
Sparse operation can avoid unnecessary calculations. It can improve the performance on the ARM or CPU drastically.
"
incubator-mxnet,2763,"Hi all,
        I want to get the shape of a certain symbol, take a look at the following code:



How can I get the shape of ?

I know for symbol, one can use  to get the shape of symbols.
But in this situation,  will return a list of shapes, which respect to all the symbol before the node of  in the compute symbol graph, say. As I want to get the shape of , and the order in  is uncertain, one can not get the expected symbol shape he wants.

Is there some solutions for this problem?
",0,how can i get the shape of a certain symbol,"how can i get the shape of a certain symbol Hi all,
        I want to get the shape of a certain symbol, take a look at the following code:



How can I get the shape of ?

I know for symbol, one can use  to get the shape of symbols.
But in this situation,  will return a list of shapes, which respect to all the symbol before the node of  in the compute symbol graph, say. As I want to get the shape of , and the order in  is uncertain, one can not get the expected symbol shape he wants.

Is there some solutions for this problem?
"
incubator-mxnet,5258,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-4.9x
Package used (Python/R/Scala/Julia):
python
MXNet version:
0.9.4
Or if installed from source:
yes
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23
If you are using python package, please provide

Python version and distribution:
python2.7
If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

following code is caption_module:  


I just use pretrain-vgg to extract fc-layer ouputs, and then input them into caption module name , I create custom-dataIter, process them by vgg and then copy them into .
However, it raises above error all the time.
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.Try to pop item in  about 
2.Use Module API, and bind symbol.
3.
",0,Embedding layer doesn't support calculate data gradient,"Embedding layer doesn't support calculate data gradient For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-4.9x
Package used (Python/R/Scala/Julia):
python
MXNet version:
0.9.4
Or if installed from source:
yes
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23
If you are using python package, please provide

Python version and distribution:
python2.7
If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

following code is caption_module:  


I just use pretrain-vgg to extract fc-layer ouputs, and then input them into caption module name , I create custom-dataIter, process them by vgg and then copy them into .
However, it raises above error all the time.
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.Try to pop item in  about 
2.Use Module API, and bind symbol.
3.
"
incubator-mxnet,12523,"## Description
There are some minor problems with the [scala intellij tutorial](https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html) with code [here](https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/scala/mxnet_scala_on_intellij.md) that could be fixed to improve the experience for new users following the tutorial.

## Issues

- When I added the MXNet package as a dependency to the pom.xml by copying the XML from the tutorial, the package version specified (1.2.0) could not be found with Intellij notification error .  Updating the version to 1.2.1 fixed this issue.
- With the initial code, the sample specification file specs.scala is missing a dependency. It causes an error when trying to run the app on step 6
- When running, the following warning shows up: 

  I was able to resolve it by adding the org.slf4j api and log4j12 dependencies: 

- The tutorial should additionally include the file target/classes/log4j.properties
- It might be worth including a note for users building mxnet scala from source that they can use the scala mxnet they built as opposed to the version from maven by changing the pom.xml.  For me (and my SystemPath including my user), it looks like:


## Environment info (Required)
floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()

3. Scala runtime if applicable: ()
Specified in pom.xml as 2.11.8 (scala.compat.version 2.11)

MXNet commit hash:
ac4ef212f6269469f3f3827da49e43fb42f1398f

@mxnet-label-bot[Doc, Scala]",0,"Updates to tutorial ""Run MXNet Scala Examples Using the IntelliJ IDE (macOS)""","Updates to tutorial ""Run MXNet Scala Examples Using the IntelliJ IDE (macOS)"" ## Description
There are some minor problems with the [scala intellij tutorial](https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html) with code [here](https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/scala/mxnet_scala_on_intellij.md) that could be fixed to improve the experience for new users following the tutorial.

## Issues

- When I added the MXNet package as a dependency to the pom.xml by copying the XML from the tutorial, the package version specified (1.2.0) could not be found with Intellij notification error .  Updating the version to 1.2.1 fixed this issue.
- With the initial code, the sample specification file specs.scala is missing a dependency. It causes an error when trying to run the app on step 6
- When running, the following warning shows up: 

  I was able to resolve it by adding the org.slf4j api and log4j12 dependencies: 

- The tutorial should additionally include the file target/classes/log4j.properties
- It might be worth including a note for users building mxnet scala from source that they can use the scala mxnet they built as opposed to the version from maven by changing the pom.xml.  For me (and my SystemPath including my user), it looks like:


## Environment info (Required)
floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()

3. Scala runtime if applicable: ()
Specified in pom.xml as 2.11.8 (scala.compat.version 2.11)

MXNet commit hash:
ac4ef212f6269469f3f3827da49e43fb42f1398f

@mxnet-label-bot[Doc, Scala]"
incubator-mxnet,7522,"Hi Dear mxnet users and developers:
    I understand that there is example of how to use intermediate layer output in prediction.
   However, in training and validation, is it possible to use intermediate layer output to calculate an evaluation metric?
   Thanks a lot",0,how to calculate an evaluation metric using intermediate layer output?,"how to calculate an evaluation metric using intermediate layer output? Hi Dear mxnet users and developers:
    I understand that there is example of how to use intermediate layer output in prediction.
   However, in training and validation, is it possible to use intermediate layer output to calculate an evaluation metric?
   Thanks a lot"
incubator-mxnet,11735,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",0,test_optimizer.test_ftml has fixed seed that can mask flakiness,"test_optimizer.test_ftml has fixed seed that can mask flakiness The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
"
incubator-mxnet,3096,"I tried using part of ami data, and using the default.cfg and my transform file is like this：



then got some error:



I changed transform file to



then the following error reported:



then I modifed default.cfg



then another error reported:



please show me how to set the ydim, thanks.
",0,How to set parameter of speech demo,"How to set parameter of speech demo I tried using part of ami data, and using the default.cfg and my transform file is like this：



then got some error:



I changed transform file to



then the following error reported:



then I modifed default.cfg



then another error reported:



please show me how to set the ydim, thanks.
"
incubator-mxnet,4471,"After going through so much inconveniences in Tensorflow and Theano, now I am trying MXNET.
I have read through the MXNET API, there is no control flow operation, i.e., functionally equivalent to tf.select/tf.cond or theano.switch/theano.ifelse . This missing functionality will limit the toolkit's capability in handling variable-length sequences.

Take note that without control flow operators, you can still perform LSTM-based variable-sequence-length prediction using masking. However, there is still something that you cannot do. For example, in training a RNN language model, I would like to reset the state vector to some specific trainable parameter whenever I encounter a sentence begin, i.e., .

So I hereby hope the developer can implement this important function. Thanks!",0,Lack of control flow operators: functionally inferior to Tensorflow and Theano,"Lack of control flow operators: functionally inferior to Tensorflow and Theano After going through so much inconveniences in Tensorflow and Theano, now I am trying MXNET.
I have read through the MXNET API, there is no control flow operation, i.e., functionally equivalent to tf.select/tf.cond or theano.switch/theano.ifelse . This missing functionality will limit the toolkit's capability in handling variable-length sequences.

Take note that without control flow operators, you can still perform LSTM-based variable-sequence-length prediction using masking. However, there is still something that you cannot do. For example, in training a RNN language model, I would like to reset the state vector to some specific trainable parameter whenever I encounter a sentence begin, i.e., .

So I hereby hope the developer can implement this important function. Thanks!"
incubator-mxnet,5370,"
Hello,

I am using Mxnet R package and walking through the following tutorial:
http://mxnet.io/tutorials/r/charRnnModel.html

I see that the lstm that was trained is used to generate text. However, is there a way to use the lstm model to evaluate test text?

When using language models, we can use perplexity to evaluate test data. Lower the perplexity, closer the language model to test data. Higher the perplexity, the farther away the language model is to test data.

Is there an equivalent score that can be generated using LSTM?

Thanks,
Aarthi

## Environment info
Operating System: MacOS

Compiler:

Package used (Python/R/Scala/Julia): R

R :
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mxnet_0.9.4   h2o_3.10.2.2  ggplot2_2.2.1 plyr_1.8.4   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.7      knitr_1.15.1     magrittr_1.5     devtools_1.12.0 
 [5] munsell_0.4.3    colorspace_1.2-7 R6_2.2.0         stringr_1.1.0   
 [9] httr_1.2.1       visNetwork_1.0.3 tools_3.3.2      drat_0.1.2      
[13] grid_3.3.2       gtable_0.2.0     git2r_0.18.0     withr_1.0.2     
[17] htmltools_0.3.5  lazyeval_0.2.0   assertthat_0.1   digest_0.6.10   
[21] tibble_1.2       codetools_0.2-15 htmlwidgets_0.7  bitops_1.0-6    
[25] RCurl_1.95-4.8   curl_2.2         memoise_1.0.0    labeling_0.3    
[29] stringi_1.1.2    scales_0.4.1     jsonlite_1.1    

## Error Message:
No error message
",0,LSTM MXNet perplexity score,"LSTM MXNet perplexity score 
Hello,

I am using Mxnet R package and walking through the following tutorial:
http://mxnet.io/tutorials/r/charRnnModel.html

I see that the lstm that was trained is used to generate text. However, is there a way to use the lstm model to evaluate test text?

When using language models, we can use perplexity to evaluate test data. Lower the perplexity, closer the language model to test data. Higher the perplexity, the farther away the language model is to test data.

Is there an equivalent score that can be generated using LSTM?

Thanks,
Aarthi

## Environment info
Operating System: MacOS

Compiler:

Package used (Python/R/Scala/Julia): R

R :
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mxnet_0.9.4   h2o_3.10.2.2  ggplot2_2.2.1 plyr_1.8.4   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.7      knitr_1.15.1     magrittr_1.5     devtools_1.12.0 
 [5] munsell_0.4.3    colorspace_1.2-7 R6_2.2.0         stringr_1.1.0   
 [9] httr_1.2.1       visNetwork_1.0.3 tools_3.3.2      drat_0.1.2      
[13] grid_3.3.2       gtable_0.2.0     git2r_0.18.0     withr_1.0.2     
[17] htmltools_0.3.5  lazyeval_0.2.0   assertthat_0.1   digest_0.6.10   
[21] tibble_1.2       codetools_0.2-15 htmlwidgets_0.7  bitops_1.0-6    
[25] RCurl_1.95-4.8   curl_2.2         memoise_1.0.0    labeling_0.3    
[29] stringi_1.1.2    scales_0.4.1     jsonlite_1.1    

## Error Message:
No error message
"
incubator-mxnet,13080,"There is a failure occurring on the Jenkins in the Scala GPU task.  The failure is occurring when running ""make scalapkg"" to build the core module.

One sample error ending is:


We have identified a number of Jenkins runs that produced this:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13077/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13071/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13052/2/pipeline

The problem has also been observed on the dev Jenkins:
http://jenkins.mxnet-ci-dev.amazon-ml.com/blue/organizations/jenkins/restricted-publish-artifacts/detail/automate-maven/61/pipeline

",0,Jenkins failing on Scala GPU,"Jenkins failing on Scala GPU There is a failure occurring on the Jenkins in the Scala GPU task.  The failure is occurring when running ""make scalapkg"" to build the core module.

One sample error ending is:


We have identified a number of Jenkins runs that produced this:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13077/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13071/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13052/2/pipeline

The problem has also been observed on the dev Jenkins:
http://jenkins.mxnet-ci-dev.amazon-ml.com/blue/organizations/jenkins/restricted-publish-artifacts/detail/automate-maven/61/pipeline

"
incubator-mxnet,6600,"I am trying to run a converted Caffe model, a ResNet 50 model that I trained on my own set of images. I have converted the model using the Caffe converter from the most recent master branch of MXNet. However, when trying to run with the Scala bindings, I have the following problem. Seems to me that  is not found in my Scala library (see below).

Note that I could run a VGG-16 model, after some edits.

## Environment info
Operating System: Mac OSX El Capitan 10.11.5

Compiler: SBT

Package used (Python/R/Scala/Julia): Scala

MXNet version: using  from [Maven Respositories](https://mvnrepository.com/)

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Basically, this layer from the model definition JSON produces the problem:


The full model definition, a ResNet 50 layer model, below:



## What have you tried to solve it?

1. tried to run on my own published JAR, but the problem persists.
2. checked the Scala library, there doesn't seem to have a .

",0,Missing `broadcast_add` layer in MXNet Scala binding,"Missing `broadcast_add` layer in MXNet Scala binding I am trying to run a converted Caffe model, a ResNet 50 model that I trained on my own set of images. I have converted the model using the Caffe converter from the most recent master branch of MXNet. However, when trying to run with the Scala bindings, I have the following problem. Seems to me that  is not found in my Scala library (see below).

Note that I could run a VGG-16 model, after some edits.

## Environment info
Operating System: Mac OSX El Capitan 10.11.5

Compiler: SBT

Package used (Python/R/Scala/Julia): Scala

MXNet version: using  from [Maven Respositories](https://mvnrepository.com/)

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Basically, this layer from the model definition JSON produces the problem:


The full model definition, a ResNet 50 layer model, below:



## What have you tried to solve it?

1. tried to run on my own published JAR, but the problem persists.
2. checked the Scala library, there doesn't seem to have a .

"
incubator-mxnet,12843,"The following code doesn't work.

It generates the error as below:
",0,MXNet doesn't work with scipy int64,"MXNet doesn't work with scipy int64 The following code doesn't work.

It generates the error as below:
"
incubator-mxnet,5028,"I have implemented model with Python sucessfully but an error arises out in C++:

param-symbol.json ... 278523 bytes
param-0020.params ... 38367630 bytes
[15:32:30] E:\OpenSource\mxnet0.9.3\mxnet\src\nnvm\legacy_json_util.cc:153: Load
ing symbol saved by previous version v0.9.1. Attempting to upgrade...
[15:32:39] E:\OpenSource\mxnet0.9.3\mxnet\nnvm\include\dmlc/logging.h:300: [15:3
2:39] e:\opensource\mxnet0.9.3\mxnet\src\operator\./softmax_output-inl.h:307: Ch
eck failed: (*in_type)[i] == dtype (4 vs. 0) This layer requires uniform type. E
xpected 0 v.s. given 4 at label
Assertion failed: pred_hnd, file E:\OpenSource\mxnet0.9.3\mxnet\example\image-cl
assification\predict-cpp\image-classification-predict.cc, line 227
--------------------------------------------------------------------------------------------
here is my code:


----------------------------------------------------------------------
How can I fix it?",0,"I want to implement CNN_LSTM_CTC with C++ instead of Python, but an error arises out","I want to implement CNN_LSTM_CTC with C++ instead of Python, but an error arises out I have implemented model with Python sucessfully but an error arises out in C++:

param-symbol.json ... 278523 bytes
param-0020.params ... 38367630 bytes
[15:32:30] E:\OpenSource\mxnet0.9.3\mxnet\src\nnvm\legacy_json_util.cc:153: Load
ing symbol saved by previous version v0.9.1. Attempting to upgrade...
[15:32:39] E:\OpenSource\mxnet0.9.3\mxnet\nnvm\include\dmlc/logging.h:300: [15:3
2:39] e:\opensource\mxnet0.9.3\mxnet\src\operator\./softmax_output-inl.h:307: Ch
eck failed: (*in_type)[i] == dtype (4 vs. 0) This layer requires uniform type. E
xpected 0 v.s. given 4 at label
Assertion failed: pred_hnd, file E:\OpenSource\mxnet0.9.3\mxnet\example\image-cl
assification\predict-cpp\image-classification-predict.cc, line 227
--------------------------------------------------------------------------------------------
here is my code:


----------------------------------------------------------------------
How can I fix it?"
incubator-mxnet,4539,"I don't know if this is the best place to communicate this, but I tried copy-pasting the only Scala [example](http://mxnet.io/tutorials/scala/mnist.html) in the website and it doesn't compile. 

I got it to compile by doing what's described below. I'm not sure whether that was the right fix (later I get a core dumped that I'll post in a separate issue). This is just a heads up for you guys to be aware of the problem with the website.

## Environment info
Operating System:
Ubuntu 16.10 amd64

Compiler:
sbt

Package used (Python/R/Scala/Julia):
Scala package
scalaVersion 2.11.8

MXNet version:
""ml.dmlc.mxnet"" % ""mxnet-full_2.10-linux-x86_64-gpu"" % ""0.1.1""

## Error Message:

## Minimum reproducible example


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Clone https://github.com/danimateos/mxnet-playground/tree/broken
2. 

## What have you tried to solve it?

I removed the  in

and got it to compile. ",0,Scala example on website doesn't compile,"Scala example on website doesn't compile I don't know if this is the best place to communicate this, but I tried copy-pasting the only Scala [example](http://mxnet.io/tutorials/scala/mnist.html) in the website and it doesn't compile. 

I got it to compile by doing what's described below. I'm not sure whether that was the right fix (later I get a core dumped that I'll post in a separate issue). This is just a heads up for you guys to be aware of the problem with the website.

## Environment info
Operating System:
Ubuntu 16.10 amd64

Compiler:
sbt

Package used (Python/R/Scala/Julia):
Scala package
scalaVersion 2.11.8

MXNet version:
""ml.dmlc.mxnet"" % ""mxnet-full_2.10-linux-x86_64-gpu"" % ""0.1.1""

## Error Message:

## Minimum reproducible example


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Clone https://github.com/danimateos/mxnet-playground/tree/broken
2. 

## What have you tried to solve it?

I removed the  in

and got it to compile. "
incubator-mxnet,4638,"When I use sgd with momentum, I train for 10 epoches first and save the parameters, but the state created by mx.optimizer.Updater for gradient updates with momentum is not saved, so if I want to train the same model from 10th epoch, the state will be initialized with all zeros, which is not what i want, so i want to know whether there is the solution to this problem? Thanks",0,issue using sgd with momentum,"issue using sgd with momentum When I use sgd with momentum, I train for 10 epoches first and save the parameters, but the state created by mx.optimizer.Updater for gradient updates with momentum is not saved, so if I want to train the same model from 10th epoch, the state will be initialized with all zeros, which is not what i want, so i want to know whether there is the solution to this problem? Thanks"
incubator-mxnet,4303,"  // test pad
the scala code IOSuite.scala   NDArrayIter hasNext is false but the size is 32

",0,NDArrayIter hasNext ,"NDArrayIter hasNext    // test pad
the scala code IOSuite.scala   NDArrayIter hasNext is false but the size is 32

"
incubator-mxnet,3086,"In R, I wasted hours figuring out that labels are zero-indexed, because in R it is natural to assume everything are 1-indexed. In the attached file, if the labels are 0-indexed, then the predictions will appear inaccurate.

I suggest that in the documentation for 'mx.mlp' and 'mx.model.FeedForward.create' and others that can use softmax included something saying the 'y' or 'label' is zero-indexed in the case of softmax


[R.txt](https://github.com/dmlc/mxnet/files/429063/R.txt)
",0,"In R documentation, remind user that softmax labels are 0 indexed","In R documentation, remind user that softmax labels are 0 indexed In R, I wasted hours figuring out that labels are zero-indexed, because in R it is natural to assume everything are 1-indexed. In the attached file, if the labels are 0-indexed, then the predictions will appear inaccurate.

I suggest that in the documentation for 'mx.mlp' and 'mx.model.FeedForward.create' and others that can use softmax included something saying the 'y' or 'label' is zero-indexed in the case of softmax


[R.txt](https://github.com/dmlc/mxnet/files/429063/R.txt)
"
incubator-mxnet,11430,"## Description
problem happened with a self-created dataset for lstm_bucketing example on CPU

But dataset with rnn-time-major works good 

## Environment info (Required)

floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):

Python 

MXNet commit hash:
7c1acb489a2d7546ffac55f5c2764f1e92e77306

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from  to  is deprecated. In future, it will be treated as .
  from ._conv import register_converters as _register_converters
WARNING: discarded 0 sentences longer than the largest bucket.
WARNING: discarded 0 sentences longer than the largest bucket.
Traceback (most recent call last):
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1521, in simple_bind
    ctypes.byref(exe_handle)))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 210, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""lstm_bucketing.py"", line 126, in <module>
    batch_end_callback  = mx.callback.Speedometer(args.batch_size, args.disp_batches, auto_reset=False))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 515, in fit
    self.forward_backward(data_batch)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 194, in forward_backward
    self.forward(data_batch, is_train=True)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 455, in forward
    data_batch.provide_label)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 376, in switch_bucket
    force_rebind=False, shared_module=self._buckets[self._default_bucket_key])
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/module.py"", line 430, in bind
    state_names=self._state_names)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 279, in __init__
    self.bind_exec(data_shapes, label_shapes, shared_group)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 375, in bind_exec
    shared_group))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 662, in _bind_ith_exec
    shared_buffer=shared_data_arrays, **input_shapes)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1527, in simple_bind
    raise RuntimeError(error_msg)
RuntimeError: simple_bind error. Arguments:
data: (32, 30)
softmax_label: (32, 30)
Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python lstm_bucketing.py
",0,lstm_bucketing example has evenly divide problem with self create dataset ,"lstm_bucketing example has evenly divide problem with self create dataset  ## Description
problem happened with a self-created dataset for lstm_bucketing example on CPU

But dataset with rnn-time-major works good 

## Environment info (Required)

floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):

Python 

MXNet commit hash:
7c1acb489a2d7546ffac55f5c2764f1e92e77306

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from  to  is deprecated. In future, it will be treated as .
  from ._conv import register_converters as _register_converters
WARNING: discarded 0 sentences longer than the largest bucket.
WARNING: discarded 0 sentences longer than the largest bucket.
Traceback (most recent call last):
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1521, in simple_bind
    ctypes.byref(exe_handle)))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 210, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""lstm_bucketing.py"", line 126, in <module>
    batch_end_callback  = mx.callback.Speedometer(args.batch_size, args.disp_batches, auto_reset=False))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 515, in fit
    self.forward_backward(data_batch)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 194, in forward_backward
    self.forward(data_batch, is_train=True)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 455, in forward
    data_batch.provide_label)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 376, in switch_bucket
    force_rebind=False, shared_module=self._buckets[self._default_bucket_key])
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/module.py"", line 430, in bind
    state_names=self._state_names)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 279, in __init__
    self.bind_exec(data_shapes, label_shapes, shared_group)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 375, in bind_exec
    shared_group))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 662, in _bind_ith_exec
    shared_buffer=shared_data_arrays, **input_shapes)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1527, in simple_bind
    raise RuntimeError(error_msg)
RuntimeError: simple_bind error. Arguments:
data: (32, 30)
softmax_label: (32, 30)
Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python lstm_bucketing.py
"
incubator-mxnet,14112,line 33   AND (NOT MSVC) ? MKLDNN不支持VC编译器吗,0,CMakeLists.txt,CMakeLists.txt line 33   AND (NOT MSVC) ? MKLDNN不支持VC编译器吗
incubator-mxnet,5900,"I am trying to use the CrossEntropyLoss() layer as an output, and get an error saying it needs 2 inputs. (data and label). But when I instead use SoftmaxOutput, I only need to provide the data, and the label is provided via the training iterator. Is there a way I can use the cross entropy loss with only providing data?


## Minimum reproducible example


depth = 3

	data = mx.sym.Variable('data')
	# layer 1 is as defined
	net = mx.sym.FullyConnected(data=data,name='fc1',num_hidden=64)
	net = mx.sym.Activation(data=net,name='ac1',act_type=""relu"")
	net = mx.sym.Dropout(data=net,name='dl1',p=0.1)
	# remaining hidden layers
	for layer in xrange(2,depth+1):
		net = mx.sym.FullyConnected(data=net,name='fc'+str(layer),num_hidden=64)
		net = mx.sym.Activation(data=net,name='ac'+str(layer),act_type=""relu"")
		net = mx.sym.Dropout(data=net,name='dl'+str(layer),p=0.1)
	# output layer
	net = mx.sym.FullyConnected(data=net,name='fcout',num_hidden=10)
	net = mx.sym.SoftmaxOutput(data=net,name='softmax')
	#net = rt.CrossEntropyLoss(data=net)
	return net

uncommenting the second-last line above (and commenting the line above it) gives me the error
",0,Using CrossEntropyLoss in the output layer,"Using CrossEntropyLoss in the output layer I am trying to use the CrossEntropyLoss() layer as an output, and get an error saying it needs 2 inputs. (data and label). But when I instead use SoftmaxOutput, I only need to provide the data, and the label is provided via the training iterator. Is there a way I can use the cross entropy loss with only providing data?


## Minimum reproducible example


depth = 3

	data = mx.sym.Variable('data')
	# layer 1 is as defined
	net = mx.sym.FullyConnected(data=data,name='fc1',num_hidden=64)
	net = mx.sym.Activation(data=net,name='ac1',act_type=""relu"")
	net = mx.sym.Dropout(data=net,name='dl1',p=0.1)
	# remaining hidden layers
	for layer in xrange(2,depth+1):
		net = mx.sym.FullyConnected(data=net,name='fc'+str(layer),num_hidden=64)
		net = mx.sym.Activation(data=net,name='ac'+str(layer),act_type=""relu"")
		net = mx.sym.Dropout(data=net,name='dl'+str(layer),p=0.1)
	# output layer
	net = mx.sym.FullyConnected(data=net,name='fcout',num_hidden=10)
	net = mx.sym.SoftmaxOutput(data=net,name='softmax')
	#net = rt.CrossEntropyLoss(data=net)
	return net

uncommenting the second-last line above (and commenting the line above it) gives me the error
"
incubator-mxnet,1814,"Dear all,
I want to initialise the parameters of BatchNorm by hand.
Here is how I initialise  and :



Yet I encounter the following error:
 when checking the type of . I notice it is in the aux, then I am wondering what is the proper way of initialising the parameters of BatchNorm?
Thanks in advance.
",0,How to initialise BatchNorm by hand?,"How to initialise BatchNorm by hand? Dear all,
I want to initialise the parameters of BatchNorm by hand.
Here is how I initialise  and :



Yet I encounter the following error:
 when checking the type of . I notice it is in the aux, then I am wondering what is the proper way of initialising the parameters of BatchNorm?
Thanks in advance.
"
incubator-mxnet,6115,"hi, I want to add batchnorm layer after i2h in gru. Here is the code:



In this way, the gamma and beta of bn are shared at each time step. 
But the aux states can't be shared like this and I get this error:

seems the aux_params are unrolled with the max input length, but duplicate names are not allowed.

I also try the following code in speech_recognition example, but it seems cannot solve the unfixed number of params due to the variable length input in my case.

and it returns the aux_params index out of range error.
I find several issues related, but seems have not soloved, like #3076 and #2663.

Thanks for your time and effort.",0,how to share auxiliary states of batchnorm in rnn with variable length input,"how to share auxiliary states of batchnorm in rnn with variable length input hi, I want to add batchnorm layer after i2h in gru. Here is the code:



In this way, the gamma and beta of bn are shared at each time step. 
But the aux states can't be shared like this and I get this error:

seems the aux_params are unrolled with the max input length, but duplicate names are not allowed.

I also try the following code in speech_recognition example, but it seems cannot solve the unfixed number of params due to the variable length input in my case.

and it returns the aux_params index out of range error.
I find several issues related, but seems have not soloved, like #3076 and #2663.

Thanks for your time and effort."
incubator-mxnet,2514,"

error is like this 

pkg-config --cflags opencvpkg-config --cflags opencv
",0,warp-ctc plugin compilation error,"warp-ctc plugin compilation error 

error is like this 

pkg-config --cflags opencvpkg-config --cflags opencv
"
incubator-mxnet,6530,"nvvm's NNSymbolListInputNames should be implement as a new method in symbol 
to list input names @piiswrong ",0,nvvm's NNSymbolListInputNames,"nvvm's NNSymbolListInputNames nvvm's NNSymbolListInputNames should be implement as a new method in symbol 
to list input names @piiswrong "
incubator-mxnet,4800,"I propose the following improvements for the mxnet Scala package, mostly making it more idiomatic and user-friendly for Scala users (could be in the form of a higher-level API while retaining the current API as the lower-level API):

 - Current API is full of , which is not at all idiomatic Scala. Manually rewrite them to normal Scala functions with default parameters. Without the reference of the mxnet Python API I'm really lost at how to use these layers/functions.
 - RNNs: Utilize the Scala //etc operations on s to automatically unroll the RNN computation graph. E.g. make an LSTM unit as a function of type , so that you can just say  to unroll an LSTM network.
 - Revamping the BucketIO/DataBatch/etc. stuff to be more Scala-idiomatic.
 - Support for GPU on Mac OS X (I've attempted this but failed)
 - Better documentations
 - Better API for executors/gradients maps/etc.
 - [tentative] Typesafe s. Encode the rank/order of the tensor into the type system (What Scala is good at! ), so that an NDArray like  means that it is of rank-3 and each cell contains a  (can be done with the typeclass / phantom type pattern in Scala and with shapeless (https://github.com/milessabin/shapeless)). Concatenation/slicing/etc. will all encode the ranks of the resulting NDArray/Symbol. This enhances compile-time type safety, e.g.  layer is a function whose type is . You cannot pass a symbol with  into an embedding layer.
 - [tentative] Migrate the build system from  to .

I can first come up with a prototype of this (also for my own use in NLP research) and we can discuss.

@javelinjs @Ldpe2G @piiswrong @jermainewang ",0,Proposed improvements for the mxnet Scala package,"Proposed improvements for the mxnet Scala package I propose the following improvements for the mxnet Scala package, mostly making it more idiomatic and user-friendly for Scala users (could be in the form of a higher-level API while retaining the current API as the lower-level API):

 - Current API is full of , which is not at all idiomatic Scala. Manually rewrite them to normal Scala functions with default parameters. Without the reference of the mxnet Python API I'm really lost at how to use these layers/functions.
 - RNNs: Utilize the Scala //etc operations on s to automatically unroll the RNN computation graph. E.g. make an LSTM unit as a function of type , so that you can just say  to unroll an LSTM network.
 - Revamping the BucketIO/DataBatch/etc. stuff to be more Scala-idiomatic.
 - Support for GPU on Mac OS X (I've attempted this but failed)
 - Better documentations
 - Better API for executors/gradients maps/etc.
 - [tentative] Typesafe s. Encode the rank/order of the tensor into the type system (What Scala is good at! ), so that an NDArray like  means that it is of rank-3 and each cell contains a  (can be done with the typeclass / phantom type pattern in Scala and with shapeless (https://github.com/milessabin/shapeless)). Concatenation/slicing/etc. will all encode the ranks of the resulting NDArray/Symbol. This enhances compile-time type safety, e.g.  layer is a function whose type is . You cannot pass a symbol with  into an embedding layer.
 - [tentative] Migrate the build system from  to .

I can first come up with a prototype of this (also for my own use in NLP research) and we can discuss.

@javelinjs @Ldpe2G @piiswrong @jermainewang "
incubator-mxnet,8564,"## Description
The test test_operator_gpu.test_residual_fused is causing a Cuda 'too many resources' error during a tests with the latest build of MXNet.

## Environment info (Required)
p2 instance with DLAMI CUDA 9, latest MXNet built with cmake.



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler gcc.

MXNet commit hash:
990bab865f5c8da168a2e68c4c6cc04fa3b117d7

Build config:
cmake -GNinja ..

## Error Message:

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.  Build using cmake
2.  Install
3.  Run gpu tests (python3 -m nose --verbose) in incubator-mxnet/tests/python/gpu.

Note: running the test individually works.

## What have you tried to solve it?

1.  Mark test as crashing.
",0,Test Crash -test_operator_gpu.test_residual_fused,"Test Crash -test_operator_gpu.test_residual_fused ## Description
The test test_operator_gpu.test_residual_fused is causing a Cuda 'too many resources' error during a tests with the latest build of MXNet.

## Environment info (Required)
p2 instance with DLAMI CUDA 9, latest MXNet built with cmake.



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler gcc.

MXNet commit hash:
990bab865f5c8da168a2e68c4c6cc04fa3b117d7

Build config:
cmake -GNinja ..

## Error Message:

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.  Build using cmake
2.  Install
3.  Run gpu tests (python3 -m nose --verbose) in incubator-mxnet/tests/python/gpu.

Note: running the test individually works.

## What have you tried to solve it?

1.  Mark test as crashing.
"
incubator-mxnet,7279,"I want to send pictures to rcnn network for prediction by batch. Does the current rcnn function like im_detect() and Predictor() support this. If they do not support this function, what change should I do to achieve the goal?",0,Batch processing for rcnn prediction,"Batch processing for rcnn prediction I want to send pictures to rcnn network for prediction by batch. Does the current rcnn function like im_detect() and Predictor() support this. If they do not support this function, what change should I do to achieve the goal?"
incubator-mxnet,16930,"## Description
In the current estimator implementation, fit_batch() is a class method of the estimator class. A common workflow of fit_batch() is that the model  forwards the training batch to generate outputs and compute loss functions. The problem is that such design is not flexible enough with different model forward interfaces on the same task. For example, fit_batch() of the base estimator trains the current batch on the label prediction task:

In the above example, the model forward interface of  is  with the return value of predict labels.  The estimator is compatible with any model using this forward interface. However, if we have another model for the label prediction task with a different forward interface , the base estimator is not compatible with this model even though both models share the same loss functions, training and evaluation metrics. A real world example can be found at LM models (https://github.com/dmlc/gluon-nlp/blob/c03665bafb1e0fe0fa5c2a59bbb4845393fbf9ba/src/gluonnlp/model/train/language_model.py).  and  shares the same forward interface, whereas  has a different one.

Forward interface of  and :

Forward interface of :


A straightforward workaround is to create a new customized estimator for each model interface. It will bring the issue that we need to create a standalone estimator each time we see a new model interface even on the same task. In machine learning community, it is common to see different model forward logic on the same task. This approach will leads to prohibitively many estimators for some simple task. In the above LM example, we need to create a  and a  even most of the training logic between these two estimators are the same.

To prevent the above estimator explosion issue, we suggest adding support of a plug and play customized  which is similar to the  for the estimator class. Given an existing estimator ,  we modify the  method to take an extra argument of . So we can call  or  to use models with different interface.
If there is no  provided, we will use the default  method.",0,Plug and Play fit_batch() for the estimator class,"Plug and Play fit_batch() for the estimator class ## Description
In the current estimator implementation, fit_batch() is a class method of the estimator class. A common workflow of fit_batch() is that the model  forwards the training batch to generate outputs and compute loss functions. The problem is that such design is not flexible enough with different model forward interfaces on the same task. For example, fit_batch() of the base estimator trains the current batch on the label prediction task:

In the above example, the model forward interface of  is  with the return value of predict labels.  The estimator is compatible with any model using this forward interface. However, if we have another model for the label prediction task with a different forward interface , the base estimator is not compatible with this model even though both models share the same loss functions, training and evaluation metrics. A real world example can be found at LM models (https://github.com/dmlc/gluon-nlp/blob/c03665bafb1e0fe0fa5c2a59bbb4845393fbf9ba/src/gluonnlp/model/train/language_model.py).  and  shares the same forward interface, whereas  has a different one.

Forward interface of  and :

Forward interface of :


A straightforward workaround is to create a new customized estimator for each model interface. It will bring the issue that we need to create a standalone estimator each time we see a new model interface even on the same task. In machine learning community, it is common to see different model forward logic on the same task. This approach will leads to prohibitively many estimators for some simple task. In the above LM example, we need to create a  and a  even most of the training logic between these two estimators are the same.

To prevent the above estimator explosion issue, we suggest adding support of a plug and play customized  which is similar to the  for the estimator class. Given an existing estimator ,  we modify the  method to take an extra argument of . So we can call  or  to use models with different interface.
If there is no  provided, we will use the default  method."
incubator-mxnet,3435,"I want to use the output of the intermediate layer in the model. 
How to get it ?
",0,How to get the output of the intermediate layer?,"How to get the output of the intermediate layer? I want to use the output of the intermediate layer in the model. 
How to get it ?
"
incubator-mxnet,8299,"
## Description
test_cifar10 fails in CI master build.
Failed build: https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/532/pipeline/

## Environment info (Required)
CI build 
Python 2 CPU


MXNet commit hash:
1c1c788916d672ee3cafdc4c91d7002a94a59d13

## Error Message:



## Steps to reproduce
Build and run unit test 

",0,test_cifar10 fails in CI master build,"test_cifar10 fails in CI master build 
## Description
test_cifar10 fails in CI master build.
Failed build: https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/532/pipeline/

## Environment info (Required)
CI build 
Python 2 CPU


MXNet commit hash:
1c1c788916d672ee3cafdc4c91d7002a94a59d13

## Error Message:



## Steps to reproduce
Build and run unit test 

"
incubator-mxnet,1099,,0,Forward,
incubator-mxnet,16723,"@ptrendx I find that the FusedOp does not support the boolean type. The following script will trigger the error.



Stack Trace:


We can also manually disable the Fuse OP, which will generate the correct answer.

",0,[Bug] fused_op does not support boolean type,"[Bug] fused_op does not support boolean type @ptrendx I find that the FusedOp does not support the boolean type. The following script will trigger the error.



Stack Trace:


We can also manually disable the Fuse OP, which will generate the correct answer.

"
incubator-mxnet,5591,"## Environment info
Operating System: Ubuntu 16.04

Compiler:


Package used (Python/R/Scala/Julia): 

MXNet version: 

Python version and distribution: , installed under virtualenv with pypi

## Error Message:


## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

1. I'm trying to run this script: https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57 (with  instead of ) and it's incorrectly telling that there's no CUDA-capable device, which does exist:


## What have you tried to solve it?

1. I searched a bit and couldn't find a solution. The Ubuntu installation script from  pollutes the global environment so I don't want it. I can normally run keras + tensorflow/theano stuff so I don't think there's an issue with my system.",0,Check failed: e == cudaSuccess CUDA: no CUDA-capable device is detected,"Check failed: e == cudaSuccess CUDA: no CUDA-capable device is detected ## Environment info
Operating System: Ubuntu 16.04

Compiler:


Package used (Python/R/Scala/Julia): 

MXNet version: 

Python version and distribution: , installed under virtualenv with pypi

## Error Message:


## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

1. I'm trying to run this script: https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57 (with  instead of ) and it's incorrectly telling that there's no CUDA-capable device, which does exist:


## What have you tried to solve it?

1. I searched a bit and couldn't find a solution. The Ubuntu installation script from  pollutes the global environment so I don't want it. I can normally run keras + tensorflow/theano stuff so I don't think there's an issue with my system."
incubator-mxnet,8827,"

when the size of data in the split axis is 1, it will return incorrect result. For example,

In [1]: import mxnet as mx

In [2]: data = mx.nd.ones((2,3,4))

In [3]: data_s = mx.nd.split(data, axis=1, num_outputs=data.shape[1], squeeze_axis=False)

In [4]: len(data_s)
Out[4]: 3

In [5]: data_s[0].shape
Out[5]: (2L, 1L, 4L)

**but, when splitting x along axis=1 below, it will return 2 NDArray.**
In [6]: x = data_s[0] #with shape  (2L, 1L, 4L)

In [8]: x_s = mx.nd.split(x, axis=1, num_outputs=x.shape[1], squeeze_axis=False)

In [9]: len(x_s)
Out[9]: 2

In [10]: x_s[0].shape
Out[10]: (1L, 4L)

Is it a bug ?",0,Question about mx.nd.split() ?,"Question about mx.nd.split() ? 

when the size of data in the split axis is 1, it will return incorrect result. For example,

In [1]: import mxnet as mx

In [2]: data = mx.nd.ones((2,3,4))

In [3]: data_s = mx.nd.split(data, axis=1, num_outputs=data.shape[1], squeeze_axis=False)

In [4]: len(data_s)
Out[4]: 3

In [5]: data_s[0].shape
Out[5]: (2L, 1L, 4L)

**but, when splitting x along axis=1 below, it will return 2 NDArray.**
In [6]: x = data_s[0] #with shape  (2L, 1L, 4L)

In [8]: x_s = mx.nd.split(x, axis=1, num_outputs=x.shape[1], squeeze_axis=False)

In [9]: len(x_s)
Out[9]: 2

In [10]: x_s[0].shape
Out[10]: (1L, 4L)

Is it a bug ?"
incubator-mxnet,297,"Hi, I want to develop some tools to manage my dataset(split,merge,append,global shuffle or something), and I found the interface to init the Iter: Init(vector< pair<string, string>>& args), How to construct this params, some param is complex just like TShape，
BTW, the api ImagerRecordIter in python is prefectcher in cpp , and ImageRecoredIoIter in cpp is another class...It is so easy to mix 
",0,How can I construct the params for ImageRecordioIter in cpp?,"How can I construct the params for ImageRecordioIter in cpp? Hi, I want to develop some tools to manage my dataset(split,merge,append,global shuffle or something), and I found the interface to init the Iter: Init(vector< pair<string, string>>& args), How to construct this params, some param is complex just like TShape，
BTW, the api ImagerRecordIter in python is prefectcher in cpp , and ImageRecoredIoIter in cpp is another class...It is so easy to mix 
"
incubator-mxnet,3924,"@mli  @piiswrong , do you have unit test operator for rnn so far? ",0,What unit test have for rnn?,"What unit test have for rnn? @mli  @piiswrong , do you have unit test operator for rnn so far? "
incubator-mxnet,7912,"Hi, I was building a conv layer sharing weights with another one, using the  #557. Since the default grad_req is 'write' and I need to update the weights using the gradient from both of the two conv layer, do I need to change it to 'add'? Will it have some affect on other layers or say can I limit the 'add' req only only the shared weights?
Thanks.",0,Do I need to change grad_req when sharing weights?,"Do I need to change grad_req when sharing weights? Hi, I was building a conv layer sharing weights with another one, using the  #557. Since the default grad_req is 'write' and I need to update the weights using the gradient from both of the two conv layer, do I need to change it to 'add'? Will it have some affect on other layers or say can I limit the 'add' req only only the shared weights?
Thanks."
incubator-mxnet,6611,"Sometimes we need to share weights in network. And Its' advised in mxnet to reuse variable by applyinng  one weight and referencing multiple times. That's OK when variable attributes like lr_mult wd_mult is fixed.
But what if we want to change the learning rate in different network structure but still share the same weight.

My solution is to manually call symbol.set_attr with different learning_rate before different module initialization, is that OK? do you have a simpler way. Is that OK to define multiple variables with same name in this case? Thanks.",0,Reuse Variable but with different attributes,"Reuse Variable but with different attributes Sometimes we need to share weights in network. And Its' advised in mxnet to reuse variable by applyinng  one weight and referencing multiple times. That's OK when variable attributes like lr_mult wd_mult is fixed.
But what if we want to change the learning rate in different network structure but still share the same weight.

My solution is to manually call symbol.set_attr with different learning_rate before different module initialization, is that OK? do you have a simpler way. Is that OK to define multiple variables with same name in this case? Thanks."
incubator-mxnet,9588,"Related to #9587. The current logic only supports what's called ""macro F1"" logic where we take the mean of F1 scores for mini-batches. ""micro F1"" should also be supported by keeping the tp, fp, fn counts across batches.
Note that these metrics share the counter logics so we should be mindful when doing oo design.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py",0,metric should have TP FP TN FN Precision Recall F1 for both macro and micro versions,"metric should have TP FP TN FN Precision Recall F1 for both macro and micro versions Related to #9587. The current logic only supports what's called ""macro F1"" logic where we take the mean of F1 scores for mini-batches. ""micro F1"" should also be supported by keeping the tp, fp, fn counts across batches.
Note that these metrics share the counter logics so we should be mindful when doing oo design.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py"
incubator-mxnet,5775,"I am trying to follow the standard installation guide @ http://mxnet.io/get_started/amazonlinux_setup.html, but get the following error.

[ec2-user@ip-xx-x-xx-xxx build]$sudo make PREFIX=/usr/local install
....
[ 89%] Built target opencv_cudaoptflow_pch_dephelp
[ 89%] Generating precomp.hpp.gch/opencv_cudaoptflow_RELEASE.gch
[ 89%] Built target pch_Generate_opencv_cudaoptflow
[ 89%] Building NVCC (Device) object modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o
nvcc error   : 'cicc' died due to signal 11 (Invalid memory reference)
CMake Error at cuda_compile_generated_pyrlk.cu.o.cmake:266 (message):
  Error generating file
  /home/ec2-user/opencv/build/modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o

make[2]: *** [modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o] Error 1
make[1]: *** [modules/cudaoptflow/CMakeFiles/opencv_cudaoptflow.dir/all] Error 2
make: *** [all] Error 2
",0,Install mxnet on amazon linux,"Install mxnet on amazon linux I am trying to follow the standard installation guide @ http://mxnet.io/get_started/amazonlinux_setup.html, but get the following error.

[ec2-user@ip-xx-x-xx-xxx build]$sudo make PREFIX=/usr/local install
....
[ 89%] Built target opencv_cudaoptflow_pch_dephelp
[ 89%] Generating precomp.hpp.gch/opencv_cudaoptflow_RELEASE.gch
[ 89%] Built target pch_Generate_opencv_cudaoptflow
[ 89%] Building NVCC (Device) object modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o
nvcc error   : 'cicc' died due to signal 11 (Invalid memory reference)
CMake Error at cuda_compile_generated_pyrlk.cu.o.cmake:266 (message):
  Error generating file
  /home/ec2-user/opencv/build/modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o

make[2]: *** [modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o] Error 1
make[1]: *** [modules/cudaoptflow/CMakeFiles/opencv_cudaoptflow.dir/all] Error 2
make: *** [all] Error 2
"
incubator-mxnet,17167,"import mxnet 
illegal instruction (core dumped)
Processor: Inter Xeon (R) CPU X5570@ 2.93 GHZ
Graphics: GeForce GTX 960/PCle/SSE2
Cuda 10.0, cudnn 7.4.2, opencv 4.1.2.
Can You help me ?",0,can't install mxnet-cu100,"can't install mxnet-cu100 import mxnet 
illegal instruction (core dumped)
Processor: Inter Xeon (R) CPU X5570@ 2.93 GHZ
Graphics: GeForce GTX 960/PCle/SSE2
Cuda 10.0, cudnn 7.4.2, opencv 4.1.2.
Can You help me ?"
incubator-mxnet,9610,"Hi,

I was following this tutorial: http://mxnet.incubator.apache.org/tutorials/python/predict_image.html
and was wondering how would I use the extracted features to create a bounding box on the image.

Also the assertion in the code fails when I run the code with a different model
Using resnet-18
> (1, 512)
> Traceback (most recent call last):
>   File ""predict.py"", line 79, in <module>
>     assert features.shape == (1, 2048)
> AssertionError

features shape is (1,512). Would this affect the feature map?

Thanks.",0,Feature extraction for object detection,"Feature extraction for object detection Hi,

I was following this tutorial: http://mxnet.incubator.apache.org/tutorials/python/predict_image.html
and was wondering how would I use the extracted features to create a bounding box on the image.

Also the assertion in the code fails when I run the code with a different model
Using resnet-18
> (1, 512)
> Traceback (most recent call last):
>   File ""predict.py"", line 79, in <module>
>     assert features.shape == (1, 2048)
> AssertionError

features shape is (1,512). Would this affect the feature map?

Thanks."
incubator-mxnet,1976,"A few files use the  method, which is not available in Python 3.
Instead, Python 3 has , which is also available in Python 2 but apparently Python 2's version is slower.
Here it should be a non-issue, since in MXNet's codebase,  appears to be invoked when initializing modules/layers from a dictionary, so the cost should be marginal (because there are few items in each dict and initialization only happens at the start of the program).

As far as I'm aware, the behavior is the same, so it's more or less a drop-in replacement.
[There are some alternatives suggested here](http://python-future.org/compatible_idioms.html#iterating-through-dict-keys-values-items)

I will attach a pull request shortly, but I haven't done the full test sweep because all my GPUs are busy.
",0,iteritems breaks Python 3 compatibility,"iteritems breaks Python 3 compatibility A few files use the  method, which is not available in Python 3.
Instead, Python 3 has , which is also available in Python 2 but apparently Python 2's version is slower.
Here it should be a non-issue, since in MXNet's codebase,  appears to be invoked when initializing modules/layers from a dictionary, so the cost should be marginal (because there are few items in each dict and initialization only happens at the start of the program).

As far as I'm aware, the behavior is the same, so it's more or less a drop-in replacement.
[There are some alternatives suggested here](http://python-future.org/compatible_idioms.html#iterating-through-dict-keys-values-items)

I will attach a pull request shortly, but I haven't done the full test sweep because all my GPUs are busy.
"
incubator-mxnet,6930,"Fail of install
I use this guide https://gist.github.com/thirdwing/89aa9bfc588ade138496e6932072152c

Fail on command 


C:\GPU\mxnet>R CMD INSTALL --no-multiarch R-package
* installing to library 'C:/Users/Statislove/Documents/R/win-library/3.4'
* installing *source* package 'mxnet' ...
** libs
make: Nothing to be done for `all'.
installing to C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64
** R
** demo
** inst
** preparing package for lazy loading
** help
No man pages found in package  'mxnet'
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error: package or namespace load failed for 'mxnet':
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: не могу загрузить разделяемый объект 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64/libmxnet.dll':
  LoadLibrary failure:  Не найден указанный модуль.

Ошибка: загрузка не удалась
Выполнение остановлено
ERROR: loading failed
* removing 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet'

What is mistake?",0,Fail Install Mxnet Windows 10,"Fail Install Mxnet Windows 10 Fail of install
I use this guide https://gist.github.com/thirdwing/89aa9bfc588ade138496e6932072152c

Fail on command 


C:\GPU\mxnet>R CMD INSTALL --no-multiarch R-package
* installing to library 'C:/Users/Statislove/Documents/R/win-library/3.4'
* installing *source* package 'mxnet' ...
** libs
make: Nothing to be done for `all'.
installing to C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64
** R
** demo
** inst
** preparing package for lazy loading
** help
No man pages found in package  'mxnet'
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error: package or namespace load failed for 'mxnet':
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: не могу загрузить разделяемый объект 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64/libmxnet.dll':
  LoadLibrary failure:  Не найден указанный модуль.

Ошибка: загрузка не удалась
Выполнение остановлено
ERROR: loading failed
* removing 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet'

What is mistake?"
incubator-mxnet,636,"I've re run the [char-lstm notebook](https://github.com/dmlc/mxnet/blob/master/example/rnn/char_lstm.ipynb) without modifing anything and compared the training and validation of the original notebook on github to the results I got (which I called SGD). It looks like something has changed and now the model is overfitting a little bit but the validation is a little bit better.
I noticed that I am running python 2.7.10 while the stored version on github was using python 3.4.2
![image](https://cloud.githubusercontent.com/assets/608789/11270580/2aafa0f4-8e8e-11e5-93ec-749177256b1a.png)
",0,char-lstm notebook gives different (overfeat) results than saved notebook on github (py2/3?),"char-lstm notebook gives different (overfeat) results than saved notebook on github (py2/3?) I've re run the [char-lstm notebook](https://github.com/dmlc/mxnet/blob/master/example/rnn/char_lstm.ipynb) without modifing anything and compared the training and validation of the original notebook on github to the results I got (which I called SGD). It looks like something has changed and now the model is overfitting a little bit but the validation is a little bit better.
I noticed that I am running python 2.7.10 while the stored version on github was using python 3.4.2
![image](https://cloud.githubusercontent.com/assets/608789/11270580/2aafa0f4-8e8e-11e5-93ec-749177256b1a.png)
"
incubator-mxnet,3604,"Hi,
         I am getting an error in the cnn text classification example. I believe the error is how the return statement is defined as i was able to run the setup_cnn_model function step by step. I am new to python so i am not able to catch the issue.

**error:**

---

NameError                                 Traceback (most recent call last)
<ipython-input-79-41ff8a3dd1cd> in <module>()
----> 1 cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)

<ipython-input-78-d7501af934ba> in setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size, dropout, initializer, with_embedding)
     36     label = cnn_exec.arg_dict['softmax_label']
     37 
---> 38     return CNNModel(cnn_exec=cnn_exec, symbol=cnn, data=data, label=label, param_blocks=param_blocks)

NameError: name 'CNNModel' is not defined

**code:**

def setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size,
        dropout=0.5, initializer=mx.initializer.Uniform(0.1), with_embedding=True):



cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)
",0,NameError: name 'CNNModel' is not defined,"NameError: name 'CNNModel' is not defined Hi,
         I am getting an error in the cnn text classification example. I believe the error is how the return statement is defined as i was able to run the setup_cnn_model function step by step. I am new to python so i am not able to catch the issue.

**error:**

---

NameError                                 Traceback (most recent call last)
<ipython-input-79-41ff8a3dd1cd> in <module>()
----> 1 cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)

<ipython-input-78-d7501af934ba> in setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size, dropout, initializer, with_embedding)
     36     label = cnn_exec.arg_dict['softmax_label']
     37 
---> 38     return CNNModel(cnn_exec=cnn_exec, symbol=cnn, data=data, label=label, param_blocks=param_blocks)

NameError: name 'CNNModel' is not defined

**code:**

def setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size,
        dropout=0.5, initializer=mx.initializer.Uniform(0.1), with_embedding=True):



cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)
"
incubator-mxnet,13718,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",0,Help,"Help Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,3665,"Thanks for providing Matlab binding for mxnet. The Matlab binding works well when I use to predict multi-class classification, but gives wrong result when I try to do binary classification.  The predicted probability is always like [0.9998  0.0002], the index-0 is near 1 while index-1 is near zero. Can someone help me solve the problem?

",0,Matlab c_api gives  wrong predict result for binary classification,"Matlab c_api gives  wrong predict result for binary classification Thanks for providing Matlab binding for mxnet. The Matlab binding works well when I use to predict multi-class classification, but gives wrong result when I try to do binary classification.  The predicted probability is always like [0.9998  0.0002], the index-0 is near 1 while index-1 is near zero. Can someone help me solve the problem?

"
incubator-mxnet,4485,Shall i write custom eval_metric?,0,How to print loss and LR for current batch,How to print loss and LR for current batch Shall i write custom eval_metric?
incubator-mxnet,1841,"In setup.py, there's only packages=['mxnet'], so after installation, the mxnet.module will not be copied to the installation folder, import it globally will raise Import Error.

so add packages=['mxnet', 'mxnet.module'] will solve this problem.
",0,Python submodule 'module' is not installed by 'python setup.py install',"Python submodule 'module' is not installed by 'python setup.py install' In setup.py, there's only packages=['mxnet'], so after installation, the mxnet.module will not be copied to the installation folder, import it globally will raise Import Error.

so add packages=['mxnet', 'mxnet.module'] will solve this problem.
"
incubator-mxnet,1932," When I delete “-msse3”  of MSSHADOW_CFLAGS in  mshadow.mk,  it occur “fatal error:emmintrin.h: No such file or directory”.  
 PS.
My cpu architecture is ARM.
",0,"How to compile mxnet on jetson tk1？when I complie the mxnet on my jetson tk，I meet ""g++:error: unrecognitzed command line option '-msse3'. ","How to compile mxnet on jetson tk1？when I complie the mxnet on my jetson tk，I meet ""g++:error: unrecognitzed command line option '-msse3'.   When I delete “-msse3”  of MSSHADOW_CFLAGS in  mshadow.mk,  it occur “fatal error:emmintrin.h: No such file or directory”.  
 PS.
My cpu architecture is ARM.
"
incubator-mxnet,15367,"A seen in this PR:

https://github.com/apache/incubator-mxnet/pull/15364

It's proposed to add get_all_registered_operators and get_operator_arguments to the Python bindings.


Your feedback is welcome.",0,[RFC] Add public functions to get list of registered operators and arguments,"[RFC] Add public functions to get list of registered operators and arguments A seen in this PR:

https://github.com/apache/incubator-mxnet/pull/15364

It's proposed to add get_all_registered_operators and get_operator_arguments to the Python bindings.


Your feedback is welcome."
incubator-mxnet,8660,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The gradients for  seem to be incorrect when used with autograd. See the script at the bottom for details. @ptrendx do you have any insight for this? 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash: v0.12
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",0,Incorrect autograd results for elemwise_add ,"Incorrect autograd results for elemwise_add  Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The gradients for  seem to be incorrect when used with autograd. See the script at the bottom for details. @ptrendx do you have any insight for this? 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash: v0.12
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,6605,"I'm trying mxnet code from API,

and the result is:

Time to finish the CPU workload: 1.327401 sec
Time to finish both CPU/GPU workloads: 117.675283 sec

There are no error during compilation, and i use the same configurations as in caffe compiled on my machine.(gpu: 980m). caffe on my PC can conduct gpu computation at once, yet mxnet on my PC has to wait 100 seconds at least. What's wrong with my configuration?",0,Large time cost over GPU computation,"Large time cost over GPU computation I'm trying mxnet code from API,

and the result is:

Time to finish the CPU workload: 1.327401 sec
Time to finish both CPU/GPU workloads: 117.675283 sec

There are no error during compilation, and i use the same configurations as in caffe compiled on my machine.(gpu: 980m). caffe on my PC can conduct gpu computation at once, yet mxnet on my PC has to wait 100 seconds at least. What's wrong with my configuration?"
incubator-mxnet,12567,"

## Description
In latest mxnet pip prebuilt packages, when using gluon data loader with num_worker > certain number, it may raise error:


Related issue: https://github.com/xianyi/OpenBLAS/issues/1735

## Environment info (Required)

Ubuntu 16




",0,1.3.0 release pre-built package contains a buggy openblas version.  Causing gluon data loader with large num_workers to crash,"1.3.0 release pre-built package contains a buggy openblas version.  Causing gluon data loader with large num_workers to crash 

## Description
In latest mxnet pip prebuilt packages, when using gluon data loader with num_worker > certain number, it may raise error:


Related issue: https://github.com/xianyi/OpenBLAS/issues/1735

## Environment info (Required)

Ubuntu 16




"
incubator-mxnet,978,"There will be several interesting addons, that requires additional dependency, and are optionally installed, this thread is used to vote for the name of addon folder, as well as suggestions on how to dynamically load these addons.
Example ongoing addons include Torch operator and Caffe adapter.

Please vote for the name you like
- 1. 
- 2. 
- 3. 
",0,[VOTE] Folder name for optional Addon,"[VOTE] Folder name for optional Addon There will be several interesting addons, that requires additional dependency, and are optionally installed, this thread is used to vote for the name of addon folder, as well as suggestions on how to dynamically load these addons.
Example ongoing addons include Torch operator and Caffe adapter.

Please vote for the name you like
- 1. 
- 2. 
- 3. 
"
incubator-mxnet,1411,"For I am training on a 11 GB image record file and always get killed because of out of memory.
So I am just wondering that does mxnet load the entire image into the memory?
And what can I do if so.
Thanks!
",0,How to deal with huge image record file,"How to deal with huge image record file For I am training on a 11 GB image record file and always get killed because of out of memory.
So I am just wondering that does mxnet load the entire image into the memory?
And what can I do if so.
Thanks!
"
incubator-mxnet,7163,"I have two questions about distributed training in mxnet.

First, after reading the code in train_mnist.py, as to my understanding, the only changes you need to make is:
1 pass ""dist_sync""/ ""dist_async"" kvstore to optimizer or module.fit() method
2 make a hosts file and make sure all IPs on that list is ssh-able or mpirun-able
3 call launch.py in tools
Is my understanding correct or am I missing something?

Second, I just want to verify the sync frequency in distributed setting. Are the weights being synced every time you call module.update()? And if I want to sync on each machine for every n batches, is there any way I can do something like module.local_update() on every batch and module.global_update() every n_batch?

Thanks in advance!
",0,About sync frequency in distributed training,"About sync frequency in distributed training I have two questions about distributed training in mxnet.

First, after reading the code in train_mnist.py, as to my understanding, the only changes you need to make is:
1 pass ""dist_sync""/ ""dist_async"" kvstore to optimizer or module.fit() method
2 make a hosts file and make sure all IPs on that list is ssh-able or mpirun-able
3 call launch.py in tools
Is my understanding correct or am I missing something?

Second, I just want to verify the sync frequency in distributed setting. Are the weights being synced every time you call module.update()? And if I want to sync on each machine for every n batches, is there any way I can do something like module.local_update() on every batch and module.global_update() every n_batch?

Thanks in advance!
"
incubator-mxnet,4971,"Dear all:

I am trying to implement a structure as follows:

Image1--->Res Net(except for last layer)
//////////////////////////////////////////////diff -> predict result
Image2--->Res Net(except for last layer)

or:

Image_Combined -> slice channel-> Image1--->Res Net(except for last layer)
///////////////////////////////////////////////////////////////////////////////////////diff -> predict result
//////////////////////////////////////////Image2--->Res Net(except for last layer)

Which way is easier. I am now trying the second way. The problem is that how to use the previous resnet  symbols to do this, as the original resnet symbol get a variable named 'data' as the input, how to make the output of slice channel transmit data to the variable 'data' and how to initialize the network with pretrained parameters? Or is there are any examples or smarter ways of doing this.




",0,Mxnet symbol implementation details?,"Mxnet symbol implementation details? Dear all:

I am trying to implement a structure as follows:

Image1--->Res Net(except for last layer)
//////////////////////////////////////////////diff -> predict result
Image2--->Res Net(except for last layer)

or:

Image_Combined -> slice channel-> Image1--->Res Net(except for last layer)
///////////////////////////////////////////////////////////////////////////////////////diff -> predict result
//////////////////////////////////////////Image2--->Res Net(except for last layer)

Which way is easier. I am now trying the second way. The problem is that how to use the previous resnet  symbols to do this, as the original resnet symbol get a variable named 'data' as the input, how to make the output of slice channel transmit data to the variable 'data' and how to initialize the network with pretrained parameters? Or is there are any examples or smarter ways of doing this.




"
incubator-mxnet,12437,"this may very well not be the right place for this, but I didnt see a webpage specific repo for mxnet

https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU

it says to get CUDA 9.0 at first, and then step 2 says install mxnet using CUDA 9.2.
it also says to be very sure which one it is, and I am about as far from sure as possible,
should I just gather all the latest libraries or is it imperative to use the older 9.0 library.

I dont expect my installation questions to be answered, just pointing out a possible error on the webpage.

Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
the mxnet.apache.org website has a possible error, where it points out multiple
versions of CUDA as neccesity for installation.

## Environment info (Required)
Ubuntu 18.04, Chromium, x86_64, NVIDIA GT 10 series

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. go to https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU
2. search CUDA, and you will find it in 1, 2, and 5 out of ten results

## What have you tried to solve it?

1. Let you lot know
2. Attempting to install with cuDNN for 9.0 and what looks like the latest cuda library (9.2?)
",0,mxnet install page for linux mentions two different versions of Cuda,"mxnet install page for linux mentions two different versions of Cuda this may very well not be the right place for this, but I didnt see a webpage specific repo for mxnet

https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU

it says to get CUDA 9.0 at first, and then step 2 says install mxnet using CUDA 9.2.
it also says to be very sure which one it is, and I am about as far from sure as possible,
should I just gather all the latest libraries or is it imperative to use the older 9.0 library.

I dont expect my installation questions to be answered, just pointing out a possible error on the webpage.

Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
the mxnet.apache.org website has a possible error, where it points out multiple
versions of CUDA as neccesity for installation.

## Environment info (Required)
Ubuntu 18.04, Chromium, x86_64, NVIDIA GT 10 series

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. go to https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU
2. search CUDA, and you will find it in 1, 2, and 5 out of ten results

## What have you tried to solve it?

1. Let you lot know
2. Attempting to install with cuDNN for 9.0 and what looks like the latest cuda library (9.2?)
"
incubator-mxnet,7219,"Hi, I am trying under R to use a constant as minimum for instance in a custom MAE loss function to cap it at 1. How do I do that?

Tried:
lro2<-mx.symbol.MakeLoss(mx.symbol.min(mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - label),1.0),name=""lro2"")

Which returns:
Error in mx.varg.symbol.min(list(...)) : 
  symbol.cc:302: RCheck failed: keys[i].length() != 0 Non Symbol parameters is only accepted via key=value style.

Thanks!",0,[R] How to include a minimum function in MakeLoss,"[R] How to include a minimum function in MakeLoss Hi, I am trying under R to use a constant as minimum for instance in a custom MAE loss function to cap it at 1. How do I do that?

Tried:
lro2<-mx.symbol.MakeLoss(mx.symbol.min(mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - label),1.0),name=""lro2"")

Which returns:
Error in mx.varg.symbol.min(list(...)) : 
  symbol.cc:302: RCheck failed: keys[i].length() != 0 Non Symbol parameters is only accepted via key=value style.

Thanks!"
incubator-mxnet,464,"Most functions have no example code provided in their documentation.
For that purpose, the R package may include some raw data to process.

There are 3 possibilities:
- add some custom data directly in the package (like in XGBoost R package)
- add a dependency to a package which contains some data. Right now, **mlbench** is used in the RMarkdown documents.
- It is also possible to include some example without the data and mark the example code as not executable (so during the package compilation the example is not tested).

@tqchen @hetong007 @thirdwing What do you think we should do?
",0,[R] Add some example data to the package to be able to have example code in function documentation,"[R] Add some example data to the package to be able to have example code in function documentation Most functions have no example code provided in their documentation.
For that purpose, the R package may include some raw data to process.

There are 3 possibilities:
- add some custom data directly in the package (like in XGBoost R package)
- add a dependency to a package which contains some data. Right now, **mlbench** is used in the RMarkdown documents.
- It is also possible to include some example without the data and mark the example code as not executable (so during the package compilation the example is not tested).

@tqchen @hetong007 @thirdwing What do you think we should do?
"
incubator-mxnet,2055,"I am reading the code of example/image-classification/train_mnist.py. There is a argument of input_shape. 

But when I refer to the source code in src/io/iter_mnist.cc, I didn't find the parameter of input_shape. The doc don't list this argument too. When I delete these two lines, everything looks OK.
",0,Does the argument of input_shape is required for MNISTIterator?,"Does the argument of input_shape is required for MNISTIterator? I am reading the code of example/image-classification/train_mnist.py. There is a argument of input_shape. 

But when I refer to the source code in src/io/iter_mnist.cc, I didn't find the parameter of input_shape. The doc don't list this argument too. When I delete these two lines, everything looks OK.
"
incubator-mxnet,2862,"I want to create a new operator to implement hierarchical softmax by writing C++ code. At the moment, the operator works fine in CPU mode, but will crash in GPU mode. One cause of this issue is that I need to access an entry in a Tensor, i.e.,


...



....

....

So what is the correct way to access one entry in GPU mode? Thanks.
",0,How to access an entry of a Tensor in mshadow when using GPU mode?,"How to access an entry of a Tensor in mshadow when using GPU mode? I want to create a new operator to implement hierarchical softmax by writing C++ code. At the moment, the operator works fine in CPU mode, but will crash in GPU mode. One cause of this issue is that I need to access an entry in a Tensor, i.e.,


...



....

....

So what is the correct way to access one entry in GPU mode? Thanks.
"
incubator-mxnet,15166,"## Description
asnumpy() fails on float16 gradient both on cpu and gpu contexts. Interestingly, when printing out the variable itself (data16 in the MRE), it works on cpu, but only every other time on gpu.

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python

## Error Message:


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

Run ^

## What have you tried to solve it?

N/A",0,asnumpy() fails on float16 gradient,"asnumpy() fails on float16 gradient ## Description
asnumpy() fails on float16 gradient both on cpu and gpu contexts. Interestingly, when printing out the variable itself (data16 in the MRE), it works on cpu, but only every other time on gpu.

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python

## Error Message:


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

Run ^

## What have you tried to solve it?

N/A"
incubator-mxnet,1811,"i am trying get predictions for images using imagenet-21k-inception model through the cpp classification code but the prediction on cpu is very slow.
The prediction takes about 1.06 seconds for a single image and i tried to give images in batch but still there is no speed gain. I thought that giving images in batch will speed things up.
Is there something that i am doing wrong?
Is there a way to make predictions fast on cpu?
",0,Mxnet prediction on cpu is very slow,"Mxnet prediction on cpu is very slow i am trying get predictions for images using imagenet-21k-inception model through the cpp classification code but the prediction on cpu is very slow.
The prediction takes about 1.06 seconds for a single image and i tried to give images in batch but still there is no speed gain. I thought that giving images in batch will speed things up.
Is there something that i am doing wrong?
Is there a way to make predictions fast on cpu?
"
incubator-mxnet,8358,"## Description
'module' object has no attribute 'nd' when run command , while a short MXNet python program for validating MXNet Installation runs successfully in terminal.

## Environment info (Required)
system: ubuntu 14.04
mxnet version: 0.11.0


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc

Build config:
make -j $(nproc) USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:
Traceback (most recent call last):
  File ""mxnet/mxnet.py"", line 1, in <module>
    import mxnet as mx
  File ""/home/qy/documents/PythonPrj/mxnet/mxnet.py"", line 3, in <module>
    a = mx.nd.array([1, 2, 3])
AttributeError: 'module' object has no attribute 'nd'

## Details

After installing mxnet, I run the official test sample in terminal as below:

Everything is okay. However, when I write these code to python file , and run ., it returned the mentioned error.
It seems that it didn't find mxnet library.",0,'module' object has no attribute 'nd',"'module' object has no attribute 'nd' ## Description
'module' object has no attribute 'nd' when run command , while a short MXNet python program for validating MXNet Installation runs successfully in terminal.

## Environment info (Required)
system: ubuntu 14.04
mxnet version: 0.11.0


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc

Build config:
make -j $(nproc) USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:
Traceback (most recent call last):
  File ""mxnet/mxnet.py"", line 1, in <module>
    import mxnet as mx
  File ""/home/qy/documents/PythonPrj/mxnet/mxnet.py"", line 3, in <module>
    a = mx.nd.array([1, 2, 3])
AttributeError: 'module' object has no attribute 'nd'

## Details

After installing mxnet, I run the official test sample in terminal as below:

Everything is okay. However, when I write these code to python file , and run ., it returned the mentioned error.
It seems that it didn't find mxnet library."
incubator-mxnet,424,"like dimshuffle function in theano, or swapaxes in numpy, how can I do it in symbol?
",0,Add Swapaxes to Symbol,"Add Swapaxes to Symbol like dimshuffle function in theano, or swapaxes in numpy, how can I do it in symbol?
"
incubator-mxnet,13386,"Currently on the master branch if you run the clojure package, you will see the warnings:



The reason this is occurring is because a new operator has been added that is brought dynamically by the backend and scala package.

This can be removed by adding it to the  in the 
*   - https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/ndarray.clj#L19 
*  - 
 https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/symbol.clj. 

It will also need to be added to the generated code as well which is in the  

*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L215
*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L308",0,[Clojure] - Remove refer warning,"[Clojure] - Remove refer warning Currently on the master branch if you run the clojure package, you will see the warnings:



The reason this is occurring is because a new operator has been added that is brought dynamically by the backend and scala package.

This can be removed by adding it to the  in the 
*   - https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/ndarray.clj#L19 
*  - 
 https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/symbol.clj. 

It will also need to be added to the generated code as well which is in the  

*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L215
*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L308"
incubator-mxnet,11612,"Find government auctions and other valueable resources that they offer online.
",0,Find government repositories,"Find government repositories Find government auctions and other valueable resources that they offer online.
"
incubator-mxnet,14030,"## Description
Hi, there.

I would like to use  to accelerate my project, but there is a flaky problem.
The example works when MXNet is built from source by myself, but it doesn't work when MXNet is installed by PIP.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 
e37ff53f0a3a0cc9276a7a1d4aff0deab91c40df

Build config:


## Minimum reproducible example
https://github.com/wkcn/test_tvm_bridge

In this example, tvm_packed_func.h is simplyfied from TVM.

## Steps to reproduce

1. clone the example
2. change the path of libmxnet.so in the line 55 of the code.
3. make
4. ./test

## What have you tried to solve it?

In the function [](https://github.com/wkcn/test_tvm_bridge/blob/master/test.cpp#L28) of the reproducible example,
 is wrong and  is sometimes wrong when MXNet is installed by pip, namely .
However, the result is correct when MXNet is built by myself,  in the latest MXNet source.

In the PR #9880,  merrymercy met a similar problem. https://github.com/apache/incubator-mxnet/pull/9880#issuecomment-421779923


It seems the temporary variable  is released before calling  in the function [](https://github.com/apache/incubator-mxnet/blob/master/src/nnvm/tvm_bridge.cc#L178) because of optimization of compiler.

Thanks!
",0,The problem of ABI compatibility in MXTVMBridge,"The problem of ABI compatibility in MXTVMBridge ## Description
Hi, there.

I would like to use  to accelerate my project, but there is a flaky problem.
The example works when MXNet is built from source by myself, but it doesn't work when MXNet is installed by PIP.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 
e37ff53f0a3a0cc9276a7a1d4aff0deab91c40df

Build config:


## Minimum reproducible example
https://github.com/wkcn/test_tvm_bridge

In this example, tvm_packed_func.h is simplyfied from TVM.

## Steps to reproduce

1. clone the example
2. change the path of libmxnet.so in the line 55 of the code.
3. make
4. ./test

## What have you tried to solve it?

In the function [](https://github.com/wkcn/test_tvm_bridge/blob/master/test.cpp#L28) of the reproducible example,
 is wrong and  is sometimes wrong when MXNet is installed by pip, namely .
However, the result is correct when MXNet is built by myself,  in the latest MXNet source.

In the PR #9880,  merrymercy met a similar problem. https://github.com/apache/incubator-mxnet/pull/9880#issuecomment-421779923


It seems the temporary variable  is released before calling  in the function [](https://github.com/apache/incubator-mxnet/blob/master/src/nnvm/tvm_bridge.cc#L178) because of optimization of compiler.

Thanks!
"
incubator-mxnet,12318,"This causes Sphinx to fail processing the API docs when shorthand references are used. I used a workaround in #12317 to just reference the functions the long way. 

This means the reference is:

When it could be:


![2018-08-23_15-08-55](https://user-images.githubusercontent.com/5974205/44555096-657b4100-a6e8-11e8-8ea5-49cf3db31063.png)

But the shorthand route doesn't work.

Example:

@Roshrini ",0,Sphinx is unable to access some MXNet ONNX module functions,"Sphinx is unable to access some MXNet ONNX module functions This causes Sphinx to fail processing the API docs when shorthand references are used. I used a workaround in #12317 to just reference the functions the long way. 

This means the reference is:

When it could be:


![2018-08-23_15-08-55](https://user-images.githubusercontent.com/5974205/44555096-657b4100-a6e8-11e8-8ea5-49cf3db31063.png)

But the shorthand route doesn't work.

Example:

@Roshrini "
incubator-mxnet,4469,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Mac OS X 10.12.2

Compiler:

Package used (Python/R/Scala/Julia):
Scala

MXNet version:
0.9.1

Or if installed from source:

MXNet commit hash ():
d0728ca552d919fd40616149016ba4dd664c4e20

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
make scalapkg
(cd /myhome/Tools/mxnet/scala-package; \
		mvn clean package -Posx-x86_64-gpu -Dcxx=""g++"" \
			-Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/myhome/Tools/mxnet/mshadow/ -I/myhome/Tools/mxnet/dmlc-core/include -fPIC -I/myhome/Tools/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/Cellar/opencv/2.4.13.2/include/opencv -I/usr/local/Cellar/opencv/2.4.13.2/include -DMSHADOW_USE_CUDNN=1  -I/usr/local/opt/openblas/include -DMXNET_USE_DIST_KVSTORE -I/myhome/Tools/mxnet/ps-lite/include -I/myhome/Tools/mxnet/deps/include -DMXNET_USE_NVRTC=0"" -Dldflags=""-pthread -lm -lcudart -lcublas -lcurand -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lopenblas  -L/usr/local/Cellar/opencv/2.4.13.2/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_gpu -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_ts -lopencv_video -lopencv_videostab -lcudnn  -L/usr/local/opt/openblas/lib -L/usr/local/lib/graphviz/ /myhome/Tools/mxnet/deps/lib/libprotobuf-lite.a /myhome/Tools/mxnet/deps/lib/libzmq.a -lcuda"" \
			-Dlddeps=""/myhome/Tools/mxnet/ps-lite/build/libps.a /myhome/Tools/mxnet/dmlc-core/libdmlc.a /myhome/Tools/mxnet/nnvm/lib/libnnvm.a"")
[INFO] Scanning for projects...
[ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] 'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
 @ 
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project ml.dmlc.mxnet:mxnet-macros_2.11:0.1.2-SNAPSHOT (/myhome/Tools/mxnet/scala-package/macros/pom.xml) has 1 error
[ERROR]     'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http:/cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException
make: *** [scalapkg] Error 1

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
make scalapkg

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.
After building mxnet
1. make scalapkg
2.
3.

## What have you tried to solve it?

1. Modify pom.xml
2.
3.
",0,Error in make scalapkg ,"Error in make scalapkg  For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Mac OS X 10.12.2

Compiler:

Package used (Python/R/Scala/Julia):
Scala

MXNet version:
0.9.1

Or if installed from source:

MXNet commit hash ():
d0728ca552d919fd40616149016ba4dd664c4e20

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
make scalapkg
(cd /myhome/Tools/mxnet/scala-package; \
		mvn clean package -Posx-x86_64-gpu -Dcxx=""g++"" \
			-Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/myhome/Tools/mxnet/mshadow/ -I/myhome/Tools/mxnet/dmlc-core/include -fPIC -I/myhome/Tools/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/Cellar/opencv/2.4.13.2/include/opencv -I/usr/local/Cellar/opencv/2.4.13.2/include -DMSHADOW_USE_CUDNN=1  -I/usr/local/opt/openblas/include -DMXNET_USE_DIST_KVSTORE -I/myhome/Tools/mxnet/ps-lite/include -I/myhome/Tools/mxnet/deps/include -DMXNET_USE_NVRTC=0"" -Dldflags=""-pthread -lm -lcudart -lcublas -lcurand -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lopenblas  -L/usr/local/Cellar/opencv/2.4.13.2/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_gpu -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_ts -lopencv_video -lopencv_videostab -lcudnn  -L/usr/local/opt/openblas/lib -L/usr/local/lib/graphviz/ /myhome/Tools/mxnet/deps/lib/libprotobuf-lite.a /myhome/Tools/mxnet/deps/lib/libzmq.a -lcuda"" \
			-Dlddeps=""/myhome/Tools/mxnet/ps-lite/build/libps.a /myhome/Tools/mxnet/dmlc-core/libdmlc.a /myhome/Tools/mxnet/nnvm/lib/libnnvm.a"")
[INFO] Scanning for projects...
[ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] 'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
 @ 
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project ml.dmlc.mxnet:mxnet-macros_2.11:0.1.2-SNAPSHOT (/myhome/Tools/mxnet/scala-package/macros/pom.xml) has 1 error
[ERROR]     'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http:/cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException
make: *** [scalapkg] Error 1

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
make scalapkg

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.
After building mxnet
1. make scalapkg
2.
3.

## What have you tried to solve it?

1. Modify pom.xml
2.
3.
"
incubator-mxnet,2705,"Hi,

I would like to know if there are any ways of passing the array values (layer wise), and using the FeedForward Class to create the model in amalgamation, just like using the prediction method in the FeedForward

Thanks
",0,Creating model along with predicting in Amalgamation,"Creating model along with predicting in Amalgamation Hi,

I would like to know if there are any ways of passing the array values (layer wise), and using the FeedForward Class to create the model in amalgamation, just like using the prediction method in the FeedForward

Thanks
"
incubator-mxnet,2924,"windows 7 
VS 2013
cuda 7.5
cmake 3.3.0

when build only with cpu, it's succeed, but when build with cuda, then failed with output log like:  



i have build mxnet with cuda on windows in 2015, and it's ok, i;m not familiar with cmake, any ideas about this? thanks. 
linux with gcc is ok here.
",0,cmake build failed when compile ndarray_function.cu on windows,"cmake build failed when compile ndarray_function.cu on windows windows 7 
VS 2013
cuda 7.5
cmake 3.3.0

when build only with cpu, it's succeed, but when build with cuda, then failed with output log like:  



i have build mxnet with cuda on windows in 2015, and it's ok, i;m not familiar with cmake, any ideas about this? thanks. 
linux with gcc is ok here.
"
incubator-mxnet,7813,"While training AlexNet CNN with ImageNet data, i don't see performance improvement (in-fact i see slight performance degradation) with increasing number of GPUs

python train_imagenet.py --data-train /local/ImageNet/MXNet_data/MXNet_data.rec --data-val /local/ImageNet/MXNet_data/MXNet_data_test.rec --gpus 0,1,2,3 --network alexnet --batch-size 256  --num-epochs 1 --kv-store device

Per epoch (and batch-size/GPU : 64),
With 1 GPU, Time-cost : 910 sec
With 2 GPU, Time-cost : 924 sec
With 4 GPU, Time-cost : 964 sec

I have 4 Titan Xps

However, with synthetic data (as shown in the demo https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/README.md) i see good scalability.
",0,Performance doesn't improve (scalability issue) with # GPUs with running train_imagenet.py,"Performance doesn't improve (scalability issue) with # GPUs with running train_imagenet.py While training AlexNet CNN with ImageNet data, i don't see performance improvement (in-fact i see slight performance degradation) with increasing number of GPUs

python train_imagenet.py --data-train /local/ImageNet/MXNet_data/MXNet_data.rec --data-val /local/ImageNet/MXNet_data/MXNet_data_test.rec --gpus 0,1,2,3 --network alexnet --batch-size 256  --num-epochs 1 --kv-store device

Per epoch (and batch-size/GPU : 64),
With 1 GPU, Time-cost : 910 sec
With 2 GPU, Time-cost : 924 sec
With 4 GPU, Time-cost : 964 sec

I have 4 Titan Xps

However, with synthetic data (as shown in the demo https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/README.md) i see good scalability.
"
incubator-mxnet,2160,"Recently, I am reproducing the result of fcn-xs in the mxnet example, I exactly follow the instruction from the README.md file, but the fcn-8s output is not like below, my train-accuracy is around 0.6 to 0.8, never get to 0.9. 

the output log may like this(when training fcn-8s):
INFO:root:Start training with gpu(3)
INFO:root:Epoch[0] Batch [50]   Speed: 1.16 samples/sec Train-accuracy=0.894318
INFO:root:Epoch[0] Batch [100]  Speed: 1.11 samples/sec Train-accuracy=0.904681
INFO:root:Epoch[0] Batch [150]  Speed: 1.13 samples/sec Train-accuracy=0.908053
INFO:root:Epoch[0] Batch [200]  Speed: 1.12 samples/sec Train-accuracy=0.912219
INFO:root:Epoch[0] Batch [250]  Speed: 1.13 samples/sec Train-accuracy=0.914238
INFO:root:Epoch[0] Batch [300]  Speed: 1.13 samples/sec Train-accuracy=0.912170
INFO:root:Epoch[0] Batch [350]  Speed: 1.12 samples/sec Train-accuracy=0.912080

Here is what I do.
First I train the fcn-32s, change the epoch: 31
Then I train the fcn-16s, change the learning rate: 10e-12 and epoch: 27
Finally I train the fcn-8s, change the learning rate: 10e-14 and epoch:19

Can anyone tell me the output log of fcn-32s and fcn-16s, just the end or the beginning log will be ok, so I can figure out which training stage is wrong
",0,Ouput log of training fcn-32s and fcn-16s,"Ouput log of training fcn-32s and fcn-16s Recently, I am reproducing the result of fcn-xs in the mxnet example, I exactly follow the instruction from the README.md file, but the fcn-8s output is not like below, my train-accuracy is around 0.6 to 0.8, never get to 0.9. 

the output log may like this(when training fcn-8s):
INFO:root:Start training with gpu(3)
INFO:root:Epoch[0] Batch [50]   Speed: 1.16 samples/sec Train-accuracy=0.894318
INFO:root:Epoch[0] Batch [100]  Speed: 1.11 samples/sec Train-accuracy=0.904681
INFO:root:Epoch[0] Batch [150]  Speed: 1.13 samples/sec Train-accuracy=0.908053
INFO:root:Epoch[0] Batch [200]  Speed: 1.12 samples/sec Train-accuracy=0.912219
INFO:root:Epoch[0] Batch [250]  Speed: 1.13 samples/sec Train-accuracy=0.914238
INFO:root:Epoch[0] Batch [300]  Speed: 1.13 samples/sec Train-accuracy=0.912170
INFO:root:Epoch[0] Batch [350]  Speed: 1.12 samples/sec Train-accuracy=0.912080

Here is what I do.
First I train the fcn-32s, change the epoch: 31
Then I train the fcn-16s, change the learning rate: 10e-12 and epoch: 27
Finally I train the fcn-8s, change the learning rate: 10e-14 and epoch:19

Can anyone tell me the output log of fcn-32s and fcn-16s, just the end or the beginning log will be ok, so I can figure out which training stage is wrong
"
incubator-mxnet,9544,"Hi , 
I had a quick question. I have prepared my data using im2rec tool.

For each training sample I have a label which is a vector of length L. However, the first 3 elements are flags that are used to identify samples for which backward gradient should be computed (otherwise send 0.) in a custom loss layer (its multi-task learning, so I have 3 flags). Therefore, the output predicted is of length L-3.
My custom loss layer takes this into account.

I wanted to know if mxnet allows this kind of unusual labelling.

I am using mxnet 0.12.1, CUDNN V5, CUDA8, Ubuntu 14, Python 2.7, gcc 4.9
",0,Can label length be different from the predicted output length,"Can label length be different from the predicted output length Hi , 
I had a quick question. I have prepared my data using im2rec tool.

For each training sample I have a label which is a vector of length L. However, the first 3 elements are flags that are used to identify samples for which backward gradient should be computed (otherwise send 0.) in a custom loss layer (its multi-task learning, so I have 3 flags). Therefore, the output predicted is of length L-3.
My custom loss layer takes this into account.

I wanted to know if mxnet allows this kind of unusual labelling.

I am using mxnet 0.12.1, CUDNN V5, CUDA8, Ubuntu 14, Python 2.7, gcc 4.9
"
incubator-mxnet,3212,"My motherboard is Intel B85 which doesn't support SLI technology and has two PCIE interfaces, and I have two gtx1080 gpu cards to construct my mxnet system. But I found the utilizations of two gtx1080 are very slow, the speed of two gtx1080 is slower than single gtx1080. Although I increased the batch sizes, the speed of two gpus is still lower than one gpu. How can I solve this problem?
",0,Does the motherboard need the SLI technology to support multiple gpus in mxnet?,"Does the motherboard need the SLI technology to support multiple gpus in mxnet? My motherboard is Intel B85 which doesn't support SLI technology and has two PCIE interfaces, and I have two gtx1080 gpu cards to construct my mxnet system. But I found the utilizations of two gtx1080 are very slow, the speed of two gtx1080 is slower than single gtx1080. Although I increased the batch sizes, the speed of two gpus is still lower than one gpu. How can I solve this problem?
"
incubator-mxnet,15647,"(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# pip install mxnet                                                                                                                                                       
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: mxnet in /root/anaconda3/lib/python3.7/site-packages (1.5.0)
Requirement already satisfied: numpy<2.0.0,>1.16.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (1.16.4)
Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (0.8.4)
Requirement already satisfied: requests<3,>=2.20.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (2.22.0)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)
Requirement already satisfied: idna<2.9,>=2.5 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.7)
Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2018.8.24)
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# python                                                                                                                                                                  
Python 3.7.0 (default, Jun 28 2018, 13:15:42) 
[GCC 7.2.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import mxnet

Segmentation fault: 11

Stack trace:
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace#    ",0,Segmentation fault: 11,"Segmentation fault: 11 (retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# pip install mxnet                                                                                                                                                       
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: mxnet in /root/anaconda3/lib/python3.7/site-packages (1.5.0)
Requirement already satisfied: numpy<2.0.0,>1.16.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (1.16.4)
Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (0.8.4)
Requirement already satisfied: requests<3,>=2.20.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (2.22.0)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)
Requirement already satisfied: idna<2.9,>=2.5 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.7)
Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2018.8.24)
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# python                                                                                                                                                                  
Python 3.7.0 (default, Jun 28 2018, 13:15:42) 
[GCC 7.2.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import mxnet

Segmentation fault: 11

Stack trace:
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace#    "
incubator-mxnet,2724,"in the script of 'mxnet/example/image-classification/train_imagenet.py' , there is 
# data

def get_iterator(args, kv):
    data_shape = (3, args.data_shape, args.data_shape)
    train = mx.io.ImageRecordIter(
        path_imgrec = os.path.join(args.data_dir, args.train_dataset),
        mean_r      = 123.68,
        mean_g      = 116.779,
        mean_b      = 103.939,
        data_shape  = data_shape,
        batch_size  = args.batch_size,
        rand_crop   = True,
        rand_mirror = True,
        num_parts   = kv.num_workers,
        part_index  = kv.rank)

but how to get the value of ' mean_r,  mean_g, mean_b' ?
and another question, the ' data_shape' is the size of the picture ?  for instance,  I have a picture with size of  1920_1080, then the   ' data_shape' should set be 3_1920_1080?
and if I crop the picture to the size 1080_1080, then the   ' data_shape' should set be 3_1080_1080? 
@mli 
thank your help.
",0,how to get the value of 'mean_r',"how to get the value of 'mean_r' in the script of 'mxnet/example/image-classification/train_imagenet.py' , there is 
# data

def get_iterator(args, kv):
    data_shape = (3, args.data_shape, args.data_shape)
    train = mx.io.ImageRecordIter(
        path_imgrec = os.path.join(args.data_dir, args.train_dataset),
        mean_r      = 123.68,
        mean_g      = 116.779,
        mean_b      = 103.939,
        data_shape  = data_shape,
        batch_size  = args.batch_size,
        rand_crop   = True,
        rand_mirror = True,
        num_parts   = kv.num_workers,
        part_index  = kv.rank)

but how to get the value of ' mean_r,  mean_g, mean_b' ?
and another question, the ' data_shape' is the size of the picture ?  for instance,  I have a picture with size of  1920_1080, then the   ' data_shape' should set be 3_1920_1080?
and if I crop the picture to the size 1080_1080, then the   ' data_shape' should set be 3_1080_1080? 
@mli 
thank your help.
"
incubator-mxnet,4447,"In the following figure, I compare commonly used data augmentation techniques for ResNet-50 on ImageNet. **Random crop, random flip, and scale augmentations** were shown to be very **effective**, and they provide as the baseline ""scale aug"". For **JPEG compression with quality 90** and **aspect ratio augmentation**, the curves indicates they almost **have no effects**. For **color augmentation**, it is shown that the accuracy is actually **decreased**.


![notes_on_aug](https://cloud.githubusercontent.com/assets/3815006/21560667/6f909480-ce9d-11e6-9340-9d8af5f41837.png)

### Compare to state-of-the-art implementation:

 (https://github.com/tornadomeet/ResNet)

For ResNet-50 on ImageNet, top-1 accuracy of 74.55% were achieved. As suggested in https://github.com/tornadomeet/ResNet, canceling scale/color/aspect augmentation will further improve the results. For a fair comparison, https://github.com/tornadomeet/ResNet actually achieved 74.20% accuracy at the 95-th epoch (right before the cancellation of scale/color/aspect augmentations). Hence, we can conclude that **augmentations beyond random crop, random flip, and scale actually hurt the performance** as (74.55%>74.20%).
",0,A note on data augmenation,"A note on data augmenation In the following figure, I compare commonly used data augmentation techniques for ResNet-50 on ImageNet. **Random crop, random flip, and scale augmentations** were shown to be very **effective**, and they provide as the baseline ""scale aug"". For **JPEG compression with quality 90** and **aspect ratio augmentation**, the curves indicates they almost **have no effects**. For **color augmentation**, it is shown that the accuracy is actually **decreased**.


![notes_on_aug](https://cloud.githubusercontent.com/assets/3815006/21560667/6f909480-ce9d-11e6-9340-9d8af5f41837.png)

### Compare to state-of-the-art implementation:

 (https://github.com/tornadomeet/ResNet)

For ResNet-50 on ImageNet, top-1 accuracy of 74.55% were achieved. As suggested in https://github.com/tornadomeet/ResNet, canceling scale/color/aspect augmentation will further improve the results. For a fair comparison, https://github.com/tornadomeet/ResNet actually achieved 74.20% accuracy at the 95-th epoch (right before the cancellation of scale/color/aspect augmentations). Hence, we can conclude that **augmentations beyond random crop, random flip, and scale actually hurt the performance** as (74.55%>74.20%).
"
incubator-mxnet,1504,"Could you give a example code?
",0,How to build a siamese network with contrastive loss?,"How to build a siamese network with contrastive loss? Could you give a example code?
"
incubator-mxnet,1067,"Linux + blas

I have put libblas.a  libcblas.a to /usr/local/lib, when I make, the cmd complains:
outside_built/gcc4.9.0/bin/g++ -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp   -o bin/im2rec tools/im2rec.cc build/resource.o build/c_api/c_api.o build/c_api/c_api_error.o build/c_api/c_predict_api.o build/common/mxrtc.o build/common/tblob_op_registry.o build/engine/engine.o build/engine/naive_engine.o build/engine/threaded_engine.o build/engine/threaded_engine_perdevice.o build/engine/threaded_engine_pooled.o build/io/io.o build/io/iter_csv.o build/io/iter_image_recordio.o build/io/iter_mnist.o build/kvstore/kvstore.o build/ndarray/ndarray.o build/ndarray/ndarray_function.o build/ndarray/unary_function.o build/operator/activation.o build/operator/batch_norm.o build/operator/block_grad.o build/operator/concat.o build/operator/convolution.o build/operator/cross_device_copy.o build/operator/cudnn_batch_norm.o build/operator/deconvolution.o build/operator/dropout.o build/operator/elementwise_binary_op.o build/operator/elementwise_binary_scalar_op.o build/operator/elementwise_sum.o build/operator/embedding.o build/operator/fully_connected.o build/operator/identity_attach_KL_sparse_reg.o build/operator/leaky_relu.o build/operator/lrn.o build/operator/native_op.o build/operator/ndarray_op.o build/operator/operator.o build/operator/pooling.o build/operator/regression_output.o build/operator/reshape.o build/operator/slice_channel.o build/operator/softmax_activation.o build/operator/softmax_output.o build/operator/swapaxis.o build/operator/upsampling.o build/optimizer/optimizer.o build/optimizer/sgd.o build/storage/storage.o build/symbol/graph_executor.o build/symbol/static_graph.o build/symbol/symbol.o dmlc-core/libdmlc.a -pthread -lm -lcblas -lrt -lcblas  
/usr/local/lib/libcblas.a(sdotsub.o): In function sdot_'
/usr/local/lib/libcblas.a(cblas_sgemm.o): In function sgemm_'
cblas_sgemm.c:(.text+0x1e6): undefined reference to `sgemm_'
collect2: error: ld returned 1 exit status
make: **\* [bin/im2rec] Error 1
",0,[install error] sdotsub.f:(.text+0x7): undefined reference to `sdot_',"[install error] sdotsub.f:(.text+0x7): undefined reference to `sdot_' Linux + blas

I have put libblas.a  libcblas.a to /usr/local/lib, when I make, the cmd complains:
outside_built/gcc4.9.0/bin/g++ -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp   -o bin/im2rec tools/im2rec.cc build/resource.o build/c_api/c_api.o build/c_api/c_api_error.o build/c_api/c_predict_api.o build/common/mxrtc.o build/common/tblob_op_registry.o build/engine/engine.o build/engine/naive_engine.o build/engine/threaded_engine.o build/engine/threaded_engine_perdevice.o build/engine/threaded_engine_pooled.o build/io/io.o build/io/iter_csv.o build/io/iter_image_recordio.o build/io/iter_mnist.o build/kvstore/kvstore.o build/ndarray/ndarray.o build/ndarray/ndarray_function.o build/ndarray/unary_function.o build/operator/activation.o build/operator/batch_norm.o build/operator/block_grad.o build/operator/concat.o build/operator/convolution.o build/operator/cross_device_copy.o build/operator/cudnn_batch_norm.o build/operator/deconvolution.o build/operator/dropout.o build/operator/elementwise_binary_op.o build/operator/elementwise_binary_scalar_op.o build/operator/elementwise_sum.o build/operator/embedding.o build/operator/fully_connected.o build/operator/identity_attach_KL_sparse_reg.o build/operator/leaky_relu.o build/operator/lrn.o build/operator/native_op.o build/operator/ndarray_op.o build/operator/operator.o build/operator/pooling.o build/operator/regression_output.o build/operator/reshape.o build/operator/slice_channel.o build/operator/softmax_activation.o build/operator/softmax_output.o build/operator/swapaxis.o build/operator/upsampling.o build/optimizer/optimizer.o build/optimizer/sgd.o build/storage/storage.o build/symbol/graph_executor.o build/symbol/static_graph.o build/symbol/symbol.o dmlc-core/libdmlc.a -pthread -lm -lcblas -lrt -lcblas  
/usr/local/lib/libcblas.a(sdotsub.o): In function sdot_'
/usr/local/lib/libcblas.a(cblas_sgemm.o): In function sgemm_'
cblas_sgemm.c:(.text+0x1e6): undefined reference to `sgemm_'
collect2: error: ld returned 1 exit status
make: **\* [bin/im2rec] Error 1
"
incubator-mxnet,15069,"# Profiler RFC: Introducing new APIs

## Introducing New APIs

### Motivation

MXNet comes with a profiler that allows users to monitor the performance of their models in two metrics: time and memory consumption. Internally, operator calls, C API calls, and memory allocation/deallocation are represented as events. For functions calls, we know the start and finish time of the events and therefore the duration. For memory operations, we know the time of the allocation/deallocation and the size of the memory chunk. 
![Screen Shot 2019-05-24 at 4 16 39 PM](https://user-images.githubusercontent.com/10722037/58362190-49f4c080-7e49-11e9-92a3-23664384544b.png)

Currently, the profiler has a function called  that will return the aggregate statistics, which include min, max, and average for entries in Device Memory, Operator, and C_API. The current return value is string and the data is presented in a table fashion (refer to the screenshot above). However, while the table is nicely formatted, it is only meant to be read by humans but is not easily parse-able otherwise by program. So, there is a need for an API that returns the same aggregate stats in a JSON string.


### Specification

A new API, , will be introduced. It will have two parameters: 

1. “sort_by” which specifies by which statistic should we sort the entries. It defaults to “avg” and valid options are [“min”, “max”, “avg”].
2. “ascending” which specifies how the entries should be sorted. It defaults to False and valid options are [True, False].

 Expected use cases of  include:

1. If customers are more interested in some events or stats than the others, they can customize the data presentation to more efficiently monitor their models.
2. Customers can easily pass the stats to automated performance tests or monitoring tools. They do not need to parse the table-like string returned by . 
3. This new API will be immediately useful to a new operator-level benchmark tool that @sandeep-krishnamurthy will work on. cwiki: https://cwiki.apache.org/confluence/display/MXNET/MXNet+Operator+Benchmarks. 


The structure of the JSON return value is shown below. It is a four layer dictionary structure. The 1st layer is “Time”, “Memory”, and “Unit”. The 2nd layer is the category that the operators/APIs fall into. The 3rd layer is the operators/APIs. Finally, the 4th layer is the stats. Notice that the time unit is ms and the memory unit is byte.




Asides from  we will also have another new API, , which will clear the aggregate statistics up until now. A typical use case is like:



In a more complex case, suppose we want to use the same profiler to benchmark various sections of a model, we can then call  and  at the end of each section or supposedly at the end of a loop neatly like:



OR



## Fixing the Output of Dumps()
![Screen Shot 2019-05-23 at 5 23 56 PM](https://user-images.githubusercontent.com/10722037/58362201-7c062280-7e49-11e9-88ec-3ab102c95795.png)
Currently labeling in the table is slightly off. For memory-related entries the labels should be “Usage” rather than “Time”. The “Time (ms)” column also does not make sense for memory entries, so it should be removed for memory entries.

The new table labeling should look like:






## F&Q

1. Why can't we use the current dumps() API?

We can use the current dumps API and basically get the save information, but then we need to manually parse the table which is not a good user experience.

1. Why add a new profiler API  in the back-end rather than a python parser utility that returns in JSON? 

This is we can use this new API in different languages and make sure the return is consistent. 

",0,Profiler RFC: Introducing new APIs,"Profiler RFC: Introducing new APIs # Profiler RFC: Introducing new APIs

## Introducing New APIs

### Motivation

MXNet comes with a profiler that allows users to monitor the performance of their models in two metrics: time and memory consumption. Internally, operator calls, C API calls, and memory allocation/deallocation are represented as events. For functions calls, we know the start and finish time of the events and therefore the duration. For memory operations, we know the time of the allocation/deallocation and the size of the memory chunk. 
![Screen Shot 2019-05-24 at 4 16 39 PM](https://user-images.githubusercontent.com/10722037/58362190-49f4c080-7e49-11e9-92a3-23664384544b.png)

Currently, the profiler has a function called  that will return the aggregate statistics, which include min, max, and average for entries in Device Memory, Operator, and C_API. The current return value is string and the data is presented in a table fashion (refer to the screenshot above). However, while the table is nicely formatted, it is only meant to be read by humans but is not easily parse-able otherwise by program. So, there is a need for an API that returns the same aggregate stats in a JSON string.


### Specification

A new API, , will be introduced. It will have two parameters: 

1. “sort_by” which specifies by which statistic should we sort the entries. It defaults to “avg” and valid options are [“min”, “max”, “avg”].
2. “ascending” which specifies how the entries should be sorted. It defaults to False and valid options are [True, False].

 Expected use cases of  include:

1. If customers are more interested in some events or stats than the others, they can customize the data presentation to more efficiently monitor their models.
2. Customers can easily pass the stats to automated performance tests or monitoring tools. They do not need to parse the table-like string returned by . 
3. This new API will be immediately useful to a new operator-level benchmark tool that @sandeep-krishnamurthy will work on. cwiki: https://cwiki.apache.org/confluence/display/MXNET/MXNet+Operator+Benchmarks. 


The structure of the JSON return value is shown below. It is a four layer dictionary structure. The 1st layer is “Time”, “Memory”, and “Unit”. The 2nd layer is the category that the operators/APIs fall into. The 3rd layer is the operators/APIs. Finally, the 4th layer is the stats. Notice that the time unit is ms and the memory unit is byte.




Asides from  we will also have another new API, , which will clear the aggregate statistics up until now. A typical use case is like:



In a more complex case, suppose we want to use the same profiler to benchmark various sections of a model, we can then call  and  at the end of each section or supposedly at the end of a loop neatly like:



OR



## Fixing the Output of Dumps()
![Screen Shot 2019-05-23 at 5 23 56 PM](https://user-images.githubusercontent.com/10722037/58362201-7c062280-7e49-11e9-88ec-3ab102c95795.png)
Currently labeling in the table is slightly off. For memory-related entries the labels should be “Usage” rather than “Time”. The “Time (ms)” column also does not make sense for memory entries, so it should be removed for memory entries.

The new table labeling should look like:






## F&Q

1. Why can't we use the current dumps() API?

We can use the current dumps API and basically get the save information, but then we need to manually parse the table which is not a good user experience.

1. Why add a new profiler API  in the back-end rather than a python parser utility that returns in JSON? 

This is we can use this new API in different languages and make sure the return is consistent. 

"
incubator-mxnet,10520,"It looks the operator counter of the aggregated output is the 2x of real value. 

I used below gluon model (mainly copied from https://mxnet.incubator.apache.org/tutorials/gluon/gluon.html, contains 2 convolutions for each forward pass) and did profiling, the aggregated convolution counter is 4 instead of 2, the counter doubled for other OPs as well.

mx.gpu(0)[mx.gpu(0), mx.gpu(1)]",0,MXNet operator profile aggregate counter issue,"MXNet operator profile aggregate counter issue It looks the operator counter of the aggregated output is the 2x of real value. 

I used below gluon model (mainly copied from https://mxnet.incubator.apache.org/tutorials/gluon/gluon.html, contains 2 convolutions for each forward pass) and did profiling, the aggregated convolution counter is 4 instead of 2, the counter doubled for other OPs as well.

mx.gpu(0)[mx.gpu(0), mx.gpu(1)]"
incubator-mxnet,5416,"Running  on the ResNet-50 model from [here](http://data.mxnet.io/models/imagenet/test/caffe/) produces an error importing the BatchNorm layers. I do not have Caffe installed, so am using the pure protobuf version of the importer. @nirbenz, @mli 

## Environment info
OSX

MXNet version:
0.9.4
dea87660c9d3b55ccd28a812116c93ca9e5032c2

Protobuf version:


Python version:
3.5


## Error Message:
`
converting layer conv1, wmat shape = (64, 3, 7, 7), bias shape = (64,)
Traceback (most recent call last):
  File ""convert_model.py"", line 162, in <module>
    main()
  File ""convert_model.py"", line 158, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 127, in convert_model
    mean = mean.reshape(aux_shape_dic[mean_name])
AttributeError: 'RepeatedScalarFieldContainer' object has no attribute 'reshape'

",0,Caffe importer fails to resnet-50,"Caffe importer fails to resnet-50 Running  on the ResNet-50 model from [here](http://data.mxnet.io/models/imagenet/test/caffe/) produces an error importing the BatchNorm layers. I do not have Caffe installed, so am using the pure protobuf version of the importer. @nirbenz, @mli 

## Environment info
OSX

MXNet version:
0.9.4
dea87660c9d3b55ccd28a812116c93ca9e5032c2

Protobuf version:


Python version:
3.5


## Error Message:
`
converting layer conv1, wmat shape = (64, 3, 7, 7), bias shape = (64,)
Traceback (most recent call last):
  File ""convert_model.py"", line 162, in <module>
    main()
  File ""convert_model.py"", line 158, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 127, in convert_model
    mean = mean.reshape(aux_shape_dic[mean_name])
AttributeError: 'RepeatedScalarFieldContainer' object has no attribute 'reshape'

"
incubator-mxnet,5098,"Recently I run the tutorial  [Handwritten Digit Recognition](http://mxnet.io/tutorials/python/mnist.html), 
if I change the optimizer option to a optimizer object as following

I got poor result. I find that the optimizer class did not set the  mini-batch optimization parameter _rescale_grad_  to (1.0/batch_size).  The correct code is

Is this an intended design?
",0,The optimizer object may not properly initialized,"The optimizer object may not properly initialized Recently I run the tutorial  [Handwritten Digit Recognition](http://mxnet.io/tutorials/python/mnist.html), 
if I change the optimizer option to a optimizer object as following

I got poor result. I find that the optimizer class did not set the  mini-batch optimization parameter _rescale_grad_  to (1.0/batch_size).  The correct code is

Is this an intended design?
"
incubator-mxnet,793,"Yesterday I read the paper, and I find the weight decay is 0.05, is this correct? 
@mli 
",0,[mxnet paper] googlenet weight decay parameter  ,"[mxnet paper] googlenet weight decay parameter   Yesterday I read the paper, and I find the weight decay is 0.05, is this correct? 
@mli 
"
incubator-mxnet,9623,"I was trying to get familiar with mxnet framework and was browsing the tutorial section - https://mxnet.apache.org/tutorials/index.html.

I did not come across any illustrations for generating vector representations of words, like word2vec models( https://en.wikipedia.org/wiki/Word2vec ). Would it make sense to create a PR with one such tutorial. Is that something that will make sense in this code repo.",0,A tutorial for Word embeddings using mxnet,"A tutorial for Word embeddings using mxnet I was trying to get familiar with mxnet framework and was browsing the tutorial section - https://mxnet.apache.org/tutorials/index.html.

I did not come across any illustrations for generating vector representations of words, like word2vec models( https://en.wikipedia.org/wiki/Word2vec ). Would it make sense to create a PR with one such tutorial. Is that something that will make sense in this code repo."
incubator-mxnet,449,"Mxnet looks very promising and I would like to give it a try. I want to train a triplet network like google facenet. One of the key issue to get a succefull training is the selection on a good triplet data to fed to the network. Since generating all possible triplets is not tractable, selecting them during the training is a good compromise.  So is it currently possible to add additional steps it the data iterator and in the SGD step such that one can do some statistics on the current batch using the current model in order to select good triplets ? The idea is to transform the source data set with just labeled image into triplet during training. Currently, I use fuel and blocks frameworks and chain different transformer to achieve this. May be Mxnet already have such kind of data pipeline transformation, or can I plug fuel into Mxnet ?
",0,Real time data augmentation and online batch generation.,"Real time data augmentation and online batch generation. Mxnet looks very promising and I would like to give it a try. I want to train a triplet network like google facenet. One of the key issue to get a succefull training is the selection on a good triplet data to fed to the network. Since generating all possible triplets is not tractable, selecting them during the training is a good compromise.  So is it currently possible to add additional steps it the data iterator and in the SGD step such that one can do some statistics on the current batch using the current model in order to select good triplets ? The idea is to transform the source data set with just labeled image into triplet during training. Currently, I use fuel and blocks frameworks and chain different transformer to achieve this. May be Mxnet already have such kind of data pipeline transformation, or can I plug fuel into Mxnet ?
"
incubator-mxnet,4436,"I tested out amalgamation on v0.9.1pre and couldn't get it to work.  My environment amalgamates perfectly in v0.8.0.

The initial error I get is 


After commenting that out, I tried to manually change paths and comment out headers not located in the source.  One issue I had is that  files are linked incorrectly, e.g. 
 -> 
And several elementwise operators were missing from :


Eventually amalgamation simply fails without explanation:


Has something significant change in the requirements for amalgamation?

## Environment info
Operating System:
Android (amalgamation)

MXNet commit hash ():
84e5155fc26563ef8bebc08f201e8a88d4c3845e
",0,Amalgamation for Android broken in v0.9.1pre,"Amalgamation for Android broken in v0.9.1pre I tested out amalgamation on v0.9.1pre and couldn't get it to work.  My environment amalgamates perfectly in v0.8.0.

The initial error I get is 


After commenting that out, I tried to manually change paths and comment out headers not located in the source.  One issue I had is that  files are linked incorrectly, e.g. 
 -> 
And several elementwise operators were missing from :


Eventually amalgamation simply fails without explanation:


Has something significant change in the requirements for amalgamation?

## Environment info
Operating System:
Android (amalgamation)

MXNet commit hash ():
84e5155fc26563ef8bebc08f201e8a88d4c3845e
"
incubator-mxnet,1525,"My problem .

I check



My data iterator


",0,Check failed: it != idx2label_.end() fail to find imagelabel for id 470889,"Check failed: it != idx2label_.end() fail to find imagelabel for id 470889 My problem .

I check



My data iterator


"
incubator-mxnet,2398,"sometimes it raise up this error:


",0,Neural art save image error,"Neural art save image error sometimes it raise up this error:


"
incubator-mxnet,3137,"if sample_size % batch_size != 0, the last batch generated by next() is still initialized with NDArray.empty() using original batch_size and set pad = (batch_size - real_size).

However, the mxnet training process seems to ignore the pad field of DataBatch. The whole batch is taken into calculation, which may produce NaN result in my linear regression model. I find that the uninitialized part of the last batch contains randomly huge numbers like xxxxxE10. 

Using NDArray.zeros() to initialize the batch or just discarding the last batch can fix in my case. And is it possible to use different batch_size for different batch in the DataIter object?
",0,batch padding bug in ml.dmlc.mxnet.spark.io.LabeledPointIter,"batch padding bug in ml.dmlc.mxnet.spark.io.LabeledPointIter if sample_size % batch_size != 0, the last batch generated by next() is still initialized with NDArray.empty() using original batch_size and set pad = (batch_size - real_size).

However, the mxnet training process seems to ignore the pad field of DataBatch. The whole batch is taken into calculation, which may produce NaN result in my linear regression model. I find that the uninitialized part of the last batch contains randomly huge numbers like xxxxxE10. 

Using NDArray.zeros() to initialize the batch or just discarding the last batch can fix in my case. And is it possible to use different batch_size for different batch in the DataIter object?
"
incubator-mxnet,2857,"My training code is in following, which is just like the code in the example.


",0,"After several iteration, model.exec.output[0].asnumpy() get slower and slower !!","After several iteration, model.exec.output[0].asnumpy() get slower and slower !! My training code is in following, which is just like the code in the example.


"
incubator-mxnet,11263,"java': double free or corruption (fasttop): 0x00007f91e0db8270 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9527a337e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9527a3c37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9527a4053c]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEE9_M_assignIZNSL_aSERKSL_EUlPKNSA_10_Hash_nodeIS8_Lb1EEEE0_EEvSO_RKT_+0x81)[0x7f92a8a7ef11]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEEaSERKSL_+0xa2)[0x7f92a8a7f212]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(MXInitPSEnv+0x346)[0x7f92ab65d686]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(Java_org_apache_mxnet_LibInfo_mxInitPSEnv+0xf5)[0x7f92a89c8895]
[0x7f95110184e7]
`
Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11210/5/pipeline",0,Memory corruption issue with Scala test,"Memory corruption issue with Scala test java': double free or corruption (fasttop): 0x00007f91e0db8270 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9527a337e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9527a3c37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9527a4053c]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEE9_M_assignIZNSL_aSERKSL_EUlPKNSA_10_Hash_nodeIS8_Lb1EEEE0_EEvSO_RKT_+0x81)[0x7f92a8a7ef11]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEEaSERKSL_+0xa2)[0x7f92a8a7f212]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(MXInitPSEnv+0x346)[0x7f92ab65d686]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(Java_org_apache_mxnet_LibInfo_mxInitPSEnv+0xf5)[0x7f92a89c8895]
[0x7f95110184e7]
`
Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11210/5/pipeline"
incubator-mxnet,13024,"## Description
Sphinx throws an error when generating the docs for this function.

## Error
",0,mxnet.random.seed docs error,"mxnet.random.seed docs error ## Description
Sphinx throws an error when generating the docs for this function.

## Error
"
incubator-mxnet,4465,"## Environment info
Operating System:


Compiler:


Package used (Python/R/Scala/Julia):



MXNet version:



Python version and distribution:



## Error Message:

/root/mxnet/dmlc-core'
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o line_split.o src/io/line_split.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/ndarray/ndarray_function_gpu.o src/ndarray/ndarray_function.cu >build/src/ndarray/ndarray_function_gpu.d
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/activation_gpu.o src/operator/activation.cu >build/src/operator/activation_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio_split.o src/io/recordio_split.cc
/usr/local/cuda/bin/nvcc -c -o build/src/ndarray/ndarray_function_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/ndarray/ndarray_function.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o input_split_base.o src/io/input_split_base.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/activation_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/activation.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/batch_norm_gpu.o src/operator/batch_norm.cu >build/src/operator/batch_norm_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o io.o src/io.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/batch_norm_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/batch_norm.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/block_grad_gpu.o src/operator/block_grad.cu >build/src/operator/block_grad_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o local_filesys.o src/io/local_filesys.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_mask_op_gpu.o src/operator/broadcast_mask_op.cu >build/src/operator/broadcast_mask_op_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o data.o src/data.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/block_grad_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/block_grad.cu
/usr/local/cuda/bin/nvcc -c -o build/src/operator/broadcast_mask_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/broadcast_mask_op.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio.o src/recordio.cc
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o config.o src/config.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_reduce_op_gpu.o src/operator/broadcast_reduce_op.cu >build/src/operator/broadcast_reduce_op_gpu.d
ar cr libdmlc.a line_split.o recordio_split.o input_split_base.o io.o local_filesys.o data.o recordio.o config.o
make[1]: Leaving directory mxnet::GraphStorageAllocator::Get(long, mxnet::TShape)':
graph_memory_allocator.cc:(.text+0x6da): undefined reference to 

If you could help me understand the error, I would really appreciate it.

Thanks!

-Besir",0,MXNet Installation fails on Ubuntu 14.04.4 LTS,"MXNet Installation fails on Ubuntu 14.04.4 LTS ## Environment info
Operating System:


Compiler:


Package used (Python/R/Scala/Julia):



MXNet version:



Python version and distribution:



## Error Message:

/root/mxnet/dmlc-core'
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o line_split.o src/io/line_split.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/ndarray/ndarray_function_gpu.o src/ndarray/ndarray_function.cu >build/src/ndarray/ndarray_function_gpu.d
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/activation_gpu.o src/operator/activation.cu >build/src/operator/activation_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio_split.o src/io/recordio_split.cc
/usr/local/cuda/bin/nvcc -c -o build/src/ndarray/ndarray_function_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/ndarray/ndarray_function.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o input_split_base.o src/io/input_split_base.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/activation_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/activation.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/batch_norm_gpu.o src/operator/batch_norm.cu >build/src/operator/batch_norm_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o io.o src/io.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/batch_norm_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/batch_norm.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/block_grad_gpu.o src/operator/block_grad.cu >build/src/operator/block_grad_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o local_filesys.o src/io/local_filesys.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_mask_op_gpu.o src/operator/broadcast_mask_op.cu >build/src/operator/broadcast_mask_op_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o data.o src/data.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/block_grad_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/block_grad.cu
/usr/local/cuda/bin/nvcc -c -o build/src/operator/broadcast_mask_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/broadcast_mask_op.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio.o src/recordio.cc
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o config.o src/config.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_reduce_op_gpu.o src/operator/broadcast_reduce_op.cu >build/src/operator/broadcast_reduce_op_gpu.d
ar cr libdmlc.a line_split.o recordio_split.o input_split_base.o io.o local_filesys.o data.o recordio.o config.o
make[1]: Leaving directory mxnet::GraphStorageAllocator::Get(long, mxnet::TShape)':
graph_memory_allocator.cc:(.text+0x6da): undefined reference to 

If you could help me understand the error, I would really appreciate it.

Thanks!

-Besir"
incubator-mxnet,13923,"Hi, recently i tried installing MXNet with RStudio on Windows 7. After the command:

I got error:


After:

I got:


And finally, after (found somewhere here when seaching for fix):

It installed but when trying to load library:


I know that Windows 7 is not fully supported but I hope it's not that case.
So the file on server is missing or something? 
I would be very grateful if someone could help me
Thanks


Session info:
R version 3.5.1 (2018-07-02)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Polish_Poland.1250  LC_CTYPE=Polish_Poland.1250    LC_MONETARY=Polish_Poland.1250
[4] LC_NUMERIC=C                   LC_TIME=Polish_Poland.1250    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] arules_1.6-2  Matrix_1.2-14

loaded via a namespace (and not attached):
 [1] coin_1.2-2        lattice_0.20-38   codetools_0.2-16  mvtnorm_1.0-8     zoo_1.8-4        
 [6] MASS_7.3-51.1     grid_3.5.1        stats4_3.5.1      multcomp_1.4-8    strucchange_1.5-1
[11] party_1.3-1       sandwich_2.5-0    splines_3.5.1     TH.data_1.0-9     tools_3.5.1      
[16] survival_2.43-3   compiler_3.5.1    modeltools_0.2-22",0,Cannot install MXNet R (cannot open URL),"Cannot install MXNet R (cannot open URL) Hi, recently i tried installing MXNet with RStudio on Windows 7. After the command:

I got error:


After:

I got:


And finally, after (found somewhere here when seaching for fix):

It installed but when trying to load library:


I know that Windows 7 is not fully supported but I hope it's not that case.
So the file on server is missing or something? 
I would be very grateful if someone could help me
Thanks


Session info:
R version 3.5.1 (2018-07-02)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Polish_Poland.1250  LC_CTYPE=Polish_Poland.1250    LC_MONETARY=Polish_Poland.1250
[4] LC_NUMERIC=C                   LC_TIME=Polish_Poland.1250    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] arules_1.6-2  Matrix_1.2-14

loaded via a namespace (and not attached):
 [1] coin_1.2-2        lattice_0.20-38   codetools_0.2-16  mvtnorm_1.0-8     zoo_1.8-4        
 [6] MASS_7.3-51.1     grid_3.5.1        stats4_3.5.1      multcomp_1.4-8    strucchange_1.5-1
[11] party_1.3-1       sandwich_2.5-0    splines_3.5.1     TH.data_1.0-9     tools_3.5.1      
[16] survival_2.43-3   compiler_3.5.1    modeltools_0.2-22"
incubator-mxnet,2783,"The [example on bidirectional LSTM](https://github.com/dmlc/mxnet/tree/master/example/bi-lstm-sort) misses the gen_data.py script that is referenced in the ReadMe
Maybe it did not get committed due to gitignore rules? 
@xlvector do you still have the script lying around?
",0,missing script in example bi-lstm-sort,"missing script in example bi-lstm-sort The [example on bidirectional LSTM](https://github.com/dmlc/mxnet/tree/master/example/bi-lstm-sort) misses the gen_data.py script that is referenced in the ReadMe
Maybe it did not get committed due to gitignore rules? 
@xlvector do you still have the script lying around?
"
incubator-mxnet,10387,"

Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10374/1/pipeline/",0,Flaky test(scala): test_arange,"Flaky test(scala): test_arange 

Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10374/1/pipeline/"
incubator-mxnet,384,"I am using mx.model.load_checkpoint and save_checkpoint to store/restore my model. It seems like the gpu/cpu information will also be stored in the .params file. 
When I try to load it (probably on other machine or gpu), I basically create a mx.ndarray and then use ""copyto"" to pass the value I just loaded. So:
1. How can I load it by assigning them a device number? I cannot load it if I had trained it on gpu=3 and try to load it on a machine that has only one gpu (gpu = 0). 
2. How can delete the old value? So I won't touch the gpu that I am not planning to use. 
3. Sometime when I reload the model and try to use .asnumpy() to print out the results, it will cause segmentation fault on some servers (and some does not have this problem). Error message:

Program received signal SIGSEGV, Segmentation fault.
0x00000036ee8897cb in memcpy () from /lib64/libc.so.6

I can still print out .context and .shape, but asnumpy doesn't work. Thanks!!
",0,Question about load_checkpoint/save_checkpoint,"Question about load_checkpoint/save_checkpoint I am using mx.model.load_checkpoint and save_checkpoint to store/restore my model. It seems like the gpu/cpu information will also be stored in the .params file. 
When I try to load it (probably on other machine or gpu), I basically create a mx.ndarray and then use ""copyto"" to pass the value I just loaded. So:
1. How can I load it by assigning them a device number? I cannot load it if I had trained it on gpu=3 and try to load it on a machine that has only one gpu (gpu = 0). 
2. How can delete the old value? So I won't touch the gpu that I am not planning to use. 
3. Sometime when I reload the model and try to use .asnumpy() to print out the results, it will cause segmentation fault on some servers (and some does not have this problem). Error message:

Program received signal SIGSEGV, Segmentation fault.
0x00000036ee8897cb in memcpy () from /lib64/libc.so.6

I can still print out .context and .shape, but asnumpy doesn't work. Thanks!!
"
incubator-mxnet,4661,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
   OS X 10.11.6

Compiler:
    Default Compile Turtoris

Package used (Python/R/Scala/Julia):
      Python
MXNet version   installed from source:
      0.9.1
MXNet commit hash ():
      5656c8601265a437c1cb7ea18a6f1661f346c8b5

Python version and distribution:
       2.7.11

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
  No just run the example in the source code

## Steps to reproduce
1. Install mxnet with setup in the official document: http://mxnet.io/get_started/osx_setup.html#install-mxnet-for-python

2. Download image_segementation pre trained model from baidu.yun

      FCN8S_VGG16_0019

3. Run example image_segmentation.py

    Segementation fault: 11
",0,Segmentation fault:11  with Python 2.7.11 OSX,"Segmentation fault:11  with Python 2.7.11 OSX For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
   OS X 10.11.6

Compiler:
    Default Compile Turtoris

Package used (Python/R/Scala/Julia):
      Python
MXNet version   installed from source:
      0.9.1
MXNet commit hash ():
      5656c8601265a437c1cb7ea18a6f1661f346c8b5

Python version and distribution:
       2.7.11

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
  No just run the example in the source code

## Steps to reproduce
1. Install mxnet with setup in the official document: http://mxnet.io/get_started/osx_setup.html#install-mxnet-for-python

2. Download image_segementation pre trained model from baidu.yun

      FCN8S_VGG16_0019

3. Run example image_segmentation.py

    Segementation fault: 11
"
incubator-mxnet,14389,"The nightly build package for windows uploaded to pypi by the build bot on March 10 seems broken. The file https://files.pythonhosted.org/packages/9a/bc/ee216a4dbe1433d881906513768cf61f9d52c1f8dee133f69f99e1ee9ec7/mxnet_cu80-1.5.0b20190310-py2.py3-none-win_amd64.whl shows a size of 0 bytes on download when it should have 259MB size. The MD5 and SHA-256 checksums are also different.

This is causing issues in our pypi mirror sync as mxnet-cu80 can never complete sync due to broken files. Please fix this if possible.",0,Broken pip package mxnet-cu80 1.5.0b20190310,"Broken pip package mxnet-cu80 1.5.0b20190310 The nightly build package for windows uploaded to pypi by the build bot on March 10 seems broken. The file https://files.pythonhosted.org/packages/9a/bc/ee216a4dbe1433d881906513768cf61f9d52c1f8dee133f69f99e1ee9ec7/mxnet_cu80-1.5.0b20190310-py2.py3-none-win_amd64.whl shows a size of 0 bytes on download when it should have 259MB size. The MD5 and SHA-256 checksums are also different.

This is causing issues in our pypi mirror sync as mxnet-cu80 can never complete sync due to broken files. Please fix this if possible."
incubator-mxnet,4945,"Is there anyone have an usable android library which mxnet vision is after v0.8.0?
I have tried compile the  amalgamation many times, but it broken when using in Android app. ",0,Upload the usable Android library libmxnet_predict.so please!!!,"Upload the usable Android library libmxnet_predict.so please!!! Is there anyone have an usable android library which mxnet vision is after v0.8.0?
I have tried compile the  amalgamation many times, but it broken when using in Android app. "
incubator-mxnet,467,"When I try to compile LSTM with quite a long time steps (200), following error occurs,



It seems that for whatever reason, 100 is a hard limit on the number of args that can be compiled ? I wonder whether we can change this bound (if we have more memory)

Thanks !
",0,Raising num_args bound ?,"Raising num_args bound ? When I try to compile LSTM with quite a long time steps (200), following error occurs,



It seems that for whatever reason, 100 is a hard limit on the number of args that can be compiled ? I wonder whether we can change this bound (if we have more memory)

Thanks !
"
incubator-mxnet,3967,"I use the symbol.simple_bind to train the network batch by batch, below is the code snippet

 exe = self.symbol.simple_bind(ctx=self.ctx, **input_shapes)
 for batch in train_data:
      exe.forward(is_train=True)
      exe.backward()
      print ""before""
      print exe.arg_dict['bn_conv1_gamma'].asnumpy()
      
      for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):
            weight, grad = pair
            if i==3:
                  print ""arr_arrays""
                  print weight.asnumpy()
                  print ""arg_dict""
                  print exe.arg_dict['bn_conv1_gamma'].asnumpy()
                  
      self.updater(i, grad, weight)


where 'bn_conv1_gamma' is the 3rd(from 0) of self.symbol.list_arguments(), i found that the value of exe.arg_dict['bn_conv1_gamma'].asnumpy() is different in different position, which really confused me.",0,"the value of executor.arg_dict[""bn_conv1_gamma""] is different in different position of one iteration","the value of executor.arg_dict[""bn_conv1_gamma""] is different in different position of one iteration I use the symbol.simple_bind to train the network batch by batch, below is the code snippet

 exe = self.symbol.simple_bind(ctx=self.ctx, **input_shapes)
 for batch in train_data:
      exe.forward(is_train=True)
      exe.backward()
      print ""before""
      print exe.arg_dict['bn_conv1_gamma'].asnumpy()
      
      for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):
            weight, grad = pair
            if i==3:
                  print ""arr_arrays""
                  print weight.asnumpy()
                  print ""arg_dict""
                  print exe.arg_dict['bn_conv1_gamma'].asnumpy()
                  
      self.updater(i, grad, weight)


where 'bn_conv1_gamma' is the 3rd(from 0) of self.symbol.list_arguments(), i found that the value of exe.arg_dict['bn_conv1_gamma'].asnumpy() is different in different position, which really confused me."
incubator-mxnet,8933,"There are 600 classes in the image dataset, each image belongs to one or more classes. How can I train such dataset?

**Is it a correct choice:**
Present image label by 600*1 binary vector, which contains one or more ""1"".
Bulid network with 600 outputs, and activate them with LogisticRegressionOutput()  (BTW, Will mxnet set the loss function to logistic loss automatically?)

I obtain a 0.49% mAP on this dataset, by it's reported 36.1% in the paper. (Parameters are set the same as the paper)",0,How to train data with multi-class label,"How to train data with multi-class label There are 600 classes in the image dataset, each image belongs to one or more classes. How can I train such dataset?

**Is it a correct choice:**
Present image label by 600*1 binary vector, which contains one or more ""1"".
Bulid network with 600 outputs, and activate them with LogisticRegressionOutput()  (BTW, Will mxnet set the loss function to logistic loss automatically?)

I obtain a 0.49% mAP on this dataset, by it's reported 36.1% in the paper. (Parameters are set the same as the paper)"
incubator-mxnet,331,"I am attempting to install on a cluster running Red Hat Enterprise Linux 6. I have loaded opencv 3.0.0, and have a link to all the .so files. However,  will still fail, saying I need to find . I cannot find that in my opencv installation, can you point me in the right direction?

See error message below:

pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/c_api.cc -o build/c_api.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/resource.cc -o build/resource.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/engine.cc -o build/engine/engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/naive_engine.cc -o build/engine/naive_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine.cc -o build/engine/threaded_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_perdevice.cc -o build/engine/threaded_engine_perdevice.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_pooled.cc -o build/engine/threaded_engine_pooled.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/io/io.cc -o build/io/io.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing 
",0,opencv not found,"opencv not found I am attempting to install on a cluster running Red Hat Enterprise Linux 6. I have loaded opencv 3.0.0, and have a link to all the .so files. However,  will still fail, saying I need to find . I cannot find that in my opencv installation, can you point me in the right direction?

See error message below:

pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/c_api.cc -o build/c_api.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/resource.cc -o build/resource.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/engine.cc -o build/engine/engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/naive_engine.cc -o build/engine/naive_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine.cc -o build/engine/threaded_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_perdevice.cc -o build/engine/threaded_engine_perdevice.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_pooled.cc -o build/engine/threaded_engine_pooled.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/io/io.cc -o build/io/io.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing 
"
incubator-mxnet,12532,"Hi,

environment MXNet v1.0.0

I want to use caffe operator to implement some custom layers,such as the solution in mxnet/example/caffe/
I follow the install command described in https://mxnet.incubator.apache.org/faq/caffe.html, how to solve these problems?
1. git clone https://github.com/BVLC/caffe
2. cd caffe && wget https://github.com/BVLC/caffe/pull/4527.patch && git apply 4527.patch

thanks a lot !!



also if it has the cmake method for below configuration.
   CAFFE_PATH = $(HOME)/caffe
   MXNET_PLUGINS += plugin/caffe/caffe.mk



![image](https://user-images.githubusercontent.com/31586393/45429203-63981280-b6d5-11e8-9738-107f94cdc2ef.png)
",0,caffeOp mxnet build failed,"caffeOp mxnet build failed Hi,

environment MXNet v1.0.0

I want to use caffe operator to implement some custom layers,such as the solution in mxnet/example/caffe/
I follow the install command described in https://mxnet.incubator.apache.org/faq/caffe.html, how to solve these problems?
1. git clone https://github.com/BVLC/caffe
2. cd caffe && wget https://github.com/BVLC/caffe/pull/4527.patch && git apply 4527.patch

thanks a lot !!



also if it has the cmake method for below configuration.
   CAFFE_PATH = $(HOME)/caffe
   MXNET_PLUGINS += plugin/caffe/caffe.mk



![image](https://user-images.githubusercontent.com/31586393/45429203-63981280-b6d5-11e8-9738-107f94cdc2ef.png)
"
incubator-mxnet,13875,"may be related to #13831

## Description
importing mxnet causes OSErrors in subprocess


## Environment info (Required)
Scientific Linux 7.5
Python 3.6.3 
MXnet 1.5.0 (from packages)
(tried on multiple computers running different cuda builds) 


## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
Using the following script (or just using the appropriate commands)


will eventually give this error message:

Traceback (most recent call last):
   File ""subcrash.py"", line 13, in <module>
     ret = subprocess.call(['ls', '/'], stdout=subprocess.PIPE)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 267, in call
     with Popen(*popenargs, **kwargs) as p:
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 709, in __init__
     restore_signals, start_new_session)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 1344, in _execute_child
     raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 14] Bad address: 'ls'

Doesn't seem to matter which executable.

## What have you tried to solve it?

Don't even know where to start.
If you try putting in a stack tract or pdb it won't break.

",0,importing mxnet causing subprocess to crash,"importing mxnet causing subprocess to crash may be related to #13831

## Description
importing mxnet causes OSErrors in subprocess


## Environment info (Required)
Scientific Linux 7.5
Python 3.6.3 
MXnet 1.5.0 (from packages)
(tried on multiple computers running different cuda builds) 


## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
Using the following script (or just using the appropriate commands)


will eventually give this error message:

Traceback (most recent call last):
   File ""subcrash.py"", line 13, in <module>
     ret = subprocess.call(['ls', '/'], stdout=subprocess.PIPE)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 267, in call
     with Popen(*popenargs, **kwargs) as p:
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 709, in __init__
     restore_signals, start_new_session)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 1344, in _execute_child
     raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 14] Bad address: 'ls'

Doesn't seem to matter which executable.

## What have you tried to solve it?

Don't even know where to start.
If you try putting in a stack tract or pdb it won't break.

"
incubator-mxnet,2975,"https://github.com/dmlc/mxnet/blob/master/example/rcnn/rcnn/rpn/generate.py#L30

For BN layers, this will erase the moving_mean and moving_var in aux, which will lead to wrong results; I don't know if there are any special reasons to do this? @precedenceguo 
",0,"a question about rcnn exmaple, why set aux to zero when testing?","a question about rcnn exmaple, why set aux to zero when testing? https://github.com/dmlc/mxnet/blob/master/example/rcnn/rcnn/rpn/generate.py#L30

For BN layers, this will erase the moving_mean and moving_var in aux, which will lead to wrong results; I don't know if there are any special reasons to do this? @precedenceguo 
"
incubator-mxnet,11334,"ref: https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213

It looks like SymbolBlock will initializing all the parameters using the initializer given in the block.initialize() function, including bias, which cannot be initialized by Xavier. 

Alought that [post](https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213) suggests a solution, and in addition, I think we should try to initialize the parameters if it was given in the symbol/json file.

e.g. 

or


Or if there a better way please let me know.",0,Cannot initializing parameters of SymbolBlock.,"Cannot initializing parameters of SymbolBlock. ref: https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213

It looks like SymbolBlock will initializing all the parameters using the initializer given in the block.initialize() function, including bias, which cannot be initialized by Xavier. 

Alought that [post](https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213) suggests a solution, and in addition, I think we should try to initialize the parameters if it was given in the symbol/json file.

e.g. 

or


Or if there a better way please let me know."
incubator-mxnet,5455,"softmax_label is not really a good default name, many times you are not doing softmax. I think 'label' would be a better default name. This proposed refactor would change the default values of 'softmax_label' to 'label'.",0,Refactor 'softmax_label' to 'label',"Refactor 'softmax_label' to 'label' softmax_label is not really a good default name, many times you are not doing softmax. I think 'label' would be a better default name. This proposed refactor would change the default values of 'softmax_label' to 'label'."
incubator-mxnet,11241,"Setup: 


Run the following script :

Gives the following error:

Note that there's no error if  is changed to 'write'. 

Can also be reproduced if I build mxnet from source at commit 5b99b25e5f6ab3a20c7bcf4821a6af0a1a95f823 where Conv1D CUDNN was initially introduced.",0,Conv1D throws CUDNN_STATUS_EXECUTION_FAILED,"Conv1D throws CUDNN_STATUS_EXECUTION_FAILED Setup: 


Run the following script :

Gives the following error:

Note that there's no error if  is changed to 'write'. 

Can also be reproduced if I build mxnet from source at commit 5b99b25e5f6ab3a20c7bcf4821a6af0a1a95f823 where Conv1D CUDNN was initially introduced."
incubator-mxnet,16101,"
## Description
### Bug 
[mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where) shows an incorrect behavior when one of the inputs is an NDArray with zero size. 

Here is a reproducible example

The output is weird and it seems that the NDArray with zero size has not been checked. We expect that it would raise an error showing the shape of x and y must be the same, according to [docs of mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where). Broadcast is not supported in the latest version but where() still has an output.

 It is also a little dangerous as it outputs incorrect answers rather than error messages, when users forget to type [] for mx.nd.array([4]).


<br>

### Feature Request
#### 1. Broadcast

Currently, there are two limitations for mx.nd.where()
 - x and y must have the same shape
 - If condition does not have the same shape as x, it must be a 1D array whose size is the same as x’s first dimension size

Similar to [np.where()](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html), it would be great if mx.nd.where() supports broadcast to make sure (cond, x, y) have the same shape, even if they are in different shapes as input. 

<br>

#### 2.  Scalar inputs (cond, x and y)
In some situations, we want to give a constant value for True/False.

It would be user-friendly if programmers only need to type 
 
instead of 





<br>
<br> 
<br> 
<br> 
<br>


---

## Environment info (Required)





## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 03f12f0fe706d35c93a2cf721b6101bcbffeb07d

Build config:  plain CMakeList.txt with USE_NCCL=1






",0,[Feature Request]  np.where compatible operator,"[Feature Request]  np.where compatible operator 
## Description
### Bug 
[mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where) shows an incorrect behavior when one of the inputs is an NDArray with zero size. 

Here is a reproducible example

The output is weird and it seems that the NDArray with zero size has not been checked. We expect that it would raise an error showing the shape of x and y must be the same, according to [docs of mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where). Broadcast is not supported in the latest version but where() still has an output.

 It is also a little dangerous as it outputs incorrect answers rather than error messages, when users forget to type [] for mx.nd.array([4]).


<br>

### Feature Request
#### 1. Broadcast

Currently, there are two limitations for mx.nd.where()
 - x and y must have the same shape
 - If condition does not have the same shape as x, it must be a 1D array whose size is the same as x’s first dimension size

Similar to [np.where()](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html), it would be great if mx.nd.where() supports broadcast to make sure (cond, x, y) have the same shape, even if they are in different shapes as input. 

<br>

#### 2.  Scalar inputs (cond, x and y)
In some situations, we want to give a constant value for True/False.

It would be user-friendly if programmers only need to type 
 
instead of 





<br>
<br> 
<br> 
<br> 
<br>


---

## Environment info (Required)





## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 03f12f0fe706d35c93a2cf721b6101bcbffeb07d

Build config:  plain CMakeList.txt with USE_NCCL=1






"
incubator-mxnet,9408,"Description WIP

Initial error: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/1/pipeline/



Future errors: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/9/pipeline/


git status on Jenkins master
",0,[CI] Merging is not possible because you have unmerged files.,"[CI] Merging is not possible because you have unmerged files. Description WIP

Initial error: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/1/pipeline/



Future errors: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/9/pipeline/


git status on Jenkins master
"
incubator-mxnet,1198,"sometimes the travis breaked in cpp_test job in pr with the log: 



but most of the time it is correct, so is due to the changed code or something else?
i met this problem a few times.
",0,travis sometimes suspend on threaded_engine_test.cc ,"travis sometimes suspend on threaded_engine_test.cc  sometimes the travis breaked in cpp_test job in pr with the log: 



but most of the time it is correct, so is due to the changed code or something else?
i met this problem a few times.
"
incubator-mxnet,12294,"I'm trying to install MXNET in R and use the library.

**Step1**: # Install the package
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")

**Comment in console:**
trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.5/drat_0.1.4.tgz'
Content type 'application/x-gzip' length 64654 bytes (63 KB)
==================================================
downloaded 63 KB


The downloaded binary packages are in
	/var/folders/rq/vv5bw20n3nv91pccc5krh55h0000gn/T//RtmpWtd63g/downloaded_packages

**Step2:**#install the library
library(mxnet)

**Error**
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so, 10): Library not loaded: /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so
  Reason: image not found
In addition: Warning message:
replacing previous import ‘scales::viridis_pal’ by ‘viridis::viridis_pal’ when loading ‘DiagrammeR’ 
*****************************

**Below is my sessioninfo:**
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.18       pillar_1.3.0       compiler_3.5.1     RColorBrewer_1.1-2 influenceR_0.1.0   plyr_1.8.4         bindr_0.1.1        viridis_0.5.1      tools_3.5.1       
[10] digest_0.6.15      jsonlite_1.5       tibble_1.4.2       gtable_0.2.0       viridisLite_0.3.0  rgexf_0.15.3       pkgconfig_2.0.2    rlang_0.2.2        igraph_1.2.2      
[19] rstudioapi_0.7     yaml_2.2.0         bindrcpp_0.2.2     gridExtra_2.3      stringr_1.3.1      DiagrammeR_0.9.0   dplyr_0.7.6        htmlwidgets_1.2    grid_3.5.1        
[28] tidyselect_0.2.4   glue_1.3.0         R6_2.2.2           Rook_1.1-1         XML_3.98-1.16      ggplot2_3.0.0      purrr_0.2.5        magrittr_1.5       scales_1.0.0      
[37] htmltools_0.3.6    assertthat_0.2.0   colorspace_1.3-2   brew_1.0-6         stringi_1.2.4      visNetwork_2.0.4   lazyeval_0.2.1     munsell_0.5.0      crayon_1.3.4   
***********************************
Can you please help?
",0,MXNET installation and library failing in R,"MXNET installation and library failing in R I'm trying to install MXNET in R and use the library.

**Step1**: # Install the package
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")

**Comment in console:**
trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.5/drat_0.1.4.tgz'
Content type 'application/x-gzip' length 64654 bytes (63 KB)
==================================================
downloaded 63 KB


The downloaded binary packages are in
	/var/folders/rq/vv5bw20n3nv91pccc5krh55h0000gn/T//RtmpWtd63g/downloaded_packages

**Step2:**#install the library
library(mxnet)

**Error**
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so, 10): Library not loaded: /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so
  Reason: image not found
In addition: Warning message:
replacing previous import ‘scales::viridis_pal’ by ‘viridis::viridis_pal’ when loading ‘DiagrammeR’ 
*****************************

**Below is my sessioninfo:**
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.18       pillar_1.3.0       compiler_3.5.1     RColorBrewer_1.1-2 influenceR_0.1.0   plyr_1.8.4         bindr_0.1.1        viridis_0.5.1      tools_3.5.1       
[10] digest_0.6.15      jsonlite_1.5       tibble_1.4.2       gtable_0.2.0       viridisLite_0.3.0  rgexf_0.15.3       pkgconfig_2.0.2    rlang_0.2.2        igraph_1.2.2      
[19] rstudioapi_0.7     yaml_2.2.0         bindrcpp_0.2.2     gridExtra_2.3      stringr_1.3.1      DiagrammeR_0.9.0   dplyr_0.7.6        htmlwidgets_1.2    grid_3.5.1        
[28] tidyselect_0.2.4   glue_1.3.0         R6_2.2.2           Rook_1.1-1         XML_3.98-1.16      ggplot2_3.0.0      purrr_0.2.5        magrittr_1.5       scales_1.0.0      
[37] htmltools_0.3.6    assertthat_0.2.0   colorspace_1.3-2   brew_1.0-6         stringi_1.2.4      visNetwork_2.0.4   lazyeval_0.2.1     munsell_0.5.0      crayon_1.3.4   
***********************************
Can you please help?
"
incubator-mxnet,11508,"This is what I guess. Is it right?

        trainer.allreduce_grads()
        with autograd.record():
            logits = model(input)
            loss = criterion(logits, target)
        loss.backward()

        grads = [i.grad(ctx) for i in model.params.values()]
        gluon.utils.clip_global_norm(grads, args.grad_clip)
        trainer.update(args.batch_size)",0,【Question】Are there any examples for gradients clipping in gluon?,"【Question】Are there any examples for gradients clipping in gluon? This is what I guess. Is it right?

        trainer.allreduce_grads()
        with autograd.record():
            logits = model(input)
            loss = criterion(logits, target)
        loss.backward()

        grads = [i.grad(ctx) for i in model.params.values()]
        gluon.utils.clip_global_norm(grads, args.grad_clip)
        trainer.update(args.batch_size)"
incubator-mxnet,5218,">>> import mxnet
libdc1394 error: Failed to initialize libdc1394
[01:20:36] /mnt/Mxnet/docker/mxnet93/dmlc-core/include/dmlc/logging.h:300: [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

Aborted (core dumped)",0,core dumped when I try to compile mxnet0.9.3 with nnpack support WHY？,"core dumped when I try to compile mxnet0.9.3 with nnpack support WHY？ >>> import mxnet
libdc1394 error: Failed to initialize libdc1394
[01:20:36] /mnt/Mxnet/docker/mxnet93/dmlc-core/include/dmlc/logging.h:300: [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

Aborted (core dumped)"
incubator-mxnet,329,"- [ ] Have a configure.win in the src to search the library, put things(libmxnet.dll) in right position
- [ ] Proper error message to tell user what to install when things do not exist.
- [ ] Ideally only compile the  x64 version.
- [ ] A Makefile option winRpack, to pack a binary distributable version of package.
  - We can ship libmxnet.dll, but need to assume all thirdparty dlls are on path.
  - It is also fine to assume libmxnet.dll is on path, if we treat it as a library(maybe easier for us to go CRAN).
",0,"[R, Windows] Process Tracking","[R, Windows] Process Tracking - [ ] Have a configure.win in the src to search the library, put things(libmxnet.dll) in right position
- [ ] Proper error message to tell user what to install when things do not exist.
- [ ] Ideally only compile the  x64 version.
- [ ] A Makefile option winRpack, to pack a binary distributable version of package.
  - We can ship libmxnet.dll, but need to assume all thirdparty dlls are on path.
  - It is also fine to assume libmxnet.dll is on path, if we treat it as a library(maybe easier for us to go CRAN).
"
incubator-mxnet,6796,"Hi,
I am new to Mxnet. I am interested in implementing a new C++ layer, but I am wondering how to debug during the process. Do I have to recompile the whole framework to test it? Or is there any other simpler way. It seems like recompiling takes way too much time. I did not find any useful info in the tutorial. Hope to get some hints. Thanks.
@mli @piiswrong @tqchen ",0,How to debug a C++ layer,"How to debug a C++ layer Hi,
I am new to Mxnet. I am interested in implementing a new C++ layer, but I am wondering how to debug during the process. Do I have to recompile the whole framework to test it? Or is there any other simpler way. It seems like recompiling takes way too much time. I did not find any useful info in the tutorial. Hope to get some hints. Thanks.
@mli @piiswrong @tqchen "
incubator-mxnet,12497,"I'm using mxnet 1.3.0 and onnx 1.3, No conversion function registered for op type _arange yet, so the arange function have not been surported?",0,Onnx arange op not supported!,"Onnx arange op not supported! I'm using mxnet 1.3.0 and onnx 1.3, No conversion function registered for op type _arange yet, so the arange function have not been surported?"
incubator-mxnet,14245,"Using Python. Trying to visualize with global_pooling and no kernel crashes.

The visualization code fails when trying to run:

on the layer below:

while it works on when setting a kernel:


labels: Bug",0,visualize with global_pooling and no kernel crashes.,"visualize with global_pooling and no kernel crashes. Using Python. Trying to visualize with global_pooling and no kernel crashes.

The visualization code fails when trying to run:

on the layer below:

while it works on when setting a kernel:


labels: Bug"
incubator-mxnet,2715,"I try to use MNISTIter to get each bacth data from it. I read the document in the corresponding page. It suppose to use DataIter's getdata() method. Why it throw a error when I use this way. Could any one explain why it happen please?  
The error message is below:
Traceback (most recent call last):
  File ""testMNIST.py"", line 58, in <module>
    X_test_batch = testIter.getdata()
  File ""C:\Python34\lib\site-packages\mxnet-0.7.0-py3.4.egg\mxnet\io.py"", line 504, in getdata
    check_call(_LIB.MXDataIterGetData(self.handle, ctypes.byref(hdl)))
OSError: exception: access violation reading 0x0000000000000000
",0,MNISTIter call getdata method throw error,"MNISTIter call getdata method throw error I try to use MNISTIter to get each bacth data from it. I read the document in the corresponding page. It suppose to use DataIter's getdata() method. Why it throw a error when I use this way. Could any one explain why it happen please?  
The error message is below:
Traceback (most recent call last):
  File ""testMNIST.py"", line 58, in <module>
    X_test_batch = testIter.getdata()
  File ""C:\Python34\lib\site-packages\mxnet-0.7.0-py3.4.egg\mxnet\io.py"", line 504, in getdata
    check_call(_LIB.MXDataIterGetData(self.handle, ctypes.byref(hdl)))
OSError: exception: access violation reading 0x0000000000000000
"
incubator-mxnet,4960,"Hi, can we have some feature supporting varaible batch size? When doing lstm validation, I need to fill those buckets with duplicated examples if the number of example is not enough.
Alough I can bypass this issue by flating each bucket data with speical designed bucket key, is there any more elegant solution? ",0,Variable batch size ,"Variable batch size  Hi, can we have some feature supporting varaible batch size? When doing lstm validation, I need to fill those buckets with duplicated examples if the number of example is not enough.
Alough I can bypass this issue by flating each bucket data with speical designed bucket key, is there any more elegant solution? "
incubator-mxnet,2699,"

  What does output mean?
the softmax loss output or the first layers output?
If not softmax loss output,how can i get it?
",0,what is the meaning of ouput in image_segmentation.py,"what is the meaning of ouput in image_segmentation.py 

  What does output mean?
the softmax loss output or the first layers output?
If not softmax loss output,how can i get it?
"
incubator-mxnet,8514,"![label2](https://user-images.githubusercontent.com/13029886/32312590-9120270e-bfd9-11e7-9fdb-de29aece2422.png)
![res2](https://user-images.githubusercontent.com/13029886/32312591-9159ea7a-bfd9-11e7-8658-e3fa1ce90bf2.png)
",0,upload result in segnet,"upload result in segnet ![label2](https://user-images.githubusercontent.com/13029886/32312590-9120270e-bfd9-11e7-9fdb-de29aece2422.png)
![res2](https://user-images.githubusercontent.com/13029886/32312591-9159ea7a-bfd9-11e7-8658-e3fa1ce90bf2.png)
"
incubator-mxnet,14426,"Minimum reproducible example. 


To reproduce, this will require the exception handling support for waitall in this PR: https://github.com/apache/incubator-mxnet/pull/14397 . This issue was found because of CI failures when running test_random.py on windows. It was hidden earlier because waitall didnt have exception rethrow support. This issue may have been around since the PR was added: #10367 

Currently working on fixing this.",0,mx.random.seed with ctx failures on a gpu build when run with cpu context,"mx.random.seed with ctx failures on a gpu build when run with cpu context Minimum reproducible example. 


To reproduce, this will require the exception handling support for waitall in this PR: https://github.com/apache/incubator-mxnet/pull/14397 . This issue was found because of CI failures when running test_random.py on windows. It was hidden earlier because waitall didnt have exception rethrow support. This issue may have been around since the PR was added: #10367 

Currently working on fixing this."
incubator-mxnet,7094,Is there a function or some sample code to save a mxnet model as a keras model (such as .h5) or load a keras model into mxnet? ,0,Save a mxnet model to keras and vice versa,Save a mxnet model to keras and vice versa Is there a function or some sample code to save a mxnet model as a keras model (such as .h5) or load a keras model into mxnet? 
incubator-mxnet,7472,"## Question

Usually, a neural network is trained by using a training, validation and test set. 
Having a continuous series of data, an event (new training data) occurring every 1-5 seconds, is it possible to continuously train (update) a recurrent neural network using mxnet? I don't need to care to reuse previous (training) data points: I just want to update the weights slightly(!) on each new event.

It's for a behaviour/game like system: depending on the (expressed/intentional) behaviour of the players (the features), the output of the system should be estimated and continuously adapted (for further processing). The system has to learn on the way, and being able to cope with, to a certain extend, changing player behaviour and it needs to remember certain patterns from weeks and if possible, months, ago. (I'd probably be mainly an LSTM.)

Storing all data and retrain the system on that data is close to impossible because:
1. I estimate there's about 10-100GB of data per day (will be varying)
2. retraining every time, let's say, 10 seconds, on all existing data would take too long.

I want a system that continuously trains itself on the real data, not splitting into training/testing/validation sets:
1. The training set is the real data, comparing the actual state of the system with the prediction previously made
2. There's not validation, besides the fact that the system validates itself
3. Testing is done on every new event. The predictive power will be continuously determined.

Can this be done with mxnet, having a training data stream?

(In dl4j, there's https://deeplearning4j.org/usingrnns#test-time-predictions-one-step-at-a-time , and one can update the model with fit, one step at a time - having a data iterator that runs a fit every x seconds)

## Environment info
This is not really relevant, but well, I don't mind providing it :)

Operating System:


Compiler: ?

Package used (Python/R/Scala/Julia): R

MXNet version:
",0,continuously train rnn - training data stream?,"continuously train rnn - training data stream? ## Question

Usually, a neural network is trained by using a training, validation and test set. 
Having a continuous series of data, an event (new training data) occurring every 1-5 seconds, is it possible to continuously train (update) a recurrent neural network using mxnet? I don't need to care to reuse previous (training) data points: I just want to update the weights slightly(!) on each new event.

It's for a behaviour/game like system: depending on the (expressed/intentional) behaviour of the players (the features), the output of the system should be estimated and continuously adapted (for further processing). The system has to learn on the way, and being able to cope with, to a certain extend, changing player behaviour and it needs to remember certain patterns from weeks and if possible, months, ago. (I'd probably be mainly an LSTM.)

Storing all data and retrain the system on that data is close to impossible because:
1. I estimate there's about 10-100GB of data per day (will be varying)
2. retraining every time, let's say, 10 seconds, on all existing data would take too long.

I want a system that continuously trains itself on the real data, not splitting into training/testing/validation sets:
1. The training set is the real data, comparing the actual state of the system with the prediction previously made
2. There's not validation, besides the fact that the system validates itself
3. Testing is done on every new event. The predictive power will be continuously determined.

Can this be done with mxnet, having a training data stream?

(In dl4j, there's https://deeplearning4j.org/usingrnns#test-time-predictions-one-step-at-a-time , and one can update the model with fit, one step at a time - having a data iterator that runs a fit every x seconds)

## Environment info
This is not really relevant, but well, I don't mind providing it :)

Operating System:


Compiler: ?

Package used (Python/R/Scala/Julia): R

MXNet version:
"
incubator-mxnet,9989,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Cannot train gluon style transfer, needs to be outside of autograd.record() block or need to call backward.

## Environment info (Required)
----------Python Info----------
('Version      :', '2.7.10')
('Compiler     :', 'GCC 4.1.2')
('Build        :', ('default', 'Jun 29 2015 12:45:31'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
No corresponding pip install for current python.
----------MXNet Info-----------
/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG
  Optimizer.opt_registry[name].__name__))
('Version      :', '1.1.0')
('Directory    :', '/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet')
Hashtag not found. Not installed from pre-built package.
----------System Info----------
('Platform     :', 'Linux-3.10.105-1.el6.elrepo.x86_64-x86_64-with-centos-6.2-Final')
('system       :', 'Linux')
('node         :', 'bladerunner')                                                                                                                                                                                                            
('release      :', '3.10.105-1.el6.elrepo.x86_64')                                                                                                                                                                                           
('version      :', '#1 SMP Fri Feb 10 10:48:08 EST 2017')                                                                                                                                                                                    
----------Hardware Info----------                                                                                                                                                                                                            
('machine      :', 'x86_64')                                                                                                                                                                                                                 
('processor    :', 'x86_64')                                                                                                                                                                                                                 
Architecture:          x86_64                                                                                                                                                                                                                
CPU op-mode(s):        32-bit, 64-bit                                                                                                                                                                                                        
Byte Order:            Little Endian                                                                                                                                                                                                         
CPU(s):                12                                                                                                                                                                                                                    
On-line CPU(s) list:   0-11                                                                                                                                                                                                                  
Thread(s) per core:    1                                                                                                                                                                                                                     
Core(s) per socket:    6                                                                                                                                                                                                                     
Socket(s):             2                                                                                                                                                                                                                     
NUMA node(s):          2                                                                                                                                                                                                                     
Vendor ID:             GenuineIntel                                                                                                                                                                                                          
CPU family:            6                                                                                                                                                                                                                     
Model:                 63                                                                                                                                                                                                                    
Model name:            Intel(R) Xeon(R) CPU E5-2609 v3 @ 1.90GHz                                                                                                                                                                             
Stepping:              2                                                                                                                                                                                                                     
CPU MHz:               1900.000                                                                                                                                                                                                              
BogoMIPS:              3796.70                                                                                                                                                                                                               
Virtualization:        VT-x                                                                                                                                                                                                                  
L1d cache:             32K                                                                                                                                                                                                                   
L1i cache:             32K                                                                                                                                                                                                                   
L2 cache:              256K                                                                                                                                                                                                                  
L3 cache:              15360K                                                                                                                                                                                                                
NUMA node0 CPU(s):     0-5                                                                                                                                                                                                                   
NUMA node1 CPU(s):     6-11                                                                                                                                                                                                                  
----------Network Test----------                                                                                                                                                                                                             
Setting timeout: 10
Error open MXNet: https://github.com/apache/incubator-mxnet, <urlopen error timed out>, DNS finished in 0.0260591506958 sec.
Error open PYPI: https://pypi.python.org/pypi/pip, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.170429944992 sec.
Error open FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.204452037811 sec.
Error open Conda: https://repo.continuum.io/pkgs/free/, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.154680967331 sec.
Error open Gluon Tutorial(en): http://gluon.mxnet.io, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.381160974503 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.432467937469 sec.


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): GCC-4.8.5 on Centos 6.2

MXNet commit hash:
b73c57c526396d6485bdf65986e3819c54eb7bd9


Build config:



## Error Message:



## Minimum reproducible example
Run the main.py in 

https://github.com/apache/incubator-mxnet/tree/master/example/gluon/style_transfer

as follows

main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models

after download the coco dataset and the style images

## Steps to reproduce

1. Install mxnet
2. get the installed version into the environment
3. cd example/gluon/style_transfer/
4. python main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models


## What have you tried to solve it?

1. move https://github.com/apache/incubator-mxnet/blob/master/example/gluon/style_transfer/main.py#L82
2. to between L79 and L80
3. Model will train but produces bad result
",0,Cannot train example gluon style transfer,"Cannot train example gluon style transfer Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Cannot train gluon style transfer, needs to be outside of autograd.record() block or need to call backward.

## Environment info (Required)
----------Python Info----------
('Version      :', '2.7.10')
('Compiler     :', 'GCC 4.1.2')
('Build        :', ('default', 'Jun 29 2015 12:45:31'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
No corresponding pip install for current python.
----------MXNet Info-----------
/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG
  Optimizer.opt_registry[name].__name__))
('Version      :', '1.1.0')
('Directory    :', '/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet')
Hashtag not found. Not installed from pre-built package.
----------System Info----------
('Platform     :', 'Linux-3.10.105-1.el6.elrepo.x86_64-x86_64-with-centos-6.2-Final')
('system       :', 'Linux')
('node         :', 'bladerunner')                                                                                                                                                                                                            
('release      :', '3.10.105-1.el6.elrepo.x86_64')                                                                                                                                                                                           
('version      :', '#1 SMP Fri Feb 10 10:48:08 EST 2017')                                                                                                                                                                                    
----------Hardware Info----------                                                                                                                                                                                                            
('machine      :', 'x86_64')                                                                                                                                                                                                                 
('processor    :', 'x86_64')                                                                                                                                                                                                                 
Architecture:          x86_64                                                                                                                                                                                                                
CPU op-mode(s):        32-bit, 64-bit                                                                                                                                                                                                        
Byte Order:            Little Endian                                                                                                                                                                                                         
CPU(s):                12                                                                                                                                                                                                                    
On-line CPU(s) list:   0-11                                                                                                                                                                                                                  
Thread(s) per core:    1                                                                                                                                                                                                                     
Core(s) per socket:    6                                                                                                                                                                                                                     
Socket(s):             2                                                                                                                                                                                                                     
NUMA node(s):          2                                                                                                                                                                                                                     
Vendor ID:             GenuineIntel                                                                                                                                                                                                          
CPU family:            6                                                                                                                                                                                                                     
Model:                 63                                                                                                                                                                                                                    
Model name:            Intel(R) Xeon(R) CPU E5-2609 v3 @ 1.90GHz                                                                                                                                                                             
Stepping:              2                                                                                                                                                                                                                     
CPU MHz:               1900.000                                                                                                                                                                                                              
BogoMIPS:              3796.70                                                                                                                                                                                                               
Virtualization:        VT-x                                                                                                                                                                                                                  
L1d cache:             32K                                                                                                                                                                                                                   
L1i cache:             32K                                                                                                                                                                                                                   
L2 cache:              256K                                                                                                                                                                                                                  
L3 cache:              15360K                                                                                                                                                                                                                
NUMA node0 CPU(s):     0-5                                                                                                                                                                                                                   
NUMA node1 CPU(s):     6-11                                                                                                                                                                                                                  
----------Network Test----------                                                                                                                                                                                                             
Setting timeout: 10
Error open MXNet: https://github.com/apache/incubator-mxnet, <urlopen error timed out>, DNS finished in 0.0260591506958 sec.
Error open PYPI: https://pypi.python.org/pypi/pip, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.170429944992 sec.
Error open FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.204452037811 sec.
Error open Conda: https://repo.continuum.io/pkgs/free/, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.154680967331 sec.
Error open Gluon Tutorial(en): http://gluon.mxnet.io, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.381160974503 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.432467937469 sec.


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): GCC-4.8.5 on Centos 6.2

MXNet commit hash:
b73c57c526396d6485bdf65986e3819c54eb7bd9


Build config:



## Error Message:



## Minimum reproducible example
Run the main.py in 

https://github.com/apache/incubator-mxnet/tree/master/example/gluon/style_transfer

as follows

main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models

after download the coco dataset and the style images

## Steps to reproduce

1. Install mxnet
2. get the installed version into the environment
3. cd example/gluon/style_transfer/
4. python main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models


## What have you tried to solve it?

1. move https://github.com/apache/incubator-mxnet/blob/master/example/gluon/style_transfer/main.py#L82
2. to between L79 and L80
3. Model will train but produces bad result
"
incubator-mxnet,3710,"hi, I want to load some labeled and unlabeled data into mxnet.  
I follow the example [https://github.com/dmlc/mxnet/blob/master/example/fcn-xs/data.py#L96](url) to create a dataiter.
how to implement the  method for unlabel data?
Thanks for your attention.",0,how to deal with the unlabel data with the dataiter?,"how to deal with the unlabel data with the dataiter? hi, I want to load some labeled and unlabeled data into mxnet.  
I follow the example [https://github.com/dmlc/mxnet/blob/master/example/fcn-xs/data.py#L96](url) to create a dataiter.
how to implement the  method for unlabel data?
Thanks for your attention."
incubator-mxnet,6073,"$ python ../../tools/launch.py -n 2 --launcher yarn python  train_mnist.py --network lenet --kv-store dist_sync
17/05/03 01:24:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/03 01:24:50 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
17/05/03 01:24:50 INFO impl.TimelineClientImpl: Timeline service address: http://<server>/X.X.X.X:8188/ws/v1/timeline/
17/05/03 01:24:50 INFO client.RMProxy: Connecting to ResourceManager at <server>/X.X.X.X:8050
17/05/03 01:24:50 INFO client.AHSProxy: Connecting to Application History server at <server>/X.X.X.X:10200
17/05/03 01:24:51 INFO dmlc.Client: jobname=DMLC[nworker=2,nsever=2]:python,username=root
17/05/03 01:24:51 INFO dmlc.Client: Submitting application application_1489701902537_0147
17/05/03 01:24:51 INFO impl.YarnClientImpl: Submitted application application_1489701902537_0147
Application application_1489701902537_0147 finished with state FINISHED at 1493774702568
Diagnostics., num_tasks4, finished=0, failed=4
[DMLC] Task 0 failed more than 3times
Available queues:
default
17/05/03 01:25:02 INFO impl.YarnClientImpl: Killed application application_1489701902537_0147

Here is my config.mk for mxnet

#-------------------------------------------------------------------------------
#  Template configuration for compiling mxnet
#
#  If you want to change the configuration, please use the following
#  steps. Assume you are on the root directory of mxnet. First copy the this
#  file so that any local changes will be ignored by git
#
#  $ cp make/config.mk .
#
#  Next modify the according entries, and then compile by
#
#  $ make
#
#  or build in parallel with 8 threads
#
#  $ make -j8
#-------------------------------------------------------------------------------

#---------------------
# choice of compiler
#--------------------

export CC = gcc
export CXX = g++
export NVCC = nvcc

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether compiler with profiler
USE_PROFILER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 0

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
# USE_CUDA_PATH = /usr/local/cuda
USE_CUDA_PATH = NONE

# whether use CuDNN R3 library
USE_CUDNN = 0

# CUDA architecture setting: going with all of them.
# For CUDA < 6.0, comment the *_50 lines for compatibility.
CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \
		-gencode arch=compute_35,code=sm_35 \
		-gencode arch=compute_50,code=sm_50 \
		-gencode arch=compute_50,code=compute_50

# whether use cuda runtime compiling for writing kernels in native language (i.e. Python)
USE_NVRTC = 0

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 0

# use openmp for parallelization
USE_OPENMP = 1


# MKL ML Library for Intel CPU/Xeon Phi
# Please refer to MKL_README.md for details

# MKL ML Library folder, need to be root for /usr/local
# Change to User Home directory for standard user
# For USE_BLAS!=mkl only
MKLML_ROOT=/usr/local

# whether use MKL2017 library
USE_MKL2017 = 0

# whether use MKL2017 experimental feature for high performance
# Prerequisite USE_MKL2017=1
USE_MKL2017_EXPERIMENTAL = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_MKL2017), 0)
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
endif
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
else
	USE_SSE=1
endif

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 1

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk

# whether to use torch integration. This requires installing torch.
# You also need to add TORCH_PATH/install/lib to your LD_LIBRARY_PATH
# TORCH_PATH = $(HOME)/torch
# MXNET_PLUGINS += plugin/torch/torch.mk

# _WARPCTC_PATH_ = $(HOME)/warp-ctc
# MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk
USE_BLAS=atlas
#ADD_CFLAGS += -I/usr/include/openblas
ADD_CFLAGS += -I/usr/include/openblas -L/usr/local/lib
#ADD_LDFLAGS += -lopencv_core -lopencv_imgproc -lopencv_imgcodecs

Can someone please tell me what is wrong with my set up? ",0,Unable to run MXnet with yarn as a launcher,"Unable to run MXnet with yarn as a launcher $ python ../../tools/launch.py -n 2 --launcher yarn python  train_mnist.py --network lenet --kv-store dist_sync
17/05/03 01:24:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/03 01:24:50 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
17/05/03 01:24:50 INFO impl.TimelineClientImpl: Timeline service address: http://<server>/X.X.X.X:8188/ws/v1/timeline/
17/05/03 01:24:50 INFO client.RMProxy: Connecting to ResourceManager at <server>/X.X.X.X:8050
17/05/03 01:24:50 INFO client.AHSProxy: Connecting to Application History server at <server>/X.X.X.X:10200
17/05/03 01:24:51 INFO dmlc.Client: jobname=DMLC[nworker=2,nsever=2]:python,username=root
17/05/03 01:24:51 INFO dmlc.Client: Submitting application application_1489701902537_0147
17/05/03 01:24:51 INFO impl.YarnClientImpl: Submitted application application_1489701902537_0147
Application application_1489701902537_0147 finished with state FINISHED at 1493774702568
Diagnostics., num_tasks4, finished=0, failed=4
[DMLC] Task 0 failed more than 3times
Available queues:
default
17/05/03 01:25:02 INFO impl.YarnClientImpl: Killed application application_1489701902537_0147

Here is my config.mk for mxnet

#-------------------------------------------------------------------------------
#  Template configuration for compiling mxnet
#
#  If you want to change the configuration, please use the following
#  steps. Assume you are on the root directory of mxnet. First copy the this
#  file so that any local changes will be ignored by git
#
#  $ cp make/config.mk .
#
#  Next modify the according entries, and then compile by
#
#  $ make
#
#  or build in parallel with 8 threads
#
#  $ make -j8
#-------------------------------------------------------------------------------

#---------------------
# choice of compiler
#--------------------

export CC = gcc
export CXX = g++
export NVCC = nvcc

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether compiler with profiler
USE_PROFILER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 0

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
# USE_CUDA_PATH = /usr/local/cuda
USE_CUDA_PATH = NONE

# whether use CuDNN R3 library
USE_CUDNN = 0

# CUDA architecture setting: going with all of them.
# For CUDA < 6.0, comment the *_50 lines for compatibility.
CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \
		-gencode arch=compute_35,code=sm_35 \
		-gencode arch=compute_50,code=sm_50 \
		-gencode arch=compute_50,code=compute_50

# whether use cuda runtime compiling for writing kernels in native language (i.e. Python)
USE_NVRTC = 0

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 0

# use openmp for parallelization
USE_OPENMP = 1


# MKL ML Library for Intel CPU/Xeon Phi
# Please refer to MKL_README.md for details

# MKL ML Library folder, need to be root for /usr/local
# Change to User Home directory for standard user
# For USE_BLAS!=mkl only
MKLML_ROOT=/usr/local

# whether use MKL2017 library
USE_MKL2017 = 0

# whether use MKL2017 experimental feature for high performance
# Prerequisite USE_MKL2017=1
USE_MKL2017_EXPERIMENTAL = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_MKL2017), 0)
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
endif
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
else
	USE_SSE=1
endif

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 1

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk

# whether to use torch integration. This requires installing torch.
# You also need to add TORCH_PATH/install/lib to your LD_LIBRARY_PATH
# TORCH_PATH = $(HOME)/torch
# MXNET_PLUGINS += plugin/torch/torch.mk

# _WARPCTC_PATH_ = $(HOME)/warp-ctc
# MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk
USE_BLAS=atlas
#ADD_CFLAGS += -I/usr/include/openblas
ADD_CFLAGS += -I/usr/include/openblas -L/usr/local/lib
#ADD_LDFLAGS += -lopencv_core -lopencv_imgproc -lopencv_imgcodecs

Can someone please tell me what is wrong with my set up? "
incubator-mxnet,3158,"I have the following code to test my model:



However, it takes as long to test as to train (even a bit longer) and I'm worried I'm training it by mistake or doing something way wrong.
",0,How to test using mx.mod.Module?,"How to test using mx.mod.Module? I have the following code to test my model:



However, it takes as long to test as to train (even a bit longer) and I'm worried I'm training it by mistake or doing something way wrong.
"
incubator-mxnet,2438,"In model.py in the python package, 
_update_params(executor_manager.param_arrays, executor_manager.grad_arrays, updater=updater, num_device=len(ctx), kvstore=kvstore) is used for updating of the parameters. However, seen from the code, the parameters (gamma and beta) of Batch Normalization operator is included in executor_manager.aux_arrays, but not included in executor_manager.param_arrays. So the parameters of Batch Normalization are not updated after each iteration ?
",0,How to update the aux parameters?,"How to update the aux parameters? In model.py in the python package, 
_update_params(executor_manager.param_arrays, executor_manager.grad_arrays, updater=updater, num_device=len(ctx), kvstore=kvstore) is used for updating of the parameters. However, seen from the code, the parameters (gamma and beta) of Batch Normalization operator is included in executor_manager.aux_arrays, but not included in executor_manager.param_arrays. So the parameters of Batch Normalization are not updated after each iteration ?
"
incubator-mxnet,4906,"Hi,
I'm attempting to load some ARK files into mxnet, but I'm not exactly sure on how to go about it. I did go over the speech-demo example, but in there, there are custom io files that is loading sequences in certain format for LSTMs. I'm trying to simply load an ark file for an acoustic model, I was wondering if you could point to me exactly what files I can use in the speech-demo or a work around on how to go about it.
-Venkatesh 

@yzhang87",0,How to load ARK files in mxnet,"How to load ARK files in mxnet Hi,
I'm attempting to load some ARK files into mxnet, but I'm not exactly sure on how to go about it. I did go over the speech-demo example, but in there, there are custom io files that is loading sequences in certain format for LSTMs. I'm trying to simply load an ark file for an acoustic model, I was wondering if you could point to me exactly what files I can use in the speech-demo or a work around on how to go about it.
-Venkatesh 

@yzhang87"
incubator-mxnet,13739,"## Description
I am building mxnet over OpenBLAS but it fails due to missing file 'cblas.h'.
Does anyone meet the same error?

## Environment info

Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
(Paste the output of  here.)
3bfcd93dff33d27a6087e39dd9387718456b5f51

Build config:
(Paste the content of config.mk, or the build command.)
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

## Error Message:
(Paste the complete error message, including stack trace.)
In file included from /home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:32,
                 from include/mxnet/operator_util.h:43,
                 from src/operator/contrib/nnz.cc:25:
/home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/./base.h:162:23: fatal error: cblas.h: No such file or directory
     #include <cblas.h>
                       ^
compilation terminated.


## Steps to reproduce
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

",0,Building mxnet over OpenBLAS fails,"Building mxnet over OpenBLAS fails ## Description
I am building mxnet over OpenBLAS but it fails due to missing file 'cblas.h'.
Does anyone meet the same error?

## Environment info

Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
(Paste the output of  here.)
3bfcd93dff33d27a6087e39dd9387718456b5f51

Build config:
(Paste the content of config.mk, or the build command.)
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

## Error Message:
(Paste the complete error message, including stack trace.)
In file included from /home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:32,
                 from include/mxnet/operator_util.h:43,
                 from src/operator/contrib/nnz.cc:25:
/home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/./base.h:162:23: fatal error: cblas.h: No such file or directory
     #include <cblas.h>
                       ^
compilation terminated.


## Steps to reproduce
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

"
incubator-mxnet,5950,"I am writing OP, I want do some unit test, but I haven't find test examples for OPs, I want know if there is a easy way to test it.",0,Is there unit test for OPs ?,"Is there unit test for OPs ? I am writing OP, I want do some unit test, but I haven't find test examples for OPs, I want know if there is a easy way to test it."
incubator-mxnet,9696,"I build the mxnet from source and follows the step in [#7002](https://github.com/apache/incubator-mxnet/issues/7002).But I found it works well if I use python3 but error occurred for python2----""AttributeError: 'module' object has no attribute 'WarpCTC'""",0,warpctc: module object has no at tribute 'WarpCTC',"warpctc: module object has no at tribute 'WarpCTC' I build the mxnet from source and follows the step in [#7002](https://github.com/apache/incubator-mxnet/issues/7002).But I found it works well if I use python3 but error occurred for python2----""AttributeError: 'module' object has no attribute 'WarpCTC'"""
incubator-mxnet,4902,"Operating System:ANDROID
Compiler:ANDROID NDKr13 using api 21(also 19)
I tried to build the mxnet to android using 'make  ANDROID=1' and finally get the 'libmxnet_predict.so'. But when I tried to use it in an android project, it coulde not run  throw this EXCEPTION: 
How can I solve this problem? Did I make some mistakes in compiling?
MXNet version:
I have tried the newest vision and the 0.8.0 vision, and all got that EXCEPTION.",0,"dlopen failed: cannot locate symbol ""cblas_sgemm"" referenced by ""libmxnet_predict.so""...","dlopen failed: cannot locate symbol ""cblas_sgemm"" referenced by ""libmxnet_predict.so""... Operating System:ANDROID
Compiler:ANDROID NDKr13 using api 21(also 19)
I tried to build the mxnet to android using 'make  ANDROID=1' and finally get the 'libmxnet_predict.so'. But when I tried to use it in an android project, it coulde not run  throw this EXCEPTION: 
How can I solve this problem? Did I make some mistakes in compiling?
MXNet version:
I have tried the newest vision and the 0.8.0 vision, and all got that EXCEPTION."
incubator-mxnet,13710,"> ENV:
> 
> 
> python gluon-cv/scripts/detection/ssd/train_ssd.py
>
> INFO:root:Start training from [Epoch 0]
> *** Error in python': malloc(): memory corruption: 0x00007f540c1a9550 ***
> ======= Backtrace: =========
> /lib64/libc.so.6(+0x82c86)[0x7f54d42dec86]
> /lib64/libc.so.6(__libc_malloc+0x4c)[0x7f54d42e184c]
> /lib64/libstdc++.so.6(_Znwm+0x1d)[0x7f54b48c7ecd]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(+0x3c042d9)[0x7f54691982d9]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x589)[0x7f5469194249]
> *** Error in 
> The full trach message is here
> [error.log](https://github.com/dmlc/gluon-cv/files/2699683/error.log)

",0,Error in `python': malloc(): memory corruption: 0x00007f540c0a6190,"Error in `python': malloc(): memory corruption: 0x00007f540c0a6190 > ENV:
> 
> 
> python gluon-cv/scripts/detection/ssd/train_ssd.py
>
> INFO:root:Start training from [Epoch 0]
> *** Error in python': malloc(): memory corruption: 0x00007f540c1a9550 ***
> ======= Backtrace: =========
> /lib64/libc.so.6(+0x82c86)[0x7f54d42dec86]
> /lib64/libc.so.6(__libc_malloc+0x4c)[0x7f54d42e184c]
> /lib64/libstdc++.so.6(_Znwm+0x1d)[0x7f54b48c7ecd]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(+0x3c042d9)[0x7f54691982d9]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x589)[0x7f5469194249]
> *** Error in 
> The full trach message is here
> [error.log](https://github.com/dmlc/gluon-cv/files/2699683/error.log)

"
incubator-mxnet,2765,"在生成imagenet的recordio文件后, 出于好奇, 我从recordio文件中读出了图片并显示出来, 结果发现与原图明显不同, 例如(原图后是对应的失真图片):
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_95.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/2.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_17.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/1.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_114.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/3.png?raw=true)

生成recordio的命令:



从recordio中读取并显示图片的代码, 在jupyter notebook中运行



忽略center crop与resize造成的影响, 请问颜色失真的原因是什么? 
",0,ImageNet图片生成RecordIO文件后的失真问题,"ImageNet图片生成RecordIO文件后的失真问题 在生成imagenet的recordio文件后, 出于好奇, 我从recordio文件中读出了图片并显示出来, 结果发现与原图明显不同, 例如(原图后是对应的失真图片):
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_95.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/2.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_17.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/1.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_114.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/3.png?raw=true)

生成recordio的命令:



从recordio中读取并显示图片的代码, 在jupyter notebook中运行



忽略center crop与resize造成的影响, 请问颜色失真的原因是什么? 
"
incubator-mxnet,2499,"The distributed mxnet on apache hadoop yarn cannot be well trained with the data directly read from HDFS. Can anybody offers an example?
",0,Is there any completed example on distributed yarn,"Is there any completed example on distributed yarn The distributed mxnet on apache hadoop yarn cannot be well trained with the data directly read from HDFS. Can anybody offers an example?
"
incubator-mxnet,4407,"Description speaks about 4 arguments.



But inside only two.



And in fact, the function waits for two arguments.



What does parameters ""X0"" & ""out"" of the function? How to use these parameters?",0,How to use the function  mx.nd.slice.axis()?,"How to use the function  mx.nd.slice.axis()? Description speaks about 4 arguments.



But inside only two.



And in fact, the function waits for two arguments.



What does parameters ""X0"" & ""out"" of the function? How to use these parameters?"
incubator-mxnet,10906,"
tested both with opencv-python            3.4.0.12 from pypi.",0,transforms.Compose not working as expected.,"transforms.Compose not working as expected. 
tested both with opencv-python            3.4.0.12 from pypi."
incubator-mxnet,4255,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
gcc

Package used (Python/R/Scala/Julia):
Python

MXNet version:
0.7

Or if installed from source:
Yes

MXNet commit hash ():
487c22a50541686cc3fd207ad4656dbd2f9fa969

If you are using python package, please provide

Python version and distribution:
2.7

If you are using R package, please provide

R :

## Error Message:
---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
<ipython-input-23-133db28d92b2> in <module>()
----> 1 mx.nd.save(""s3://imagetraining.xxxx.com/testing/a"",[a,b])

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.pyc in save(fname, data)
   1082                                   mx_uint(len(handles)),
   1083                                   c_array(NDArrayHandle, handles),
-> 1084                                   keys))
   1085 
   1086 def imdecode(str_img, clip_rect=(0, 0, 0, 0), out=None, index=0, channels=3, mean=None):

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.pyc in check_call(ret)
     75     """"""
     76     if ret != 0:
---> 77         raise MXNetError(py_str(_LIB.MXGetLastError()))
     78 
     79 if sys.version_info[0] < 3:

MXNetError: [03:32:57] src/io/s3_filesys.cc:682: Check failed: num_retry < max_error_retry_  maximum retry time reached

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Create a new Jyputer notebook, run the following Python , make sure that the bucket name of S3 has period in it: 

a = mx.nd.zeros((100, 200))
b = a+1
mx.nd.save(""s3://imagetraining.xxx.com/testing/a"",[a,b])




## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Start Jupyter.
2. Create a notebook with the sample code above 
3. Run it and then will fail

## What have you tried to solve it?

1. Tried another S3 bucket without period in the bucket name. It worked.
2. In the document of S3: http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html, found the following description:

When using virtual hosted–style buckets with SSL, the SSL wild card certificate only matches buckets that do not contain periods. To work around this, use HTTP or write your own certificate verification logic.



3. Looked into the source code dmlc-core/src/io/s3_filesys.cc:682, found that the source code is using virtual host style url to access S3, as the following code shows:

surl << ""https://"" << path_.host << "".s3.amazonaws.com"" << '/'
       << RemoveBeginSlash(path_.name) << args;

This virtual host style method will fail because of SSL issue when the target bucket has period in the bucket name.
",0,mx.nd.save function can't be used to save into S3 bucket with periods in bucket name,"mx.nd.save function can't be used to save into S3 bucket with periods in bucket name For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
gcc

Package used (Python/R/Scala/Julia):
Python

MXNet version:
0.7

Or if installed from source:
Yes

MXNet commit hash ():
487c22a50541686cc3fd207ad4656dbd2f9fa969

If you are using python package, please provide

Python version and distribution:
2.7

If you are using R package, please provide

R :

## Error Message:
---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
<ipython-input-23-133db28d92b2> in <module>()
----> 1 mx.nd.save(""s3://imagetraining.xxxx.com/testing/a"",[a,b])

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.pyc in save(fname, data)
   1082                                   mx_uint(len(handles)),
   1083                                   c_array(NDArrayHandle, handles),
-> 1084                                   keys))
   1085 
   1086 def imdecode(str_img, clip_rect=(0, 0, 0, 0), out=None, index=0, channels=3, mean=None):

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.pyc in check_call(ret)
     75     """"""
     76     if ret != 0:
---> 77         raise MXNetError(py_str(_LIB.MXGetLastError()))
     78 
     79 if sys.version_info[0] < 3:

MXNetError: [03:32:57] src/io/s3_filesys.cc:682: Check failed: num_retry < max_error_retry_  maximum retry time reached

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Create a new Jyputer notebook, run the following Python , make sure that the bucket name of S3 has period in it: 

a = mx.nd.zeros((100, 200))
b = a+1
mx.nd.save(""s3://imagetraining.xxx.com/testing/a"",[a,b])




## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Start Jupyter.
2. Create a notebook with the sample code above 
3. Run it and then will fail

## What have you tried to solve it?

1. Tried another S3 bucket without period in the bucket name. It worked.
2. In the document of S3: http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html, found the following description:

When using virtual hosted–style buckets with SSL, the SSL wild card certificate only matches buckets that do not contain periods. To work around this, use HTTP or write your own certificate verification logic.



3. Looked into the source code dmlc-core/src/io/s3_filesys.cc:682, found that the source code is using virtual host style url to access S3, as the following code shows:

surl << ""https://"" << path_.host << "".s3.amazonaws.com"" << '/'
       << RemoveBeginSlash(path_.name) << args;

This virtual host style method will fail because of SSL issue when the target bucket has period in the bucket name.
"
incubator-mxnet,9392,"Recently i found MobileNet gluon version of model.param.

I would like to have symbolic version of mobileNet in model.param and also .json format file.
Is anything are avilable in modelzoo with json and mobilenet.param file. 
Kindly reply...
@szha do you any updates on this.... ",0,Official version of MobileNet pretrained model and .json file,"Official version of MobileNet pretrained model and .json file Recently i found MobileNet gluon version of model.param.

I would like to have symbolic version of mobileNet in model.param and also .json format file.
Is anything are avilable in modelzoo with json and mobilenet.param file. 
Kindly reply...
@szha do you any updates on this.... "
incubator-mxnet,8914,"## Description
The group context was used for model parallelism of neural network train. The mx.sym.LogisticRegressionOutput works when it's been used for loss calculation, but not customized operator.

## Environment info (Required)
OS: Ubuntu 14.04.5 LTS
Python: 2.7.13
mxnet: 0.12.1, pulled from master branch and built from source

Package used (Python/R/Scala/Julia):
Python: mxnet, numpy, scipy

## Build info (Required if built from source)
Bulit from command line by following https://mxnet.incubator.apache.org/get_started/install.html

MXNet commit hash:
2f8c1e83f94e84a25a48d2cd43136030fb3f2d1e

Build config:
Only change is to enable the profiler.

## Error Message:
Traceback (most recent call last):
  File ""_ctypes/callbacks.c"", line 315, in 'calling callback function'
  File ""/git/mxnet/python/mxnet/operator.py"", line 621, in creator
    op_prop = prop_cls(**kwargs)
TypeError: __init__() got an unexpected keyword argument '__ctx_group__'

## Minimum reproducible example
The script to generate the network, which works:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
loss = mx.sym.LogisticRegressionOutput(data=fc2, label=labs)

The script to generate the network which used customized operator, and didn't work:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
act2 = mx.sym.Activation(data=fc2, name='acout_'+str(gpu), act_type='sigmoid')
loss = mx.sym.Custom(data=act2, label=label, name='ce_'+str(gpu), op_type='CrossEntropyLoss')

Is this because the custom op is not support yet for group context?",0,The custom operator not supported for group context?,"The custom operator not supported for group context? ## Description
The group context was used for model parallelism of neural network train. The mx.sym.LogisticRegressionOutput works when it's been used for loss calculation, but not customized operator.

## Environment info (Required)
OS: Ubuntu 14.04.5 LTS
Python: 2.7.13
mxnet: 0.12.1, pulled from master branch and built from source

Package used (Python/R/Scala/Julia):
Python: mxnet, numpy, scipy

## Build info (Required if built from source)
Bulit from command line by following https://mxnet.incubator.apache.org/get_started/install.html

MXNet commit hash:
2f8c1e83f94e84a25a48d2cd43136030fb3f2d1e

Build config:
Only change is to enable the profiler.

## Error Message:
Traceback (most recent call last):
  File ""_ctypes/callbacks.c"", line 315, in 'calling callback function'
  File ""/git/mxnet/python/mxnet/operator.py"", line 621, in creator
    op_prop = prop_cls(**kwargs)
TypeError: __init__() got an unexpected keyword argument '__ctx_group__'

## Minimum reproducible example
The script to generate the network, which works:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
loss = mx.sym.LogisticRegressionOutput(data=fc2, label=labs)

The script to generate the network which used customized operator, and didn't work:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
act2 = mx.sym.Activation(data=fc2, name='acout_'+str(gpu), act_type='sigmoid')
loss = mx.sym.Custom(data=act2, label=label, name='ce_'+str(gpu), op_type='CrossEntropyLoss')

Is this because the custom op is not support yet for group context?"
incubator-mxnet,15337,"## Description
The current MXNET master dev branch, pypi version 1.5.0b20190623 breaks the loading of certain MXNET-models (both in mxnet-mkl & mxnet-cu100), which previously were loaded successfully with mxnet==1.4.1.
The model uses grouped depthwise (a.ka. depthwise seperable) convolutions which could be the cause for this issue because other models (e.g.  CrazyAraFish_0.5.0_RiseV1.zip) still work correctly as usual.

## Environment info
I'm using python, but the same problem also occurs when building the MXNET-CPP package from source.

## Error Message:


## Minimum reproducible example

## Steps to reproduce

Download  release  at:
* https://github.com/QueensGambit/CrazyAra/releases
Install [python-chess](https://github.com/niklasf/python-chess).


Extract  and run 

from the commandline.
More details for install instructions can be found here:
* [Install Guide](https://github.com/QueensGambit/CrazyAra/wiki/Installation-Guide)

Alternatively, you can load the mxnet model from the  directory manually in python.

Does someones have an idea what recent change causes this?
Can you include more automated unit tests for MXNET to ensure that the loading of different model types is preserved for version updates?
",0,Current MXNet-Dev master breaks loading of certain models,"Current MXNet-Dev master breaks loading of certain models ## Description
The current MXNET master dev branch, pypi version 1.5.0b20190623 breaks the loading of certain MXNET-models (both in mxnet-mkl & mxnet-cu100), which previously were loaded successfully with mxnet==1.4.1.
The model uses grouped depthwise (a.ka. depthwise seperable) convolutions which could be the cause for this issue because other models (e.g.  CrazyAraFish_0.5.0_RiseV1.zip) still work correctly as usual.

## Environment info
I'm using python, but the same problem also occurs when building the MXNET-CPP package from source.

## Error Message:


## Minimum reproducible example

## Steps to reproduce

Download  release  at:
* https://github.com/QueensGambit/CrazyAra/releases
Install [python-chess](https://github.com/niklasf/python-chess).


Extract  and run 

from the commandline.
More details for install instructions can be found here:
* [Install Guide](https://github.com/QueensGambit/CrazyAra/wiki/Installation-Guide)

Alternatively, you can load the mxnet model from the  directory manually in python.

Does someones have an idea what recent change causes this?
Can you include more automated unit tests for MXNET to ensure that the loading of different model types is preserved for version updates?
"
incubator-mxnet,695,"why?
at the very least the doc has to be updated
",0,mnist example disappeared,"mnist example disappeared why?
at the very least the doc has to be updated
"
incubator-mxnet,8685,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I am currently running into an error when trying to build a single jar on OSX. I get the following error:  

## Environment info (Required)
Mac OSX. Maven. Scala

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: 1.8.0_144
2. Maven version: 3.5.0
3. Scala runtime if applicable:  2.11.8

## Error Message:


## Minimum reproducible example
Below are my maven dependencies, plugins, and assembly.xml:





assembly.xml:





## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Use dependencies and plug from pom above.

## What have you tried to solve it?

1. I added the assembly.xml page, but didn't have any luck with jni.
",0,Error Adding file-set for 'ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a',"Error Adding file-set for 'ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a' Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I am currently running into an error when trying to build a single jar on OSX. I get the following error:  

## Environment info (Required)
Mac OSX. Maven. Scala

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: 1.8.0_144
2. Maven version: 3.5.0
3. Scala runtime if applicable:  2.11.8

## Error Message:


## Minimum reproducible example
Below are my maven dependencies, plugins, and assembly.xml:





assembly.xml:





## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Use dependencies and plug from pom above.

## What have you tried to solve it?

1. I added the assembly.xml page, but didn't have any luck with jni.
"
incubator-mxnet,7224,"Hello,

I'd like to use a LSTM in combination with a CNN as a feature extractor to classify videos. I am using mxnet -cu80 0.10.0.post2 in python 2.7.9. I have a pretrained resnet-50 which is loaded and then I chop off the final classification layer:


The LSTM expects an input in the NTC format, thus my forward pass first puts the entire sequence through the CNN and then  reshapes the extracted features to match the LSTM. The LSTM bind looks like this (All sequences have the same length in my model so I don't use bucketing): 

And here is the forward backward pass:




However this only works up the cnn backward pass where I get the following error which I really do not understand as the output of the CNN has exactly the same dimension as the gradient of the LSTM after reshaping and I tried to follow the dcgan example which uses a similar technique.




I should mention that 2048 is the feature dimension of the last resnet layer, the sequence lenght is fixed to 10 and batch_size (in this case the number of sequences per batch) is 2, so this explains the 20 and 2048. So lstm_grad is an NDArray of size 20x2048 and so is the cnn_output. 

Thank's for your help,
Max 


",0,Passing gradient between 2 networks,"Passing gradient between 2 networks Hello,

I'd like to use a LSTM in combination with a CNN as a feature extractor to classify videos. I am using mxnet -cu80 0.10.0.post2 in python 2.7.9. I have a pretrained resnet-50 which is loaded and then I chop off the final classification layer:


The LSTM expects an input in the NTC format, thus my forward pass first puts the entire sequence through the CNN and then  reshapes the extracted features to match the LSTM. The LSTM bind looks like this (All sequences have the same length in my model so I don't use bucketing): 

And here is the forward backward pass:




However this only works up the cnn backward pass where I get the following error which I really do not understand as the output of the CNN has exactly the same dimension as the gradient of the LSTM after reshaping and I tried to follow the dcgan example which uses a similar technique.




I should mention that 2048 is the feature dimension of the last resnet layer, the sequence lenght is fixed to 10 and batch_size (in this case the number of sequences per batch) is 2, so this explains the 20 and 2048. So lstm_grad is an NDArray of size 20x2048 and so is the cnn_output. 

Thank's for your help,
Max 


"
incubator-mxnet,10901,"Check out the latest master, build it with . 
Run with . 
Happens on all configurations, no matter whether CPU or GPU etc.

",0,Broken test_sparse_operator.test_sparse_mathematical_core with scipy 1.1.0,"Broken test_sparse_operator.test_sparse_mathematical_core with scipy 1.1.0 Check out the latest master, build it with . 
Run with . 
Happens on all configurations, no matter whether CPU or GPU etc.

"
incubator-mxnet,1336,"Hi, I'm having problems trying to install mxnet in R when using the pre-built windows binary hosted here 
https://github.com/dmlc/mxnet/releases

and using the instructions on the Installation Guide page. All seems to work ok, in that the mxnet library for R gets created. However, when I run the Handwritten Digits Tutorial using LeNet, when using the gpu it doesn't seem to optimise correctly. I've downloaded the windows release and the zip from github today.

Training using cpu (similar to example) 
Start training with 1 devices
[1] Train-accuracy=0.55708830548926

Training using gpu (different to example)
Start training with 1 devices
[1] Train-accuracy=0.0983770883054893
[2] Train-accuracy=0.0983809523809524
[3] Train-accuracy=0.0983809523809524
[4] Train-accuracy=0.0983809523809524
[5] Train-accuracy=0.0983809523809524

I realise that from the information i've given it's going to be hard to diagnose, and I probably have made a mistake during installation. Any help would be appreciated.

Regards,
Chris

I have attached the log when I run R CMD INSTALL ...
[mxnet R CMD INSTALL Output.txt](https://github.com/dmlc/mxnet/files/101155/mxnet.R.CMD.INSTALL.Output.txt)
",0,Issue installing mxnet R-package using gpu on Windows,"Issue installing mxnet R-package using gpu on Windows Hi, I'm having problems trying to install mxnet in R when using the pre-built windows binary hosted here 
https://github.com/dmlc/mxnet/releases

and using the instructions on the Installation Guide page. All seems to work ok, in that the mxnet library for R gets created. However, when I run the Handwritten Digits Tutorial using LeNet, when using the gpu it doesn't seem to optimise correctly. I've downloaded the windows release and the zip from github today.

Training using cpu (similar to example) 
Start training with 1 devices
[1] Train-accuracy=0.55708830548926

Training using gpu (different to example)
Start training with 1 devices
[1] Train-accuracy=0.0983770883054893
[2] Train-accuracy=0.0983809523809524
[3] Train-accuracy=0.0983809523809524
[4] Train-accuracy=0.0983809523809524
[5] Train-accuracy=0.0983809523809524

I realise that from the information i've given it's going to be hard to diagnose, and I probably have made a mistake during installation. Any help would be appreciated.

Regards,
Chris

I have attached the log when I run R CMD INSTALL ...
[mxnet R CMD INSTALL Output.txt](https://github.com/dmlc/mxnet/files/101155/mxnet.R.CMD.INSTALL.Output.txt)
"
incubator-mxnet,3837,"I was looking for the ResNet config file for the ILSVRC12 dataset, but I only find the one for the Cifar10 dataset:

https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol_resnet.py

Do we have a ResNet config file for the ILSVRC12 dataset?

Thank you very much!",0,ResNet for ILSVRC12 dataset,"ResNet for ILSVRC12 dataset I was looking for the ResNet config file for the ILSVRC12 dataset, but I only find the one for the Cifar10 dataset:

https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol_resnet.py

Do we have a ResNet config file for the ILSVRC12 dataset?

Thank you very much!"
incubator-mxnet,3607,"Dear team,

I am trying to use a CNN on a dataset with 6x8 data. I am working in R.
The dataset has the following header:



I am attaching the full dataset.csv [dataset.zip](https://github.com/dmlc/mxnet/files/548954/dataset.zip)
the code I am using is the following:



When I run the R code I get the following:



but I do not understand what is the reason.
May I ask you if you see any discrepancy in my code?
Thanks.
Cheers.
",0,CNN on 6x8 data in R,"CNN on 6x8 data in R Dear team,

I am trying to use a CNN on a dataset with 6x8 data. I am working in R.
The dataset has the following header:



I am attaching the full dataset.csv [dataset.zip](https://github.com/dmlc/mxnet/files/548954/dataset.zip)
the code I am using is the following:



When I run the R code I get the following:



but I do not understand what is the reason.
May I ask you if you see any discrepancy in my code?
Thanks.
Cheers.
"
incubator-mxnet,11039,"We can not download R in the linux .
Where do we download R in the linux?

Thank You",0,Linux-R,"Linux-R We can not download R in the linux .
Where do we download R in the linux?

Thank You"
incubator-mxnet,1794,"I built with torch and got errors as follows:



Then I use  and :



So I modified the  in  to . Then I continued the make procedure and got happy results. Maybe this is a small bug related to my torch installation. Hope this will be helpful to potential users.
",0,Error when build with torch,"Error when build with torch I built with torch and got errors as follows:



Then I use  and :



So I modified the  in  to . Then I continued the make procedure and got happy results. Maybe this is a small bug related to my torch installation. Hope this will be helpful to potential users.
"
incubator-mxnet,11576,,0,AttributeError: 'ResNetV2' object has no attribute 'save_parameters',
incubator-mxnet,2749,"The Xavier initializer is mx.init.Xavier(factor_type=""in"", magnitude=3), and
The MSRA initializer  is mx.init.Xavier(factor_type=""in"", rnd_type=""gaussian"", magnitude=2).

Why the default initializer adopts a strange magnitude of 2.34, any special reason for this?
",0,"Any special reason for the default initializer mx.init.Xavier(factor_type=""in"", magnitude=2.34) to take the magnitude 2.34?","Any special reason for the default initializer mx.init.Xavier(factor_type=""in"", magnitude=2.34) to take the magnitude 2.34? The Xavier initializer is mx.init.Xavier(factor_type=""in"", magnitude=3), and
The MSRA initializer  is mx.init.Xavier(factor_type=""in"", rnd_type=""gaussian"", magnitude=2).

Why the default initializer adopts a strange magnitude of 2.34, any special reason for this?
"
incubator-mxnet,894,"I got following error while package compilation ():

> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc:220:15: error: ambiguous overload for ‘operator=’ (operand types are ‘std::vectorstd::__cxx11::basic_string<char >’ and ‘Rcpp::NamesProxyPolicyRcpp::Vector<19 >::const_NamesProxy’)
>      lst_names = data_lst.names();
",0,R package compilation error,"R package compilation error I got following error while package compilation ():

> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc:220:15: error: ambiguous overload for ‘operator=’ (operand types are ‘std::vectorstd::__cxx11::basic_string<char >’ and ‘Rcpp::NamesProxyPolicyRcpp::Vector<19 >::const_NamesProxy’)
>      lst_names = data_lst.names();
"
incubator-mxnet,5016,"Hi, I'm new to mxnet, and I am walking through a kaggle project to familiar with its python interface.
But something confused me when I try to call mx.mod.Module.predict function to complete my final work.
Since there was no headache when I called mx.mod.Module.score function, predict function should also work fine unless bug around. Then I read through python source code to find the bug.
following info displayed when I run the code 



Notice it's an index out of range problems, and the fault is directed by , I check the variable  and find it equals to -1.

That's the key problem. Next I find where  defined. Since I initialize  variable by following code


I check  and find  is assigned by  from  of 455 line.
By just change the  to  , I successfully fixed the bug.
But I still not sure whether the right code is  or 
the second way also fix the problem.

Any idea about this little bug? and if I certainly fix the bug, could you give me a chance to help me pull request to merge my little work into mxnet? Thank you, ",0,A little bug in mxnet python code,"A little bug in mxnet python code Hi, I'm new to mxnet, and I am walking through a kaggle project to familiar with its python interface.
But something confused me when I try to call mx.mod.Module.predict function to complete my final work.
Since there was no headache when I called mx.mod.Module.score function, predict function should also work fine unless bug around. Then I read through python source code to find the bug.
following info displayed when I run the code 



Notice it's an index out of range problems, and the fault is directed by , I check the variable  and find it equals to -1.

That's the key problem. Next I find where  defined. Since I initialize  variable by following code


I check  and find  is assigned by  from  of 455 line.
By just change the  to  , I successfully fixed the bug.
But I still not sure whether the right code is  or 
the second way also fix the problem.

Any idea about this little bug? and if I certainly fix the bug, could you give me a chance to help me pull request to merge my little work into mxnet? Thank you, "
incubator-mxnet,8062,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: DeepLearninig AMI 

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash (): ae975e5f8a70f9e2c36f78278f2553cdd4d87e79

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Run the above code. Same kind of error for libsvm iterator. 
2.
3.
",0,CSVIter and LibSVMIter not returning correct number of batches per epoch,"CSVIter and LibSVMIter not returning correct number of batches per epoch For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: DeepLearninig AMI 

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash (): ae975e5f8a70f9e2c36f78278f2553cdd4d87e79

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Run the above code. Same kind of error for libsvm iterator. 
2.
3.
"
incubator-mxnet,1118,,0,[R] mx.symbol.bind is missing one parameter,
incubator-mxnet,8037,"I want to maximize a dice coefficient and minimize the smooth_l1_loss at the same time,  I tried multiple  to the dice coefficient but seems it doesn't work.",0,How to maximize one loss function and minimize another one?,"How to maximize one loss function and minimize another one? I want to maximize a dice coefficient and minimize the smooth_l1_loss at the same time,  I tried multiple  to the dice coefficient but seems it doesn't work."
incubator-mxnet,1008,"The help information of mx.simple.bind() is too simple. I just can't figure out how to really use it from its help message.  Also, I can't find any sample code that used this function. I wonder if any of you can help me understand its usage a little better. 

Many thanks for your help.
",0,[R] How to use mx.simple.bind() in R package,"[R] How to use mx.simple.bind() in R package The help information of mx.simple.bind() is too simple. I just can't figure out how to really use it from its help message.  Also, I can't find any sample code that used this function. I wonder if any of you can help me understand its usage a little better. 

Many thanks for your help.
"
incubator-mxnet,3914,建立自己的数据的时候，如果我的图片不是每个类别一个文件夹，而是所有图片都在一个文件夹中，类别标签由单独的文本文件保存，那么如何使用im2rec.py生成自己的数据，还有image.lst中integer_image_index是做什么用的，感觉有类别有路径不就够了么,0,im2rec 各个文件里存放了每一类的图片,im2rec 各个文件里存放了每一类的图片 建立自己的数据的时候，如果我的图片不是每个类别一个文件夹，而是所有图片都在一个文件夹中，类别标签由单独的文本文件保存，那么如何使用im2rec.py生成自己的数据，还有image.lst中integer_image_index是做什么用的，感觉有类别有路径不就够了么
incubator-mxnet,2149,"I am trying to run mxnet on nVidia GPU clusters, sugon HPC.  I don't know how to subject the jobs though . 

GPU programming is quite new to me. It is there any tutorial I can follow?
",0,How to run mxnet on GPU clusters?,"How to run mxnet on GPU clusters? I am trying to run mxnet on nVidia GPU clusters, sugon HPC.  I don't know how to subject the jobs though . 

GPU programming is quite new to me. It is there any tutorial I can follow?
"
incubator-mxnet,12640,"## Description

In BaseModule.fit function, <code>forward_backward</code> only needs 0.00055s, <code>update</code> only needs 0.079953s, <code>next(data_iter)</code> only needs 0.000265s. However, we run <code>forward_backward</code> and <code>next(data_iter)</code> together and spend 2.919867s. Could you please tell me what is the reason of this time bottleneck?

## Environment info (Required)

Platform: MacOS
Language: Python 2.7
Platform Version: MXNet 1.2.0
Device: 2.9 GHz Intel Core i5 (The test runs using single CPU)
Memory: 8 GB 1867 MHz DDR3
Install Tool: pip

## Steps to reproduce (In BaseModule.fit function)

* Run <code>forward_backward</code> only:



result: [CALC TIME] 0.000551	

* Run <code>next(data_iter)</code> only:



result: [DATAITER TIME] 0.000265

* Run <code>forward_backward</code> and <code>next(data_iter)</code> together:



result: [CALC AND DATAITER TIME] 2.919867	

## What have you tried to solve it?

1. I read the source code of <code>forward_backward</code> and <code>ImageRecordIter</code> but have no idea.
2. I found little modify in <code>data_batch</code> variable would also cause the time bottleneck in the loop of <code>forward_backward</code>.

Thanks a lot for your kind !
",0,Time bottleneck in forward_backward and next(train_iter),"Time bottleneck in forward_backward and next(train_iter) ## Description

In BaseModule.fit function, <code>forward_backward</code> only needs 0.00055s, <code>update</code> only needs 0.079953s, <code>next(data_iter)</code> only needs 0.000265s. However, we run <code>forward_backward</code> and <code>next(data_iter)</code> together and spend 2.919867s. Could you please tell me what is the reason of this time bottleneck?

## Environment info (Required)

Platform: MacOS
Language: Python 2.7
Platform Version: MXNet 1.2.0
Device: 2.9 GHz Intel Core i5 (The test runs using single CPU)
Memory: 8 GB 1867 MHz DDR3
Install Tool: pip

## Steps to reproduce (In BaseModule.fit function)

* Run <code>forward_backward</code> only:



result: [CALC TIME] 0.000551	

* Run <code>next(data_iter)</code> only:



result: [DATAITER TIME] 0.000265

* Run <code>forward_backward</code> and <code>next(data_iter)</code> together:



result: [CALC AND DATAITER TIME] 2.919867	

## What have you tried to solve it?

1. I read the source code of <code>forward_backward</code> and <code>ImageRecordIter</code> but have no idea.
2. I found little modify in <code>data_batch</code> variable would also cause the time bottleneck in the loop of <code>forward_backward</code>.

Thanks a lot for your kind !
"
incubator-mxnet,7552,What networks are suitable for CIFAR-10 besides inception and resnet?,0,Networks for CIFAR-10.,Networks for CIFAR-10. What networks are suitable for CIFAR-10 besides inception and resnet?
incubator-mxnet,9359,"The data consists of lines like the following:

-1 4:1 6:1 15:1 21:1 35:1 40:1 57:1 63:1 67:1 73:1 74:1 77:1 80:1 83:1 \n",0,Does gluon's dnn support data format of libsvm other than mxnet's?,"Does gluon's dnn support data format of libsvm other than mxnet's? The data consists of lines like the following:

-1 4:1 6:1 15:1 21:1 35:1 40:1 57:1 63:1 67:1 73:1 74:1 77:1 80:1 83:1 \n"
incubator-mxnet,3759,,0,how to get result of intermediate network?,
incubator-mxnet,10890,"The idea is very similar to a GAN, but instead of two neural networks I want to use a neural network generator and a prebuilt GLM as the discriminator.

Is this possible using the Mxnet symbols?

Example pseudo-code:

",0,[R] Is it possible to train Mxnet symbols and a GLM pretrained model as loss?,"[R] Is it possible to train Mxnet symbols and a GLM pretrained model as loss? The idea is very similar to a GAN, but instead of two neural networks I want to use a neural network generator and a prebuilt GLM as the discriminator.

Is this possible using the Mxnet symbols?

Example pseudo-code:

"
incubator-mxnet,7127,"## Environment info
Operating System: Windows

Package used: R (Installed using the binaries.)

Which parameter should I use to do regularization (L2) for a feed forward neural network?
Where should I implement this. 

I could find references to the weight decay parameter (wd). But I am not sure where to include it. 

An example would be much appreciated. 
 
",0,How to use regularization for a feed forward neural network in R using mxnet? ,"How to use regularization for a feed forward neural network in R using mxnet?  ## Environment info
Operating System: Windows

Package used: R (Installed using the binaries.)

Which parameter should I use to do regularization (L2) for a feed forward neural network?
Where should I implement this. 

I could find references to the weight decay parameter (wd). But I am not sure where to include it. 

An example would be much appreciated. 
 
"
incubator-mxnet,1455,"in the train_cifar or train_imagenet.py, rand_crop is set to True as default, however, the crop_ratio(size) does not to be manually set. What actually happen behind this setting?
",0,About the rand_crop in the example,"About the rand_crop in the example in the train_cifar or train_imagenet.py, rand_crop is set to True as default, however, the crop_ratio(size) does not to be manually set. What actually happen behind this setting?
"
incubator-mxnet,3659,"Questions about Embedding layer
(1) What is the function of Embedding layer ?
 In Keras ,it says Turn positive
 integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]

But what is the meaning ? When will it be used ?

(2)I try some simple codes to see how the Embedding layer works:
I use the code in the xlvector blog:
http://blog.xlvector.net/2016-05/mxnet-regression-classification-for-concret-continuous-features/
# 我们虚构了201个不同的品牌，并给每个品牌设置一个出场价格

seriesdata = [1 + i for i in range(100)] + [101 - i for i in range(100)]

for i in range(10000):
    k = random.randint(0, 199)
    #越贵的品牌，我们认为在数据集里出现的次数越少，因为它卖的少
    count = 1000 / seriesdata[k]
    for j in range(count):
        dis = random.random() \* 10
        #实际的价格是品牌的出场价除以里程数的开方
        price = seriesdata[k] / math.sqrt(1.0 + dis)
        print str(price) + '\t' + str(dis) + '\t' + str(k)
# dis 是输入的里程

dis = mx.symbol.Variable('dis')
# price 是要预测的目标价格

price = mx.symbol.Variable('price')
# price_interval 是要预测的价格区间

price_interval = mx.symbol.Variable('price_interval')
# series 是输入的车的品牌

series = mx.symbol.Variable('series')

series_out = mx.symbol.Embedding(data = series, input_dim = 200,
                             output_dim = 100, name = ""series_embed"")
ne = mx.symbol.Flatten(series_out, name = ""series_flatten"")

arg , out,aux = ne.infer_shape(series=(6,1))
print arg
print ne.list_arguments()
print out

execute = ne.bind(ctx=mx.cpu(),args={'dis_flatten':seriesdata})
execute.forward()
d_out = execute.outputs[0]
print d_out.asnumpy()

IN console:
[(6L, 1L), (200L, 100L)]
['series', 'series_embed_weight']
[(6L, 100L)]
Then throw an error:
    raise ValueError('Must specify all the arguments in %s' % arg_key)
ValueError: Must specify all the arguments in args

I know it means that I did not give values to  the series_embed_weight . But in this example, which values to give it?
",0,Some questions about Embedding Layer,"Some questions about Embedding Layer Questions about Embedding layer
(1) What is the function of Embedding layer ?
 In Keras ,it says Turn positive
 integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]

But what is the meaning ? When will it be used ?

(2)I try some simple codes to see how the Embedding layer works:
I use the code in the xlvector blog:
http://blog.xlvector.net/2016-05/mxnet-regression-classification-for-concret-continuous-features/
# 我们虚构了201个不同的品牌，并给每个品牌设置一个出场价格

seriesdata = [1 + i for i in range(100)] + [101 - i for i in range(100)]

for i in range(10000):
    k = random.randint(0, 199)
    #越贵的品牌，我们认为在数据集里出现的次数越少，因为它卖的少
    count = 1000 / seriesdata[k]
    for j in range(count):
        dis = random.random() \* 10
        #实际的价格是品牌的出场价除以里程数的开方
        price = seriesdata[k] / math.sqrt(1.0 + dis)
        print str(price) + '\t' + str(dis) + '\t' + str(k)
# dis 是输入的里程

dis = mx.symbol.Variable('dis')
# price 是要预测的目标价格

price = mx.symbol.Variable('price')
# price_interval 是要预测的价格区间

price_interval = mx.symbol.Variable('price_interval')
# series 是输入的车的品牌

series = mx.symbol.Variable('series')

series_out = mx.symbol.Embedding(data = series, input_dim = 200,
                             output_dim = 100, name = ""series_embed"")
ne = mx.symbol.Flatten(series_out, name = ""series_flatten"")

arg , out,aux = ne.infer_shape(series=(6,1))
print arg
print ne.list_arguments()
print out

execute = ne.bind(ctx=mx.cpu(),args={'dis_flatten':seriesdata})
execute.forward()
d_out = execute.outputs[0]
print d_out.asnumpy()

IN console:
[(6L, 1L), (200L, 100L)]
['series', 'series_embed_weight']
[(6L, 100L)]
Then throw an error:
    raise ValueError('Must specify all the arguments in %s' % arg_key)
ValueError: Must specify all the arguments in args

I know it means that I did not give values to  the series_embed_weight . But in this example, which values to give it?
"
incubator-mxnet,9372,"
## Description
I try to compile mxnet from source code and get the error below: 
/usr/bin/ld: cannot find -lcuda
Even i try to reset the path of CUDA (such as ""USE_CUDA_PATH=/apps2/cuda/8.0.61""), however, the compiler keep finding CUDA in the system folder.

## Environment info (Required)
Red Hat Enterprise Linux Workstation release 6.7 (Santiago)

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc 4.8.2

## Error Message:
/usr/bin/ld: cannot find -lcuda
collect2: error: ld returned 1 exit status
/make: usr*** [bin/im2rec] Error 1/
bin/ld: cannot find -lcuda
make: *** Waiting for unfinished jobs....
collect2: error: ld returned 1 exit status
make: *** [lib/libmxnet.so] Error 1

## What have you tried to solve it?

1. Add following two lines into all config.mk files 
ADD_LDFLAGS=-L/apps2/cuda/8.0.61/lib64
ADD_CFLAGS=-I/apps2/cuda/8.0.61/include

The command line i use to compile as below:
make -j 10 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/apps2/cuda/8.0.61

Here is one thing need to be mentioned: CUDA doesn't be installed in the default system path. We installed CUDA in the customized directory. 

Please help me to solve this problem. 
Thank you so much


",0,Compile Error: /usr/bin/ld: cannot find -lcuda,"Compile Error: /usr/bin/ld: cannot find -lcuda 
## Description
I try to compile mxnet from source code and get the error below: 
/usr/bin/ld: cannot find -lcuda
Even i try to reset the path of CUDA (such as ""USE_CUDA_PATH=/apps2/cuda/8.0.61""), however, the compiler keep finding CUDA in the system folder.

## Environment info (Required)
Red Hat Enterprise Linux Workstation release 6.7 (Santiago)

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc 4.8.2

## Error Message:
/usr/bin/ld: cannot find -lcuda
collect2: error: ld returned 1 exit status
/make: usr*** [bin/im2rec] Error 1/
bin/ld: cannot find -lcuda
make: *** Waiting for unfinished jobs....
collect2: error: ld returned 1 exit status
make: *** [lib/libmxnet.so] Error 1

## What have you tried to solve it?

1. Add following two lines into all config.mk files 
ADD_LDFLAGS=-L/apps2/cuda/8.0.61/lib64
ADD_CFLAGS=-I/apps2/cuda/8.0.61/include

The command line i use to compile as below:
make -j 10 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/apps2/cuda/8.0.61

Here is one thing need to be mentioned: CUDA doesn't be installed in the default system path. We installed CUDA in the customized directory. 

Please help me to solve this problem. 
Thank you so much


"
incubator-mxnet,9971,"Using pip to install mxnet-cu90 and onnx-mxnet causes pip to reinstall mxnet, removing GPU support. Changing the order the packages are installed does not address this issue.
",0,onnx-mxnet pip package prevents gpu use,"onnx-mxnet pip package prevents gpu use Using pip to install mxnet-cu90 and onnx-mxnet causes pip to reinstall mxnet, removing GPU support. Changing the order the packages are installed does not address this issue.
"
incubator-mxnet,17113,"## Description
See https://github.com/apache/incubator-mxnet/pull/17098 and please help to review it.

 will currently fail on some systems, as OpenMP detects and attempts to build nvptx offloading target (which is not needed, but whose build fails).",0,3rdparty/openmp cmake build broken on some systems,"3rdparty/openmp cmake build broken on some systems ## Description
See https://github.com/apache/incubator-mxnet/pull/17098 and please help to review it.

 will currently fail on some systems, as OpenMP detects and attempts to build nvptx offloading target (which is not needed, but whose build fails)."
incubator-mxnet,4249,Add support for std deviation operator. Refer#4207 on how this could be done.,0,[Keras] Add support for std (deviation) operator.,[Keras] Add support for std (deviation) operator. Add support for std deviation operator. Refer#4207 on how this could be done.
incubator-mxnet,7457,"This is the most minimal example of what should be used to load a symbol with the c_api and it doesn't work. Unless I'm missing something completely like a compiler flag, otherwise


## Environment info
Operating System:

centos

Compiler:

gcc

Package used (Python/R/Scala/Julia):

C

MXNet version:

0.9.3

## Error Message:
Please paste the full error message, including stack trace.

[16:17:17] /share/tools/mxnet/dmlc-core/include/dmlc/./logging.h:300: [16:17:17] src/core/op.cc:55: Check failed: op != nullptr Operator FullyConnected is not registered

Stack trace returned 10 entries:
[bt] (0) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm2Op3GetERKSs+0x329) [0x7fcb0323f179]
[bt] (1) /share/tools/mxnet/lib/libmxnet.so(+0xef8268) [0x7fcb03227268]
[bt] (2) /share/tools/mxnet/lib/libmxnet.so(_ZN4dmlc20JSONObjectReadHelper13ReadAllFieldsEPNS_10JSONReaderE+0x100) [0x7fcb0322d680]
[bt] (3) /share/tools/mxnet/lib/libmxnet.so(+0xef70ef) [0x7fcb032260ef]
[bt] (4) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (5) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (6) /share/tools/mxnet/lib/libmxnet.so(_ZN5mxnet18LoadLegacyJSONPassEN4nnvm5GraphE+0x180) [0x7fcb02e851c0]
[bt] (7) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (8) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (9) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm9ApplyPassENS_5GraphERKSs+0x8e) [0x7fcb0318006e]



## Minimum reproducible example
test.c : 

#include <stdio.h>
#include ""mxnet/c_api.h""

int main(void)
{
    const char * symfn = ""net_symbol.json"";
    SymbolHandle sym;
    MXSymbolCreateFromFile(symfn, &sym);
    return 0;
}


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. compiled with   gcc -I../include -L. -Wl,--whole-archive -lmxnet -Wl,--no-whole-archive test.c -o testrun
2. run 

## What have you tried to solve it?

1. including every header in the include/mxnet directory
2. copying all compiler flags from the make file 

",0,Minimal C example fails to register operators,"Minimal C example fails to register operators This is the most minimal example of what should be used to load a symbol with the c_api and it doesn't work. Unless I'm missing something completely like a compiler flag, otherwise


## Environment info
Operating System:

centos

Compiler:

gcc

Package used (Python/R/Scala/Julia):

C

MXNet version:

0.9.3

## Error Message:
Please paste the full error message, including stack trace.

[16:17:17] /share/tools/mxnet/dmlc-core/include/dmlc/./logging.h:300: [16:17:17] src/core/op.cc:55: Check failed: op != nullptr Operator FullyConnected is not registered

Stack trace returned 10 entries:
[bt] (0) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm2Op3GetERKSs+0x329) [0x7fcb0323f179]
[bt] (1) /share/tools/mxnet/lib/libmxnet.so(+0xef8268) [0x7fcb03227268]
[bt] (2) /share/tools/mxnet/lib/libmxnet.so(_ZN4dmlc20JSONObjectReadHelper13ReadAllFieldsEPNS_10JSONReaderE+0x100) [0x7fcb0322d680]
[bt] (3) /share/tools/mxnet/lib/libmxnet.so(+0xef70ef) [0x7fcb032260ef]
[bt] (4) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (5) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (6) /share/tools/mxnet/lib/libmxnet.so(_ZN5mxnet18LoadLegacyJSONPassEN4nnvm5GraphE+0x180) [0x7fcb02e851c0]
[bt] (7) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (8) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (9) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm9ApplyPassENS_5GraphERKSs+0x8e) [0x7fcb0318006e]



## Minimum reproducible example
test.c : 

#include <stdio.h>
#include ""mxnet/c_api.h""

int main(void)
{
    const char * symfn = ""net_symbol.json"";
    SymbolHandle sym;
    MXSymbolCreateFromFile(symfn, &sym);
    return 0;
}


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. compiled with   gcc -I../include -L. -Wl,--whole-archive -lmxnet -Wl,--no-whole-archive test.c -o testrun
2. run 

## What have you tried to solve it?

1. including every header in the include/mxnet directory
2. copying all compiler flags from the make file 

"
incubator-mxnet,3205,"I compiled warp-ctc and mxnet successful.
I add warp-ctc in config.mk，and compiled mxnet，
but when I run lstm_ocr.py, the problem disappear

> > > from captcha.image import ImageCaptcha
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > ImportError: No module named captcha.image

Did you have idea about this?
",0,ImportError: No module named captcha.image,"ImportError: No module named captcha.image I compiled warp-ctc and mxnet successful.
I add warp-ctc in config.mk，and compiled mxnet，
but when I run lstm_ocr.py, the problem disappear

> > > from captcha.image import ImageCaptcha
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > ImportError: No module named captcha.image

Did you have idea about this?
"
incubator-mxnet,7997,"Hi,

If I run the train_imagenet with benchmark option, I can see that for each epoch it executes 50 batches irrespective of batch size.

Is there a way to change the number of batches?

Thanks,
Saiful",0,Question about benchmarking imagenet,"Question about benchmarking imagenet Hi,

If I run the train_imagenet with benchmark option, I can see that for each epoch it executes 50 batches irrespective of batch size.

Is there a way to change the number of batches?

Thanks,
Saiful"
incubator-mxnet,13011,"## Description
Sphinx is throwing errors when generating docs for .

## Error

",0,mxnet.module.BaseModule docs errors,"mxnet.module.BaseModule docs errors ## Description
Sphinx is throwing errors when generating docs for .

## Error

"
incubator-mxnet,3192,"whether i can get each neural output when i finish my training
",0,get each layer output,"get each layer output whether i can get each neural output when i finish my training
"
incubator-mxnet,4699,"

## Environment info
Operating System: Ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): Scala

MXNet version: v0.9

Or if installed from source:

MXNet commit hash (): 6d05979cce53041f356204b17db2effb09371328

## Error Message:


## Steps to reproduce
1. compile mxnet with CUDA & NVRTC and then compile the scalapkg


2.



3.


## What have you tried to solve it?

I have locate the commit which cause the problem, it's the pr #4528 
after I roll back to the commit 50a3a3184e3034a98b2d4ad82f186d035803ab9b before #4528 
the problem have solved.

And I also check the CUDA doc, error code 201 means:

CUDA_ERROR_INVALID_CONTEXT = 201
This most frequently indicates that there is no context bound to the current thread. This can also be returned if the context passed to an API call is not a valid handle (such as a context that has had cuCtxDestroy() invoked on it). This can also be returned if a user mixes different API versions (i.e. 3010 context with 3020 API calls). See cuCtxGetApiVersion() for more details.


@javelinjs @piiswrong 
",0,[Scala] fail to run the example ExampleCustomOpWithRtc.scala,"[Scala] fail to run the example ExampleCustomOpWithRtc.scala 

## Environment info
Operating System: Ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): Scala

MXNet version: v0.9

Or if installed from source:

MXNet commit hash (): 6d05979cce53041f356204b17db2effb09371328

## Error Message:


## Steps to reproduce
1. compile mxnet with CUDA & NVRTC and then compile the scalapkg


2.



3.


## What have you tried to solve it?

I have locate the commit which cause the problem, it's the pr #4528 
after I roll back to the commit 50a3a3184e3034a98b2d4ad82f186d035803ab9b before #4528 
the problem have solved.

And I also check the CUDA doc, error code 201 means:

CUDA_ERROR_INVALID_CONTEXT = 201
This most frequently indicates that there is no context bound to the current thread. This can also be returned if the context passed to an API call is not a valid handle (such as a context that has had cuCtxDestroy() invoked on it). This can also be returned if a user mixes different API versions (i.e. 3010 context with 3020 API calls). See cuCtxGetApiVersion() for more details.


@javelinjs @piiswrong 
"
incubator-mxnet,5176,"Hi!

I got following error when try some demo code, 

 I thought the usage is fine since there is no problems in numpy, but a TypeError occur


Is that normal?

Best Regards,
Haria",0,source_array must be array like object,"source_array must be array like object Hi!

I got following error when try some demo code, 

 I thought the usage is fine since there is no problems in numpy, but a TypeError occur


Is that normal?

Best Regards,
Haria"
incubator-mxnet,4236,"i want to find the max value of a tensor.
i think of a method as follows:
Tensor<xpu, 2, DType> data = in_data[activation::kData].FlatTo2D<xpu, DType>(s);
Shape<1> maxshape=Shape<1>(1);
Tensor<xpu, 1, DType> out_max=NewTensor<xpu,DType,2>(maxshape,Dtype(0),false);
out_max=pool<mshadow::red::maximum>(pad(data,0,0),Shape<1>,data.shape_[0],data.shape_[1],1,1);

Are there any concise way?
And if i want to use the max value to the following calculation in gpu ,i can't access it using out_max[0] in cpu kernal, so how to solve it?
",0,how to  find the max value of a tensor,"how to  find the max value of a tensor i want to find the max value of a tensor.
i think of a method as follows:
Tensor<xpu, 2, DType> data = in_data[activation::kData].FlatTo2D<xpu, DType>(s);
Shape<1> maxshape=Shape<1>(1);
Tensor<xpu, 1, DType> out_max=NewTensor<xpu,DType,2>(maxshape,Dtype(0),false);
out_max=pool<mshadow::red::maximum>(pad(data,0,0),Shape<1>,data.shape_[0],data.shape_[1],1,1);

Are there any concise way?
And if i want to use the max value to the following calculation in gpu ,i can't access it using out_max[0] in cpu kernal, so how to solve it?
"
incubator-mxnet,7533,"Call mx.nd.smooth_l1 without scalar parameter will cause mxnet to crash


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.



## What have you tried to solve it?

Specify scalar will solve it

However, in the example, the argument is specified as , which is very confusing.
http://mxnet.io/api/python/symbol.html#mxnet.symbol.smooth_l1

We should add a default value for scalar (1.0), fix the document, and fix the uncaught exception anyway
",0,Call symbol/nd.smooth_l1 without scalar causing uncaught exception,"Call symbol/nd.smooth_l1 without scalar causing uncaught exception Call mx.nd.smooth_l1 without scalar parameter will cause mxnet to crash


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.



## What have you tried to solve it?

Specify scalar will solve it

However, in the example, the argument is specified as , which is very confusing.
http://mxnet.io/api/python/symbol.html#mxnet.symbol.smooth_l1

We should add a default value for scalar (1.0), fix the document, and fix the uncaught exception anyway
"
incubator-mxnet,7766,"Fixed size pooling such as SPP is commonly used in CNN, however I found SPP doesn't exist in mxnet symbols.",0,How to implement fixed size pooling like spatial pyramid pooling?,"How to implement fixed size pooling like spatial pyramid pooling? Fixed size pooling such as SPP is commonly used in CNN, however I found SPP doesn't exist in mxnet symbols."
incubator-mxnet,3347,"https://github.com/dmlc/mxnet/blob/master/docs/system/note_engine.md#case-study-on-multi-gpu-neural-net

The original sample code is:



Should it be revised as following?



There is same problem in the graph show:

![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/engine/dep_net.png)
",0,"Is there any typo in ""Dependency Engine for Deep Learning""?","Is there any typo in ""Dependency Engine for Deep Learning""? https://github.com/dmlc/mxnet/blob/master/docs/system/note_engine.md#case-study-on-multi-gpu-neural-net

The original sample code is:



Should it be revised as following?



There is same problem in the graph show:

![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/engine/dep_net.png)
"
incubator-mxnet,11567,"## Description
HI, following PR Builds are failing on dockcross-linux-arm64. 
https://github.com/apache/incubator-mxnet/pull/11478
https://github.com/apache/incubator-mxnet/pull/11548

Probably some issue with this dockerfile:
https://hub.docker.com/r/mxnetci/dockcross-linux-arm64/tags/

@marcoabreu  Can you please take a look?

@anirudh2290 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",0,MXNet v1.2.0 branch PR build failure,"MXNet v1.2.0 branch PR build failure ## Description
HI, following PR Builds are failing on dockcross-linux-arm64. 
https://github.com/apache/incubator-mxnet/pull/11478
https://github.com/apache/incubator-mxnet/pull/11548

Probably some issue with this dockerfile:
https://hub.docker.com/r/mxnetci/dockcross-linux-arm64/tags/

@marcoabreu  Can you please take a look?

@anirudh2290 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
"
incubator-mxnet,16037,"## Description
1) Create an RNN op with  and bind it
2) Run a forward pass
3) Change the NDArray holding the RNN parameters
4) Run a forward pass again

The output doesn't change, unless the second forward pass is performed in training mode (). Setting  doesn't fix the issue, but using a build without MKL-DNN does.

This severly impacts training with a validation set, because evaluating the performance on the validation set is typically performed with  after several updates of the weights. In this case, validation shows no improvement because the output of the layer is stuck at the very first training iteration.

## Environment info (Required)



Package used (Python/R/Scala/Julia): python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 076b2f330c60f05cb939beea28dd04cd571a34c0

Build config: plain config.mk, except for USE_OPENCV=0

## Minimum reproducible example


When using a build with MKL-DNN, this script print something like this:

Which shows that the output doesn't change after changing the weights unless the forward pass is performed in training mode. Setting  doesn't fix the issue, but using a build without MKL-DNN does.",0,LSTM with MKL-DNN produces wrong output after weights are changed,"LSTM with MKL-DNN produces wrong output after weights are changed ## Description
1) Create an RNN op with  and bind it
2) Run a forward pass
3) Change the NDArray holding the RNN parameters
4) Run a forward pass again

The output doesn't change, unless the second forward pass is performed in training mode (). Setting  doesn't fix the issue, but using a build without MKL-DNN does.

This severly impacts training with a validation set, because evaluating the performance on the validation set is typically performed with  after several updates of the weights. In this case, validation shows no improvement because the output of the layer is stuck at the very first training iteration.

## Environment info (Required)



Package used (Python/R/Scala/Julia): python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 076b2f330c60f05cb939beea28dd04cd571a34c0

Build config: plain config.mk, except for USE_OPENCV=0

## Minimum reproducible example


When using a build with MKL-DNN, this script print something like this:

Which shows that the output doesn't change after changing the weights unless the forward pass is performed in training mode. Setting  doesn't fix the issue, but using a build without MKL-DNN does."
incubator-mxnet,5224,"hello, Now I use mxnet and face detection model 'mtcnn' to inference an image, but it shows error: 
I doubt that whether it is caused by mxnet or not.
Can you give me some advices how to solve this problem?",0,"include/dmlc/logging.h:235: [00:59:21] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open ""model/det1-symbol.json""","include/dmlc/logging.h:235: [00:59:21] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open ""model/det1-symbol.json"" hello, Now I use mxnet and face detection model 'mtcnn' to inference an image, but it shows error: 
I doubt that whether it is caused by mxnet or not.
Can you give me some advices how to solve this problem?"
incubator-mxnet,6095,"If calling train several times, I ran out of GPU memory:

pooled_storage_manager.h:80: cudaMalloc failed: out of memory

looks like GPU buffers are never cleared and memory runs out. 
It needs to be solved to be able to use MXNet in the larger application, where multiple train attempts are made in sequence, without restarting the app.",0,Multiple calls to train cause cudaMalloc to fail,"Multiple calls to train cause cudaMalloc to fail If calling train several times, I ran out of GPU memory:

pooled_storage_manager.h:80: cudaMalloc failed: out of memory

looks like GPU buffers are never cleared and memory runs out. 
It needs to be solved to be able to use MXNet in the larger application, where multiple train attempts are made in sequence, without restarting the app."
incubator-mxnet,9711,"Presently, we are use 4-dim data flow to build most of our models, **BatchSize x W x H x Channels** or **BatchSize x Channels x H x W**.

Is it possible to build 5-dim data flow? Maybe **BatchSize x Capsule x W x H x Channels**, which should be useful in ideas like CapsNet for that we don't have to reshape out data. So we can build high dimensions models which are more complicated and should be better both in structure and data extraction performance. 

According to **MobileNetV2**, performance of relu  is better in high dimensions than in low dimensions. So it maybe even more better if we can build our entire model with high dimensions operations. 
Further more, how about 6-dim or 7-dim operations, even x-dim operations?

Is this kind of operations possible? If possible, how hard will it be to implement them?",0,Is it possible to support 5-dim or x-dim data operation,"Is it possible to support 5-dim or x-dim data operation Presently, we are use 4-dim data flow to build most of our models, **BatchSize x W x H x Channels** or **BatchSize x Channels x H x W**.

Is it possible to build 5-dim data flow? Maybe **BatchSize x Capsule x W x H x Channels**, which should be useful in ideas like CapsNet for that we don't have to reshape out data. So we can build high dimensions models which are more complicated and should be better both in structure and data extraction performance. 

According to **MobileNetV2**, performance of relu  is better in high dimensions than in low dimensions. So it maybe even more better if we can build our entire model with high dimensions operations. 
Further more, how about 6-dim or 7-dim operations, even x-dim operations?

Is this kind of operations possible? If possible, how hard will it be to implement them?"
incubator-mxnet,6005,"finally, I found why my training loss can not decreased with kvstore.
that is because kvstore can not get the new weight value after its init.
kvstore only updates the weight in itself.
set_param() can not affect the weight of kvstore actually!
but, In my training, I need to exchange the weight value periodically.
So, I suggest kvstore can accept the new weight value by using set_params() in the training time.

@piiswrong @tqchen 
",0,An advice for set_params() when using kvstore,"An advice for set_params() when using kvstore finally, I found why my training loss can not decreased with kvstore.
that is because kvstore can not get the new weight value after its init.
kvstore only updates the weight in itself.
set_param() can not affect the weight of kvstore actually!
but, In my training, I need to exchange the weight value periodically.
So, I suggest kvstore can accept the new weight value by using set_params() in the training time.

@piiswrong @tqchen 
"
incubator-mxnet,9847,"I tried to implement a simple linear regression with ndarray in imperative style.

batchDataBatch
I think the point of the error is **""src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute""**.

I also got the similar errors with  and . With  I get no errors while it is not the regression that I want. The imperative style regression outputs may not be used frequently but anyway they could be useful sometimes and listed in the API document anyway. Please fix them.
",0,Imperative regression output layers are broken,"Imperative regression output layers are broken I tried to implement a simple linear regression with ndarray in imperative style.

batchDataBatch
I think the point of the error is **""src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute""**.

I also got the similar errors with  and . With  I get no errors while it is not the regression that I want. The imperative style regression outputs may not be used frequently but anyway they could be useful sometimes and listed in the API document anyway. Please fix them.
"
incubator-mxnet,9826,"I try to test Mtcnn face detection from this repository: https://github.com/pangyupo/mxnet_mtcnn_face_detection

After some iteration I got a severe crash of Mxnet with this error : https://gist.github.com/edmBernard/91731e795decd7b7c5456cb0d7a1d303

I was not able to reproduce this out of my code. All the code was in python only Mxnet use C++.
Does someone have a idea where this can come from ?

Note: maybe it's linked but this code use a old API with FeedForward


Note: 
On GPU I got this error : 
On CPU I got this error : ",0,Crash Mxnet: Error in `python3': corrupted double-linked list: 0x00007f1c4b2e09d0,"Crash Mxnet: Error in `python3': corrupted double-linked list: 0x00007f1c4b2e09d0 I try to test Mtcnn face detection from this repository: https://github.com/pangyupo/mxnet_mtcnn_face_detection

After some iteration I got a severe crash of Mxnet with this error : https://gist.github.com/edmBernard/91731e795decd7b7c5456cb0d7a1d303

I was not able to reproduce this out of my code. All the code was in python only Mxnet use C++.
Does someone have a idea where this can come from ?

Note: maybe it's linked but this code use a old API with FeedForward


Note: 
On GPU I got this error : 
On CPU I got this error : "
incubator-mxnet,5163,"We can use im2rec according to the lst file to generate rec files. But how could we generate synset.txt files? And if we use NDArrayIter, how to find the relation between the sequence of the prediction and label file?
Many thanks.",0,How to generate synset.txt files?,"How to generate synset.txt files? We can use im2rec according to the lst file to generate rec files. But how could we generate synset.txt files? And if we use NDArrayIter, how to find the relation between the sequence of the prediction and label file?
Many thanks."
incubator-mxnet,4660,"## Environment info
Operating System: ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): python

MXNet version: 0.9.1 (0.7.1 nightly 32cb6bc)

Or if installed from source:

MXNet commit hash (): 32cb6bc

If you are using python package, please provide

Python version and distribution: anaconda 2.7.11

## Error Message:
I used cnn-lstm-ctc to do ocr tasks, and it can work well with mxnet 0.7 version, but when I use the latest mxnet version 0.9.1 it will block here forever :

## Minimum reproducible example

## Steps to reproduce
1.
2.
3.

## What have you tried to solve it?

",0,cudnn-convolution performance tests on cnn-lstm-ctc,"cudnn-convolution performance tests on cnn-lstm-ctc ## Environment info
Operating System: ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): python

MXNet version: 0.9.1 (0.7.1 nightly 32cb6bc)

Or if installed from source:

MXNet commit hash (): 32cb6bc

If you are using python package, please provide

Python version and distribution: anaconda 2.7.11

## Error Message:
I used cnn-lstm-ctc to do ocr tasks, and it can work well with mxnet 0.7 version, but when I use the latest mxnet version 0.9.1 it will block here forever :

## Minimum reproducible example

## Steps to reproduce
1.
2.
3.

## What have you tried to solve it?

"
incubator-mxnet,3684,"Hi @javelinjs 

I use MXNet-Scala to deploy my model for a while and it works great, the engineering team stress tested my service and found the service could stop response after a while.

They printed the info with :



Here's my code:



",0,Would predict and NDArray.toArray cause BLOCK ?,"Would predict and NDArray.toArray cause BLOCK ? Hi @javelinjs 

I use MXNet-Scala to deploy my model for a while and it works great, the engineering team stress tested my service and found the service could stop response after a while.

They printed the info with :



Here's my code:



"
incubator-mxnet,371,"I recall, from version 1 of Cxxnet, that there was a utility for creating the .bin for the image mean; I can iterate through the dataset, compute the mean image, save it as a jpg, and then convert it with ./bin/im2rec, but I was wondering if there was a utility to do this that I missed in the documentation?
",0,computing image mean,"computing image mean I recall, from version 1 of Cxxnet, that there was a utility for creating the .bin for the image mean; I can iterate through the dataset, compute the mean image, save it as a jpg, and then convert it with ./bin/im2rec, but I was wondering if there was a utility to do this that I missed in the documentation?
"
incubator-mxnet,8391,"I was trying to use CIFAR dataset to train a mobilenet, since the origin size is 32x32 so I resize them to 224x224 which is the size of the mobilenet input:

but after I resize them, I will encounter this problem:
**mxnet_source/dmlc-core/include/dmlc/./logging.h:308: [16:20:13] include/mxnet/././tensor_blob.h:275: Check failed: this->shape_.Size() == shape.Size() (4515840000 vs. 220872704) TBlob.get_with_shape: new and old shape do not match total elements**

if I did not resize the image, it will be ok, and I check the meomery use, seems a memory leak happened, my computer has 64GB memory, the program will use them all.

the other parts of my script is:



can any one help?
",0,use 224x224 size to train mobilenet will encounter memory problem,"use 224x224 size to train mobilenet will encounter memory problem I was trying to use CIFAR dataset to train a mobilenet, since the origin size is 32x32 so I resize them to 224x224 which is the size of the mobilenet input:

but after I resize them, I will encounter this problem:
**mxnet_source/dmlc-core/include/dmlc/./logging.h:308: [16:20:13] include/mxnet/././tensor_blob.h:275: Check failed: this->shape_.Size() == shape.Size() (4515840000 vs. 220872704) TBlob.get_with_shape: new and old shape do not match total elements**

if I did not resize the image, it will be ok, and I check the meomery use, seems a memory leak happened, my computer has 64GB memory, the program will use them all.

the other parts of my script is:



can any one help?
"
incubator-mxnet,14961,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14959/2/pipeline.
TensorRT build fails with:
",0,CI Build Failures: unix-gpu TensorRT,"CI Build Failures: unix-gpu TensorRT http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14959/2/pipeline.
TensorRT build fails with:
"
incubator-mxnet,3244,"I have checked out the latest master in both Julia 0.4.6 and latest 0.6. Pkg.test runs correctly in 0.6, but fails in 0.4.6 at:

/usr/bin/julia --check-bounds=yes --code-coverage=none --color=yes /home/colin/.julia/v0.4/MXNet/test/runtests.jl
",0,"Pkg.test on v 0.6 succeeds, but fails on 0.4.6","Pkg.test on v 0.6 succeeds, but fails on 0.4.6 I have checked out the latest master in both Julia 0.4.6 and latest 0.6. Pkg.test runs correctly in 0.6, but fails in 0.4.6 at:

/usr/bin/julia --check-bounds=yes --code-coverage=none --color=yes /home/colin/.julia/v0.4/MXNet/test/runtests.jl
"
incubator-mxnet,9176,"Currently  and  return dense NDArray. Instead it can return a row-sparse NDArray directly. This is causing extra conversions when checkpointing the model, as  calls [this](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/module/executor_group.py#L414-L416) which in turn calls . 
To support sparse ndarray output for these two operators we just need to update the infer storage logic [here](https://github.com/apache/incubator-mxnet/blob/05047ad8fee4e8ee63ae2b7f96e7e9c7684fa4a0/src/operator/tensor/elemwise_binary_scalar_op_basic.cc#L61-L66)

Also  should also return sparse result. 
",0,row_sparse ndarray + 0 should not return dense ndarray,"row_sparse ndarray + 0 should not return dense ndarray Currently  and  return dense NDArray. Instead it can return a row-sparse NDArray directly. This is causing extra conversions when checkpointing the model, as  calls [this](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/module/executor_group.py#L414-L416) which in turn calls . 
To support sparse ndarray output for these two operators we just need to update the infer storage logic [here](https://github.com/apache/incubator-mxnet/blob/05047ad8fee4e8ee63ae2b7f96e7e9c7684fa4a0/src/operator/tensor/elemwise_binary_scalar_op_basic.cc#L61-L66)

Also  should also return sparse result. 
"
incubator-mxnet,10648,"## Description
code link is here https://github.com/apache/incubator-mxnet/tree/master/example/sparse/wide_deep    
Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB)

## Environment info (Required)
### win10
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('default', 'Jul  5 2016 11:41:13')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 10.0.1
----------MXNet Info-----------
Version      : 1.1.0
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.15063-SP0
system       : Windows
node         : minhozhou-PC0
release      : 10
version      : 10.0.15063
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel
Name
Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz
### Linux
----------Python Info----------
('Version      :', '2.7.5')
('Compiler     :', 'GCC 4.8.5 20150623 (Red Hat 4.8.5-4)')
('Build        :', ('default', 'Nov 20 2015 02:00:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
----------System Info----------
('Platform     :', 'Linux-3.10.104-1-tlinux2-0041.tl2-x86_64-with-centos-7.2-Final')
('system       :', 'Linux')
('release      :', '3.10.104-1-tlinux2-0041.tl2')
('version      :', '#1 SMP Fri Oct 28 20:58:27 CST 2016')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                56
On-line CPU(s) list:   0-55
Thread(s) per core:    2
Core(s) per socket:    14
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
Stepping:              1
CPU MHz:               2401.000
BogoMIPS:              4801.66
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              35840K
NUMA node0 CPU(s):     0-13,28-41
NUMA node1 CPU(s):     14-27,42-55

## log
### win10
2018-04-23 11:33:37,170 epoch 0, accuracy = 0.7957062007874016
2018-04-23 11:33:37,173 Saved checkpoint to ""checkpoint-0000.params""
2018-04-23 11:33:37,175 Saved optimizer state to ""checkpoint-0000.states""
2018-04-23 11:33:37,276 Epoch[1] Batch [100]    Speed: 127659.84 samples/sec    accuracy=0.811797
2018-04-23 11:33:37,378 Epoch[1] Batch [200]    Speed: 126396.03 samples/sec    accuracy=0.826719
2018-04-23 11:33:37,484 epoch 1, accuracy = 0.8258489173228346
2018-04-23 11:33:37,488 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:33:37,489 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:33:37,593 Epoch[2] Batch [100]    Speed: 125157.28 samples/sec    accuracy=0.826250
2018-04-23 11:33:37,696 Epoch[2] Batch [200]    Speed: 123941.43 samples/sec    accuracy=0.829922
2018-04-23 11:33:37,806 epoch 2, accuracy = 0.8415969488188977

### Linux
2018-04-23 11:43:50,156 Epoch[1] Batch [100]	Speed: 24695.55 samples/sec	accuracy=0.782266
2018-04-23 11:43:50,755 Epoch[1] Batch [200]	Speed: 21366.17 samples/sec	accuracy=0.783750
2018-04-23 11:43:51,558 epoch 1, accuracy = 0.795583169291
2018-04-23 11:43:51,570 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:43:51,574 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:43:52,132 Epoch[2] Batch [100]	Speed: 23574.39 samples/sec	accuracy=0.789219
2018-04-23 11:43:52,721 Epoch[2] Batch [200]	Speed: 21724.27 samples/sec	accuracy=0.793438
2018-04-23 11:43:53,718 epoch 2, accuracy = 0.799950787402


**win10: 127659.84 samples/sec**
**Linux : 23574.39 samples/sec**

",0,Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB),"Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB) ## Description
code link is here https://github.com/apache/incubator-mxnet/tree/master/example/sparse/wide_deep    
Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB)

## Environment info (Required)
### win10
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('default', 'Jul  5 2016 11:41:13')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 10.0.1
----------MXNet Info-----------
Version      : 1.1.0
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.15063-SP0
system       : Windows
node         : minhozhou-PC0
release      : 10
version      : 10.0.15063
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel
Name
Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz
### Linux
----------Python Info----------
('Version      :', '2.7.5')
('Compiler     :', 'GCC 4.8.5 20150623 (Red Hat 4.8.5-4)')
('Build        :', ('default', 'Nov 20 2015 02:00:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
----------System Info----------
('Platform     :', 'Linux-3.10.104-1-tlinux2-0041.tl2-x86_64-with-centos-7.2-Final')
('system       :', 'Linux')
('release      :', '3.10.104-1-tlinux2-0041.tl2')
('version      :', '#1 SMP Fri Oct 28 20:58:27 CST 2016')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                56
On-line CPU(s) list:   0-55
Thread(s) per core:    2
Core(s) per socket:    14
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
Stepping:              1
CPU MHz:               2401.000
BogoMIPS:              4801.66
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              35840K
NUMA node0 CPU(s):     0-13,28-41
NUMA node1 CPU(s):     14-27,42-55

## log
### win10
2018-04-23 11:33:37,170 epoch 0, accuracy = 0.7957062007874016
2018-04-23 11:33:37,173 Saved checkpoint to ""checkpoint-0000.params""
2018-04-23 11:33:37,175 Saved optimizer state to ""checkpoint-0000.states""
2018-04-23 11:33:37,276 Epoch[1] Batch [100]    Speed: 127659.84 samples/sec    accuracy=0.811797
2018-04-23 11:33:37,378 Epoch[1] Batch [200]    Speed: 126396.03 samples/sec    accuracy=0.826719
2018-04-23 11:33:37,484 epoch 1, accuracy = 0.8258489173228346
2018-04-23 11:33:37,488 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:33:37,489 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:33:37,593 Epoch[2] Batch [100]    Speed: 125157.28 samples/sec    accuracy=0.826250
2018-04-23 11:33:37,696 Epoch[2] Batch [200]    Speed: 123941.43 samples/sec    accuracy=0.829922
2018-04-23 11:33:37,806 epoch 2, accuracy = 0.8415969488188977

### Linux
2018-04-23 11:43:50,156 Epoch[1] Batch [100]	Speed: 24695.55 samples/sec	accuracy=0.782266
2018-04-23 11:43:50,755 Epoch[1] Batch [200]	Speed: 21366.17 samples/sec	accuracy=0.783750
2018-04-23 11:43:51,558 epoch 1, accuracy = 0.795583169291
2018-04-23 11:43:51,570 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:43:51,574 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:43:52,132 Epoch[2] Batch [100]	Speed: 23574.39 samples/sec	accuracy=0.789219
2018-04-23 11:43:52,721 Epoch[2] Batch [200]	Speed: 21724.27 samples/sec	accuracy=0.793438
2018-04-23 11:43:53,718 epoch 2, accuracy = 0.799950787402


**win10: 127659.84 samples/sec**
**Linux : 23574.39 samples/sec**

"
incubator-mxnet,12869,"Hi,

We have model trained in python and want to use it from c++ as for getting 512D float features.

c++ gives different output when we try with image-classification-predict.cpp 

We just want to get data (as in code) 512d float vector as in python output ? 

model:
https://pan.baidu.com/s/1mj6X7MK 
or

 https://www.dropbox.com/s/ou8v3c307vyzawc/model-r50-arcface-ms1m-refine-v1.zip?dl=0

Isnt there a clear method for C++ feature extraction ?

Best

 ",0,Python trained model gives different features set in C++,"Python trained model gives different features set in C++ Hi,

We have model trained in python and want to use it from c++ as for getting 512D float features.

c++ gives different output when we try with image-classification-predict.cpp 

We just want to get data (as in code) 512d float vector as in python output ? 

model:
https://pan.baidu.com/s/1mj6X7MK 
or

 https://www.dropbox.com/s/ou8v3c307vyzawc/model-r50-arcface-ms1m-refine-v1.zip?dl=0

Isnt there a clear method for C++ feature extraction ?

Best

 "
incubator-mxnet,9703,"## Description
(Brief description of the problem in no more than 2 sentences.)
Can't run mx.nd.smooth_l1

## Environment info (Required)
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('v3.5.2:4def2a2901a5', 'Jun 25 2016 22:18:55')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 9.0.1
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.16299-SP0
system       : Windows
node         : DESKTOP-NRACBB8
release      : 10
version      : 10.0.16299
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel
Name
Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz

----------Network Test----------
Setting timeout: 10
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0393 sec, LOAD: 1.9675 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0338 sec, LOAD: 1.6308 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0321 sec, LOAD: 0.4048 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2478 sec, LOAD: 1.1301 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0341 sec, LOAD: 1.5128 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.3811 sec.


## Build info (Required if built from source)
N/A

## Error Message:
Traceback (most recent call last):
  File ""<pyshell#13>"", line 1, in <module>
    b=mx.nd.smooth_l1(a)
  File ""<string>"", line 48, in smooth_l1
  File ""C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet\_ctypes\ndarray.py"", line 92, in _imperative_invoke
    ctypes.byref(out_stypes)))
OSError: [WinError -529697949] Windows Error 0xe06d7363

## Steps to reproduce



",0,Can't run mx.nd.smooth_l1,"Can't run mx.nd.smooth_l1 ## Description
(Brief description of the problem in no more than 2 sentences.)
Can't run mx.nd.smooth_l1

## Environment info (Required)
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('v3.5.2:4def2a2901a5', 'Jun 25 2016 22:18:55')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 9.0.1
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.16299-SP0
system       : Windows
node         : DESKTOP-NRACBB8
release      : 10
version      : 10.0.16299
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel
Name
Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz

----------Network Test----------
Setting timeout: 10
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0393 sec, LOAD: 1.9675 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0338 sec, LOAD: 1.6308 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0321 sec, LOAD: 0.4048 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2478 sec, LOAD: 1.1301 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0341 sec, LOAD: 1.5128 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.3811 sec.


## Build info (Required if built from source)
N/A

## Error Message:
Traceback (most recent call last):
  File ""<pyshell#13>"", line 1, in <module>
    b=mx.nd.smooth_l1(a)
  File ""<string>"", line 48, in smooth_l1
  File ""C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet\_ctypes\ndarray.py"", line 92, in _imperative_invoke
    ctypes.byref(out_stypes)))
OSError: [WinError -529697949] Windows Error 0xe06d7363

## Steps to reproduce



"
incubator-mxnet,861,"Hi, I wonder if I can fix the parameter of some layer while training, like have a different learning rate for different layer and make some of them zero. Thank you
",0,Can I fix some layer when training a big network,"Can I fix some layer when training a big network Hi, I wonder if I can fix the parameter of some layer while training, like have a different learning rate for different layer and make some of them zero. Thank you
"
incubator-mxnet,3062,"I want to implement CNN for text on my own but failed to get evaluation metric in batch_end_callback like this(not exactly top-k, its just accuracy):



Here's my network:



I use DataIter in which the shape in  and  are same as the netowrk's :







It makes me confused why evaluation metrics doesn't show up. I suppose it should have even though I do not provide .
",0,batch_end_callback doesn't show eval_metric,"batch_end_callback doesn't show eval_metric I want to implement CNN for text on my own but failed to get evaluation metric in batch_end_callback like this(not exactly top-k, its just accuracy):



Here's my network:



I use DataIter in which the shape in  and  are same as the netowrk's :







It makes me confused why evaluation metrics doesn't show up. I suppose it should have even though I do not provide .
"
incubator-mxnet,8531,"Suppose I have two feature maps F1 and F2 output by a network. I want to compute convolution of F1 and F2. Assume that F1 has shape (1, C, 10, 10) and F2 has shape (1, C, 3, 3) and the wanted result should have shape (1, 1, 8, 8) if pad = 0, stride = 1 and dilate = 1.
How to implement this using MXNet?
I have come up with one possible way that uses mx.sym.Correlation, but I cannot get the idea how correlation operator computes by reading the doc.
Or, can I set the weight of a mx.sym.Convolution layer to F2, and data to F1? Would this interfere the propagation of grads when training?",0,How to get the correlation result of two feature maps?,"How to get the correlation result of two feature maps? Suppose I have two feature maps F1 and F2 output by a network. I want to compute convolution of F1 and F2. Assume that F1 has shape (1, C, 10, 10) and F2 has shape (1, C, 3, 3) and the wanted result should have shape (1, 1, 8, 8) if pad = 0, stride = 1 and dilate = 1.
How to implement this using MXNet?
I have come up with one possible way that uses mx.sym.Correlation, but I cannot get the idea how correlation operator computes by reading the doc.
Or, can I set the weight of a mx.sym.Convolution layer to F2, and data to F1? Would this interfere the propagation of grads when training?"
incubator-mxnet,12539,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTests_onBinaries/detail/NightlyTests_onBinaries/148/pipeline

",0,Failing nighty test: test_pixel2pixel (test_notebooks_single_gpu.StraightDopeSingleGpuTests),"Failing nighty test: test_pixel2pixel (test_notebooks_single_gpu.StraightDopeSingleGpuTests) http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTests_onBinaries/detail/NightlyTests_onBinaries/148/pipeline

"
incubator-mxnet,8902,"## throw exception on storage fallback
Currently when storage fallback happens, the log message is printed in the console, but it's very hard for the user to figure out when the fallback happens in the code even if they use NaiveEngine for debugging. We should throw an exception when storage fallback happens to help the user debug it. 
https://github.com/apache/incubator-mxnet/blob/master/src/operator/operator_common.h#L526

## missing storage fallback message/exception during ndarray copy
cast_storage may happen when the source and destination ndarray are of different storage types. Currently it's converted in silence and the user is not aware. 

## sparse vector with shape=(10)
https://github.com/apache/incubator-mxnet/issues/8817 
Still under discussion. We should either fix it or at least not let VM crash. 

## distributed training tutorial for sparse
Maybe do this after kvstore=device is done. 

## Testing
https://github.com/apache/incubator-mxnet/issues/8709
https://github.com/apache/incubator-mxnet/issues/8542 
#8980
",0,A todo list for usability improvement for sparse tensor,"A todo list for usability improvement for sparse tensor ## throw exception on storage fallback
Currently when storage fallback happens, the log message is printed in the console, but it's very hard for the user to figure out when the fallback happens in the code even if they use NaiveEngine for debugging. We should throw an exception when storage fallback happens to help the user debug it. 
https://github.com/apache/incubator-mxnet/blob/master/src/operator/operator_common.h#L526

## missing storage fallback message/exception during ndarray copy
cast_storage may happen when the source and destination ndarray are of different storage types. Currently it's converted in silence and the user is not aware. 

## sparse vector with shape=(10)
https://github.com/apache/incubator-mxnet/issues/8817 
Still under discussion. We should either fix it or at least not let VM crash. 

## distributed training tutorial for sparse
Maybe do this after kvstore=device is done. 

## Testing
https://github.com/apache/incubator-mxnet/issues/8709
https://github.com/apache/incubator-mxnet/issues/8542 
#8980
"
incubator-mxnet,6181,"I am implementing tree-LSTM's for predicting the negativity/positivity of sentences in mxnet and I am using the [BucketingModule](https://github.com/dmlc/mxnet/blob/master/docs/how_to/bucketing.md) to do this. The tree LSTM is structured similar to the structure of the parse-tree of each sentence. Therefore, each training sample will need a different structure. So I am using one bucket per input sample. Also, not all the LSTM blocks in a single structure have shared weights. For example, in a tree consisting of n nodes, k of the nodes can share the same weights and the other (n-k) can share their weights. The partition is not limited to two. In fact, it often is the case that most of the blocks do not share weights with the others.

  * My first problem is with training. If I train using 'sgd', and 'momentum' : 0.0, the training works fine. However, if I change momentum or try to use other optimizers such as 'adam', the training returns an inconsistency shape error due to the self.states dictionary in the Updater class in [optimizer.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py). It initializes the self.states dictionary for the first sentence. When the second sentence is fed, the ""index"" of the states is not necessarily the same as the first sentence. But the updater re-uses the already created states for the first sentence and fails at look-up time for the second equation. 

  * My second question is how can I do mini-batch training under this setting?

[My code](https://github.com/ForoughA/neuralTrig) is available on github. The main file to run is neuralTrig.py.

**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**


## Environment info
Operating System: 
MAC OS X El Capitan

Compiler: 
clang-800.0.38

Package used (Python/R/Scala/Julia): 
Python

MXNet version:

Or if installed from source:

MXNet commit hash ():
58e334639c4d5a875bb5b8b33036c3fab8ed7115

If you are using python package, please provide

Python version and distribution:
Python 2.7.13 :: Anaconda 4.3.1 (x86_64)

If you are using R package, please provide

R :

## Error Message:

[08:11:32] /Users/Forough/mxnet/dmlc-core/include/dmlc/logging.h:300: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

Traceback (most recent call last):
  File ""neuralTrig.py"", line 214, in <module>
    main()
  File ""neuralTrig.py"", line 184, in main
    epoch_end_callback  = mx.rnn.do_rnn_checkpoint(cell, 'trainedModel', 1))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/base_module.py"", line 475, in fit
    self.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/bucketing_module.py"", line 401, in update
    self._curr_module.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/module.py"", line 570, in update
    kvstore=self._kvstore)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/model.py"", line 123, in _update_params
    updater(index*num_device+k, g, w)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 690, in __call__
    self.optimizer.update(index, weight, grad, self.states[index])
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 324, in update
    lr=lr, wd=wd, **self.kwargs)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/_ctypes/ndarray.py"", line 133, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/base.py"", line 78, in check_call
    **raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)**

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

## Minimum reproducible example
Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. 

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. If we set the momentum to something other than zero it fails. If we use another optimzier it also fails.
**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**
",0,Problem with implementing tree-LSTM's in mxnet,"Problem with implementing tree-LSTM's in mxnet I am implementing tree-LSTM's for predicting the negativity/positivity of sentences in mxnet and I am using the [BucketingModule](https://github.com/dmlc/mxnet/blob/master/docs/how_to/bucketing.md) to do this. The tree LSTM is structured similar to the structure of the parse-tree of each sentence. Therefore, each training sample will need a different structure. So I am using one bucket per input sample. Also, not all the LSTM blocks in a single structure have shared weights. For example, in a tree consisting of n nodes, k of the nodes can share the same weights and the other (n-k) can share their weights. The partition is not limited to two. In fact, it often is the case that most of the blocks do not share weights with the others.

  * My first problem is with training. If I train using 'sgd', and 'momentum' : 0.0, the training works fine. However, if I change momentum or try to use other optimizers such as 'adam', the training returns an inconsistency shape error due to the self.states dictionary in the Updater class in [optimizer.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py). It initializes the self.states dictionary for the first sentence. When the second sentence is fed, the ""index"" of the states is not necessarily the same as the first sentence. But the updater re-uses the already created states for the first sentence and fails at look-up time for the second equation. 

  * My second question is how can I do mini-batch training under this setting?

[My code](https://github.com/ForoughA/neuralTrig) is available on github. The main file to run is neuralTrig.py.

**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**


## Environment info
Operating System: 
MAC OS X El Capitan

Compiler: 
clang-800.0.38

Package used (Python/R/Scala/Julia): 
Python

MXNet version:

Or if installed from source:

MXNet commit hash ():
58e334639c4d5a875bb5b8b33036c3fab8ed7115

If you are using python package, please provide

Python version and distribution:
Python 2.7.13 :: Anaconda 4.3.1 (x86_64)

If you are using R package, please provide

R :

## Error Message:

[08:11:32] /Users/Forough/mxnet/dmlc-core/include/dmlc/logging.h:300: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

Traceback (most recent call last):
  File ""neuralTrig.py"", line 214, in <module>
    main()
  File ""neuralTrig.py"", line 184, in main
    epoch_end_callback  = mx.rnn.do_rnn_checkpoint(cell, 'trainedModel', 1))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/base_module.py"", line 475, in fit
    self.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/bucketing_module.py"", line 401, in update
    self._curr_module.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/module.py"", line 570, in update
    kvstore=self._kvstore)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/model.py"", line 123, in _update_params
    updater(index*num_device+k, g, w)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 690, in __call__
    self.optimizer.update(index, weight, grad, self.states[index])
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 324, in update
    lr=lr, wd=wd, **self.kwargs)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/_ctypes/ndarray.py"", line 133, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/base.py"", line 78, in check_call
    **raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)**

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

## Minimum reproducible example
Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. 

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. If we set the momentum to something other than zero it fails. If we use another optimzier it also fails.
**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**
"
incubator-mxnet,3353,"I ran example/image-classification/train_mnist.py with batch_size = 10000, so there would be 6 batches for the forword training ( val is set to None)，the Forword function of the first Fully-connect layer should be called 6 times. I added some debug codes as follows:
![p hayw f d 0 t 11 i u3j](https://cloud.githubusercontent.com/assets/21171292/18749082/de8e6ada-8107-11e6-9df1-3f52a0650dcc.png)
![o466yu t _ tq_ yrezt3oy](https://cloud.githubusercontent.com/assets/21171292/18749092/e5510e18-8107-11e6-9b6c-40553ccf2522.png)

But the log printed  is not what I supposed:
![_o smuqtw sdk ou 6 ji](https://cloud.githubusercontent.com/assets/21171292/18749230/6e527bfc-8108-11e6-9e58-a54226372fd3.png)

why is ""logger.info(load123)"" in python executed 6 times as supposed, while  ""LOG(INFO) << ""forward123"" in fully_connected-inl.h just once ? 
@piiswrong 
",0,Why is LOG(INFO)  not working as supposed in mxnet C++ code ?,"Why is LOG(INFO)  not working as supposed in mxnet C++ code ? I ran example/image-classification/train_mnist.py with batch_size = 10000, so there would be 6 batches for the forword training ( val is set to None)，the Forword function of the first Fully-connect layer should be called 6 times. I added some debug codes as follows:
![p hayw f d 0 t 11 i u3j](https://cloud.githubusercontent.com/assets/21171292/18749082/de8e6ada-8107-11e6-9df1-3f52a0650dcc.png)
![o466yu t _ tq_ yrezt3oy](https://cloud.githubusercontent.com/assets/21171292/18749092/e5510e18-8107-11e6-9b6c-40553ccf2522.png)

But the log printed  is not what I supposed:
![_o smuqtw sdk ou 6 ji](https://cloud.githubusercontent.com/assets/21171292/18749230/6e527bfc-8108-11e6-9e58-a54226372fd3.png)

why is ""logger.info(load123)"" in python executed 6 times as supposed, while  ""LOG(INFO) << ""forward123"" in fully_connected-inl.h just once ? 
@piiswrong 
"
incubator-mxnet,5943,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:ubuntu 16.0.4

Compiler: g++

Package used (Python/R/Scala/Julia): Python

MXNet version: 0.9.3

Or if installed from source: 

MXNet commit hash (): 0.9.3 release

If you are using python package, please provide python 3.5

Python version and distribution: python 3.5

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0,1
INFO:root:Epoch[0] Batch [100] Speed: 189.20 samples/sec Train-accuracy=0.100402


~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0
INFO:root:Epoch[0] Batch [300] Speed: 81716.01 samples/sec Train-accuracy=0.928594




## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. python train_mnist.py --network mlp 
2. python train_mnist.py --network mlp --gpus 0
3. python train_mnist.py --network mlp --gpus 0,1

## What have you tried to solve it?

1.
2.
3.
",0, Multi GPU training speed LOW," Multi GPU training speed LOW For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:ubuntu 16.0.4

Compiler: g++

Package used (Python/R/Scala/Julia): Python

MXNet version: 0.9.3

Or if installed from source: 

MXNet commit hash (): 0.9.3 release

If you are using python package, please provide python 3.5

Python version and distribution: python 3.5

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0,1
INFO:root:Epoch[0] Batch [100] Speed: 189.20 samples/sec Train-accuracy=0.100402


~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0
INFO:root:Epoch[0] Batch [300] Speed: 81716.01 samples/sec Train-accuracy=0.928594




## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. python train_mnist.py --network mlp 
2. python train_mnist.py --network mlp --gpus 0
3. python train_mnist.py --network mlp --gpus 0,1

## What have you tried to solve it?

1.
2.
3.
"
incubator-mxnet,2657,"thanks.
",0,how to edit and write mxnet model for json file or to converter from code?,"how to edit and write mxnet model for json file or to converter from code? thanks.
"
incubator-mxnet,2539,"Hello,everyone.I am a mxnet and python beginer.So when I use MXnet ,I encounter some errors that confuse me so much.

I wanna use MXnet to do the image's  super resolution.So when I set up the DataIter object,I refer to the data.py in fcn-xs example. Because I use gray images,so I modify some codes. and  set the batch_size=1

Some changed codes as follows:
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def _read_img(self, img_name, label_name):
        img = Image.open(os.path.join(self.root_dir, img_name))
        label = Image.open(os.path.join(self.root_dir, label_name))
        img = np.array(img, dtype=np.float32)  # (h, w, c)
        label = np.array(label)  # (h, w)
        img = img - self.mean
        img = np.expand_dims(img, axis=0)  # (1, c, h, w)
        img = np.expand_dims(img, axis=0)
        label = np.array(label)  # (h, w)
        label = np.expand_dims(label, axis=0)  # (1, h, w)
""''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def next(self):
        """"""return one dict which contains ""data"" and ""label"" """"""
        if self.iter_next():
            self.data, self.label = self._read()
           # return {self.data_name  :  self.data[0][1],
           #         self.label_name :  self.label[0][1]}
           #change the numpy to nd
            mydata=mx.nd.array(self.data[0][1],self.ctx)
            mylabel=mx.nd.array(self.label[0][1],self.ctx)
            return mx.io.DataBatch(data=mydata,label=mylabel)
        else:
            raise StopIteration
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

When I create the Dataiter object ,it it right.But when I  execute the following command ,I get errors below:
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

> > > model=mx.model.FeedForward.create(mynet,X=train_data,num_epoch=10,learning_rate=0.01)
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 901, in create
> > >     eval_batch_end_callback=eval_batch_end_callback)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 784, in fit
> > >     sym_gen=self.sym_gen)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 222, in _train_multi_device
> > >     executor_manager.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 394, in load_data_batch
> > >     self.curr_execgrp.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 245, in load_data_batch
> > >     _load_data(data_batch, self.data_arrays)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 87, in _load_data
> > >     _load_general(batch.data, targets)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 78, in _load_general
> > >     for d_src, d_targets in zip(data, targets):
> > >   File ""/opt/mxnet/python/mxnet/ndarray.py"", line 212, in __getitem__
> > >     raise ValueError('NDArray only support continuous slicing on axis 0')
> > > ValueError: NDArray only support continuous slicing on axis 0
> > > ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

I have no idea about the error.I hope that some expert can give me some advice.Thank you so much
",0,"""ValueError:NDArray only support continous slicing on axis 0"" what it happened","""ValueError:NDArray only support continous slicing on axis 0"" what it happened Hello,everyone.I am a mxnet and python beginer.So when I use MXnet ,I encounter some errors that confuse me so much.

I wanna use MXnet to do the image's  super resolution.So when I set up the DataIter object,I refer to the data.py in fcn-xs example. Because I use gray images,so I modify some codes. and  set the batch_size=1

Some changed codes as follows:
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def _read_img(self, img_name, label_name):
        img = Image.open(os.path.join(self.root_dir, img_name))
        label = Image.open(os.path.join(self.root_dir, label_name))
        img = np.array(img, dtype=np.float32)  # (h, w, c)
        label = np.array(label)  # (h, w)
        img = img - self.mean
        img = np.expand_dims(img, axis=0)  # (1, c, h, w)
        img = np.expand_dims(img, axis=0)
        label = np.array(label)  # (h, w)
        label = np.expand_dims(label, axis=0)  # (1, h, w)
""''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def next(self):
        """"""return one dict which contains ""data"" and ""label"" """"""
        if self.iter_next():
            self.data, self.label = self._read()
           # return {self.data_name  :  self.data[0][1],
           #         self.label_name :  self.label[0][1]}
           #change the numpy to nd
            mydata=mx.nd.array(self.data[0][1],self.ctx)
            mylabel=mx.nd.array(self.label[0][1],self.ctx)
            return mx.io.DataBatch(data=mydata,label=mylabel)
        else:
            raise StopIteration
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

When I create the Dataiter object ,it it right.But when I  execute the following command ,I get errors below:
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

> > > model=mx.model.FeedForward.create(mynet,X=train_data,num_epoch=10,learning_rate=0.01)
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 901, in create
> > >     eval_batch_end_callback=eval_batch_end_callback)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 784, in fit
> > >     sym_gen=self.sym_gen)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 222, in _train_multi_device
> > >     executor_manager.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 394, in load_data_batch
> > >     self.curr_execgrp.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 245, in load_data_batch
> > >     _load_data(data_batch, self.data_arrays)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 87, in _load_data
> > >     _load_general(batch.data, targets)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 78, in _load_general
> > >     for d_src, d_targets in zip(data, targets):
> > >   File ""/opt/mxnet/python/mxnet/ndarray.py"", line 212, in __getitem__
> > >     raise ValueError('NDArray only support continuous slicing on axis 0')
> > > ValueError: NDArray only support continuous slicing on axis 0
> > > ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

I have no idea about the error.I hope that some expert can give me some advice.Thank you so much
"
incubator-mxnet,1563,"I wonder if a  should be added, which joins a list of symbols into a symbol.
This feature is very important if we want to build a complicated end-to-end symbol graph.
",0,A mx.symbol.JoinList is needed?,"A mx.symbol.JoinList is needed? I wonder if a  should be added, which joins a list of symbols into a symbol.
This feature is very important if we want to build a complicated end-to-end symbol graph.
"
incubator-mxnet,11535,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I'm on ubuntu16.04 with GPU and pip, and follows instruction in official documentation web page (https://mxnet.incubator.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU). I follow that instructions, which can install mxnet-cu92 but cannot run example code correctly.

## Environment info (Required)




Package used Python2.7.12

## Build info
I first download and intalled cuda-9.2 and cudnn7.1 from nvidia website.
Then I 

## Error Message:
see next section for full info

## Minimum reproducible example
I use the official website's example code in a interpret envirionment. The code and output is:




## Steps to reproduce
install ubuntu16.04
install cuda9.2
install cudnn7.1
use python 2.7.12
Open terminal and type:


## What have you tried to solve it?
Note that I can build official Caffe with my installed cuda9.2 and cudnn7.1 (https://github.com/BVLC/caffe). It only gives some cudnn warnings  but can complete compilation.",0,installed mxnet-cu92 on ubuntu but can't run example code correctly,"installed mxnet-cu92 on ubuntu but can't run example code correctly Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I'm on ubuntu16.04 with GPU and pip, and follows instruction in official documentation web page (https://mxnet.incubator.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU). I follow that instructions, which can install mxnet-cu92 but cannot run example code correctly.

## Environment info (Required)




Package used Python2.7.12

## Build info
I first download and intalled cuda-9.2 and cudnn7.1 from nvidia website.
Then I 

## Error Message:
see next section for full info

## Minimum reproducible example
I use the official website's example code in a interpret envirionment. The code and output is:




## Steps to reproduce
install ubuntu16.04
install cuda9.2
install cudnn7.1
use python 2.7.12
Open terminal and type:


## What have you tried to solve it?
Note that I can build official Caffe with my installed cuda9.2 and cudnn7.1 (https://github.com/BVLC/caffe). It only gives some cudnn warnings  but can complete compilation."
incubator-mxnet,5250,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-9.4.x
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.9.4
Or if installed from source:
yeap
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23

If you are using python package, please provide
anaconda4.2
Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.


Also, I custom my dataprovider, here , , , my word are padding to 37, so I dont use BucketingModule.

## Steps to reproduce

For above code, when it run into  and run at the line where , it will raise segfault, when I comment it and it works well. My dataIter works well and I test it some times. So I think the error must be related to update_metric... However, the example--lstm_bucketing.py runs well..I dont what I should do .

",0,`mx.metric.Perplexity(-1) ` update_metric raise segement fault,"`mx.metric.Perplexity(-1) ` update_metric raise segement fault For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-9.4.x
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.9.4
Or if installed from source:
yeap
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23

If you are using python package, please provide
anaconda4.2
Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.


Also, I custom my dataprovider, here , , , my word are padding to 37, so I dont use BucketingModule.

## Steps to reproduce

For above code, when it run into  and run at the line where , it will raise segfault, when I comment it and it works well. My dataIter works well and I test it some times. So I think the error must be related to update_metric... However, the example--lstm_bucketing.py runs well..I dont what I should do .

"
incubator-mxnet,8510,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
mnist accuracy differ slightly when training with local gpu and distributed training with GPU but accuracy is the same when training with CPU.

## Environment info (Required)
CentOS 7
MxNet latest master 

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) Python!

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)
train_mnist.py with data shuffle turned off so accuracy of each run is the same.

Compiler (gcc/clang/mingw/visual studio):
gcc 4.9

MXNet commit hash:
(Paste the output of  here.)
8592e1cd3b9f79cff740f29e599ba7788a454c54

Build config:
(Paste the content of config.mk, or the build command.)

USE_DISTRIBUTED_KVSTORE=1
USE_CUDNN=1
USE_CUDA=/usr/local/cuda

## Error Message:
1 server 1 client training with train_mnist.py WITHOUT GPU
INFO:root:Epoch[0] Batch [100]  Speed: 3606.78 samples/sec      accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 3747.11 samples/sec      accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 3982.58 samples/sec      accuracy=0.912656
INFO:root:Epoch[0] Batch [400]  Speed: 3960.68 samples/sec      accuracy=0.928594
INFO:root:Epoch[0] Batch [500]  Speed: 5376.55 samples/sec      accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 4133.33 samples/sec      accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 5935.95 samples/sec      accuracy=0.944688
INFO:root:Epoch[0] Batch [800]  Speed: 3966.74 samples/sec      accuracy=0.940312
INFO:root:Epoch[0] Batch [900]  Speed: 3803.05 samples/sec      accuracy=0.953906
INFO:root:Epoch[0] Train-accuracy=0.966639
INFO:root:Epoch[0] Time cost=14.467
INFO:root:Epoch[0] Validation-accuracy=0.943670

1 server 1 client training with train_mnist.py WITH GPU
INFO:root:Epoch[0] Batch [100]  Speed: 13700.01 samples/sec     accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 27909.23 samples/sec     accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 23719.16 samples/sec     accuracy=0.910781
INFO:root:Epoch[0] Batch [400]  Speed: 30796.60 samples/sec     accuracy=0.925312
INFO:root:Epoch[0] Batch [500]  Speed: 26746.35 samples/sec     accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 29120.16 samples/sec     accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 30805.82 samples/sec     accuracy=0.944531
INFO:root:Epoch[0] Batch [800]  Speed: 22852.49 samples/sec     accuracy=0.937813
INFO:root:Epoch[0] Batch [900]  Speed: 28238.62 samples/sec     accuracy=0.952031
INFO:root:Epoch[0] Train-accuracy=0.969172
INFO:root:Epoch[0] Time cost=2.452
INFO:root:Epoch[0] Validation-accuracy=0.936505

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

(pgrep python | xargs kill -9 && rm ~/train/profile.json) &>/dev/null
(pgrep memcheck-amd64- | xargs kill -9) &> /dev/null
export DMLC_PS_ROOT_PORT=9091;
export DMLC_NUM_WORKER=1;
export DMLC_NUM_SERVER=1;
export DMLC_PS_ROOT_URI=127.0.0.1;
export DMLC_ROLE=scheduler;
python train_mnist.py &

export DMLC_ROLE=server; 
export DMLC_SERVER_ID=0
python train_mnist.py --kv-store dist_sync --gpus 0 &

export DMLC_ROLE=worker; 
export DMLC_WORKER_ID=0
python train_mnist.py --kv-store dist_sync --num-epochs 1 --gpus 0&

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the example and toggle --gpus 0
2. Observe accuracy differences.

## What have you tried to solve it?

1. The problem seems to be the initialization of params in GPU.
2. The first divergence of these two training is the first gradient sent out after the first batch.
",0,Minor differences in distributed training with GPU/without GPU.,"Minor differences in distributed training with GPU/without GPU. Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
mnist accuracy differ slightly when training with local gpu and distributed training with GPU but accuracy is the same when training with CPU.

## Environment info (Required)
CentOS 7
MxNet latest master 

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) Python!

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)
train_mnist.py with data shuffle turned off so accuracy of each run is the same.

Compiler (gcc/clang/mingw/visual studio):
gcc 4.9

MXNet commit hash:
(Paste the output of  here.)
8592e1cd3b9f79cff740f29e599ba7788a454c54

Build config:
(Paste the content of config.mk, or the build command.)

USE_DISTRIBUTED_KVSTORE=1
USE_CUDNN=1
USE_CUDA=/usr/local/cuda

## Error Message:
1 server 1 client training with train_mnist.py WITHOUT GPU
INFO:root:Epoch[0] Batch [100]  Speed: 3606.78 samples/sec      accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 3747.11 samples/sec      accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 3982.58 samples/sec      accuracy=0.912656
INFO:root:Epoch[0] Batch [400]  Speed: 3960.68 samples/sec      accuracy=0.928594
INFO:root:Epoch[0] Batch [500]  Speed: 5376.55 samples/sec      accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 4133.33 samples/sec      accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 5935.95 samples/sec      accuracy=0.944688
INFO:root:Epoch[0] Batch [800]  Speed: 3966.74 samples/sec      accuracy=0.940312
INFO:root:Epoch[0] Batch [900]  Speed: 3803.05 samples/sec      accuracy=0.953906
INFO:root:Epoch[0] Train-accuracy=0.966639
INFO:root:Epoch[0] Time cost=14.467
INFO:root:Epoch[0] Validation-accuracy=0.943670

1 server 1 client training with train_mnist.py WITH GPU
INFO:root:Epoch[0] Batch [100]  Speed: 13700.01 samples/sec     accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 27909.23 samples/sec     accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 23719.16 samples/sec     accuracy=0.910781
INFO:root:Epoch[0] Batch [400]  Speed: 30796.60 samples/sec     accuracy=0.925312
INFO:root:Epoch[0] Batch [500]  Speed: 26746.35 samples/sec     accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 29120.16 samples/sec     accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 30805.82 samples/sec     accuracy=0.944531
INFO:root:Epoch[0] Batch [800]  Speed: 22852.49 samples/sec     accuracy=0.937813
INFO:root:Epoch[0] Batch [900]  Speed: 28238.62 samples/sec     accuracy=0.952031
INFO:root:Epoch[0] Train-accuracy=0.969172
INFO:root:Epoch[0] Time cost=2.452
INFO:root:Epoch[0] Validation-accuracy=0.936505

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

(pgrep python | xargs kill -9 && rm ~/train/profile.json) &>/dev/null
(pgrep memcheck-amd64- | xargs kill -9) &> /dev/null
export DMLC_PS_ROOT_PORT=9091;
export DMLC_NUM_WORKER=1;
export DMLC_NUM_SERVER=1;
export DMLC_PS_ROOT_URI=127.0.0.1;
export DMLC_ROLE=scheduler;
python train_mnist.py &

export DMLC_ROLE=server; 
export DMLC_SERVER_ID=0
python train_mnist.py --kv-store dist_sync --gpus 0 &

export DMLC_ROLE=worker; 
export DMLC_WORKER_ID=0
python train_mnist.py --kv-store dist_sync --num-epochs 1 --gpus 0&

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the example and toggle --gpus 0
2. Observe accuracy differences.

## What have you tried to solve it?

1. The problem seems to be the initialization of params in GPU.
2. The first divergence of these two training is the first gradient sent out after the first batch.
"
incubator-mxnet,9745,"Error caused by eval_data.pad not found:
https://github.com/apache/incubator-mxnet/blob/8205e24d99b95cc2971006f3453a7e7addac7ffe/python/mxnet/module/base_module.py#L295

These templates need to change:
https://mxnet.incubator.apache.org/api/python/io.html#develop-a-new-iterator

I am not quite sure if this example is simple'', but it also needs to include pad in return:
https://mxnet.incubator.apache.org/tutorials/basic/data.html#custom-iterator

Thanks,
Yifei",0,MultiIter example should also return pad in next(self),"MultiIter example should also return pad in next(self) Error caused by eval_data.pad not found:
https://github.com/apache/incubator-mxnet/blob/8205e24d99b95cc2971006f3453a7e7addac7ffe/python/mxnet/module/base_module.py#L295

These templates need to change:
https://mxnet.incubator.apache.org/api/python/io.html#develop-a-new-iterator

I am not quite sure if this example is simple'', but it also needs to include pad in return:
https://mxnet.incubator.apache.org/tutorials/basic/data.html#custom-iterator

Thanks,
Yifei"
incubator-mxnet,66,"NaiveEngine works well
",0,ThreadEngine is buggy with CuDNN,"ThreadEngine is buggy with CuDNN NaiveEngine works well
"
incubator-mxnet,11108,"https://github.com/apache/incubator-mxnet/blob/2dbd143e4892bb9ad4aa1835c79f0046603e3531/Makefile#L221

Refer to the mxnet Makefile above, the search paths for gperftools-devel and jemalloc-devel are under //.
But gperftools-devel and jemalloc-devel package installed via yum will place the dynamic library files into ****

TL,DR;
As the title said.",0,Seems the gperftools-devel and jemalloc-devel wouldn't be detected correctly on rhel(Redhat Enterprise Linux),"Seems the gperftools-devel and jemalloc-devel wouldn't be detected correctly on rhel(Redhat Enterprise Linux) https://github.com/apache/incubator-mxnet/blob/2dbd143e4892bb9ad4aa1835c79f0046603e3531/Makefile#L221

Refer to the mxnet Makefile above, the search paths for gperftools-devel and jemalloc-devel are under //.
But gperftools-devel and jemalloc-devel package installed via yum will place the dynamic library files into ****

TL,DR;
As the title said."
incubator-mxnet,1253,"Hi,

When I change the optimizer to Adam. For example,



I get the following error message:



Isn't this the correct way of setting the optimizer?
",0,Running Adam optimizer error,"Running Adam optimizer error Hi,

When I change the optimizer to Adam. For example,



I get the following error message:



Isn't this the correct way of setting the optimizer?
"
incubator-mxnet,4301,Does mxnet still not support 3D convolution？？,0,"When I use the 'mx.symbol.Convolution' with 3d kernel,  I get the problem""Volume convolution is not implmented in mshadow"" .","When I use the 'mx.symbol.Convolution' with 3d kernel,  I get the problem""Volume convolution is not implmented in mshadow"" . Does mxnet still not support 3D convolution？？"
incubator-mxnet,16495,"Probably related to git filters when adding the files.
https://stackoverflow.com/questions/8006393/force-add-despite-the-gitignore-file



",0,docs for gluon.data.* are missing,"docs for gluon.data.* are missing Probably related to git filters when adding the files.
https://stackoverflow.com/questions/8006393/force-add-despite-the-gitignore-file



"
incubator-mxnet,5233,"Although mxnet documentation did mention that it is possible to Use C++/mshadow and CUDA to create custom operations, it has no real examples of how to used a custom CUDA kernel (taking gpu pointers) as part of a custom operation. Can anyone provide a simple example of this flow?",0,How to create a custom GPU operation with custom CUDA kernels for computation,"How to create a custom GPU operation with custom CUDA kernels for computation Although mxnet documentation did mention that it is possible to Use C++/mshadow and CUDA to create custom operations, it has no real examples of how to used a custom CUDA kernel (taking gpu pointers) as part of a custom operation. Can anyone provide a simple example of this flow?"
incubator-mxnet,12526,"## Description
Our mnist smokescreen tests are breaking in the latest build (mxnet-1.3.0b20180911) as a result of this PR (#12285) with an index out of range error.

## Environment info (Required)

Breaks on both Linux and OSX. Build mxnet-1.3.0b20180909 is fine, 1.3.0b20180911 is faulty.",0,#12285 Breaks NDArrayIter For 3D Arrays,"#12285 Breaks NDArrayIter For 3D Arrays ## Description
Our mnist smokescreen tests are breaking in the latest build (mxnet-1.3.0b20180911) as a result of this PR (#12285) with an index out of range error.

## Environment info (Required)

Breaks on both Linux and OSX. Build mxnet-1.3.0b20180909 is fine, 1.3.0b20180911 is faulty."
incubator-mxnet,5243,"Hello,

I am trying to compile the newest MxNet in Windows, by using Visual Studio. I am constantly getting that error and can't fix it. The cub directory is included in the MxNet source and the CMake seems to have it added in the Additional Include Directories line in the project properties, under C/C++. The line which creates problem is in the sort_op-inl.cuh file:

    /*!
     *  Copyright (c) 2017 by Contributors
     * \file sort_op-inl.cuh
     * \brief CUDA implementations for sort_op.h
     */
     #ifndef MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #define MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #include <thrust/device_ptr.h>
     #include <thrust/sort.h>
     #include <cub/device/device_radix_sort.cuh>
     #if CUDA_VERSION >= 7000
     #include <thrust/system/cuda/execution_policy.h>
     #endif


The line   generates the error. I double checked both the cub folder and the device_radix_sort.cuh file; both do exist and under the appropriate location pointed by the entry in Additional Include Directories.

What else may cause that error? The file being included has the .cuh extension, which belongs to a CUDA kernel for example, can this cause a problem with the Visual Studio while trying to include?

Thanks in advance",0,error C1083: Cannot open include file: 'cub/device/device_radix_sort.cuh': No such file or directory,"error C1083: Cannot open include file: 'cub/device/device_radix_sort.cuh': No such file or directory Hello,

I am trying to compile the newest MxNet in Windows, by using Visual Studio. I am constantly getting that error and can't fix it. The cub directory is included in the MxNet source and the CMake seems to have it added in the Additional Include Directories line in the project properties, under C/C++. The line which creates problem is in the sort_op-inl.cuh file:

    /*!
     *  Copyright (c) 2017 by Contributors
     * \file sort_op-inl.cuh
     * \brief CUDA implementations for sort_op.h
     */
     #ifndef MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #define MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #include <thrust/device_ptr.h>
     #include <thrust/sort.h>
     #include <cub/device/device_radix_sort.cuh>
     #if CUDA_VERSION >= 7000
     #include <thrust/system/cuda/execution_policy.h>
     #endif


The line   generates the error. I double checked both the cub folder and the device_radix_sort.cuh file; both do exist and under the appropriate location pointed by the entry in Additional Include Directories.

What else may cause that error? The file being included has the .cuh extension, which belongs to a CUDA kernel for example, can this cause a problem with the Visual Studio while trying to include?

Thanks in advance"
incubator-mxnet,9131,"The code  crashes with 


caused by



Experienced with mxnet 1.0.0 on macOS Sierra and python 3.6.3",0,random_uniform causes VM to crash,"random_uniform causes VM to crash The code  crashes with 


caused by



Experienced with mxnet 1.0.0 on macOS Sierra and python 3.6.3"
incubator-mxnet,2883,"I notice that some experiments should use the mean_img file and set the path of the mean_img in the iterator.But I can't find a tool in the mxnet that generate the mean file.
Can someone tell me how to do it ?
",0,How to generate the mean file of a dataset used in the iterator.,"How to generate the mean file of a dataset used in the iterator. I notice that some experiments should use the mean_img file and set the path of the mean_img in the iterator.But I can't find a tool in the mxnet that generate the mean file.
Can someone tell me how to do it ?
"
incubator-mxnet,14280,"## Description
Compiling from source code occurred ***link libzmq*** error.
## Environment info (Required)


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash:
7c617ccc7a8655f3b93acdfac8aeee20eee2a778

Build config:
In CMakeLists.txt, I set:

and build files with 

## Error Message:
std::_Sp_counted_deleter<char*, ps::ZMQVan::RecvMsg(ps::Message*)::{lambda(char*)#1}, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()':
van.cc:(.text._ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv[_ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv]+0x9): undefined reference to ps::ZMQVan::Stop()':
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0xe5): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x2c2): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x55d): undefined reference to ps::ZMQVan::Bind(ps::Node const&, int)':
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3a): undefined reference to zmq_bind'
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3e7): undefined reference to ps::ZMQVan::Connect(ps::Node const&)':
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x20d): undefined reference to zmq_setsockopt'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x423): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x5c5): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x11d): undefined reference to zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x15e): undefined reference to zmq_ctx_set'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x267): undefined reference to zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x348): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0xf6): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x116): undefined reference to zmq_msg_size'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x217): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x300): undefined reference to zmq_msg_more'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3d0): undefined reference to zmq_msg_close'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3ff): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x56a): undefined reference to 

## Steps to reproduce

1. mkdir cmake_build && cd cmake_build
2. cmake -DBLAS=open -DUSE_OPENCV=1 -GNinja ..
3. ninja -v

## What have you tried to solve it?

1. Use Makefile to install mxnet, but failed with the above error, either.

## Alternative information
1. opencv version: 4.0.1
",0,Compiling from source code error,"Compiling from source code error ## Description
Compiling from source code occurred ***link libzmq*** error.
## Environment info (Required)


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash:
7c617ccc7a8655f3b93acdfac8aeee20eee2a778

Build config:
In CMakeLists.txt, I set:

and build files with 

## Error Message:
std::_Sp_counted_deleter<char*, ps::ZMQVan::RecvMsg(ps::Message*)::{lambda(char*)#1}, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()':
van.cc:(.text._ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv[_ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv]+0x9): undefined reference to ps::ZMQVan::Stop()':
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0xe5): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x2c2): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x55d): undefined reference to ps::ZMQVan::Bind(ps::Node const&, int)':
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3a): undefined reference to zmq_bind'
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3e7): undefined reference to ps::ZMQVan::Connect(ps::Node const&)':
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x20d): undefined reference to zmq_setsockopt'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x423): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x5c5): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x11d): undefined reference to zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x15e): undefined reference to zmq_ctx_set'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x267): undefined reference to zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x348): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0xf6): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x116): undefined reference to zmq_msg_size'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x217): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x300): undefined reference to zmq_msg_more'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3d0): undefined reference to zmq_msg_close'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3ff): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x56a): undefined reference to 

## Steps to reproduce

1. mkdir cmake_build && cd cmake_build
2. cmake -DBLAS=open -DUSE_OPENCV=1 -GNinja ..
3. ninja -v

## What have you tried to solve it?

1. Use Makefile to install mxnet, but failed with the above error, either.

## Alternative information
1. opencv version: 4.0.1
"
incubator-mxnet,5275,"I've noticed that in mxnet.symbol we have defined:
* mxnet.symbol.tanh
* mnet.symbol.LeakyReLU
However, we don't have mxnet.symbol.ReLU or mxnet.symbol.sigmoid defined. These functions are defined but only within the 

I think this is bad for a couple reasons:
* This appears disorganized. Like functions should be grouped in like folders.
* This makes our library overly married to neural network notation. We could imagine other times when someone might want to access the sigmoid or hinge functions but wouldn't think of them as activation functions.

I think both ReLU (better to spell ""relu"") and sigmoid should both be available in mxnet.symbol



For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
",0,Why no mxnet.symbol.relu (or sigmoid)?,"Why no mxnet.symbol.relu (or sigmoid)? I've noticed that in mxnet.symbol we have defined:
* mxnet.symbol.tanh
* mnet.symbol.LeakyReLU
However, we don't have mxnet.symbol.ReLU or mxnet.symbol.sigmoid defined. These functions are defined but only within the 

I think this is bad for a couple reasons:
* This appears disorganized. Like functions should be grouped in like folders.
* This makes our library overly married to neural network notation. We could imagine other times when someone might want to access the sigmoid or hinge functions but wouldn't think of them as activation functions.

I think both ReLU (better to spell ""relu"") and sigmoid should both be available in mxnet.symbol



For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
"
incubator-mxnet,12923,"**We have been troubled by the problem for a few days, so we need everyone's help, thank you!**

**Environment**：
GPU: Tesla P4; CPU: Intel(R) Xeon(R) Gold 6133 CPU @ 2.50GHz.

**Appearance**：
The program receives the Image data as a server. After a period of time, the program starts to appear similar to Deadlock (may be caused by some requests, but cannot be accurately reproduced)

We tested on mxnet versions 1.0, 1.2, and 1.3, and the program showed the same appearance.

**Program running process**：
We called the python engine in a C++ multithreaded program that uses the mxnet-python api. As can be seen from the stack information, MXNDArraySyncCopyToCPU() waits for a condition variable during execution, and the program will always be stuck in this place.

**Stack information**：
Thread 85 (Thread 0x7f3cba52f700 (LWP 41394)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb86d5 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bd94b4d in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3c7be7e9c3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#6  0x00007f3c7bc516db in MXNDArraySyncCopyToCPU () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#7  0x00007f3d53e15adc in ffi_call_unix64 () from my_app/libs/./libffi.so.6
#8  0x00007f3d53e15282 in ffi_call () from my_app/libs/./libffi.so.6
#9  0x00007f3bfdd09376 in _call_function_pointer (argcount=3, resmem=0x7f3b3c1c4040, restype=<optimized out>, atypes=<optimized out>, avalues=0x7f3b3c1c4010, pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, flags=4353) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:841
#10 _ctypes_callproc (pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, argtuple=0x7f3b3c1c4130, flags=4353, argtypes=<optimized out>, restype=0x1616b80, checker=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:1184
#11 0x00007f3bfdd00db3 in PyCFuncPtr_call (self=<optimized out>, inargs=<optimized out>, kwds=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/_ctypes.c:3979
#12 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a11a050, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#13 0x00007f3d52cf580d in do_call (nk=<optimized out>, na=<optimized out>, pp_stack=0x7f3b3c1c43b8, func=0x7f3d2a11a050) at Python/ceval.c:4569
#14 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c43b8) at Python/ceval.c:4374
#15 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#16 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d3f730030, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x7f3d2a186fd0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#17 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=1, n=<optimized out>, pp_stack=0x7f3b3c1c45d8, func=0x7f3d3f6ee5f0) at Python/ceval.c:4447
#18 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c45d8) at Python/ceval.c:4372
#19 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#20 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4748, func=0x7f3d2aea9c80) at Python/ceval.c:4437
#21 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4748) at Python/ceval.c:4372
#22 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#23 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d528fcc30, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=2, kws=0x7f3d2a18dc68, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#24 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=2, n=<optimized out>, pp_stack=0x7f3b3c1c4968, func=0x7f3d2a33f0c8) at Python/ceval.c:4447
#25 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4968) at Python/ceval.c:4372
#26 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#27 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4ad8, func=0x7f3d2a33f410) at Python/ceval.c:4437
#28 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4ad8) at Python/ceval.c:4372
#29 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#30 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d52963db0, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#31 0x00007f3d52c72a61 in function_call (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=0x0) at Objects/funcobject.c:523
#32 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a33f8c0, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#33 0x00007f3d52ced7b3 in PyEval_CallObjectWithKeywords (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=<optimized out>) at Python/ceval.c:4221
#34 0x00007f3d52d13468 in PyEval_CallMethod (obj=<optimized out>, methodname=<optimized out>, format=<optimized out>) at Python/modsupport.c:612
#35 0x00007f3d5303141f in ?? ()
#36 0x0000000000000000 in ?? ()




----------------------------------------------------------------------------------------------------


**In addition**:
there are occasions when other threads are blocked at the same time, such as the stack information below, which is the stack information of an unrelated CPU thread. The strange thing is that there is actually libmxnet.so:

Thread 70 (Thread 0x7f3b0bff6700 (LWP 41409)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb88a3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bcc0339 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3d577c4702 in fork () from /lib64/libc.so.6
......",0,Deadlock happend while calling MXNDArraySyncCopyToCPU() ?,"Deadlock happend while calling MXNDArraySyncCopyToCPU() ? **We have been troubled by the problem for a few days, so we need everyone's help, thank you!**

**Environment**：
GPU: Tesla P4; CPU: Intel(R) Xeon(R) Gold 6133 CPU @ 2.50GHz.

**Appearance**：
The program receives the Image data as a server. After a period of time, the program starts to appear similar to Deadlock (may be caused by some requests, but cannot be accurately reproduced)

We tested on mxnet versions 1.0, 1.2, and 1.3, and the program showed the same appearance.

**Program running process**：
We called the python engine in a C++ multithreaded program that uses the mxnet-python api. As can be seen from the stack information, MXNDArraySyncCopyToCPU() waits for a condition variable during execution, and the program will always be stuck in this place.

**Stack information**：
Thread 85 (Thread 0x7f3cba52f700 (LWP 41394)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb86d5 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bd94b4d in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3c7be7e9c3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#6  0x00007f3c7bc516db in MXNDArraySyncCopyToCPU () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#7  0x00007f3d53e15adc in ffi_call_unix64 () from my_app/libs/./libffi.so.6
#8  0x00007f3d53e15282 in ffi_call () from my_app/libs/./libffi.so.6
#9  0x00007f3bfdd09376 in _call_function_pointer (argcount=3, resmem=0x7f3b3c1c4040, restype=<optimized out>, atypes=<optimized out>, avalues=0x7f3b3c1c4010, pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, flags=4353) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:841
#10 _ctypes_callproc (pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, argtuple=0x7f3b3c1c4130, flags=4353, argtypes=<optimized out>, restype=0x1616b80, checker=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:1184
#11 0x00007f3bfdd00db3 in PyCFuncPtr_call (self=<optimized out>, inargs=<optimized out>, kwds=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/_ctypes.c:3979
#12 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a11a050, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#13 0x00007f3d52cf580d in do_call (nk=<optimized out>, na=<optimized out>, pp_stack=0x7f3b3c1c43b8, func=0x7f3d2a11a050) at Python/ceval.c:4569
#14 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c43b8) at Python/ceval.c:4374
#15 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#16 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d3f730030, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x7f3d2a186fd0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#17 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=1, n=<optimized out>, pp_stack=0x7f3b3c1c45d8, func=0x7f3d3f6ee5f0) at Python/ceval.c:4447
#18 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c45d8) at Python/ceval.c:4372
#19 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#20 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4748, func=0x7f3d2aea9c80) at Python/ceval.c:4437
#21 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4748) at Python/ceval.c:4372
#22 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#23 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d528fcc30, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=2, kws=0x7f3d2a18dc68, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#24 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=2, n=<optimized out>, pp_stack=0x7f3b3c1c4968, func=0x7f3d2a33f0c8) at Python/ceval.c:4447
#25 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4968) at Python/ceval.c:4372
#26 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#27 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4ad8, func=0x7f3d2a33f410) at Python/ceval.c:4437
#28 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4ad8) at Python/ceval.c:4372
#29 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#30 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d52963db0, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#31 0x00007f3d52c72a61 in function_call (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=0x0) at Objects/funcobject.c:523
#32 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a33f8c0, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#33 0x00007f3d52ced7b3 in PyEval_CallObjectWithKeywords (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=<optimized out>) at Python/ceval.c:4221
#34 0x00007f3d52d13468 in PyEval_CallMethod (obj=<optimized out>, methodname=<optimized out>, format=<optimized out>) at Python/modsupport.c:612
#35 0x00007f3d5303141f in ?? ()
#36 0x0000000000000000 in ?? ()




----------------------------------------------------------------------------------------------------


**In addition**:
there are occasions when other threads are blocked at the same time, such as the stack information below, which is the stack information of an unrelated CPU thread. The strange thing is that there is actually libmxnet.so:

Thread 70 (Thread 0x7f3b0bff6700 (LWP 41409)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb88a3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bcc0339 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3d577c4702 in fork () from /lib64/libc.so.6
......"
incubator-mxnet,6814,"I read the page: http://mxnet-tqchen.readthedocs.io/en/latest/system/multi_node.html  
But i can not find the AlexNet on imagenet example.
Can anyone give some help here?  


> local_allreduce_cpu is similar to local_update_cpu except that the averaged gradients are copied back to the devices, and then weights are updated on devices. It is faster than 1 when the weight size is large so we can use the device to accelerate the computation (but we increase the workload by k times). Examples are AlexNet on imagenet.  

",0,Can not find the link to 'local_allreduce_cpu'  example according to the mxnet doc,"Can not find the link to 'local_allreduce_cpu'  example according to the mxnet doc I read the page: http://mxnet-tqchen.readthedocs.io/en/latest/system/multi_node.html  
But i can not find the AlexNet on imagenet example.
Can anyone give some help here?  


> local_allreduce_cpu is similar to local_update_cpu except that the averaged gradients are copied back to the devices, and then weights are updated on devices. It is faster than 1 when the weight size is large so we can use the device to accelerate the computation (but we increase the workload by k times). Examples are AlexNet on imagenet.  

"
incubator-mxnet,13374,"Outputs of diagnose.py:
floatnp.floatingnp.float64 == np.dtype(float).typefloatnp.floatingnp.float64 == np.dtype(float).type",0,"[Bug] ValueError: There are multiple outputs with name ""resnetv1b0_layers1_relu0_fwd_output"".","[Bug] ValueError: There are multiple outputs with name ""resnetv1b0_layers1_relu0_fwd_output"". Outputs of diagnose.py:
floatnp.floatingnp.float64 == np.dtype(float).typefloatnp.floatingnp.float64 == np.dtype(float).type"
incubator-mxnet,9198,"## Description
https://mxnet.incubator.apache.org/architecture/release_note_0_9.html?highlight=cython#image-io
> mx.image provides a set of fast image processing API that leverage MXNet Engine to automatically parallelize processing. You can write  and decoding will be automatically run in parallel.

**i tried parallel decoding using mxnet.image.imdecode() function. but it's not working.**

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): 

MXNet commit hash: 
(Paste the output of  here.)

Build config:





## Steps to reproduce





## What have you tried to solve it?

1. build from latest sources

",0,parallel decoding (mxnet.image.imdecode) is not working,"parallel decoding (mxnet.image.imdecode) is not working ## Description
https://mxnet.incubator.apache.org/architecture/release_note_0_9.html?highlight=cython#image-io
> mx.image provides a set of fast image processing API that leverage MXNet Engine to automatically parallelize processing. You can write  and decoding will be automatically run in parallel.

**i tried parallel decoding using mxnet.image.imdecode() function. but it's not working.**

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): 

MXNet commit hash: 
(Paste the output of  here.)

Build config:





## Steps to reproduce





## What have you tried to solve it?

1. build from latest sources

"
incubator-mxnet,1875,"i am new, i got this error here

07:33:45 INFO:Start training with [gpu(0)]
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
Traceback (most recent call last):
  File ""char-rnn.py"", line 120, in <module>
    epoch_end_callback=mx.callback.do_checkpoint(""obama""))
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 774, in fit
    sym_gen=self.sym_gen)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 244, in _train_multi_device
    executor_manager.update_metric(eval_metric, data_batch.label)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 406, in update_metric
    self.curr_execgrp.update_metric(metric, labels)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 262, in update_metric
    metric.update(labels_slice, texec.outputs)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 338, in update
    self.sum_metric += self._feval(label, pred)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 355, in feval
    return numpy_feval(label, pred)
  File ""char-rnn.py"", line 50, in Perplexity
    loss += -np.log(max(1e-10, pred[i][int(label[i])]))
TypeError: only length-1 arrays can be converted to Python scalars
",0,run example/rnn/char-rnn.ipynb failed,"run example/rnn/char-rnn.ipynb failed i am new, i got this error here

07:33:45 INFO:Start training with [gpu(0)]
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
Traceback (most recent call last):
  File ""char-rnn.py"", line 120, in <module>
    epoch_end_callback=mx.callback.do_checkpoint(""obama""))
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 774, in fit
    sym_gen=self.sym_gen)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 244, in _train_multi_device
    executor_manager.update_metric(eval_metric, data_batch.label)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 406, in update_metric
    self.curr_execgrp.update_metric(metric, labels)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 262, in update_metric
    metric.update(labels_slice, texec.outputs)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 338, in update
    self.sum_metric += self._feval(label, pred)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 355, in feval
    return numpy_feval(label, pred)
  File ""char-rnn.py"", line 50, in Perplexity
    loss += -np.log(max(1e-10, pred[i][int(label[i])]))
TypeError: only length-1 arrays can be converted to Python scalars
"
incubator-mxnet,11407,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11358/9/pipeline

",0,Corrupt image fails Caffe converter test,"Corrupt image fails Caffe converter test http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11358/9/pipeline

"
incubator-mxnet,6628,"Hi folks. 😄 

Now, I'm trying to run [image-classification-predict.cc](https://github.com/dmlc/mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) as a sample code of image classification with using pre-trained model.

I'm facing an error at the point of creating a predictor like,



The error I got is like,


If any of you know how to solve and run this code, please help me out.

Thanks in advance! 🎉 

## Environment info
Operating System: OS X 10.12.4

Compiler: AppleClang

Package used (Python/R/Scala/Julia): C++

MXNet commit hash (): 918d48526481cf424197079ae47841e1b8afe399

## Error Message:
The whole error message is as below.



## Minimum reproducible example
I only modified the name of the model files and their paths.
I use the models downloaded from [here](https://pan.baidu.com/s/1sjXKrqX).
And the image I used was a size of 240 x 240.
![apple](https://user-images.githubusercontent.com/19764434/26961671-85bf35de-4d1b-11e7-9c48-f25434ff8638.jpg)


Since this is running at my own local project, I wrote a  like this.



## Steps to reproduce
I tried to run this program with the command of  and received that error.
",0,[C++][Tutorial Error] Model file for image-classification-predict.cc seems like broken,"[C++][Tutorial Error] Model file for image-classification-predict.cc seems like broken Hi folks. 😄 

Now, I'm trying to run [image-classification-predict.cc](https://github.com/dmlc/mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) as a sample code of image classification with using pre-trained model.

I'm facing an error at the point of creating a predictor like,



The error I got is like,


If any of you know how to solve and run this code, please help me out.

Thanks in advance! 🎉 

## Environment info
Operating System: OS X 10.12.4

Compiler: AppleClang

Package used (Python/R/Scala/Julia): C++

MXNet commit hash (): 918d48526481cf424197079ae47841e1b8afe399

## Error Message:
The whole error message is as below.



## Minimum reproducible example
I only modified the name of the model files and their paths.
I use the models downloaded from [here](https://pan.baidu.com/s/1sjXKrqX).
And the image I used was a size of 240 x 240.
![apple](https://user-images.githubusercontent.com/19764434/26961671-85bf35de-4d1b-11e7-9c48-f25434ff8638.jpg)


Since this is running at my own local project, I wrote a  like this.



## Steps to reproduce
I tried to run this program with the command of  and received that error.
"
incubator-mxnet,3668,"I've been using MXNET for a while and get used to the interface mxnet.model.FeedForward, which has a method save_checkpoint(). This method returns a JSON file of symbol definition and .params for saving args and aux params. But with the new API mxnet.module I can't figure out how to get/save the symbol easily in this module, and it makes more complex to use or finetune on models based on this interface, since loading a model requires a JSON file for symbol definition.

In  there's a property  which allows us to get the symbol in module. But in other inherit classes like  and , we can comprise/stack modules to build more complex networks. This makes harder to access the whole symbol in these modules, even though we can get symbols of each submodules in recursive way and concat them, but this is still not straightforward for me.",0,Difficult to get/save symbols in new API mxnet.module,"Difficult to get/save symbols in new API mxnet.module I've been using MXNET for a while and get used to the interface mxnet.model.FeedForward, which has a method save_checkpoint(). This method returns a JSON file of symbol definition and .params for saving args and aux params. But with the new API mxnet.module I can't figure out how to get/save the symbol easily in this module, and it makes more complex to use or finetune on models based on this interface, since loading a model requires a JSON file for symbol definition.

In  there's a property  which allows us to get the symbol in module. But in other inherit classes like  and , we can comprise/stack modules to build more complex networks. This makes harder to access the whole symbol in these modules, even though we can get symbols of each submodules in recursive way and concat them, but this is still not straightforward for me."
